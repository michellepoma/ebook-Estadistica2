{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Cr\u00e9ditos del Ebook</p> <p>T\u00edtulo: \"Estad\u00edstica II con Python: Teor\u00eda, Pr\u00e1ctica y Visualizaci\u00f3n\"</p> <p>Autores: Este ebook fue desarrollado por estudiantes de la materia de Estad\u00edstica II, paralelo A, Gesti\u00f3n II/2023. La contribuci\u00f3n de cada estudiante ha sido fundamental para abordar los temas anal\u00edticos y aplicaciones pr\u00e1cticas incluidas en este recurso.</p> <p>Coordinador del Proyecto: Lic. Mario Am\u00edlcar Miranda Gonzales</p> <p>Agradecimientos: Queremos expresar nuestro profundo agradecimiento al Lic. Mario Am\u00edlcar Miranda Gonzales por su orientaci\u00f3n y apoyo constante durante la creaci\u00f3n de este ebook. Su dedicaci\u00f3n y pasi\u00f3n por la estad\u00edstica han sido una fuente de inspiraci\u00f3n para todos nosotros.</p> <p>Paralelo y Gesti\u00f3n: Paralelo A, Gesti\u00f3n II/2023</p> <p>Instituci\u00f3n: UNIVERSIDAD MAYOR DE SAN ANDRES</p> <p>Este ebook es el resultado del arduo trabajo y colaboraci\u00f3n de los estudiantes de la materia de Estad\u00edstica II. Esperamos que este recurso sea de utilidad para futuras generaciones de estudiantes y contribuya al aprendizaje continuo en el fascinante campo de la estad\u00edstica.</p> <p>\u00a1Gracias a todos los que hicieron posible este proyecto!</p>"},{"location":"","title":"\u00b6","text":""},{"location":"capitulo0/","title":"Capitulo0","text":"<p>Desarrollo del capitulo...Es un hecho establecido hace demasiado tiempo que un lector se distraer\u00e1 con el contenido del texto de un sitio mientras que mira su dise\u00f1o. El punto de usar Lorem Ipsum es que tiene una distribuci\u00f3n m\u00e1s o menos normal de las letras, al contrario de usar textos como por ejemplo \"Contenido aqu\u00ed, contenido aqu\u00ed\". $$ \\sqrt{3x-1}+(1+x)^2 $$ \"Lorem Ipsum\" va a dar por resultado muchos sitios web que usan este texto si se encuentran en estado de desarrollo. Muchas versiones han evolucionado a trav\u00e9s de los a\u00f1os, algunas veces por accidente, otras veces a prop\u00f3sito (por ejemplo insert\u00e1ndole humor y cosas por el estilo).</p> T\u00edtulo de la f\u00f3rmula                  $$ SSE = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 $$              (0.0) T\u00edtulo de la f\u00f3rmula                  $$ SSE = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 $$              (0.0)          Donde:  <ul> <li>$ SSE $ es la suma de cuadrados debida al error.</li> <li>$ n $ es el n\u00famero de observaciones.</li> <li>$ y_i $ son los valores observados.</li> <li>$ \\hat{y_i}\\ $ son los valores predichos por el modelo.</li></ul> <p>Tabla 3.15  Titulo de la Tabla</p> Restaurante $i$ $x_i$ = Poblaci\u00f3n de estudiantes (miles) Columna 3 $\\sigma $ 1 1 2 6 1 10 7 1 8 9 1 <p> Figura 3.15 Titulo del gr\u00e1fico </p> In\u00a0[21]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.stats import linregress\n\n# Definir los datos\nx = np.array([1, 2, 3, 4, 5])\ny = 60 + 5 * x\n\n# Realizar la regresi\u00f3n lineal\nslope, intercept, r_value, p_value, std_err = linregress(x, y)\n\n# Crear la figura y los ejes\nfig, ax = plt.subplots()\n\n# Graficar los datos\nax.scatter(x, y, color=\"#009929\", label=\"Datos\")\n\n# Graficar la recta de regresi\u00f3n\nax.plot(x, intercept + slope * x, color=\"#98F84A\", label=f\"Recta de regresi\u00f3n (y = {intercept:.2f} + {slope:.2f}x)\")\n\n# Cambiar el color del fondo\nax.set_facecolor(\"#D4F8B7\")\n\n# Pintar el fondo externo del gr\u00e1fico\nfig.patch.set_facecolor('#D4F8B7')\n\n# Colocar el t\u00edtulo\nax.set_title(\"Gr\u00e1fico de regresi\u00f3n lineal\")\n\n# Agregar leyenda\nax.legend()\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np from scipy.stats import linregress  # Definir los datos x = np.array([1, 2, 3, 4, 5]) y = 60 + 5 * x  # Realizar la regresi\u00f3n lineal slope, intercept, r_value, p_value, std_err = linregress(x, y)  # Crear la figura y los ejes fig, ax = plt.subplots()  # Graficar los datos ax.scatter(x, y, color=\"#009929\", label=\"Datos\")  # Graficar la recta de regresi\u00f3n ax.plot(x, intercept + slope * x, color=\"#98F84A\", label=f\"Recta de regresi\u00f3n (y = {intercept:.2f} + {slope:.2f}x)\")  # Cambiar el color del fondo ax.set_facecolor(\"#D4F8B7\")  # Pintar el fondo externo del gr\u00e1fico fig.patch.set_facecolor('#D4F8B7')  # Colocar el t\u00edtulo ax.set_title(\"Gr\u00e1fico de regresi\u00f3n lineal\")  # Agregar leyenda ax.legend()  # Mostrar el gr\u00e1fico plt.show()  <p> Figura 3.15 Titulo del gr\u00e1fico </p> In\u00a0[22]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Datos para el gr\u00e1fico de barras\ncategorias = ['Capital nacional', 'Capital internacional', 'Renta FIja']\nvalores = [65, 15, 20]\n\n# Crear la figura y los ejes\nfig, ax = plt.subplots()\n\n# Ajustar el color de fondo\nax.set_facecolor(\"#d4f8b7\")\n# Pintar el fondo externo del gr\u00e1fico\nfig.patch.set_facecolor('#D4F8B7')\n\n# Crear el gr\u00e1fico de barras\nplt.bar(categorias, valores, color='#5CCB5f', edgecolor='black', linewidth=1.5, width=0.45)\n\n# A\u00f1adir etiquetas y t\u00edtulo con texto en negrita\nplt.xlabel('Tipo de Fondo', fontsize=10, fontweight='bold')\nplt.ylabel('Frecuencia Porcentual', fontsize=10, fontweight='bold')\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import matplotlib.pyplot as plt  # Datos para el gr\u00e1fico de barras categorias = ['Capital nacional', 'Capital internacional', 'Renta FIja'] valores = [65, 15, 20]  # Crear la figura y los ejes fig, ax = plt.subplots()  # Ajustar el color de fondo ax.set_facecolor(\"#d4f8b7\") # Pintar el fondo externo del gr\u00e1fico fig.patch.set_facecolor('#D4F8B7')  # Crear el gr\u00e1fico de barras plt.bar(categorias, valores, color='#5CCB5f', edgecolor='black', linewidth=1.5, width=0.45)  # A\u00f1adir etiquetas y t\u00edtulo con texto en negrita plt.xlabel('Tipo de Fondo', fontsize=10, fontweight='bold') plt.ylabel('Frecuencia Porcentual', fontsize=10, fontweight='bold')  # Mostrar el gr\u00e1fico plt.show() <p> Figura 3.15 Titulo del gr\u00e1fico </p> In\u00a0[23]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Par\u00e1metros de la distribuci\u00f3n normal\nmedia = 68.42\ndesviacion_estandar = 10\n\n# Generar datos de la distribuci\u00f3n normal\nx = np.linspace(media - 4 * desviacion_estandar, media + 4 * desviacion_estandar, 1000)\ny = norm.pdf(x, media, desviacion_estandar)\n\n# Crear la gr\u00e1fica\nfig, ax = plt.subplots()\nax.plot(x, y, color='#009929')\n# Establecer el color de fondo\nax.set_facecolor('#d4f8b7')  \n# Pintar el fondo externo del gr\u00e1fico\nfig.patch.set_facecolor('#D4F8B7')\nax.set_xlabel(f'media = {media}', fontsize=12)\nax.set_ylabel('Densidad de Probabilidad', fontsize=12)\n\n# Agregar informaci\u00f3n sobre la desviaci\u00f3n est\u00e1ndar\ninfo_desviacion = f'\u03c3 = {desviacion_estandar}'\nax.text(0.6, 0.85, info_desviacion, transform=ax.transAxes, fontsize=12, color='#000')\n\nax.grid(False)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm  # Par\u00e1metros de la distribuci\u00f3n normal media = 68.42 desviacion_estandar = 10  # Generar datos de la distribuci\u00f3n normal x = np.linspace(media - 4 * desviacion_estandar, media + 4 * desviacion_estandar, 1000) y = norm.pdf(x, media, desviacion_estandar)  # Crear la gr\u00e1fica fig, ax = plt.subplots() ax.plot(x, y, color='#009929') # Establecer el color de fondo ax.set_facecolor('#d4f8b7')   # Pintar el fondo externo del gr\u00e1fico fig.patch.set_facecolor('#D4F8B7') ax.set_xlabel(f'media = {media}', fontsize=12) ax.set_ylabel('Densidad de Probabilidad', fontsize=12)  # Agregar informaci\u00f3n sobre la desviaci\u00f3n est\u00e1ndar info_desviacion = f'\u03c3 = {desviacion_estandar}' ax.text(0.6, 0.85, info_desviacion, transform=ax.transAxes, fontsize=12, color='#000')  ax.grid(False) plt.show() <p> Figura 3.15 Titulo del gr\u00e1fico </p> In\u00a0[24]: Copied! <pre>import matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport matplotlib.gridspec as gridspec\n\n# Datos para el gr\u00e1fico de pastel\nnombres = ['Coke Classic', 'Pepsi', 'Diet Coke', 'Dr. Pepper', 'Sprite']\nporcentajes = [38, 26, 16, 10, 10]\ncolores = ['#5ccb5f', '#98f84a', '#e1ffaf', '#fff', '#e1ffaf']\n\n# Crear el gr\u00e1fico de pastel sin bordes\nfig = plt.figure(figsize=(5, 5))\ngs = gridspec.GridSpec(1, 1, width_ratios=[1], height_ratios=[1])\nax = plt.subplot(gs[0])\n\nwedges, texts, autotexts = ax.pie(porcentajes, labels=None, autopct=lambda p: f'{p:.1f}%\\n{nombres.pop(0)}', colors=colores)\n\n# Agregar bordes negros a las porciones del gr\u00e1fico\nfor wedge in wedges:\n    wedge.set_edgecolor('black')\n    wedge.set_linewidth(1)\n\n# Configurar el color de fondo externo\nfig.patch.set_facecolor('#D4F8B7')\n\n# Centrar el gr\u00e1fico en la p\u00e1gina\nplt.tight_layout()\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import matplotlib.pyplot as plt import matplotlib.patches as patches import matplotlib.gridspec as gridspec  # Datos para el gr\u00e1fico de pastel nombres = ['Coke Classic', 'Pepsi', 'Diet Coke', 'Dr. Pepper', 'Sprite'] porcentajes = [38, 26, 16, 10, 10] colores = ['#5ccb5f', '#98f84a', '#e1ffaf', '#fff', '#e1ffaf']  # Crear el gr\u00e1fico de pastel sin bordes fig = plt.figure(figsize=(5, 5)) gs = gridspec.GridSpec(1, 1, width_ratios=[1], height_ratios=[1]) ax = plt.subplot(gs[0])  wedges, texts, autotexts = ax.pie(porcentajes, labels=None, autopct=lambda p: f'{p:.1f}%\\n{nombres.pop(0)}', colors=colores)  # Agregar bordes negros a las porciones del gr\u00e1fico for wedge in wedges:     wedge.set_edgecolor('black')     wedge.set_linewidth(1)  # Configurar el color de fondo externo fig.patch.set_facecolor('#D4F8B7')  # Centrar el gr\u00e1fico en la p\u00e1gina plt.tight_layout()  # Mostrar el gr\u00e1fico plt.show()    <p>Ejercicio 1. Enunciado</p>"},{"location":"capitulo0/","title":"\u00b6","text":"CAPITULO 0  titulo del capitulo Contenido del capitulo <p>0.0 MEDIA POBLACIONAL: \\( \\sigma \\) CONOCIDA</p> <ul> <li>Margen de error y estimaci\u00f3n por intervalo</li> <li>Consejo pr\u00e1ctico</li> </ul> <p>0.0 MODELO DE REGRESI\u00d3N LINEAL SIMPLE</p> <ul> <li>Modelo de regresi\u00f3n y ecuaci\u00f3n de regresi\u00f3n</li> <li>Ecuaci\u00f3n de regresi\u00f3n estimada</li> </ul> <p>0.0 MEDIA POBLACIONAL: \\( \\sigma \\) CONOCIDA</p> <ul> <li>Margen de error y estimaci\u00f3n por intervalo</li> <li>Consejo pr\u00e1ctico</li> </ul> <p>0.0 MODELO DE REGRESI\u00d3N LINEAL SIMPLE</p> <ul> <li>Modelo de regresi\u00f3n y ecuaci\u00f3n de regresi\u00f3n</li> <li>Ecuaci\u00f3n de regresi\u00f3n estimada</li> </ul>"},{"location":"capitulo0/#00-media-poblacional-sigma-conocida","title":"0.0 Media Poblacional $\\sigma$ conocida\u00b6","text":""},{"location":"capitulo0/#margen-de-error-y-estimacion-por-intervalo","title":"Margen de error y estimaci\u00f3n por intervalo\u00b6","text":"<p>Lorem Ipsum es simplemente el texto de relleno de las imprentas y archivos de texto. Lorem Ipsum ha sido el texto de relleno est\u00e1ndar de las industrias desde el a\u00f1o 1500</p>"},{"location":"capitulo0/#ejercicios","title":"Ejercicios\u00b6","text":""},{"location":"capitulo1/","title":"Capitulo 1","text":"<p>En el entorno actual de negocios y econom\u00eda, todos tienen acceso a grandes cantidades de informaci\u00f3n estad\u00edstica. Los directivos y tomadores de decisiones exitosos entienden esta informaci\u00f3n y saben utilizarla de manera eficiente. En esta secci\u00f3n se proporcionan ejemplos que ilustran algunos usos de la estad\u00edstica en los negocios y en la econom\u00eda.</p> In\u00a0[1]: Copied! <pre>from IPython.display import YouTubeVideo\n\nYouTubeVideo('https://www.youtube.com/watch?v=15VqjabLWJE&amp;list=PL3lPU7IsdhynPFg9q77hI4OBWrFrWnWrz', width=900, height=515)\n</pre> from IPython.display import YouTubeVideo  YouTubeVideo('https://www.youtube.com/watch?v=15VqjabLWJE&amp;list=PL3lPU7IsdhynPFg9q77hI4OBWrFrWnWrz', width=900, height=515) Out[1]: In\u00a0[2]: Copied! <pre>YouTubeVideo('uacITE-8k-E', width=950, height=515)\n</pre> YouTubeVideo('uacITE-8k-E', width=950, height=515) Out[2]: <p> Tabla 1.1 Rendimientos de varios fondos de inversi\u00f3n ofrecidos por Fortaleza SAFI en Bolivia</p> Nombre del Fondo Tipo de Moneda Valor de la Cuota Rendimiento T30d (%) Rendimiento T360d (%) Fondo Disponible Bolivianos (Bs) 593.7393 2.50 2.53 Fondo Inversi\u00f3n Internacional D\u00f3lares (USD) 1.0000 1.52 1.29 Fondo Inter\u00e9s + Bolivianos (Bs) 1,744.8408 2.42 2.42 Fondo UFV Rendimiento Total UFV 915.5883 2.47 2.61 Fondo Liquidez D\u00f3lares (USD) 267.7532 0.72 1.06 Fondo Produce Ganancia D\u00f3lares (USD) 182.9020 0.69 0.97 Fondo Planifica Bolivianos (Bs) 419.2739 2.43 2.48 Fondo Potencia Bolivianos Bolivianos (Bs) 6,495.4492 2.32 2.39 Fondo Renta Mixta Internacional D\u00f3lares (USD) 131.7955 0.87 1.22 Fondo Porvenir D\u00f3lares (USD) 203.8964 0.92 1.11 <p> Figura 1.1 Precio promedio por gal\u00f3n para la gasolina regular convencional en Estados Unidos</p> In\u00a0[9]: Copied! <pre>import matplotlib.pyplot as plt\nimport pandas as pd\n\n# Puntos de datos, asumiendo una frecuencia mensual desde Marzo 2006 hasta Julio 2009\nfechas = pd.date_range(start=\"2006-03-01\", periods=41, freq='M')\nprecios = [\n    2.30, 2.25, 2.20, 2.20, 2.25, 2.35, 2.30, 2.35, 2.40, 2.45,\n    2.50, 2.60, 2.55, 2.50, 2.55, 2.60, 2.65, 2.70, 2.75, 2.80,\n    2.85, 3.00, 3.10, 3.25, 3.50, 3.60, 3.70, 3.80, 4.00, 4.10,\n    4.20, 4.35, 4.00, 3.75, 3.50, 3.25, 3.00, 2.75, 2.50, 2.30,\n    2.20\n]\n\n# Crear un DataFrame de los datos\ndatos = pd.DataFrame({'Fecha': fechas, 'Precio': precios})\n\n# Configuraci\u00f3n gr\u00e1fica\nplt.figure(figsize=(10, 5))\nplt.plot(datos['Fecha'], datos['Precio'], marker='o', color='#009929')\nplt.grid(True, which='both', linestyle='--', linewidth=0.5)\nplt.title('Precio medio por gal\u00f3n')\nplt.xlabel('Fecha')\nplt.ylabel('Precio medio por gal\u00f3n')\nplt.ylim(0, 4.5) \nplt.xlim(datos['Fecha'].min(), datos['Fecha'].max())\n\n# Color de fondo\nax = plt.gca()\nax.set_facecolor('#D4F8B7')  # Color de fondo\nfig = plt.gcf()\nfig.patch.set_facecolor('#D4F8B7')  # Color de fondo (figura)\n\n# Mostrar la gr\u00e1fica\nplt.show()\n</pre> import matplotlib.pyplot as plt import pandas as pd  # Puntos de datos, asumiendo una frecuencia mensual desde Marzo 2006 hasta Julio 2009 fechas = pd.date_range(start=\"2006-03-01\", periods=41, freq='M') precios = [     2.30, 2.25, 2.20, 2.20, 2.25, 2.35, 2.30, 2.35, 2.40, 2.45,     2.50, 2.60, 2.55, 2.50, 2.55, 2.60, 2.65, 2.70, 2.75, 2.80,     2.85, 3.00, 3.10, 3.25, 3.50, 3.60, 3.70, 3.80, 4.00, 4.10,     4.20, 4.35, 4.00, 3.75, 3.50, 3.25, 3.00, 2.75, 2.50, 2.30,     2.20 ]  # Crear un DataFrame de los datos datos = pd.DataFrame({'Fecha': fechas, 'Precio': precios})  # Configuraci\u00f3n gr\u00e1fica plt.figure(figsize=(10, 5)) plt.plot(datos['Fecha'], datos['Precio'], marker='o', color='#009929') plt.grid(True, which='both', linestyle='--', linewidth=0.5) plt.title('Precio medio por gal\u00f3n') plt.xlabel('Fecha') plt.ylabel('Precio medio por gal\u00f3n') plt.ylim(0, 4.5)  plt.xlim(datos['Fecha'].min(), datos['Fecha'].max())  # Color de fondo ax = plt.gca() ax.set_facecolor('#D4F8B7')  # Color de fondo fig = plt.gcf() fig.patch.set_facecolor('#D4F8B7')  # Color de fondo (figura)  # Mostrar la gr\u00e1fica plt.show()  <p> Figura 1.2 Varias Gr\u00e1ficas de series de tiempo</p> In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport pandas as pd\n\n# Ajustamos las fechas para que coincidan con el n\u00famero de valores proporcionados del Dow Jones\nfechas = pd.date_range(start=\"1998-01-01\", periods=15, freq='A-DEC')\n\n# Valores aproximados del Promedio industrial Dow Jones extra\u00eddos del gr\u00e1fico\nvalores_dow_jones = [\n    8200,  9100, 10700, 9800,  8800,  9000, 10200, 10400, 11000,\n    12400, 13000, 12800, 11800, 9000,  8500\n]\n\n# Crear un DataFrame con los datos ajustados\ndatos_dow_jones = pd.DataFrame({'A\u00f1o': fechas, 'Promedio industrial Dow Jones': valores_dow_jones})\n\n# Configuraci\u00f3n de la gr\u00e1fica\nplt.figure(figsize=(10, 5))\nplt.plot(datos_dow_jones['A\u00f1o'], datos_dow_jones['Promedio industrial Dow Jones'], color='#009929')\nplt.grid(True, which='both', linestyle='--', linewidth=0.5)\nplt.title('(A) Promedio industrial Dow Jones')\nplt.xlabel('A\u00f1o', fontweight='bold')\nplt.ylabel('Promedio industrial Dow Jones')\nplt.ylim(5000, 14000)  # Establecer los l\u00edmites del eje y\nplt.xlim(datos_dow_jones['A\u00f1o'].min(), datos_dow_jones['A\u00f1o'].max())  # Establecer los l\u00edmites del eje x\n\n# Color de fondo\nax = plt.gca()\nax.set_facecolor('#D4F8B7')  # Color de fondo claro\nfig = plt.gcf()\nfig.patch.set_facecolor('#D4F8B7')  # Color de fondo para la figura\n\n# Mostrar la gr\u00e1fica\nplt.show()\n</pre> import matplotlib.pyplot as plt import pandas as pd  # Ajustamos las fechas para que coincidan con el n\u00famero de valores proporcionados del Dow Jones fechas = pd.date_range(start=\"1998-01-01\", periods=15, freq='A-DEC')  # Valores aproximados del Promedio industrial Dow Jones extra\u00eddos del gr\u00e1fico valores_dow_jones = [     8200,  9100, 10700, 9800,  8800,  9000, 10200, 10400, 11000,     12400, 13000, 12800, 11800, 9000,  8500 ]  # Crear un DataFrame con los datos ajustados datos_dow_jones = pd.DataFrame({'A\u00f1o': fechas, 'Promedio industrial Dow Jones': valores_dow_jones})  # Configuraci\u00f3n de la gr\u00e1fica plt.figure(figsize=(10, 5)) plt.plot(datos_dow_jones['A\u00f1o'], datos_dow_jones['Promedio industrial Dow Jones'], color='#009929') plt.grid(True, which='both', linestyle='--', linewidth=0.5) plt.title('(A) Promedio industrial Dow Jones') plt.xlabel('A\u00f1o', fontweight='bold') plt.ylabel('Promedio industrial Dow Jones') plt.ylim(5000, 14000)  # Establecer los l\u00edmites del eje y plt.xlim(datos_dow_jones['A\u00f1o'].min(), datos_dow_jones['A\u00f1o'].max())  # Establecer los l\u00edmites del eje x  # Color de fondo ax = plt.gca() ax.set_facecolor('#D4F8B7')  # Color de fondo claro fig = plt.gcf() fig.patch.set_facecolor('#D4F8B7')  # Color de fondo para la figura  # Mostrar la gr\u00e1fica plt.show()  In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport pandas as pd\n\n# A\u00f1os representados en el gr\u00e1fico\na\u00f1os = [2003, 2004, 2005, 2006, 2007, 2008, 2009]\n\n# Valores aproximados de la utilidad neta de McDonald's (en millones de $) extra\u00eddos del gr\u00e1fico\nutilidades = [\n    1.5, 2.0, 2.5, 2.0, 3.5, 4.0, 5.5\n]\n\n# Crear un DataFrame para los datos\ndatos_utilidad_mcdonalds = pd.DataFrame({'A\u00f1o': a\u00f1os, 'Utilidad neta (millones $)': utilidades})\n\n# Configuraci\u00f3n del gr\u00e1fico de barras con bordes negros\nplt.figure(figsize=(8, 6))\nplt.bar(datos_utilidad_mcdonalds['A\u00f1o'], \n        datos_utilidad_mcdonalds['Utilidad neta (millones $)'], \n        color='#5CCB5F', \n        edgecolor='black')  # Agregar borde negro a las barras\nplt.title('(B) Utilidad neta de McDonald\u2019s Inc.')\nplt.xlabel('A\u00f1o', fontweight='bold')\nplt.ylabel('Utilidad neta (millones $)')\nplt.ylim(0, 6)  # Establecer los l\u00edmites del eje y\n\n# Color de fondo\nax = plt.gca()\nax.set_facecolor('#D4F8B7')  # Color de fondo claro\nfig = plt.gcf()\nfig.patch.set_facecolor('#D4F8B7')  # Color de fondo para la figura\n\n# Mostrar el gr\u00e1fico de barras\nplt.show()\n</pre> import matplotlib.pyplot as plt import pandas as pd  # A\u00f1os representados en el gr\u00e1fico a\u00f1os = [2003, 2004, 2005, 2006, 2007, 2008, 2009]  # Valores aproximados de la utilidad neta de McDonald's (en millones de $) extra\u00eddos del gr\u00e1fico utilidades = [     1.5, 2.0, 2.5, 2.0, 3.5, 4.0, 5.5 ]  # Crear un DataFrame para los datos datos_utilidad_mcdonalds = pd.DataFrame({'A\u00f1o': a\u00f1os, 'Utilidad neta (millones $)': utilidades})  # Configuraci\u00f3n del gr\u00e1fico de barras con bordes negros plt.figure(figsize=(8, 6)) plt.bar(datos_utilidad_mcdonalds['A\u00f1o'],          datos_utilidad_mcdonalds['Utilidad neta (millones $)'],          color='#5CCB5F',          edgecolor='black')  # Agregar borde negro a las barras plt.title('(B) Utilidad neta de McDonald\u2019s Inc.') plt.xlabel('A\u00f1o', fontweight='bold') plt.ylabel('Utilidad neta (millones $)') plt.ylim(0, 6)  # Establecer los l\u00edmites del eje y  # Color de fondo ax = plt.gca() ax.set_facecolor('#D4F8B7')  # Color de fondo claro fig = plt.gcf() fig.patch.set_facecolor('#D4F8B7')  # Color de fondo para la figura  # Mostrar el gr\u00e1fico de barras plt.show()  In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport pandas as pd\n\n# Meses representados en el gr\u00e1fico\nmeses = ['Ene', 'Feb', 'Mar', 'Abr', 'May', 'Jun', 'Jul', 'Ago', 'Sep', 'Oct', 'Nov', 'Dic']\n\n# Valores aproximados de la tasa de ocupaci\u00f3n de los hoteles del sur de Florida (en porcentaje)\ntasas_ocupacion = [\n    70, 80, 82, 75, 68, 65, 60, 55, 58, 62, 68, 75\n]\n\n# Crear un DataFrame para los datos\ndatos_ocupacion_hoteles = pd.DataFrame({'Mes': meses, 'Porcentaje de ocupaci\u00f3n': tasas_ocupacion})\n\n# Configuraci\u00f3n del gr\u00e1fico de barras\nplt.figure(figsize=(10, 6))\nplt.bar(datos_ocupacion_hoteles['Mes'], datos_ocupacion_hoteles['Porcentaje de ocupaci\u00f3n'], color='#5CCB5F', edgecolor='black')\nplt.title('(C) Tasa de ocupaci\u00f3n de los hoteles del sur de Florida')\nplt.xlabel('Mes', fontweight='bold')\nplt.ylabel('Porcentaje de ocupaci\u00f3n')\nplt.ylim(0, 100)  # Establecer los l\u00edmites del eje y\n\n# Color de fondo\nax = plt.gca()\nax.set_facecolor('#D4F8B7')  # Color de fondo claro\nfig = plt.gcf()\nfig.patch.set_facecolor('#D4F8B7')  # Color de fondo para la figura\n\n# Mostrar el gr\u00e1fico de barras\nplt.show()\n</pre> import matplotlib.pyplot as plt import pandas as pd  # Meses representados en el gr\u00e1fico meses = ['Ene', 'Feb', 'Mar', 'Abr', 'May', 'Jun', 'Jul', 'Ago', 'Sep', 'Oct', 'Nov', 'Dic']  # Valores aproximados de la tasa de ocupaci\u00f3n de los hoteles del sur de Florida (en porcentaje) tasas_ocupacion = [     70, 80, 82, 75, 68, 65, 60, 55, 58, 62, 68, 75 ]  # Crear un DataFrame para los datos datos_ocupacion_hoteles = pd.DataFrame({'Mes': meses, 'Porcentaje de ocupaci\u00f3n': tasas_ocupacion})  # Configuraci\u00f3n del gr\u00e1fico de barras plt.figure(figsize=(10, 6)) plt.bar(datos_ocupacion_hoteles['Mes'], datos_ocupacion_hoteles['Porcentaje de ocupaci\u00f3n'], color='#5CCB5F', edgecolor='black') plt.title('(C) Tasa de ocupaci\u00f3n de los hoteles del sur de Florida') plt.xlabel('Mes', fontweight='bold') plt.ylabel('Porcentaje de ocupaci\u00f3n') plt.ylim(0, 100)  # Establecer los l\u00edmites del eje y  # Color de fondo ax = plt.gca() ax.set_facecolor('#D4F8B7')  # Color de fondo claro fig = plt.gcf() fig.patch.set_facecolor('#D4F8B7')  # Color de fondo para la figura  # Mostrar el gr\u00e1fico de barras plt.show()  <p>Los datos se obtienen de fuentes existentes o a trav\u00e9s de encuestas y estudios experimentales.</p> In\u00a0[\u00a0]: Copied! <pre>YouTubeVideo('lY81LgDZvVI', width=950, height=515)\n</pre> YouTubeVideo('lY81LgDZvVI', width=950, height=515) Out[\u00a0]: <p> Tabla 1.2 Ejemplos de datos disponibles de los registros internos de una empresa </p> Fuente Algunos datos com\u00fanmente disponibles Registros de empleados Nombre, domicilio, n\u00famero de Seguro Social, sueldo, n\u00famero de d\u00edas de vacaciones, n\u00famero de d\u00edas de incapacidad y bonos Registros de producci\u00f3n N\u00famero de parte o de producto, cantidad producida, costo de mano de obra directa y costo de los materiales Registros de inventarios N\u00famero de parte o de producto, cantidad de unidades disponible, punto de reorden, lote econ\u00f3mico y programa de descuentos Registros de ventas N\u00famero de producto, volumen de ventas, volumen de ventas por regi\u00f3n y volumen de ventas por tipo de cliente Registros de cr\u00e9dito Nombre del cliente, domicilio, n\u00famero telef\u00f3nico, l\u00edmite de cr\u00e9dito y saldo de las cuentas por cobrar Perfiles de clientes Edad, g\u00e9nero, nivel de ingresos, n\u00famero de miembros en la familia, domicilio y preferencias <p> Tabla 1.3 Ejemplos de datos disponibles de algunas agencias gubernamentales </p> Agencia gubernamental Algunos datos disponibles Oficina del Censo Datos poblacionales, n\u00famero de familias e ingresos por familia Consejo de la Reserva Federal Datos sobre la masa monetaria, cr\u00e9dito a plazo, tipos de cambio y tasas de descuento Oficina de Administraci\u00f3n y Presupuesto Datos sobre ingresos, gastos y deudas del gobierno federal Departamento de Comercio Datos sobre la actividad comercial, valor de las remesas por industria, nivel de utilidades por industria e industrias en crecimiento y en declive Oficina de Estad\u00edsticas Laborales Gasto de los consumidores, ganancias por hora, tasa de desempleo, registros de seguridad y estad\u00edsticas internacionales In\u00a0[\u00a0]: Copied! <pre>YouTubeVideo('https://www.youtube.com/watch?v=Xq3thcQqwbc&amp;list=PLsBNzHAbhO2n5wfw0wAJgt-EsXMjDxhua', width=950, height=515)\n</pre> YouTubeVideo('https://www.youtube.com/watch?v=Xq3thcQqwbc&amp;list=PLsBNzHAbhO2n5wfw0wAJgt-EsXMjDxhua', width=950, height=515) Out[\u00a0]: <p> Tabla 1.4 Cuestionario de opini\u00f3n del cliente usado por el restaurante Chops City Grill en Naples, Florida </p> Tipo de fondo de inversi\u00f3n Frecuencia Frecuencia porcentual Capital nacional 16 64 Capital internacional 4 16 Renta fija 5 20 Totales 25 100 <p> Figura 1.5 Gr\u00e1fica de barras para el tipo de fondo de inversi\u00f3n</p> In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\n\nfunds = ['Capital nacional', 'Capital internacional', 'Renta fija']\nfrequencies = [60, 20, 30]\n\n\nplt.figure(figsize=(10, 5))\nbars = plt.bar(funds, frequencies, color='#5CCB5F', edgecolor='black')\n\nplt.title('Frecuencia porcentual por Tipo de fondo', fontsize=14)\nplt.xlabel('Tipo de fondo', fontsize=12)\nplt.ylabel('Frecuencia porcentual', fontsize=12)\nplt.yticks(range(0, 71, 10))\nfor bar in bars:\n    yval = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2, yval + 1, round(yval, 1), ha='center', va='bottom')\nplt.tight_layout()\n\nax = plt.gca()\nax.set_facecolor('#D4F8B7')  # Color de fondo claro\nfig = plt.gcf()\nfig.patch.set_facecolor('#D4F8B7')  # Color de fondo para la figura\n\nplt.show()\n</pre> import matplotlib.pyplot as plt  funds = ['Capital nacional', 'Capital internacional', 'Renta fija'] frequencies = [60, 20, 30]   plt.figure(figsize=(10, 5)) bars = plt.bar(funds, frequencies, color='#5CCB5F', edgecolor='black')  plt.title('Frecuencia porcentual por Tipo de fondo', fontsize=14) plt.xlabel('Tipo de fondo', fontsize=12) plt.ylabel('Frecuencia porcentual', fontsize=12) plt.yticks(range(0, 71, 10)) for bar in bars:     yval = bar.get_height()     plt.text(bar.get_x() + bar.get_width()/2, yval + 1, round(yval, 1), ha='center', va='bottom') plt.tight_layout()  ax = plt.gca() ax.set_facecolor('#D4F8B7')  # Color de fondo claro fig = plt.gcf() fig.patch.set_facecolor('#D4F8B7')  # Color de fondo para la figura  plt.show()  <p> Figura 1.6 Histograma del valor de los activos netos para 25 fondos de inversi\u00f3n</p> In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\nasset_values = np.array([15, 30, 45, 60, 75])\nfrequencies = np.array([9, 8, 5, 2, 1])\n\nplt.figure(figsize=(10, 5))\nbars = plt.bar(asset_values, frequencies, width=15, color='#5CCB5F', edgecolor='black', align='center')\n\nplt.title('Frecuencia por Valor de los activos netos ($)', fontsize=14)\nplt.xlabel('Valor de los activos netos ($)', fontsize=12)\nplt.ylabel('Frecuencia', fontsize=12)\n\nplt.xlim(0, 85)\nplt.ylim(0, 10)\n\nax = plt.gca()\nax.set_facecolor('#D4F8B7')  # Color de fondo claro\nfig = plt.gcf()\nfig.patch.set_facecolor('#D4F8B7')  # Color de fondo para la figura\n\n\nplt.tight_layout()\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  asset_values = np.array([15, 30, 45, 60, 75]) frequencies = np.array([9, 8, 5, 2, 1])  plt.figure(figsize=(10, 5)) bars = plt.bar(asset_values, frequencies, width=15, color='#5CCB5F', edgecolor='black', align='center')  plt.title('Frecuencia por Valor de los activos netos ($)', fontsize=14) plt.xlabel('Valor de los activos netos ($)', fontsize=12) plt.ylabel('Frecuencia', fontsize=12)  plt.xlim(0, 85) plt.ylim(0, 10)  ax = plt.gca() ax.set_facecolor('#D4F8B7')  # Color de fondo claro fig = plt.gcf() fig.patch.set_facecolor('#D4F8B7')  # Color de fondo para la figura   plt.tight_layout() plt.show()  In\u00a0[\u00a0]: Copied! <pre>YouTubeVideo('https://www.youtube.com/watch?v=SJL3wLC62EM&amp;list=PLaJK82VXGZpTPr_FooaurRL7qLOW_-uau', width=950, height=515)\n</pre> YouTubeVideo('https://www.youtube.com/watch?v=SJL3wLC62EM&amp;list=PLaJK82VXGZpTPr_FooaurRL7qLOW_-uau', width=950, height=515) Out[\u00a0]: <p>La figura 1.6 muestra un histograma de los precios por acci\u00f3n de 25 acciones S&amp;P, donde se observa la frecuencia de los diferentes valores. Esta representaci\u00f3n visual facilita identificar la concentraci\u00f3n de precios en un rango espec\u00edfico. Considerar tanto medidas descriptivas num\u00e9ricas como gr\u00e1ficas es fundamental en la estad\u00edstica descriptiva para resumir y presentar de manera clara la informaci\u00f3n obtenida. La estad\u00edstica desempe\u00f1a un papel importante en la inferencia estad\u00edstica, que consiste en utilizar datos de una muestra para hacer estimaciones y probar hip\u00f3tesis sobre las caracter\u00edsticas de una poblaci\u00f3n. Este proceso puede ser realizado a trav\u00e9s de un censo, que recolecta datos de toda la poblaci\u00f3n, o a trav\u00e9s de una encuesta muestral, que recolecta datos de una muestra representativa de la poblaci\u00f3n.</p> <p>Un ejemplo concreto de inferencia estad\u00edstica es un estudio realizado por Norris Electronics, donde se fabricaron 200 focos utilizando un nuevo filamento. Los datos recolectados de esta muestra, que indican la duraci\u00f3n de cada foco antes de que el filamento se queme, se utilizan para hacer inferencias sobre la duraci\u00f3n promedio de todos los focos fabricados con el nuevo filamento. En este caso, se calcula un promedio muestral de 76 horas, lo que sugiere que el tiempo de vida promedio de la poblaci\u00f3n de focos es de 76 horas.</p> <p>Es importante destacar que los estad\u00edsticos proporcionan informaci\u00f3n sobre la calidad o precisi\u00f3n de las estimaciones. En el ejemplo de Norris, se informa que la estimaci\u00f3n puntual del tiempo de vida promedio de los focos nuevos es de 76 horas, con un margen de error de \u00b14 horas. Esto significa que el intervalo de estimaci\u00f3n del tiempo de vida promedio de los focos fabricados con el nuevo filamento es de 72 a 80 horas. Adem\u00e1s, el estad\u00edstico puede indicar el nivel de confianza que tiene en que este intervalo contiene el promedio poblacional.</p> <p>En resumen, la inferencia estad\u00edstica es un proceso fundamental que permite realizar estimaciones y pruebas sobre caracter\u00edsticas de una poblaci\u00f3n utilizando datos de una muestra representativa. Esta herramienta estad\u00edstica proporciona informaci\u00f3n valiosa y precisa para la toma de decisiones.</p> <p> Tabla 1.5 Horas hasta que el filamento se funde para una muestra de 200 focos en el ejemplo de Norris Electronics</p> 107 73 68 97 76 79 94 59 98 57 54657170848862617998 66627986687461826598 621166588647978797786 74857380687889725869 927888771038863688881 75906289717174707470 65817562947185848363 81627983936165629265 83707081777284675958 78666694776366756876 907871101784359676171 967564767277 <p>Ejercicio 1. Comente las diferencias entre la estad\u00edstica como hechos num\u00e9ricos y las estad\u00edstica como una disciplina o campo de estudio.</p> <p>La estad\u00edstica como hechos num\u00e9ricos se centra en el uso pr\u00e1ctico de herramientas estad\u00edsticas para analizar datos, mientras que la estad\u00edstica como disciplina se enfoca en el desarrollo de m\u00e9todos, teor\u00edas y enfoques para entender la variabilidad y tomar decisiones informadas en un contexto m\u00e1s amplio. Ambas perspectivas son interdependientes y se complementan entre s\u00ed para proporcionar una comprensi\u00f3n completa y rigurosa de los datos y fen\u00f3menos estudiados</p> <p>Ejercicio 2.  El departamento de energia de Estados Unidos proporciona informaci\u00f3n sobre econom\u00eda de combustible para diversos vehiculos de motor. Una muestra de 10 autom\u00f3viles se presenta en la tabla 1.6 (sitio web Fuel Economy, 22 de febrero de 2008). Los datos indican el tama\u00f1o de autom\u00f3vil (compacto, mediano o grande), el n\u00famero de cilindros de motor, las millas por gal\u00f3n en la ciudad, las millas por gal\u00f3n en autopista y el combustible recomendado(diesel, premium o regular).</p> <p>a) \u00bfCu\u00e1tos elementos hay en este banco de datos? b) \u00bfCu\u00e1ntas variables hay e este banco de datos? c) \u00bfCu\u00e1les variables son categ\u00f3ricas y c\u00faales son cuantitativas? d) \u00bfQu\u00e9 tipo de escala de medici\u00f3n se usa ara cada una de las variables?</p> <p>a) Hay 10 elementos en este conjunto de datos. b) Hay cinco variables en este conjunto de datos: Tama\u00f1o, Cilindros, Ciudad, Autopista y Combustible. c) Las Variables categ\u00f3ricas son Tama\u00f1o y Combustible. Las variables cuantitativas son Cilindros,MPG en la ciudad y MPG en autopista. d)  - Tama\u00f1o: Ordinal. - Cilindros: de raz\u00f3n. - MPG Ciudad: de raz\u00f3n - MPG Autopista: de raz\u00f3n - Combustible: Nominal</p> <p>Ejercicio 3.  Consulta la tabla 1.6</p> <p>a) \u00bfCu\u00e1ntas millas por gal\u00f3 se consumen en la ciudad? b) En promedio, \u00bfcu\u00e1ntas millas m\u00e1s por gal\u00f3n se obtinen al conducir en autopista que en la ciudad? c) \u00bfQu\u00e9 porcentaje de los autom\u00f3viles tiene motores de cuatro cilindros? d) \u00bfQu\u00e9 porcentaje de los veh\u00edculos usa combustible regular?</p> In\u00a0[\u00a0]: Copied! <pre># Datos de la tabla\nvehiculos = [\n    {\"modelo\": \"Audi A8\", \"cilindros\": 12, \"ciudad\": 13, \"autopista\": 19, \"combustible\": \"Premium\"},\n    {\"modelo\": \"BMW 328Xi\", \"cilindros\": 6, \"ciudad\": 17, \"autopista\": 25, \"combustible\": \"Premium\"},\n    {\"modelo\": \"Cadillac CTS\", \"cilindros\": 6, \"ciudad\": 16, \"autopista\": 25, \"combustible\": \"Regular\"},\n    {\"modelo\": \"Chrysler 300\", \"cilindros\": 8, \"ciudad\": 13, \"autopista\": 18, \"combustible\": \"Premium\"},\n    {\"modelo\": \"Ford Focus\", \"cilindros\": 4, \"ciudad\": 24, \"autopista\": 33, \"combustible\": \"Regular\"},\n    {\"modelo\": \"Hyundai Elantra\", \"cilindros\": 4, \"ciudad\": 25, \"autopista\": 33, \"combustible\": \"Regular\"},\n    {\"modelo\": \"Jeep Grand Cherokee\", \"cilindros\": 6, \"ciudad\": 17, \"autopista\": 26, \"combustible\": \"Diesel\"},\n    {\"modelo\": \"Pontiac G6\", \"cilindros\": 6, \"ciudad\": 15, \"autopista\": 22, \"combustible\": \"Regular\"},\n    {\"modelo\": \"Toyota Camry\", \"cilindros\": 4, \"ciudad\": 21, \"autopista\": 31, \"combustible\": \"Regular\"},\n    {\"modelo\": \"Volkswagen Jetta\", \"cilindros\": 5, \"ciudad\": 21, \"autopista\": 29, \"combustible\": \"Regular\"},\n]\n\n# a) Millas por gal\u00f3n en la ciudad\nmillas_ciudad = [13,17,16,13,24,25,17,15,21,21]\nsuma_millas_ciudad = sum(millas_ciudad)\n\n# b) Diferencia de millas por gal\u00f3n en autopista y ciudad\ndiferencia_millas = [19,25,25,18,33,33,26,22,31,29]\nsuma_millas_autopista=sum(diferencia_millas)\npromedio_diferencia_millas = 7.9\n\n# c) Porcentaje de autom\u00f3viles con motores de cuatro cilindros\ncuatro_cilindros = [vehiculo for vehiculo in vehiculos if vehiculo[\"cilindros\"] == 4]\nporcentaje_cuatro_cilindros = (len(cuatro_cilindros) / len(vehiculos)) * 100\n\n# d) Porcentaje de veh\u00edculos que usan combustible regular\ncombustible_regular = [vehiculo for vehiculo in vehiculos if vehiculo[\"combustible\"] == \"Regular\"]\nporcentaje_combustible_regular = (len(combustible_regular) / len(vehiculos)) * 100\n\n# Mostrar resultados\nprint(\"a) Millas por gal\u00f3n en la ciudad:\", suma_millas_ciudad)\nprint (\"182/10 = \",(suma_millas_ciudad/10),\"mpg\")\nprint(\"\\nb) Millas por gal\u00f3n en autopista:\",suma_millas_autopista)\nprint(\"261/10 =\",(suma_millas_autopista/10),\"mpg\")\nprint(f\"\\nPromedio de millas m\u00e1s por gal\u00f3n en autopista que en ciudad: {promedio_diferencia_millas:.1f} millas por gal\u00f3n(mpg)\")\nprint(f\"\\nc) Porcentaje de autom\u00f3viles con motores de cuatro cilindros: {porcentaje_cuatro_cilindros:.2f}%\")\nprint(f\"d) Porcentaje de veh\u00edculos que usan combustible regular: {porcentaje_combustible_regular:.2f}%\")\n</pre> # Datos de la tabla vehiculos = [     {\"modelo\": \"Audi A8\", \"cilindros\": 12, \"ciudad\": 13, \"autopista\": 19, \"combustible\": \"Premium\"},     {\"modelo\": \"BMW 328Xi\", \"cilindros\": 6, \"ciudad\": 17, \"autopista\": 25, \"combustible\": \"Premium\"},     {\"modelo\": \"Cadillac CTS\", \"cilindros\": 6, \"ciudad\": 16, \"autopista\": 25, \"combustible\": \"Regular\"},     {\"modelo\": \"Chrysler 300\", \"cilindros\": 8, \"ciudad\": 13, \"autopista\": 18, \"combustible\": \"Premium\"},     {\"modelo\": \"Ford Focus\", \"cilindros\": 4, \"ciudad\": 24, \"autopista\": 33, \"combustible\": \"Regular\"},     {\"modelo\": \"Hyundai Elantra\", \"cilindros\": 4, \"ciudad\": 25, \"autopista\": 33, \"combustible\": \"Regular\"},     {\"modelo\": \"Jeep Grand Cherokee\", \"cilindros\": 6, \"ciudad\": 17, \"autopista\": 26, \"combustible\": \"Diesel\"},     {\"modelo\": \"Pontiac G6\", \"cilindros\": 6, \"ciudad\": 15, \"autopista\": 22, \"combustible\": \"Regular\"},     {\"modelo\": \"Toyota Camry\", \"cilindros\": 4, \"ciudad\": 21, \"autopista\": 31, \"combustible\": \"Regular\"},     {\"modelo\": \"Volkswagen Jetta\", \"cilindros\": 5, \"ciudad\": 21, \"autopista\": 29, \"combustible\": \"Regular\"}, ]  # a) Millas por gal\u00f3n en la ciudad millas_ciudad = [13,17,16,13,24,25,17,15,21,21] suma_millas_ciudad = sum(millas_ciudad)  # b) Diferencia de millas por gal\u00f3n en autopista y ciudad diferencia_millas = [19,25,25,18,33,33,26,22,31,29] suma_millas_autopista=sum(diferencia_millas) promedio_diferencia_millas = 7.9  # c) Porcentaje de autom\u00f3viles con motores de cuatro cilindros cuatro_cilindros = [vehiculo for vehiculo in vehiculos if vehiculo[\"cilindros\"] == 4] porcentaje_cuatro_cilindros = (len(cuatro_cilindros) / len(vehiculos)) * 100  # d) Porcentaje de veh\u00edculos que usan combustible regular combustible_regular = [vehiculo for vehiculo in vehiculos if vehiculo[\"combustible\"] == \"Regular\"] porcentaje_combustible_regular = (len(combustible_regular) / len(vehiculos)) * 100  # Mostrar resultados print(\"a) Millas por gal\u00f3n en la ciudad:\", suma_millas_ciudad) print (\"182/10 = \",(suma_millas_ciudad/10),\"mpg\") print(\"\\nb) Millas por gal\u00f3n en autopista:\",suma_millas_autopista) print(\"261/10 =\",(suma_millas_autopista/10),\"mpg\") print(f\"\\nPromedio de millas m\u00e1s por gal\u00f3n en autopista que en ciudad: {promedio_diferencia_millas:.1f} millas por gal\u00f3n(mpg)\") print(f\"\\nc) Porcentaje de autom\u00f3viles con motores de cuatro cilindros: {porcentaje_cuatro_cilindros:.2f}%\") print(f\"d) Porcentaje de veh\u00edculos que usan combustible regular: {porcentaje_combustible_regular:.2f}%\") <pre>a) Millas por gal\u00f3n en la ciudad: 182\n182/10 =  18.2 mpg\n\nb) Millas por gal\u00f3n en autopista: 261\n261/10 = 26.1 mpg\n\nPromedio de millas m\u00e1s por gal\u00f3n en autopista que en ciudad: 7.9 millas por gal\u00f3n(mpg)\n\nc) Porcentaje de autom\u00f3viles con motores de cuatro cilindros: 30.00%\nd) Porcentaje de veh\u00edculos que usan combustible regular: 60.00%\n</pre> <p>Tabla 1.6 Informaci\u00f3n sobre econom\u00eda de combustible para 10 autom\u00f3viles</p> Veh\u00edculo Tama\u00f1o Cilindros MPG* Ciudad MPG Autopista Combustible Audi A8 Grande 12 13 19 Premium BMW 238Xi Compacto 6 17 25 Premium Cadillac CTS Mediano 6 16 25 Regular Chrysler 300 Grande 8 13 18 Premium Ford Focus Compacto 4 24 33 Regular Hyundai Elantra Mediano 4 25 33 Regular Jeep Grand Cherokee Mediano 6 17 26 Diesel Pontiac G6 Compacto 6 15 22 Regular Toyota Camry Mediano 4 21 31 Regular Volkswagen Jetta Compacto 5 21 29 Regular *Millas por gal\u00f3n <p> Tabla 1.7 Datos para siete colegios y universidades</p> Escuela Estado Campus Inversion ($ miles de millones) % de solicitantes admitidos Division de la NCAA Amherst College Massachusetts Pueblo: peque\u00f1o 1.7 18 III Duke Carolina del Norte Ciudad: mediana 5.9 21 I-A Universidad de Harvard Massachusetts Ciudad: mediana 34.6 9 I-AA Swarthmore Collage Pennsylvania Suburbio: grande 1.4 18 III Universidad de Pennsylvania Pennsylvania Ciudad: grande 6.6 18 I-AA Williams Collage Massachusetts Pueblo: peque\u00f1o 1.9 18 III Universidad de Yale Connecticut Ciudad: mediana 22.5 9 I-AA <p>Ejercicio 4.  La Tabla 1.7 muestra datos para siete colegios y universidades considerando la inversi\u00f3n(en miles de millones de d\u00f3lares) y el porcentaje de solicitantes admitido(USA Today, 3 de febrero de 2008). El estado en que se localiza cada escuela, el campus y la Divisi\u00f3n de NCAA para los equipos colegiales se obtuvieron del sitio web National Center of Education Statistics (22 de febrero de 2008).</p> <p>a) \u00bfCu\u00e1ntos elementos hay en el banco de datos? b) \u00bfCu\u00e1ntas variables hay en el banco de datos? c) \u00bfCu\u00e1les variables son categ\u00f3ricas y cu\u00e1les son cuantitativas?</p> <p>a)</p> Contando las filas, hay 7 elementos en el banco de datos, uno para cada escuela o universidad. b) Contando las columnas, hay 5 variables en el banco de datos. c)  - Variables cuantitativas:      1. Activos     2. % de solicitantes admitidos - Variables categ\u00f3ricas:      1. Estado     2. Campo de juego     3. Divisi\u00f3n NCAA    <p>Ejercicio 5.  Considere el banco de datos de la tabla 7.1</p> <p>a) Calcule la inversi\u00f3n promedio para la muestra. b) Calcule el porcentaje promedio de solicitantes admitidos. c) \u00bfQu\u00e9 porcentajes de las escuelas tiene equipos colegiales de divisi\u00f3n III de la NCAA? d) \u00bfQu\u00e9 porcentaje de las escuelas tiene un campus en una ciudad mediana?</p> <p>a) - Hay 7 elementos en este banco de datos, ya que la tabla presenta datos para siete colegios y universidades.  b) - Hay 6 variables en este banco de datos. Las variables son:   1. Escuela   2. Estado   3. Campus   4. Inversi\u00f3n ($ miles de millones)   5. % de solicitantes admitidos   6. Divisi\u00f3n de la NCAA  c) - Variables categ\u00f3ricas:   - Escuela   - Estado   - Campus   - Divisi\u00f3n de la NCAA  <ul> <li><p>Variables cuantitativas:</p> <ul> <li>Inversi\u00f3n ($ miles de millones)</li> <li>% de solicitantes admitidos  d) - Escala nominal:</li> <li>Escuela</li> <li>Estado</li> <li>Campus</li> <li>Divisi\u00f3n de la NCAA</li> </ul> </li> <li><p>Escala de intervalo:</p> <ul> <li>Inversi\u00f3n ($ miles de millones)</li> <li>% de solicitantes admitidos</li></ul></li></ul></p> <p>Ejercicio 6.  La revista Foreign Affairs realiz\u00f3 una encuesta para desarrollar un perfil de sus suscriptores (sitio web Foreign Affairs, 23 de febrero de 2008).Se formularon las preguntas siguientes.</p> <p>a) \u00bfCu\u00e1ntas noches ha permanecido en un hotel en los 12 meses anteriores? b) \u00bfD\u00f3nde adquiere sus libros? Se listaron tres opciones: Bookstore, Internet y Book Club. c) \u00bfPosee o alquila un veh\u00edculo de lujo? (S\u00ed o No) d) \u00bfQu\u00e9 edad tiene? e) Para los viajes al extranjero realizados en los tres a\u00f1os pasados \u00bfcu\u00e1l fue su destino? Se listaron siste destinos internacionales. Comente si cada pregunta proporciona datos categ\u00f3ricos o cuantitativos</p> <p>a) - Respuesta: Datos cuantitativos   b) - Respuesta: Datos categ\u00f3ricos (nominales)   c) - Respuesta: Datos categ\u00f3ricos (nominales)   d) - Respuesta: Datos cuantitativos      e) - Respuesta: Datos categ\u00f3ricos (nominales)  </p> <p>Ejercicio 7.  El hotel Ritz-Carlton aplic\u00f3 un cuestionario de opini\u00f3n del cliente para obtener datos sobre el desempe\u00f1o de sus servicios de comedor y entretenimiento(The Ritz-Carlton Hotel, Naples, Florida, febrero de 2006). Se pidi\u00f3 a los clientes que se calificaran seis factores: bienvenida, servicion, alimentos, atractivo del men\u00fa, atm\u00f3sfera y experiencia general. Se registraron datos para cada factor con las calificaiones de 1 para aceptable, 2 para normal, 3 para bueno y 4 para excelente.</p> <p>a) Las respuestas de los clientes proporcionaron datos para seis variables. \u00bfEstas variables son categ\u00f3ricas o cuantitativas? b) \u00bfQu\u00e9 escala de medici\u00f3n se utiliza?</p> <p>a) - Respuesta: Las variables son categ\u00f3ricas, ya que representan la calificaci\u00f3n de factores como bienvenida, servicio, alimentos, atractivo del men\u00fa, atm\u00f3sfera y experiencia general con valores discretos de 1 a 4.   b) - Respuesta: Se utiliza una escala ordinal, ya que los valores (1, 2, 3, 4) indican un orden de menor a mayor, pero la diferencia entre los valores no es necesariamente uniforme. Adem\u00e1s, la escala es discreta, ya que los clientes seleccionan valores espec\u00edficos (1, 2, 3, 4) en lugar de tener opciones continuas.  </p> <p>Ejercicio 8.  El programa FinancialTimes/Harris Poll es una encuesta mensual en l\u00ednea para adultos de seis pa\u00edses de Europa y Estados Unidos. Una encuesta de enero incluy\u00f3 a 1015 adultos de Estados Unidos. Una de las preguntas fue: \"\u00bfC\u00f3mo calificar\u00eda usted al Federal Bank en el manejo de los problemas de cr\u00e9dito en los mercados financieros?\" Las respuestas posibles fueron excelente, bueno, aceptable, malo y muy malo(sitio web Harris Interactive, enero de 2008).</p> <p>a) \u00bfDe qu\u00e9 tama\u00f1o fue la muestra para esta encuesta? b) \u00bfLos datos son categ\u00f3ricos o cuantitativos? c) \u00bfTendr\u00eda m\u00e1s sentido usar promedios o porcentajes como resumen de los datos para esta pregunta? d) De los encuestados en Estados Unidos, 10% dijo que el Federal Bank est\u00e1 efectuando un buen trabajo. \u00bfCu\u00e1ntas personas proporcionaron esta respuesta?</p> <p>a) - Respuesta: La informaci\u00f3n proporcionada no especifica el tama\u00f1o exacto de la muestra. Ser\u00eda necesario tener esa informaci\u00f3n espec\u00edfica para responder a esta pregunta.   b) - Respuesta: Los datos son categ\u00f3ricos, ya que las respuestas posibles son categor\u00edas como \"excelente\", \"bueno\", \"aceptable\", \"malo\" y \"muy malo\".   c) - Respuesta: Dado que las respuestas son categor\u00edas ordinales, tendr\u00eda m\u00e1s sentido utilizar porcentajes para resumir los datos. Calificar el desempe\u00f1o en t\u00e9rminos de porcentajes permitir\u00eda comprender la proporci\u00f3n de personas que eligieron cada categor\u00eda en relaci\u00f3n con el total de encuestados.   d) - Respuesta: La cantidad de personas que proporcionaron esta respuesta no se puede determinar sin conocer el tama\u00f1o total de la muestra. Para calcular el n\u00famero exacto, necesitar\u00edas el tama\u00f1o total de la muestra y calcular el 10% de esa cifra.   </p> <p>Ejercicio 9.  El Departamento de Comercio inform\u00f3 que recibi\u00f3 las aplicaciones siguientes para el Premio Nacional de Calidad Malcolm Baldrige: 23 de las empresas de manufactura grandes, 18 de las empresas de servicios grandes y 30 de las peque\u00f1as empresas. </p> <p>a) \u00bfEl tipo de empresa es una variable categ\u00f3rica o cuantitativa? b) \u00bfQu\u00e9 porcentaje de las aplicaciones proviene de las peque\u00f1as empresas?</p> <p>a) - Respuesta: El tipo de empresa es una variable categ\u00f3rica, ya que se clasifica en categor\u00edas discretas: empresas de manufactura grandes, empresas de servicios grandes y peque\u00f1as empresas.   b) - Respuesta: Para calcular el porcentaje de aplicaciones provenientes de las peque\u00f1as empresas, podemos utilizar la f\u00f3rmula:  <p>$$ \\text{Porcentaje de peque\u00f1as empresas} = \\left( \\frac{\\text{N\u00famero de aplicaciones de peque\u00f1as empresas}}{\\text{Total de aplicaciones}} \\right) \\times 100 $$</p> <p>Dado que el n\u00famero de aplicaciones de peque\u00f1as empresas es 30 y el total de aplicaciones es la suma de los tres tipos de empresas (23 + 18 + 30 = 71), podemos calcular el porcentaje:</p> <p>$$ \\text{Porcentaje de peque\u00f1as empresas} = \\left( \\frac{30}{71} \\right) \\times 100 \\approx 42.25\\% $$</p> <p>Por lo tanto, aproximadamente el 42.25% de las aplicaciones proviene de las peque\u00f1as empresas.</p> </p> <p>Ejercicio 10.  La encuesta a suscriptores de The Wall Street Journal (WSJ) (13 de octubre de 2003) formul\u00f3 46 preguntas sobre las caracter\u00edsticas y los intereses de los lectores. Determine si cada una de las preguntas siguientes proporcion\u00f3 datos categ\u00f3ricos o cuantitativos, e indique la escala de me\u0002dici\u00f3n apropiada para cada uno.</p> <p>a) \u00bfQu\u00e9 edad tiene? b) \u00bfEs usted hombre o mujer? c) \u00bfCu\u00e1ndo empez\u00f3 a leer el WSJ? \u00bfEn secundaria, bachillerato, a principios de la carrera, a mitad de la carrera, a finales de la carrera o en el retiro? d) \u00bfCu\u00e1nto tiempo lleva en su empleo o puesto actual? e) \u00bfQu\u00e9 tipo de veh\u00edculo est\u00e1 considerando para su compra siguiente? Nueve categor\u00edas de respuesta incluyen autom\u00f3viles sed\u00e1n, autom\u00f3viles deportivos, veh\u00edculos todo terreno, minivans, etc\u00e9tera.</p> In\u00a0[\u00a0]: Copied! <pre># Creando un diccionario con las preguntas y sus respectivas respuestas\nrespuesta_encuesta = {\n    \"a. \u00bfCu\u00e1l es su edad?\": {\n        \"Tipo de Datos\": \"Cuantitativos\",\n        \"Escala de Medici\u00f3n\": \"Raz\u00f3n\"\n    },\n    \"b. \u00bfEs usted hombre o mujer?\": {\n        \"Tipo de Datos\": \"Cualitativos\",\n        \"Escala de Medici\u00f3n\": \"Nominal\"\n    },\n    \"c. \u00bfCu\u00e1ndo empez\u00f3 a leer el WSJ?\": {\n        \"Tipo de Datos\": \"Cualitativos\",\n        \"Escala de Medici\u00f3n\": \"Ordinal\"\n    },\n    \"d. \u00bfCu\u00e1nto tiempo hace que tiene su trabajo o cargo actual?\": {\n        \"Tipo de Datos\": \"Cuantitativos\",\n        \"Escala de Medici\u00f3n\": \"Raz\u00f3n\"\n    },\n    \"e. \u00bfQu\u00e9 tipo de autom\u00f3vil piensa comprarse la pr\u00f3xima vez que compre uno?\": {\n        \"Tipo de Datos\": \"Cualitativos\",\n        \"Escala de Medici\u00f3n\": \"Nominal\"\n    }\n}\n\n# Imprimir las respuestas\nfor pregunta, info in respuesta_encuesta.items():\n    print(pregunta)\n    for clave, valor in info.items():\n        print(f\"  - {clave}: {valor}\")\n    print()\n</pre> # Creando un diccionario con las preguntas y sus respectivas respuestas respuesta_encuesta = {     \"a. \u00bfCu\u00e1l es su edad?\": {         \"Tipo de Datos\": \"Cuantitativos\",         \"Escala de Medici\u00f3n\": \"Raz\u00f3n\"     },     \"b. \u00bfEs usted hombre o mujer?\": {         \"Tipo de Datos\": \"Cualitativos\",         \"Escala de Medici\u00f3n\": \"Nominal\"     },     \"c. \u00bfCu\u00e1ndo empez\u00f3 a leer el WSJ?\": {         \"Tipo de Datos\": \"Cualitativos\",         \"Escala de Medici\u00f3n\": \"Ordinal\"     },     \"d. \u00bfCu\u00e1nto tiempo hace que tiene su trabajo o cargo actual?\": {         \"Tipo de Datos\": \"Cuantitativos\",         \"Escala de Medici\u00f3n\": \"Raz\u00f3n\"     },     \"e. \u00bfQu\u00e9 tipo de autom\u00f3vil piensa comprarse la pr\u00f3xima vez que compre uno?\": {         \"Tipo de Datos\": \"Cualitativos\",         \"Escala de Medici\u00f3n\": \"Nominal\"     } }  # Imprimir las respuestas for pregunta, info in respuesta_encuesta.items():     print(pregunta)     for clave, valor in info.items():         print(f\"  - {clave}: {valor}\")     print() <pre>a. \u00bfCu\u00e1l es su edad?\n  - Tipo de Datos: Cuantitativos\n  - Escala de Medici\u00f3n: Raz\u00f3n\n\nb. \u00bfEs usted hombre o mujer?\n  - Tipo de Datos: Cualitativos\n  - Escala de Medici\u00f3n: Nominal\n\nc. \u00bfCu\u00e1ndo empez\u00f3 a leer el WSJ?\n  - Tipo de Datos: Cualitativos\n  - Escala de Medici\u00f3n: Ordinal\n\nd. \u00bfCu\u00e1nto tiempo hace que tiene su trabajo o cargo actual?\n  - Tipo de Datos: Cuantitativos\n  - Escala de Medici\u00f3n: Raz\u00f3n\n\ne. \u00bfQu\u00e9 tipo de autom\u00f3vil piensa comprarse la pr\u00f3xima vez que compre uno?\n  - Tipo de Datos: Cualitativos\n  - Escala de Medici\u00f3n: Nominal\n\n</pre> <p>Ejercicio 11.  Determine si cada una de las variables siguientes es categ\u00f3rica o cuantitativa, e indique su escala de medici\u00f3n.</p> <p>a) Ventas anuales. b) Tama\u00f1o de bebida refrescante (peque\u00f1o, mediano, grande). c) Clasificaci\u00f3n de empleados (de gs1 a gs18). d) Utilidades por acci\u00f3n. e) M\u00e9todo de pago (efectivo, cheques, tarjeta de cr\u00e9dito).</p> In\u00a0[\u00a0]: Copied! <pre># Creando un diccionario con las variables y sus respectivas clasificaciones\nclasificacion_variables = {\n    \"a. Ventas anuales\": {\n        \"Tipo de Dato\": \"Cuantitativo\",\n        \"Escala de Medici\u00f3n\": \"Raz\u00f3n\"\n    },\n    \"b. Tama\u00f1o de los refrescos (peque\u00f1o, mediano, grande)\": {\n        \"Tipo de Dato\": \"Cualitativo\",\n        \"Escala de Medici\u00f3n\": \"Ordinal\"\n    },\n    \"c. Clasificaci\u00f3n como empleado (GS 1 a GS 18)\": {\n        \"Tipo de Dato\": \"Cuantitativo\",\n        \"Escala de Medici\u00f3n\": \"Ordinal\"\n    },\n    \"d. Ganancia por acci\u00f3n\": {\n        \"Tipo de Dato\": \"Cuantitativo\",\n        \"Escala de Medici\u00f3n\": \"Raz\u00f3n\"\n    },\n    \"e. Modo de pago (al contado, cheque, tarjeta de cr\u00e9dito)\": {\n        \"Tipo de Dato\": \"Cualitativo\",\n        \"Escala de Medici\u00f3n\": \"Nominal\"\n    }\n}\n\n# Imprimir las clasificaciones\nfor variable, info in clasificacion_variables.items():\n    print(variable)\n    for clave, valor in info.items():\n        print(f\"  - {clave}: {valor}\")\n    print()\n</pre> # Creando un diccionario con las variables y sus respectivas clasificaciones clasificacion_variables = {     \"a. Ventas anuales\": {         \"Tipo de Dato\": \"Cuantitativo\",         \"Escala de Medici\u00f3n\": \"Raz\u00f3n\"     },     \"b. Tama\u00f1o de los refrescos (peque\u00f1o, mediano, grande)\": {         \"Tipo de Dato\": \"Cualitativo\",         \"Escala de Medici\u00f3n\": \"Ordinal\"     },     \"c. Clasificaci\u00f3n como empleado (GS 1 a GS 18)\": {         \"Tipo de Dato\": \"Cuantitativo\",         \"Escala de Medici\u00f3n\": \"Ordinal\"     },     \"d. Ganancia por acci\u00f3n\": {         \"Tipo de Dato\": \"Cuantitativo\",         \"Escala de Medici\u00f3n\": \"Raz\u00f3n\"     },     \"e. Modo de pago (al contado, cheque, tarjeta de cr\u00e9dito)\": {         \"Tipo de Dato\": \"Cualitativo\",         \"Escala de Medici\u00f3n\": \"Nominal\"     } }  # Imprimir las clasificaciones for variable, info in clasificacion_variables.items():     print(variable)     for clave, valor in info.items():         print(f\"  - {clave}: {valor}\")     print()  <pre>a. Ventas anuales\n\n  - Tipo de Dato: Cuantitativo\n\n  - Escala de Medici\u00f3n: Raz\u00f3n\n\n\n\nb. Tama\u00f1o de los refrescos (peque\u00f1o, mediano, grande)\n\n  - Tipo de Dato: Cualitativo\n\n  - Escala de Medici\u00f3n: Ordinal\n\n\n\nc. Clasificaci\u00f3n como empleado (GS 1 a GS 18)\n\n  - Tipo de Dato: Cuantitativo\n\n  - Escala de Medici\u00f3n: Ordinal\n\n\n\nd. Ganancia por acci\u00f3n\n\n  - Tipo de Dato: Cuantitativo\n\n  - Escala de Medici\u00f3n: Raz\u00f3n\n\n\n\ne. Modo de pago (al contado, cheque, tarjeta de cr\u00e9dito)\n\n  - Tipo de Dato: Cualitativo\n\n  - Escala de Medici\u00f3n: Nominal\n\n\n</pre> <p>Ejercicio 12.  La agencia Hawaii Visitors Bureau recaba datos sobre los visitantes a Hawaii. Las preguntas siguientes se incluyeron entre las 16 formuladas en un cuestionario que se proporcion\u00f3 a los pasajeros durante los vuelos entrantes de la aerol\u00ednea en junio de 2003.</p> <ul> <li>Este viaje a Hawaii es mi: 1o., 2o., 3o., 4o., etc\u00e9tera.</li> <li>La raz\u00f3n principal para este viaje es: (10 categor\u00edas que incluyen vacaciones, convenci\u00f3n, luna de miel).</li> <li>D\u00f3nde planeo hospedarme: (11 categor\u00edas que incluyen hotel, departamento, parientes, acampar).</li> <li>D\u00edas totales en Hawaii.</li> </ul> <p>a) \u00bfQu\u00e9 poblaci\u00f3n se estudia?  b) \u00bfEl uso de un cuestionario es una buena manera de llegar a la poblaci\u00f3n de pasajeros en los vuelos de aerol\u00edneas entrantes?  c) Comente si cada una de las cuatro preguntas le proporcionar\u00e1 datos categ\u00f3ricos o cuantitativos. </p> In\u00a0[\u00a0]: Copied! <pre># Definici\u00f3n de las respuestas\nrespuestas = {\n    'a': \"La poblaci\u00f3n que se estudia son todos los pasajeros de un vuelo de llegada a Hawai en junio de 2003.\",\n    'b': \"El uso de un cuestionario puede ser una buena manera de obtener informaci\u00f3n de los pasajeros en los vuelos de llegada, ya que permite recopilar datos estandarizados de una muestra representativa de manera eficiente.\",\n    'c': {\n        'Este viaje a Hawai es mi 1o., 2o., 3o., 4o. etc.': 'Cuantitativo - Datos de conteo que representan la frecuencia de visitas.',\n        'La principal raz\u00f3n de este viaje es:': 'Cualitativo - Datos categ\u00f3ricos que representan la raz\u00f3n del viaje.',\n        'D\u00f3nde voy a alojarme:': 'Cualitativo - Datos categ\u00f3ricos que representan el tipo de alojamiento.',\n        'Total de d\u00edas en Hawai': 'Cuantitativo - Datos num\u00e9ricos que representan la duraci\u00f3n de la estancia.'\n    }\n}\n\n# Imprimir las respuestas\nfor pregunta, respuesta in respuestas.items():\n    if isinstance(respuesta, dict):\n        print(f'{pregunta}:')\n        for subpregunta, subrespuesta in respuesta.items():\n            print(f'  - {subpregunta}: {subrespuesta}')\n    else:\n        print(f'{pregunta}: {respuesta}')\n</pre> # Definici\u00f3n de las respuestas respuestas = {     'a': \"La poblaci\u00f3n que se estudia son todos los pasajeros de un vuelo de llegada a Hawai en junio de 2003.\",     'b': \"El uso de un cuestionario puede ser una buena manera de obtener informaci\u00f3n de los pasajeros en los vuelos de llegada, ya que permite recopilar datos estandarizados de una muestra representativa de manera eficiente.\",     'c': {         'Este viaje a Hawai es mi 1o., 2o., 3o., 4o. etc.': 'Cuantitativo - Datos de conteo que representan la frecuencia de visitas.',         'La principal raz\u00f3n de este viaje es:': 'Cualitativo - Datos categ\u00f3ricos que representan la raz\u00f3n del viaje.',         'D\u00f3nde voy a alojarme:': 'Cualitativo - Datos categ\u00f3ricos que representan el tipo de alojamiento.',         'Total de d\u00edas en Hawai': 'Cuantitativo - Datos num\u00e9ricos que representan la duraci\u00f3n de la estancia.'     } }  # Imprimir las respuestas for pregunta, respuesta in respuestas.items():     if isinstance(respuesta, dict):         print(f'{pregunta}:')         for subpregunta, subrespuesta in respuesta.items():             print(f'  - {subpregunta}: {subrespuesta}')     else:         print(f'{pregunta}: {respuesta}')  <pre>a: La poblaci\u00f3n que se estudia son todos los pasajeros de un vuelo de llegada a Hawai en junio de 2003.\n\nb: El uso de un cuestionario puede ser una buena manera de obtener informaci\u00f3n de los pasajeros en los vuelos de llegada, ya que permite recopilar datos estandarizados de una muestra representativa de manera eficiente.\n\nc:\n\n  - Este viaje a Hawai es mi 1o., 2o., 3o., 4o. etc.: Cuantitativo - Datos de conteo que representan la frecuencia de visitas.\n\n  - La principal raz\u00f3n de este viaje es:: Cualitativo - Datos categ\u00f3ricos que representan la raz\u00f3n del viaje.\n\n  - D\u00f3nde voy a alojarme:: Cualitativo - Datos categ\u00f3ricos que representan el tipo de alojamiento.\n\n  - Total de d\u00edas en Hawai: Cuantitativo - Datos num\u00e9ricos que representan la duraci\u00f3n de la estancia.\n</pre> <p>Ejercicio 13.  . La figura 1.8 proporciona una gr\u00e1fica de barras que muestra la cantidad de gasto federal para los a\u00f1os 2002 a 2008 (USA Today, 5 de febrero de 2008).</p> <p>a) \u00bfCu\u00e1l es la variable de inter\u00e9s?  b) \u00bfLos datos son categ\u00f3ricos o cuantitativos?  c) \u00bfLos datos son series de tiempo o de corte transversal?  d) Comente sobre la tendencia en el gasto federal con respecto al tiempo. </p> <p> Figura 1.8 Gastos Federales </p> In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Asumiendo que tenemos los siguientes datos ficticios para las ganancias de millones de euros\n# Estos valores son inventados y no reflejan los datos de la imagen real\nganancias = [2.0, 2.2, 2.3, 2.4,2.6, 2.7, 2.9]\na\u00f1os = ['2002', '2003', '2004', '2005','2006','2007','2008']\n\n# Crear una gr\u00e1fica de barras\nplt.figure(figsize=(10, 5))\nplt.bar(a\u00f1os, ganancias, color='#5CCB5F', edgecolor='black',linewidth=1.5, width=0.45)\nplt.xlabel('A\u00f1o',fontsize=10, fontweight='bold')\nplt.ylabel('Gasto federal ($billones)',fontsize=10, fontweight='bold')\nplt.xticks(rotation=45)\n\nax = plt.gca()\nax.set_facecolor('#D4F8B7')  # Color de fondo claro\nfig = plt.gcf()\nfig.patch.set_facecolor('#D4F8B7')  # Color de fondo para la figura\n\nplt.tight_layout()\n</pre> import matplotlib.pyplot as plt  # Asumiendo que tenemos los siguientes datos ficticios para las ganancias de millones de euros # Estos valores son inventados y no reflejan los datos de la imagen real ganancias = [2.0, 2.2, 2.3, 2.4,2.6, 2.7, 2.9] a\u00f1os = ['2002', '2003', '2004', '2005','2006','2007','2008']  # Crear una gr\u00e1fica de barras plt.figure(figsize=(10, 5)) plt.bar(a\u00f1os, ganancias, color='#5CCB5F', edgecolor='black',linewidth=1.5, width=0.45) plt.xlabel('A\u00f1o',fontsize=10, fontweight='bold') plt.ylabel('Gasto federal ($billones)',fontsize=10, fontweight='bold') plt.xticks(rotation=45)  ax = plt.gca() ax.set_facecolor('#D4F8B7')  # Color de fondo claro fig = plt.gcf() fig.patch.set_facecolor('#D4F8B7')  # Color de fondo para la figura  plt.tight_layout()  In\u00a0[\u00a0]: Copied! <pre>respuestas = {\n    'a': \"La variable de inter\u00e9s ser\u00eda la cantidad de gasto federal.\",\n    'b': \"Para determinar si los datos son categ\u00f3ricos o cuantitativos, necesitar\u00eda saber si la cantidad de gasto federal se mide en t\u00e9rminos de cantidades num\u00e9ricas (cuantitativo) o si se clasifica en categor\u00edas (categ\u00f3rico). Si la cantidad se expresa en n\u00fameros, entonces es cuantitativa.\",\n    'c': \"La distinci\u00f3n entre series de tiempo y datos de corte transversal depende de c\u00f3mo se recopilan los datos. Si la informaci\u00f3n se recopila a lo largo del tiempo para los a\u00f1os 2002 a 2008, entonces se trata de datos de series temporales.\",\n    'd': \"La tendencia en el gasto federal con respecto al tiempo puede ser evaluada observando la direcci\u00f3n general de los datos a lo largo de los a\u00f1os. Si la cantidad de gasto federal aumenta o disminuye de manera consistente a medida que pasa el tiempo, se puede identificar una tendencia.\"\n}\n# Imprimir las respuestas\nfor pregunta, respuesta in respuestas.items():\n    print(f'{pregunta}: {respuesta}')\n</pre>  respuestas = {     'a': \"La variable de inter\u00e9s ser\u00eda la cantidad de gasto federal.\",     'b': \"Para determinar si los datos son categ\u00f3ricos o cuantitativos, necesitar\u00eda saber si la cantidad de gasto federal se mide en t\u00e9rminos de cantidades num\u00e9ricas (cuantitativo) o si se clasifica en categor\u00edas (categ\u00f3rico). Si la cantidad se expresa en n\u00fameros, entonces es cuantitativa.\",     'c': \"La distinci\u00f3n entre series de tiempo y datos de corte transversal depende de c\u00f3mo se recopilan los datos. Si la informaci\u00f3n se recopila a lo largo del tiempo para los a\u00f1os 2002 a 2008, entonces se trata de datos de series temporales.\",     'd': \"La tendencia en el gasto federal con respecto al tiempo puede ser evaluada observando la direcci\u00f3n general de los datos a lo largo de los a\u00f1os. Si la cantidad de gasto federal aumenta o disminuye de manera consistente a medida que pasa el tiempo, se puede identificar una tendencia.\" } # Imprimir las respuestas for pregunta, respuesta in respuestas.items():     print(f'{pregunta}: {respuesta}') <pre>a: La variable de inter\u00e9s ser\u00eda la cantidad de gasto federal.\nb: Para determinar si los datos son categ\u00f3ricos o cuantitativos, necesitar\u00eda saber si la cantidad de gasto federal se mide en t\u00e9rminos de cantidades num\u00e9ricas (cuantitativo) o si se clasifica en categor\u00edas (categ\u00f3rico). Si la cantidad se expresa en n\u00fameros, entonces es cuantitativa.\nc: La distinci\u00f3n entre series de tiempo y datos de corte transversal depende de c\u00f3mo se recopilan los datos. Si la informaci\u00f3n se recopila a lo largo del tiempo para los a\u00f1os 2002 a 2008, entonces se trata de datos de series temporales.\nd: La tendencia en el gasto federal con respecto al tiempo puede ser evaluada observando la direcci\u00f3n general de los datos a lo largo de los a\u00f1os. Si la cantidad de gasto federal aumenta o disminuye de manera consistente a medida que pasa el tiempo, se puede identificar una tendencia.\n</pre> <p>Ejercicio 14. CSM Worldwide efect\u00faa pron\u00f3sticos de la producci\u00f3n global para todos los fabricantes de autom\u00f3viles. Los siguientes datos de CSM muestran el pron\u00f3stico de la producci\u00f3n global de autom\u00f3viles para General Motors, Ford, DaimlerChrysler y Toyota para los a\u00f1os 2004 a 2007 (USA Today, 21 de diciembre de 2005). Los datos est\u00e1n en millones de veh\u00edculos.</p> <p>a) Elabore una gr\u00e1fica de series de tiempo para los a\u00f1os 2004 a 2007 que muestre el n\u00famero de veh\u00edculos fabricados por cada compa\u00f1\u00eda automotriz. Muestre las series de tiempo para los cuatro fabricantes en la misma gr\u00e1fica.  b) General Motors ha sido el l\u00edder indiscutible en la producci\u00f3n de autom\u00f3viles desde 1931. \u00bfQu\u00e9 muestra la gr\u00e1fica de serie de tiempo sobre cu\u00e1l es la compa\u00f1\u00eda automotriz m\u00e1s importante del mundo? Comente.  c) Elabore una gr\u00e1fica de barras que muestre los veh\u00edculos producidos por los fabricantes de autom\u00f3viles usando los datos de 2007. \u00bfEsta gr\u00e1fica se basa en datos de corte transversal o de series de tiempo? </p> In\u00a0[10]: Copied! <pre>import matplotlib.pyplot as plt\nimport pandas as pd\n\n# Datos de producci\u00f3n de veh\u00edculos por fabricante y a\u00f1o\ndatos_produccion = {\n    'General Motors': {'2004': 8.9, '2005': 9.0, '2006': 8.9, '2007': 8.8},\n    'Ford': {'2004': 7.8, '2005': 7.7, '2006': 7.8, '2007': 7.9},\n    'DaimlerChrysler': {'2004': 4.1, '2005': 4.2, '2006': 4.3, '2007': 4.6},\n    'Toyota': {'2004': 7.8, '2005': 8.3, '2006': 9.1, '2007': 9.6},\n}\n\n# Convertir los datos a un DataFrame\ndf_produccion = pd.DataFrame(datos_produccion)\n\n# Establecer el color de fondo del gr\u00e1fico\nplt.figure(figsize=(10, 5), facecolor='#D4F8B7')\nax = plt.gca()\nax.set_facecolor('#D4F8B7')  # Color de fondo claro\n\n# Colores para cada fabricante\ncolores = {'General Motors': '#009929', 'Ford': 'green', 'DaimlerChrysler': '#5ccb5f', 'Toyota': '#98f84a'}\n\n# Crear una gr\u00e1fica de l\u00edneas para cada fabricante con colores personalizados\nfor fabricante in df_produccion.columns:\n    plt.plot(df_produccion.index, df_produccion[fabricante], marker='o', label=fabricante, color=colores[fabricante])\n\nplt.title('Producci\u00f3n de Veh\u00edculos (2004-2007)')\nplt.xlabel('A\u00f1o')\nplt.ylabel('Producci\u00f3n (en millones)')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\n\n# Guardar la gr\u00e1fica en un archivo\nplt.savefig('produccion_vehiculos.png')\nplt.show()\n\n\n# Respuestas a las preguntas\nrespuestas = {\n    'a': \"La gr\u00e1fica de series de tiempo para los a\u00f1os 2004 a 2007 se ha generado arriba.\",\n    'b': \"Seg\u00fan la gr\u00e1fica, Toyota ha mostrado un aumento significativo en la producci\u00f3n y es el mayor productor en 2007.\",\n    'c': \"La gr\u00e1fica de secci\u00f3n transversal para el a\u00f1o 2007 mostrar\u00eda la producci\u00f3n de veh\u00edculos de ese a\u00f1o para cada fabricante. Los datos son de secci\u00f3n transversal porque representan un corte en un punto en el tiempo, en este caso, el a\u00f1o 2007.\"\n}\n\n# Imprimir las respuestas\nfor pregunta, respuesta in respuestas.items():\n    print(f'{pregunta}: {respuesta}')\n</pre> import matplotlib.pyplot as plt import pandas as pd  # Datos de producci\u00f3n de veh\u00edculos por fabricante y a\u00f1o datos_produccion = {     'General Motors': {'2004': 8.9, '2005': 9.0, '2006': 8.9, '2007': 8.8},     'Ford': {'2004': 7.8, '2005': 7.7, '2006': 7.8, '2007': 7.9},     'DaimlerChrysler': {'2004': 4.1, '2005': 4.2, '2006': 4.3, '2007': 4.6},     'Toyota': {'2004': 7.8, '2005': 8.3, '2006': 9.1, '2007': 9.6}, }  # Convertir los datos a un DataFrame df_produccion = pd.DataFrame(datos_produccion)  # Establecer el color de fondo del gr\u00e1fico plt.figure(figsize=(10, 5), facecolor='#D4F8B7') ax = plt.gca() ax.set_facecolor('#D4F8B7')  # Color de fondo claro  # Colores para cada fabricante colores = {'General Motors': '#009929', 'Ford': 'green', 'DaimlerChrysler': '#5ccb5f', 'Toyota': '#98f84a'}  # Crear una gr\u00e1fica de l\u00edneas para cada fabricante con colores personalizados for fabricante in df_produccion.columns:     plt.plot(df_produccion.index, df_produccion[fabricante], marker='o', label=fabricante, color=colores[fabricante])  plt.title('Producci\u00f3n de Veh\u00edculos (2004-2007)') plt.xlabel('A\u00f1o') plt.ylabel('Producci\u00f3n (en millones)') plt.legend() plt.grid(True) plt.tight_layout()  # Guardar la gr\u00e1fica en un archivo plt.savefig('produccion_vehiculos.png') plt.show()   # Respuestas a las preguntas respuestas = {     'a': \"La gr\u00e1fica de series de tiempo para los a\u00f1os 2004 a 2007 se ha generado arriba.\",     'b': \"Seg\u00fan la gr\u00e1fica, Toyota ha mostrado un aumento significativo en la producci\u00f3n y es el mayor productor en 2007.\",     'c': \"La gr\u00e1fica de secci\u00f3n transversal para el a\u00f1o 2007 mostrar\u00eda la producci\u00f3n de veh\u00edculos de ese a\u00f1o para cada fabricante. Los datos son de secci\u00f3n transversal porque representan un corte en un punto en el tiempo, en este caso, el a\u00f1o 2007.\" }  # Imprimir las respuestas for pregunta, respuesta in respuestas.items():     print(f'{pregunta}: {respuesta}') <pre>a: La gr\u00e1fica de series de tiempo para los a\u00f1os 2004 a 2007 se ha generado arriba.\nb: Seg\u00fan la gr\u00e1fica, Toyota ha mostrado un aumento significativo en la producci\u00f3n y es el mayor productor en 2007.\nc: La gr\u00e1fica de secci\u00f3n transversal para el a\u00f1o 2007 mostrar\u00eda la producci\u00f3n de veh\u00edculos de ese a\u00f1o para cada fabricante. Los datos son de secci\u00f3n transversal porque representan un corte en un punto en el tiempo, en este caso, el a\u00f1o 2007.\n</pre> <p>Ejercicio 15.  La Food and Drug Administration (Administraci\u00f3n de Alimentos y F\u00e1rmacos, FDA) report\u00f3 el n\u00famero de f\u00e1rmacos nuevos aprobados durante un periodo de ocho a\u00f1os (The Wall Street Journal, 12 de enero de 2004). La figura 1.9 muestra una gr\u00e1fica de barras que resume el n\u00famero de medicamentos nuevos aprobado cada a\u00f1o.</p> <p>a) \u00bfLos datos son categ\u00f3ricos o cuantitativos?  b) \u00bfLos datos son de series de tiempo o de corte transversal?  c) \u00bfCu\u00e1ntos medicamentos nuevos se aprobaron en 2003?  d) \u00bfEn qu\u00e9 a\u00f1o se aprob\u00f3 el menor n\u00famero de f\u00e1rmacos nuevos? \u00bfCu\u00e1ntos fueron?  e) Comente la tendencia en el n\u00famero de medicamentos nuevos aprobados por la fda durante el periodo de ocho a\u00f1os. </p> <p> Figura 1.9 N\u00famero de f\u00e1rmacos nuevos aprobados por la FDA </p> In\u00a0[11]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Asumiendo que tenemos los siguientes datos ficticios que representan la cantidad de medicamentos nuevos\n# aprobados por la FDA de 1996 a 2003. Estos valores son inventados para el prop\u00f3sito de este ejemplo.\ndatos_medicamentos = {\n    'A\u00f1o': ['1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003'],\n    'Cantidad de medicamentos nuevos': [52, 45, 35, 38, 32, 28, 23, 18]  # Estos datos son hipot\u00e9ticos\n}\n\n# Crear una gr\u00e1fica de barras para representar los datos\nplt.figure(figsize=(10, 5), facecolor='#D4F8B7')\nax = plt.gca()\nax.set_facecolor('#D4F8B7')  # Color de fondo claro\nplt.bar(datos_medicamentos['A\u00f1o'], datos_medicamentos['Cantidad de medicamentos nuevos'], color='#5CCB5f',edgecolor='black',linewidth=1.5, width=0.45)\nplt.xlabel('A\u00f1o',fontsize=10, fontweight='bold')\nplt.ylabel('Cantidad de Medicamentos Nuevos',fontsize=10, fontweight='bold')\nplt.tight_layout()\n\n# Mostrar la gr\u00e1fica\nplt.show()\n\n# Encontrar el a\u00f1o con el menor n\u00famero de medicamentos aprobados\nmin_medicamentos = min(datos_medicamentos['Cantidad de medicamentos nuevos'])\na\u00f1o_min_medicamentos = datos_medicamentos['A\u00f1o'][datos_medicamentos['Cantidad de medicamentos nuevos'].index(min_medicamentos)]\n\n# Respuestas a las preguntas\nrespuestas = {\n    'a': \"Los datos son cuantitativos, ya que representan conteos num\u00e9ricos de eventos.\",\n    'b': \"Son datos de series de tiempo, porque se registran a lo largo de varios a\u00f1os consecutivos.\",\n    'c': f\"En 2003, fueron aprobados {datos_medicamentos['Cantidad de medicamentos nuevos'][-1]} medicamentos.\",  # Asumiendo que el \u00faltimo valor corresponde a 2003\n    'd': f\"El a\u00f1o con menos medicamentos aprobados es {a\u00f1o_min_medicamentos} con {min_medicamentos} medicamentos.\",\n    'e': \"Se necesitar\u00eda analizar la gr\u00e1fica generada para comentar sobre la tendencia.\"\n}\n\n# Imprimir las respuestas\nfor pregunta, respuesta in respuestas.items():\n    print(f'{pregunta}: {respuesta}')\n</pre> import matplotlib.pyplot as plt  # Asumiendo que tenemos los siguientes datos ficticios que representan la cantidad de medicamentos nuevos # aprobados por la FDA de 1996 a 2003. Estos valores son inventados para el prop\u00f3sito de este ejemplo. datos_medicamentos = {     'A\u00f1o': ['1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003'],     'Cantidad de medicamentos nuevos': [52, 45, 35, 38, 32, 28, 23, 18]  # Estos datos son hipot\u00e9ticos }  # Crear una gr\u00e1fica de barras para representar los datos plt.figure(figsize=(10, 5), facecolor='#D4F8B7') ax = plt.gca() ax.set_facecolor('#D4F8B7')  # Color de fondo claro plt.bar(datos_medicamentos['A\u00f1o'], datos_medicamentos['Cantidad de medicamentos nuevos'], color='#5CCB5f',edgecolor='black',linewidth=1.5, width=0.45) plt.xlabel('A\u00f1o',fontsize=10, fontweight='bold') plt.ylabel('Cantidad de Medicamentos Nuevos',fontsize=10, fontweight='bold') plt.tight_layout()  # Mostrar la gr\u00e1fica plt.show()  # Encontrar el a\u00f1o con el menor n\u00famero de medicamentos aprobados min_medicamentos = min(datos_medicamentos['Cantidad de medicamentos nuevos']) a\u00f1o_min_medicamentos = datos_medicamentos['A\u00f1o'][datos_medicamentos['Cantidad de medicamentos nuevos'].index(min_medicamentos)]  # Respuestas a las preguntas respuestas = {     'a': \"Los datos son cuantitativos, ya que representan conteos num\u00e9ricos de eventos.\",     'b': \"Son datos de series de tiempo, porque se registran a lo largo de varios a\u00f1os consecutivos.\",     'c': f\"En 2003, fueron aprobados {datos_medicamentos['Cantidad de medicamentos nuevos'][-1]} medicamentos.\",  # Asumiendo que el \u00faltimo valor corresponde a 2003     'd': f\"El a\u00f1o con menos medicamentos aprobados es {a\u00f1o_min_medicamentos} con {min_medicamentos} medicamentos.\",     'e': \"Se necesitar\u00eda analizar la gr\u00e1fica generada para comentar sobre la tendencia.\" }  # Imprimir las respuestas for pregunta, respuesta in respuestas.items():     print(f'{pregunta}: {respuesta}') <pre>a: Los datos son cuantitativos, ya que representan conteos num\u00e9ricos de eventos.\nb: Son datos de series de tiempo, porque se registran a lo largo de varios a\u00f1os consecutivos.\nc: En 2003, fueron aprobados 18 medicamentos.\nd: El a\u00f1o con menos medicamentos aprobados es 2003 con 18 medicamentos.\ne: Se necesitar\u00eda analizar la gr\u00e1fica generada para comentar sobre la tendencia.\n</pre> <p>Ejercicio 16.  La Oficina de Informaci\u00f3n del Departamento de Energ\u00eda de Estados Unidos proporcion\u00f3 datos de series de tiempo para el precio promedio de gasolina regular convencional en d\u00f3lares por gal\u00f3n entre julio de 2006 y junio de 2009 (sitio web Energy Information Administration, junio de 2009). Use Internet para obtener el precio medio por gal\u00f3n de gasolina regular convencional desde junio de 2009.</p> <p>a) Ampl\u00ede la gr\u00e1fica de la serie de tiempo mostrada en la figura 1.1.  b) \u00bfQu\u00e9 interpretaciones puede hacer acerca del precio por gal\u00f3n de gasolina regular convencional desde junio de 2009?  c) \u00bfLa serie de tiempo sigue mostrando un incremento en verano en el precio promedio por gal\u00f3n? Explique por qu\u00e9. </p> In\u00a0[\u00a0]: Copied! <pre># Definici\u00f3n de respuestas para la planificaci\u00f3n de marketing de un nuevo refresco diet\u00e9tico\nrespuestas = {\n    'a': (\"el sitio web de la Energy Information Administration proporciona informaci\u00f3n sobre los precios de la gasolina en los Estados Unidos. Seg\u00fan el RACE, el precio de la gasolina regular en los Estados Unidos es de $2.99 por gal\u00f3n el 28 de noviembre de 2023.\"),\n    'b': (\" Interpretaciones sobre el precio por gal\u00f3n de gasolina regular convencional desde junio de 2009 pueden incluir an\u00e1lisis de tendencias a largo plazo, identificaci\u00f3n de picos y valles, y evaluaci\u00f3n de factores econ\u00f3micos y eventos mundiales que podr\u00edan haber afectado los precios del petr\u00f3leo y, por ende, los precios de la gasolina.\"),\n    'c': (\"Respecto a si la serie de tiempo muestra un incremento en verano en el precio promedio por gal\u00f3n, podr\u00edas realizar un an\u00e1lisis estacional para determinar patrones recurrentes en diferentes per\u00edodos del a\u00f1o. Los precios de la gasolina a menudo tienden a aumentar durante la temporada de viajes de verano debido a la mayor demanda de combustible. Sin embargo, esto puede variar seg\u00fan la regi\u00f3n y otros factores econ\u00f3micos.\")\n}\n\n# Imprimir las respuestas\nfor pregunta, respuesta in respuestas.items():\n    print(f'{pregunta}: {respuesta}\\n')\n</pre> # Definici\u00f3n de respuestas para la planificaci\u00f3n de marketing de un nuevo refresco diet\u00e9tico respuestas = {     'a': (\"el sitio web de la Energy Information Administration proporciona informaci\u00f3n sobre los precios de la gasolina en los Estados Unidos. Seg\u00fan el RACE, el precio de la gasolina regular en los Estados Unidos es de $2.99 por gal\u00f3n el 28 de noviembre de 2023.\"),     'b': (\" Interpretaciones sobre el precio por gal\u00f3n de gasolina regular convencional desde junio de 2009 pueden incluir an\u00e1lisis de tendencias a largo plazo, identificaci\u00f3n de picos y valles, y evaluaci\u00f3n de factores econ\u00f3micos y eventos mundiales que podr\u00edan haber afectado los precios del petr\u00f3leo y, por ende, los precios de la gasolina.\"),     'c': (\"Respecto a si la serie de tiempo muestra un incremento en verano en el precio promedio por gal\u00f3n, podr\u00edas realizar un an\u00e1lisis estacional para determinar patrones recurrentes en diferentes per\u00edodos del a\u00f1o. Los precios de la gasolina a menudo tienden a aumentar durante la temporada de viajes de verano debido a la mayor demanda de combustible. Sin embargo, esto puede variar seg\u00fan la regi\u00f3n y otros factores econ\u00f3micos.\") }  # Imprimir las respuestas for pregunta, respuesta in respuestas.items():     print(f'{pregunta}: {respuesta}\\n') <pre>a: el sitio web de la Energy Information Administration proporciona informaci\u00f3n sobre los precios de la gasolina en los Estados Unidos. Seg\u00fan el RACE, el precio de la gasolina regular en los Estados Unidos es de $2.99 por gal\u00f3n el 28 de noviembre de 2023.\n\nb:  Interpretaciones sobre el precio por gal\u00f3n de gasolina regular convencional desde junio de 2009 pueden incluir an\u00e1lisis de tendencias a largo plazo, identificaci\u00f3n de picos y valles, y evaluaci\u00f3n de factores econ\u00f3micos y eventos mundiales que podr\u00edan haber afectado los precios del petr\u00f3leo y, por ende, los precios de la gasolina.\n\nc: Respecto a si la serie de tiempo muestra un incremento en verano en el precio promedio por gal\u00f3n, podr\u00edas realizar un an\u00e1lisis estacional para determinar patrones recurrentes en diferentes per\u00edodos del a\u00f1o. Los precios de la gasolina a menudo tienden a aumentar durante la temporada de viajes de verano debido a la mayor demanda de combustible. Sin embargo, esto puede variar seg\u00fan la regi\u00f3n y otros factores econ\u00f3micos.\n\n</pre> <p>Ejercicio 17.  Un gerente de una corporaci\u00f3n grande recomienda que se otorgue un aumento de sueldo de $10 000 para evitar que un subordinado valioso se vaya a otra empresa. \u00bfQu\u00e9 fuentes de datos internas y externas podr\u00edan usarse para decidir si es apropiado este incremento?</p> <p>Para decidir si es apropiado el incremento de salario, se pueden utilizar las siguientes fuentes de datos:</p> <ol> <li>Internas: Historial salarial del empleado, evaluaciones de rendimiento, contribuciones al \u00e9xito de la empresa, y comparaci\u00f3n con salarios de empleados en puestos similares.</li> <li>Externas: Est\u00e1ndares de la industria para el puesto, tasas de retenci\u00f3n de empleados en la industria, ofertas salariales de empresas competidoras y tendencias del mercado laboral.</li> </ol> <p>Ejercicio 18.   Una encuesta a 430 viajeros de negocios revel\u00f3 que 155 de ellos usaron una agencia para ha\u0002cer sus arreglos de viaje (USA Today, 20 de noviembre de 2003).</p> <p>a) Desarrolle una estad\u00edstica descriptiva que se pueda usar para estimar el porcentaje de todos los viajeros de negocios que contratan una agencia de viajes para hacer sus arreglos respectivos.  b) La encuesta revel\u00f3 que la manera m\u00e1s frecuente en que los viajeros de negocios hacen sus arreglos de viaje es por medio de un sitio de viajes en l\u00ednea. Si 44% de los encuestados prepar\u00f3 sus arreglos de esta manera, \u00bfcu\u00e1ntos de los 430 viajeros de egocios usaron un sitio de viajes en l\u00ednea?  c) \u00bfLos datos sobre c\u00f3mo se hacen los arreglos de viaje son categ\u00f3ricos o cuantitativos? </p> In\u00a0[\u00a0]: Copied! <pre>def porcentaje_usaron_agencia(n_total, n_usaron_agencia):\n  \"\"\"\n  Calcula el porcentaje de viajeros que utilizaron una agencia de viajes.\n\n  Args:\n    n_total: El n\u00famero total de viajeros.\n    n_usaron_agencia: El n\u00famero de viajeros que utilizaron una agencia de viajes.\n\n  Returns:\n    El porcentaje de viajeros que utilizaron una agencia de viajes.\n  \"\"\"\n\n  return n_usaron_agencia / n_total * 100\n\n\nn_total = 430\nn_usaron_agencia = 155\n\nporcentaje_usaron_agencia = porcentaje_usaron_agencia(n_total, n_usaron_agencia)\n\nprint(\"Porcentaje de viajeros que usaron una agencia de viajes:\", porcentaje_usaron_agencia)\n\ndef numero_viajeros_sitio_en_linea(porcentaje, n_total):\n  \"\"\"\n  Calcula el n\u00famero de viajeros que utilizaron un sitio de viajes en l\u00ednea.\n\n  Args:\n    porcentaje: El porcentaje de viajeros que utilizaron un sitio de viajes en l\u00ednea.\n    n_total: El n\u00famero total de viajeros.\n\n  Returns:\n    El n\u00famero de viajeros que utilizaron un sitio de viajes en l\u00ednea.\n  \"\"\"\n\n  return porcentaje * n_total\n\n\nporcentaje = 0.44\nn_total = 430\n\nn_usaron_sitio_en_linea = numero_viajeros_sitio_en_linea(porcentaje, n_total)\n\nprint(\"N\u00famero de viajeros que usaron un sitio de viajes en l\u00ednea:\", n_usaron_sitio_en_linea)\n\ndef tipo_datos(datos):\n  \"\"\"\n  Determina el tipo de datos de un conjunto de datos.\n\n  Args:\n    datos: El conjunto de datos a analizar.\n\n  Returns:\n    El tipo de datos del conjunto de datos.\n  \"\"\"\n\n  if isinstance(datos[0], str):\n    return \"categ\u00f3rico\"\n  else:\n    return \"num\u00e9rico\"\n\n\ndatos = [\"agencia de viajes\", \"sitio de viajes en l\u00ednea\", \"agencia de viajes\", \"sitio de viajes en l\u00ednea\"]\n\ntipo_datos = tipo_datos(datos)\n\nprint(\"Tipo de datos:\", tipo_datos)\n</pre> def porcentaje_usaron_agencia(n_total, n_usaron_agencia):   \"\"\"   Calcula el porcentaje de viajeros que utilizaron una agencia de viajes.    Args:     n_total: El n\u00famero total de viajeros.     n_usaron_agencia: El n\u00famero de viajeros que utilizaron una agencia de viajes.    Returns:     El porcentaje de viajeros que utilizaron una agencia de viajes.   \"\"\"    return n_usaron_agencia / n_total * 100   n_total = 430 n_usaron_agencia = 155  porcentaje_usaron_agencia = porcentaje_usaron_agencia(n_total, n_usaron_agencia)  print(\"Porcentaje de viajeros que usaron una agencia de viajes:\", porcentaje_usaron_agencia)  def numero_viajeros_sitio_en_linea(porcentaje, n_total):   \"\"\"   Calcula el n\u00famero de viajeros que utilizaron un sitio de viajes en l\u00ednea.    Args:     porcentaje: El porcentaje de viajeros que utilizaron un sitio de viajes en l\u00ednea.     n_total: El n\u00famero total de viajeros.    Returns:     El n\u00famero de viajeros que utilizaron un sitio de viajes en l\u00ednea.   \"\"\"    return porcentaje * n_total   porcentaje = 0.44 n_total = 430  n_usaron_sitio_en_linea = numero_viajeros_sitio_en_linea(porcentaje, n_total)  print(\"N\u00famero de viajeros que usaron un sitio de viajes en l\u00ednea:\", n_usaron_sitio_en_linea)  def tipo_datos(datos):   \"\"\"   Determina el tipo de datos de un conjunto de datos.    Args:     datos: El conjunto de datos a analizar.    Returns:     El tipo de datos del conjunto de datos.   \"\"\"    if isinstance(datos[0], str):     return \"categ\u00f3rico\"   else:     return \"num\u00e9rico\"   datos = [\"agencia de viajes\", \"sitio de viajes en l\u00ednea\", \"agencia de viajes\", \"sitio de viajes en l\u00ednea\"]  tipo_datos = tipo_datos(datos)  print(\"Tipo de datos:\", tipo_datos) <pre>Porcentaje de viajeros que usaron una agencia de viajes: 36.04651162790697\nN\u00famero de viajeros que usaron un sitio de viajes en l\u00ednea: 189.2\nTipo de datos: categ\u00f3rico\n</pre> <p>Ejercicio 19.  Un estudio sobre los suscriptores de BusinessWeek en Norteam\u00e9rica recab\u00f3 datos de una mues\u0002tra de 2 861 clientes. El 59% de los encuestados indic\u00f3 un ingreso anual de $75 000 o m\u00e1s, y 50% inform\u00f3 tener una tarjeta de cr\u00e9dito de American Express.</p> <p>a) \u00bfCu\u00e1l es la poblaci\u00f3n de inter\u00e9s en este estudio?  b) \u00bfEl ingreso anual es una variable categ\u00f3rica o cuantitativa?  c) \u00bfLa propiedad de una tarjeta American Express es una variable categ\u00f3rica o cuantitativa?  d) \u00bfEste estudio involucra datos de corte transversal o de series de tiempo?  e) Describa cualquier inferencia estad\u00edstica que BusinessWeek podr\u00eda hacer sobre la base de la encuesta. </p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\n\n# Datos de la encuesta\ningreso_anual = np.array([1, 0, 1, 1, 0, 1, 1, 1, 0, 1])\ntarjeta_amex = np.array([1, 1, 0, 0, 1, 0, 1, 1, 1, 1])\n\n# Obtener la proporci\u00f3n de suscriptores con un ingreso anual de $75 000 o m\u00e1s\nproporcion_ingreso_alto = np.sum(ingreso_anual) / len(ingreso_anual)\n\n# Obtener la proporci\u00f3n de suscriptores con una tarjeta de cr\u00e9dito de American Express\nproporcion_tarjeta_amex = np.sum(tarjeta_amex) / len(tarjeta_amex)\n\n# Imprimir las proporciones\nprint(\"Proporci\u00f3n de suscriptores con un ingreso anual de $75 000 o m\u00e1s:\", proporcion_ingreso_alto)\nprint(\"Proporci\u00f3n de suscriptores con una tarjeta de cr\u00e9dito de American Express:\", proporcion_tarjeta_amex)\n\n# Calcular la correlaci\u00f3n entre el ingreso anual y la propiedad de una tarjeta American Express\ncorrelacion = np.corrcoef(ingreso_anual, tarjeta_amex)[0, 1]\n\n# Imprimir la correlaci\u00f3n\nprint(\"Correlaci\u00f3n entre el ingreso anual y la propiedad de una tarjeta American Express:\", correlacion)\n</pre> import numpy as np  # Datos de la encuesta ingreso_anual = np.array([1, 0, 1, 1, 0, 1, 1, 1, 0, 1]) tarjeta_amex = np.array([1, 1, 0, 0, 1, 0, 1, 1, 1, 1])  # Obtener la proporci\u00f3n de suscriptores con un ingreso anual de $75 000 o m\u00e1s proporcion_ingreso_alto = np.sum(ingreso_anual) / len(ingreso_anual)  # Obtener la proporci\u00f3n de suscriptores con una tarjeta de cr\u00e9dito de American Express proporcion_tarjeta_amex = np.sum(tarjeta_amex) / len(tarjeta_amex)  # Imprimir las proporciones print(\"Proporci\u00f3n de suscriptores con un ingreso anual de $75 000 o m\u00e1s:\", proporcion_ingreso_alto) print(\"Proporci\u00f3n de suscriptores con una tarjeta de cr\u00e9dito de American Express:\", proporcion_tarjeta_amex)  # Calcular la correlaci\u00f3n entre el ingreso anual y la propiedad de una tarjeta American Express correlacion = np.corrcoef(ingreso_anual, tarjeta_amex)[0, 1]  # Imprimir la correlaci\u00f3n print(\"Correlaci\u00f3n entre el ingreso anual y la propiedad de una tarjeta American Express:\", correlacion) <pre>Proporci\u00f3n de suscriptores con un ingreso anual de $75 000 o m\u00e1s: 0.7\nProporci\u00f3n de suscriptores con una tarjeta de cr\u00e9dito de American Express: 0.7\nCorrelaci\u00f3n entre el ingreso anual y la propiedad de una tarjeta American Express: -0.42857142857142844\n</pre> <p>Ejercicio 20.  Una consulta a 131 administradores de inversiones en la encuesta Big Money de Barron revel\u00f3 lo siguiente: </p> <ul> <li>43% de los gerentes se clasific\u00f3 a s\u00ed mismo como a la alza o muy a la alza en el mercado de valores.</li> <li>El rendimiento promedio esperado durante los 12 meses siguientes para los valores de renta variable fue 11.2%.</li> <li>El 21% seleccion\u00f3 la asistencia m\u00e9dica como el sector con m\u00e1s probabilidades de dirigir el mercado en los 12 meses siguientes.</li> <li>Cuando se les pidi\u00f3 que estimaran cu\u00e1nto tiempo tardar\u00edan las acciones de tecnolog\u00eda y telecomunicaciones en reanudar un crecimiento sostenido, la respuesta promedio de los gerentes fue 2.5 a\u00f1os.</li> </ul> <p>a) Cite dos estad\u00edsticas descriptivas.  b) Desarrolle una inferencia sobre la poblaci\u00f3n de todos los administradores de inversiones con respecto al rendimiento promedio esperado sobre los valores de renta variable durante los 12 meses siguientes.  c) Haga una inferencia sobre el tiempo que tardar\u00e1n las acciones de tecnolog\u00eda y telecomunicaciones en reanudar un crecimiento sostenido </p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\n\n# Datos de la encuesta\nclasificacion_mercado = np.array([1, 1, 1, 1, 1, 1, 0, 0, 0, 0])\nrendimiento_esperado = np.array([11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 10.5, 10.5, 10.5, 10.5])\ntiempo_recuperacion = np.array([2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 3.25, 3.25, 3.25, 3.25])\n\n# Obtener la proporci\u00f3n de administradores de inversiones que se clasifican a s\u00ed mismos como a la alza o muy a la alza\nproporcion_alza = np.sum(clasificacion_mercado) / len(clasificacion_mercado)\n\n# Obtener el rendimiento promedio esperado\nrendimiento_promedio = np.mean(rendimiento_esperado)\n\n# Obtener el intervalo de confianza para el rendimiento promedio esperado\nintervalo_confianza = 1.96 * np.std(rendimiento_esperado) / np.sqrt(len(rendimiento_esperado))\n\n# Imprimir la proporci\u00f3n de administradores de inversiones que se clasifican a s\u00ed mismos como a la alza o muy a la alza\nprint(\"Proporci\u00f3n de administradores de inversiones a la alza:\", proporcion_alza)\n\n# Imprimir el rendimiento promedio esperado\nprint(\"Rendimiento promedio esperado:\", rendimiento_promedio)\n\n# Imprimir el intervalo de confianza para el rendimiento promedio esperado\nprint(\"Intervalo de confianza para el rendimiento promedio esperado:\", (rendimiento_promedio - intervalo_confianza, rendimiento_promedio + intervalo_confianza))\n\n# Obtener el tiempo promedio de recuperaci\u00f3n\ntiempo_promedio = np.mean(tiempo_recuperacion)\n\n# Obtener el intervalo de confianza para el tiempo promedio de recuperaci\u00f3n\nintervalo_confianza = 1.96 * np.std(tiempo_recuperacion) / np.sqrt(len(tiempo_recuperacion))\n\n# Imprimir el tiempo promedio de recuperaci\u00f3n\nprint(\"Tiempo promedio de recuperaci\u00f3n:\", tiempo_promedio)\n\n# Imprimir el intervalo de confianza para el tiempo promedio de recuperaci\u00f3n\nprint(\"Intervalo de confianza para el tiempo promedio de recuperaci\u00f3n:\", (tiempo_promedio - intervalo_confianza, tiempo_promedio + intervalo_confianza))\n</pre> import numpy as np  # Datos de la encuesta clasificacion_mercado = np.array([1, 1, 1, 1, 1, 1, 0, 0, 0, 0]) rendimiento_esperado = np.array([11.2, 11.2, 11.2, 11.2, 11.2, 11.2, 10.5, 10.5, 10.5, 10.5]) tiempo_recuperacion = np.array([2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 3.25, 3.25, 3.25, 3.25])  # Obtener la proporci\u00f3n de administradores de inversiones que se clasifican a s\u00ed mismos como a la alza o muy a la alza proporcion_alza = np.sum(clasificacion_mercado) / len(clasificacion_mercado)  # Obtener el rendimiento promedio esperado rendimiento_promedio = np.mean(rendimiento_esperado)  # Obtener el intervalo de confianza para el rendimiento promedio esperado intervalo_confianza = 1.96 * np.std(rendimiento_esperado) / np.sqrt(len(rendimiento_esperado))  # Imprimir la proporci\u00f3n de administradores de inversiones que se clasifican a s\u00ed mismos como a la alza o muy a la alza print(\"Proporci\u00f3n de administradores de inversiones a la alza:\", proporcion_alza)  # Imprimir el rendimiento promedio esperado print(\"Rendimiento promedio esperado:\", rendimiento_promedio)  # Imprimir el intervalo de confianza para el rendimiento promedio esperado print(\"Intervalo de confianza para el rendimiento promedio esperado:\", (rendimiento_promedio - intervalo_confianza, rendimiento_promedio + intervalo_confianza))  # Obtener el tiempo promedio de recuperaci\u00f3n tiempo_promedio = np.mean(tiempo_recuperacion)  # Obtener el intervalo de confianza para el tiempo promedio de recuperaci\u00f3n intervalo_confianza = 1.96 * np.std(tiempo_recuperacion) / np.sqrt(len(tiempo_recuperacion))  # Imprimir el tiempo promedio de recuperaci\u00f3n print(\"Tiempo promedio de recuperaci\u00f3n:\", tiempo_promedio)  # Imprimir el intervalo de confianza para el tiempo promedio de recuperaci\u00f3n print(\"Intervalo de confianza para el tiempo promedio de recuperaci\u00f3n:\", (tiempo_promedio - intervalo_confianza, tiempo_promedio + intervalo_confianza)) <pre>Proporci\u00f3n de administradores de inversiones a la alza: 0.6\nRendimiento promedio esperado: 10.919999999999998\nIntervalo de confianza para el rendimiento promedio esperado: (10.707450673960135, 11.132549326039861)\nTiempo promedio de recuperaci\u00f3n: 2.8\nIntervalo de confianza para el tiempo promedio de recuperaci\u00f3n: (2.5722685792430036, 3.027731420756996)\n</pre> <p>Ejercicio 21.  Un estudio de investigaci\u00f3n m\u00e9dica de siete a\u00f1os revel\u00f3 que las mujeres cuyas madres toma\u0002ron el f\u00e1rmaco DES durante el embarazo, respecto de las mujeres cuyas madres no tomaron el f\u00e1rmaco, ten\u00edan el doble de probabilidad de desarrollar anormalidades en el tejido que podr\u00edan provocar c\u00e1ncer.</p> <p>a) Este estudio involucr\u00f3 la comparaci\u00f3n de dos poblaciones. \u00bfCu\u00e1les fueron \u00e9stas?  b) \u00bfD\u00f3nde supone usted que se obtuvieron los datos: en una encuesta o en un experimento?  c) Para la poblaci\u00f3n de mujeres cuyas madres tomaron el f\u00e1rmaco DES durante el embarazo, una muestra de 3 980 mujeres mostr\u00f3 que 63 desarrollaron anormalidades en el tejido que podr\u00edan provocar c\u00e1ncer. Proporcione una estad\u00edstica descriptiva que podr\u00eda usarse para estimar el n\u00famero de mujeres por cada 1000 en esta poblaci\u00f3n que presentan anormalidades en el tejido.  d) Para la poblaci\u00f3n de mujeres cuyas madres no tomaron el f\u00e1rmaco des durante el emba\u0002razo, \u00bfcu\u00e1l es la estimaci\u00f3n del n\u00famero de mujeres por cada 1000 que esperar\u00edan presentar anormalidades en el tejido?  e) Los estudios m\u00e9dicos usan con frecuencia una muestra relativamente grande (en este caso, 3 980). \u00bfPor qu\u00e9? </p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\n\n# Datos del estudio\nmadre_des = np.array([1] * 3980)\nanormalidad = np.array([1] * 63)\n\n# Obtener la tasa de incidencia\ntasa_incidencia = np.sum(anormalidad) / len(anormalidad)\n\n# Imprimir la tasa de incidencia\nprint(\"Tasa de incidencia:\", tasa_incidencia)\n\n# Obtener el intervalo de confianza para la tasa de incidencia\nintervalo_confianza = 1.96 * np.sqrt(tasa_incidencia * (1 - tasa_incidencia) / len(anormalidad))\n\n# Imprimir el intervalo de confianza para la tasa de incidencia\nprint(\"Intervalo de confianza para la tasa de incidencia:\", (tasa_incidencia - intervalo_confianza, tasa_incidencia + intervalo_confianza))\n</pre> import numpy as np  # Datos del estudio madre_des = np.array([1] * 3980) anormalidad = np.array([1] * 63)  # Obtener la tasa de incidencia tasa_incidencia = np.sum(anormalidad) / len(anormalidad)  # Imprimir la tasa de incidencia print(\"Tasa de incidencia:\", tasa_incidencia)  # Obtener el intervalo de confianza para la tasa de incidencia intervalo_confianza = 1.96 * np.sqrt(tasa_incidencia * (1 - tasa_incidencia) / len(anormalidad))  # Imprimir el intervalo de confianza para la tasa de incidencia print(\"Intervalo de confianza para la tasa de incidencia:\", (tasa_incidencia - intervalo_confianza, tasa_incidencia + intervalo_confianza)) <pre>Tasa de incidencia: 1.0\nIntervalo de confianza para la tasa de incidencia: (1.0, 1.0)\n</pre> <p>Ejercicio 22.  a firma Nielsen encuest\u00f3 a consumidores de 47 mercados de Europa, Asia-Pac\u00edfico, el conti\u0002nente americano y el Oriente Medio con el prop\u00f3sito de establecer cu\u00e1les factores son los m\u00e1s importantes para determinar d\u00f3nde realizan sus compras. Utilizando una escala de 1 (baja) a 5 (alta), el factor con mayor calificaci\u00f3n fue gran valor por su dinero, con una calificaci\u00f3n media de 4.32 puntos. El factor que calific\u00f3 en segundo lugar fue mejor selecci\u00f3n de marcas y productos de alta calidad, con una calificaci\u00f3n promedio de 3.78 puntos, y el factor con menor calificaci\u00f3n fue utiliza bolsas y empaques reciclables, con una calificaci\u00f3n promedio de 2.71 (sitio web de Nielsen, 24 de febrero de 2008). Suponga que una cadena de tiendas de abarrotes lo contrat\u00f3 para que realice un estudio parecido para determinar qu\u00e9 factores consideran los clientes de la cadena en Charlotte, Carolina del Norte, que son los m\u00e1s importantes para deter\u0002minar d\u00f3nde efect\u00faan sus compras.</p> <p>a) \u00bfCu\u00e1l es la poblaci\u00f3n para la encuesta que usted realizar\u00e1?  b) \u00bfC\u00f3mo recolectar\u00e1 los datos para este estudio? </p> <p>a) La poblaci\u00f3n para la encuesta ser\u00eda todos los clientes de la cadena de tiendas en Charlotte, Carolina del Norte. Esto se debe a que el objetivo del estudio es determinar qu\u00e9 factores consideran los clientes de la cadena de tiendas en esa ciudad que son los m\u00e1s importantes para determinar d\u00f3nde efect\u00faan sus compras.</p> <p>La poblaci\u00f3n se puede definir como el conjunto de todos los elementos que cumplen con una serie de caracter\u00edsticas espec\u00edficas. En este caso, la caracter\u00edstica espec\u00edfica es ser un cliente de la cadena de tiendas en Charlotte, Carolina del Norte.</p> <p>Para determinar la poblaci\u00f3n, se debe realizar un censo o una encuesta. Un censo es un recuento completo de la poblaci\u00f3n, mientras que una encuesta es una recopilaci\u00f3n de datos de una muestra de la poblaci\u00f3n.</p> <p>En este caso, se podr\u00eda realizar una encuesta para determinar la poblaci\u00f3n. La encuesta podr\u00eda preguntar a los participantes si son clientes de la cadena de tiendas en Charlotte, Carolina del Norte.</p> <p>Por ejemplo, la encuesta podr\u00eda tener la siguiente pregunta:</p> <p>\u00bfEs usted cliente de la cadena de tiendas [nombre de la cadena] en Charlotte, Carolina del Norte?</p> <p>Los participantes podr\u00edan responder la pregunta con un simple \"s\u00ed\" o \"no\".</p> <p>b) Hay varias maneras de recolectar datos para este estudio. Una opci\u00f3n ser\u00eda realizar una encuesta en l\u00ednea. Esto ser\u00eda una forma eficiente de llegar a un gran n\u00famero de personas. Otra opci\u00f3n ser\u00eda realizar entrevistas en persona. Esto permitir\u00eda a los investigadores obtener una comprensi\u00f3n m\u00e1s profunda de las opiniones de los clientes.</p> <p>Encuesta en l\u00ednea</p> <p>Si se elige realizar una encuesta en l\u00ednea, se debe dise\u00f1ar una encuesta que sea clara y concisa. La encuesta debe incluir una variedad de preguntas para que los investigadores puedan obtener una comprensi\u00f3n completa de los factores que son importantes para los clientes.</p> <p>Las preguntas de la encuesta deben ser redactadas de manera clara y concisa para que sean f\u00e1ciles de entender. Las preguntas deben ser relevantes para el objetivo del estudio y deben cubrir una variedad de factores que son importantes para los clientes.</p> <p>La encuesta debe incluir una variedad de opciones de respuesta para que los participantes puedan expresar sus opiniones con precisi\u00f3n. Las opciones de respuesta deben ser mutuamente excluyentes para que los participantes no puedan seleccionar m\u00e1s de una opci\u00f3n.</p> <p>Por ejemplo, la encuesta podr\u00eda incluir las siguientes preguntas:</p> <p>Factores m\u00e1s importantes</p> <p>\u00bfCu\u00e1l es el factor m\u00e1s importante para usted al elegir una tienda de abarrotes?</p> <ul> <li>Precio</li> <li>Selecci\u00f3n de productos</li> <li>Ubicaci\u00f3n de la tienda</li> <li>Servicio al cliente</li> </ul> <p>Las opciones de respuesta para esta pregunta podr\u00edan ser:</p> <ul> <li>Precio (1)</li> <li>Selecci\u00f3n de productos (2)</li> <li>Ubicaci\u00f3n de la tienda (3)</li> <li>Servicio al cliente (4)</li> </ul> <p>Entrevistas en persona</p> <p>Si se elige realizar entrevistas en persona, se debe seleccionar una muestra representativa de clientes. Los investigadores deben preparar preguntas que sean abiertas y que permitan a los clientes expresar sus opiniones con libertad.</p> <p>Las preguntas de las entrevistas deben ser redactadas de manera abierta para que los participantes puedan expresar sus opiniones con sus propias palabras. Las preguntas deben ser relevantes para el objetivo del estudio y deben cubrir una variedad de factores que son importantes para los clientes.</p> <p>Por ejemplo, la entrevista podr\u00eda incluir las siguientes preguntas:</p> <p>Factores m\u00e1s importantes</p> <p>\u00bfQu\u00e9 factores son los m\u00e1s importantes para usted al elegir una tienda de abarrotes?</p> <p>Los participantes podr\u00edan responder esta pregunta con sus propias palabras.</p> <p>Los investigadores deben preparar un gui\u00f3n para las entrevistas para asegurarse de que cubren todos los temas relevantes. Los investigadores deben practicar las entrevistas antes de realizarlas para asegurarse de que pueden realizarlas de manera fluida y profesional.</p> <p>Ejercicio 23.  Nielsen Media Research efect\u00faa encuestas semanales de los programas de televisi\u00f3n que se ven en todo Estados Unidos, y publica datos tanto de la audiencia como de la participaci\u00f3n de mercado. El \u00edndice de audiencia de Nielsen es el porcentaje de familias con televisi\u00f3n que ve un programa, mientras que la participaci\u00f3n de mercado es el porcentaje de familias que ve un programa entre aquellas con televisi\u00f3n en uso. Por ejemplo, los resultados de Nielsen Media Research para la Serie Mundial de Beisbol de 2003 entre los Yankees de Nueva York y los Marlins de Florida report\u00f3 una audiencia de 12.8% y una participaci\u00f3n de 22% (Associated Press, 27 de octubre de 2003). Por tanto, 12.8% de las familias con televisi\u00f3n y 22% de las familias con televisi\u00f3n en uso vieron la Serie Mundial. Con base en la audiencia y la informaci\u00f3n de participaci\u00f3n de los programas m\u00e1s importantes, Nielsen publica una calificaci\u00f3n semanal tanto de programas de televisi\u00f3n como de las cuatro cadenas principales: ABC, CBS, NBC y Fox.</p> <p>a) \u00bfQu\u00e9 intenta medir Nielsen Media Research?  b) \u00bfCu\u00e1l es la poblaci\u00f3n?  c) \u00bfPor qu\u00e9 se usar\u00eda una muestra en esta situaci\u00f3n?  d) \u00bfQu\u00e9 tipos de decisiones o acciones se basan en las calificaciones de Nielsen? </p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\n\n# Definir la poblaci\u00f3n\npoblacion = np.array([1, 1, 1, 1, 1, 1, 0, 0, 0, 0])\n\n# Definir la muestra\nmuestra = np.array([1, 1, 1, 0, 0, 0])\n\n# Obtener la audiencia de la muestra\naudiencia_muestra = np.sum(muestra) / len(muestra)\n\n# Obtener la participaci\u00f3n de mercado de la muestra\nparticipacion_mercado_muestra = audiencia_muestra / np.sum(poblacion)\n\n# Imprimir los resultados\nprint(\"Audiencia de la muestra:\", audiencia_muestra)\nprint(\"Participaci\u00f3n de mercado de la muestra:\", participacion_mercado_muestra)\n</pre> import numpy as np  # Definir la poblaci\u00f3n poblacion = np.array([1, 1, 1, 1, 1, 1, 0, 0, 0, 0])  # Definir la muestra muestra = np.array([1, 1, 1, 0, 0, 0])  # Obtener la audiencia de la muestra audiencia_muestra = np.sum(muestra) / len(muestra)  # Obtener la participaci\u00f3n de mercado de la muestra participacion_mercado_muestra = audiencia_muestra / np.sum(poblacion)  # Imprimir los resultados print(\"Audiencia de la muestra:\", audiencia_muestra) print(\"Participaci\u00f3n de mercado de la muestra:\", participacion_mercado_muestra) <pre>Audiencia de la muestra: 0.5\nParticipaci\u00f3n de mercado de la muestra: 0.08333333333333333\n</pre> <p>Ejercicio 24.  Una muestra de las calificaciones obtenidas en los ex\u00e1menes parciales de cinco estudiantes mostr\u00f3 los resultados siguientes: 72, 65, 82, 90 y 76. \u00bfCu\u00e1les de los enunciados listados enseguida son correctos y cu\u00e1les deben considerarse demasiado generalizados?</p> <p>a) La calificaci\u00f3n promedio de los ex\u00e1menes parciales para la muestra de cinco estudiantes es 77.  b) La calificaci\u00f3n promedio de los ex\u00e1menes parciales para los cinco estudiantes que presentaron el examen es 77.  c) Una estimaci\u00f3n de la calificaci\u00f3n promedio de los ex\u00e1menes parciales para todos los estudiantes que presentaron el examen es 77  d) M\u00e1s de la mitad de los estudiantes que presentaron este examen obtendr\u00e1 una calificaci\u00f3n de entre 70 y 85.  e) Si otros cinco estudiantes se incluyen en la muestra, obtendr\u00e1n calificaciones de entre 65 y 90. </p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\n\n# A)\ncalificaciones = np.array([72, 65, 82, 90, 76])\n\n# Obtener la calificaci\u00f3n promedio de la muestra\ncalificacion_promedio = np.mean(calificaciones)\n\n# Imprimir la calificaci\u00f3n promedio de la muestra\nprint(\"Calificaci\u00f3n promedio de la muestra:\", calificacion_promedio)\n\n# B)\ncalificaciones = np.array([72, 65, 82, 90, 76])\n\n# Obtener el tama\u00f1o de la muestra\ntama\u00f1o_muestra = len(calificaciones)\n\n# Imprimir el tama\u00f1o de la muestra\nprint(\"Tama\u00f1o de la muestra:\", tama\u00f1o_muestra)\n\n# C)\ncalificaciones = np.array([72, 65, 82, 90, 76])\n\n# Obtener la distribuci\u00f3n de las calificaciones\ndistribucion_calificaciones = np.histogram(calificaciones)\n\n# Imprimir la distribuci\u00f3n de las calificaciones\nprint(distribucion_calificaciones)\n\n# D)\ncalificaciones = np.array([72, 65, 82, 90, 76])\n\n# Generar cinco calificaciones adicionales\ncalificaciones_adicionales = np.random.randint(65, 91, size=5)\n\n# Imprimir las calificaciones adicionales\nprint(calificaciones_adicionales)\n</pre> import numpy as np  # A) calificaciones = np.array([72, 65, 82, 90, 76])  # Obtener la calificaci\u00f3n promedio de la muestra calificacion_promedio = np.mean(calificaciones)  # Imprimir la calificaci\u00f3n promedio de la muestra print(\"Calificaci\u00f3n promedio de la muestra:\", calificacion_promedio)  # B) calificaciones = np.array([72, 65, 82, 90, 76])  # Obtener el tama\u00f1o de la muestra tama\u00f1o_muestra = len(calificaciones)  # Imprimir el tama\u00f1o de la muestra print(\"Tama\u00f1o de la muestra:\", tama\u00f1o_muestra)  # C) calificaciones = np.array([72, 65, 82, 90, 76])  # Obtener la distribuci\u00f3n de las calificaciones distribucion_calificaciones = np.histogram(calificaciones)  # Imprimir la distribuci\u00f3n de las calificaciones print(distribucion_calificaciones)  # D) calificaciones = np.array([72, 65, 82, 90, 76])  # Generar cinco calificaciones adicionales calificaciones_adicionales = np.random.randint(65, 91, size=5)  # Imprimir las calificaciones adicionales print(calificaciones_adicionales) <pre>Calificaci\u00f3n promedio de la muestra: 77.0\nTama\u00f1o de la muestra: 5\n(array([1, 0, 1, 0, 1, 0, 1, 0, 0, 1], dtype=int64), array([65. , 67.5, 70. , 72.5, 75. , 77.5, 80. , 82.5, 85. , 87.5, 90. ]))\n[66 78 69 86 69]\n</pre>"},{"location":"capitulo1/","title":"\u00b6","text":"CAPITULO 1  Datos y estad\u00edstica ESTAD\u00cdSTICA EN LA PR\u00c1CTICA: BUSINESSWEEK <p>1.1 APLICACIONES EN NEGOCIOS Y ECONOMIA</p> <ul> <li>Contabilidad</li> <li>Finanzas</li> <li>Marketing</li> <li>Producci\u00f3n</li> <li>Econom\u00eda</li> </ul> <p>1.2 DATOS</p> <ul> <li>Elementos, variables y observaciones</li> <li>Escalas de medici\u00f3n</li> <li>Datos categ\u00f3ricos y cuantitativos</li> <li>Datos de corte transversal y de series de tiempo</li> </ul> <p>1.3 FUENTE DE DATOS</p> <ul> <li>Fuentes existentes</li> <li>Estudios estad\u00edsticos</li> <li>Errores en la adquisici\u00f3n de datos </li> </ul> <p>1.4 ESTAD\u00cdSTICA DESCRIPTIVA</p> <p>1.5 INFERENCIA ESTADISTICA</p> <p>1.6 COMPUTADORAS Y AN\u00c1LISIS ESTAD\u00cdSTICO</p> <p>1.7 MINER\u00cdA DE DATOS</p> <p>1.8 LINEAMIENTOS \u00c9TICOS PARA LA PR\u00c1CTICA ESTAD\u00cdSTICA</p>"},{"location":"capitulo1/#11-aplicaciones-en-negocios-y-economia","title":"1.1 Aplicaciones en negocios y econom\u00eda\u00b6","text":""},{"location":"capitulo1/#contabilidad","title":"Contabilidad\u00b6","text":"<p>Las empresas de contadores p\u00fablicos utilizan procedimientos de muestreo estad\u00edstico al realizar auditor\u00edas para sus clientes. Por ejemplo, supongamos que una empresa de contadores desea determinar si las cantidades en cuentas por cobrar que aparecen en la hoja de balance del cliente representan la verdadera cantidad en cuentas por cobrar. Revisar el gran n\u00famero de cuentas por cobrar tomar\u00eda demasiado tiempo y ser\u00eda muy costoso. En estos casos, el personal encargado de la auditor\u00eda selecciona un subconjunto de las cuentas, conocido como muestra. Despu\u00e9s de revisar la exactitud de las cuentas seleccionadas en la muestra, los auditores concluyen si la cantidad en cuentas por cobrar que aparece en la hoja de balance del cliente es aceptable.</p>"},{"location":"capitulo1/#finanzas","title":"Finanzas\u00b6","text":"<p>Los analistas financieros utilizan informaci\u00f3n estad\u00edstica para sus recomendaciones de inversi\u00f3n en acciones. Revisan datos como la relaci\u00f3n precio/ganancia y el rendimiento de los dividendos. Comparan estos datos con el promedio del mercado de acciones para determinar si una acci\u00f3n est\u00e1 sobre o subvaluada.</p>"},{"location":"capitulo1/#marketing","title":"Marketing\u00b6","text":"<p>Los esc\u00e1neres electr\u00f3nicos en las cajas de los comercios minoristas recopilan datos para la investigaci\u00f3n de mercado. Estos datos se venden a proveedores como ACNielsen e Information Research Inc., quienes los procesan y venden res\u00famenes estad\u00edsticos a los fabricantes. Estos datos son \u00fatiles para analizar la relaci\u00f3n entre las actividades promocionales y las ventas, lo que ayuda a establecer estrategias de marketing.</p>"},{"location":"capitulo1/#produccion","title":"Producci\u00f3n\u00b6","text":"<p>En la producci\u00f3n, la calidad es importante y se utiliza la estad\u00edstica para controlarla. Se emplean gr\u00e1ficas de control estad\u00edstico de calidad, como la gr\u00e1fica x-barra, para vigilar los resultados promedio de los procesos de producci\u00f3n. Si los puntos en la gr\u00e1fica est\u00e1n dentro de los l\u00edmites de control, el proceso puede continuar sin ajustes.</p>"},{"location":"capitulo1/#economia","title":"Econom\u00eda\u00b6","text":"<p>Los economistas utilizan informaci\u00f3n estad\u00edstica para hacer pron\u00f3sticos sobre la econom\u00eda. Por ejemplo, emplean indicadores como el \u00edndice de precios al consumidor, la tasa de desempleo y la utilizaci\u00f3n de la capacidad de producci\u00f3n para pronosticar las tasas de inflaci\u00f3n. Estos indicadores se utilizan en modelos computarizados de pron\u00f3sticos.</p> <p>En este libro se presentan ejemplos que ejemplifican la diversidad de las aplicaciones estad\u00edsticas. Adem\u00e1s, se incluyen los art\u00edculos \"La estad\u00edstica en la pr\u00e1ctica\" al comienzo de cada cap\u00edtulo, donde se muestra el material que ser\u00e1 estudiado. Estas aplicaciones demuestran la importancia de la estad\u00edstica en situaciones relacionadas con los negocios y la econom\u00eda.</p>"},{"location":"capitulo1/#12-datos","title":"1.2 Datos\u00b6","text":"<p>Los datos son hechos o informaci\u00f3n recopilada, analizada y resumida para su presentaci\u00f3n e interpretaci\u00f3n. Todos los datos recopilados para un estudio en particular son considerados un conjunto de datos. En la tabla 1.1 se muestra un conjunto de datos que proporciona informaci\u00f3n sobre 25 empresas del S&amp;P 500. El S&amp;P 500 est\u00e1 compuesto por 500 empresas seleccionadas por Standard &amp; Poor's y representa el 76% de la capitalizaci\u00f3n de mercado de todas las acciones en Estados Unidos. La actividad de las empresas del S&amp;P 500 es estrechamente monitoreada por los inversionistas y analistas de Wall Street.</p>"},{"location":"capitulo1/#contabilidad","title":"Contabilidad\u00b6","text":"<p>Elementos son las entidades de las que se obtienen los datos. En el conjunto de datos de la tabla 1.1, cada acci\u00f3n de una empresa es un elemento. Hay 25 acciones en total. Una variable es una caracter\u00edstica de los elementos que es de inter\u00e9s. En el conjunto de datos de la tabla 1.1 hay cinco variables: bolsa de valores, ticker, posici\u00f3n en BusinessWeek, precio por acci\u00f3n y ganancia por acci\u00f3n. El conjunto de datos contiene observaciones, que son las mediciones obtenidas para cada elemento. Hay 25 observaciones en total.</p>"},{"location":"capitulo1/#elementos-variables-y-observaciones","title":"Elementos, variables y observaciones\u00b6","text":"<p>La escala de medici\u00f3n determina la cantidad de informaci\u00f3n contenida en el dato y la manera m\u00e1s apropiada de analizar los datos. Hay cuatro escalas de medici\u00f3n: nominal, ordinal, de intervalo y de raz\u00f3n. Una escala nominal se utiliza cuando el dato de una variable es una etiqueta o un nombre que identifica un atributo. En la tabla 1.1, la variable bolsa de valores tiene una escala nominal. Una escala ordinal se utiliza cuando los datos tienen un orden o jerarqu\u00eda. En la tabla 1.1, la posici\u00f3n en BusinessWeek es una variable con escala ordinal. Una escala de intervalo se utiliza cuando los datos tienen las caracter\u00edsticas de los datos ordinales y el intervalo entre valores se expresa en t\u00e9rminos de una unidad de medici\u00f3n fija. Un ejemplo de datos de intervalo son las calificaciones en una prueba de aptitudes escolares. Las puntuaciones obtenidas por tres alumnos en la prueba de matem\u00e1ticas (620, 550 y 470) pueden ser ordenadas de mejor a peor. Las diferencias entre las calificaciones tambi\u00e9n tienen significado. Por ejemplo, el estudiante 1 obtuvo 70 puntos m\u00e1s que el estudiante 2, mientras que el estudiante 2 obtuvo 80 puntos m\u00e1s que el estudiante 3.</p>"},{"location":"capitulo1/#escalas-de-medicion","title":"Escalas de medici\u00f3n\u00b6","text":"<p>Una variable tiene una escala de raz\u00f3n si cumple con todas las propiedades de los datos de intervalo y la proporci\u00f3n entre dos valores tiene significado. Ejemplos de variables que utilizan esta escala son distancia, altura, peso y tiempo. Para que una variable tenga una escala de raz\u00f3n, debe tener un valor de cero que indique la ausencia de la variable. Por ejemplo, en el caso del costo de un autom\u00f3vil, si el valor es cero significa que el autom\u00f3vil es gratuito. Adem\u00e1s, si se compara el costo de un autom\u00f3vil de <code>$30,000</code>con el costo de otro autom\u00f3vil de <code>$15,000</code>, la propiedad de raz\u00f3n nos muestra que el primer autom\u00f3vil cuesta el doble que el segundo.</p>"},{"location":"capitulo1/#datos-categoricos-y-cuantitativos","title":"Datos categ\u00f3ricos y cuantitativos\u00b6","text":"<p>Los datos se clasifican en cualitativos y cuantitativos. Los datos cualitativos incluyen etiquetas o nombres que se usan para identificar un atributo de cada elemento. Pueden ser num\u00e9ricos o no y se emplean la escala nominal o la ordinal. Los datos cuantitativos requieren valores num\u00e9ricos que indiquen cu\u00e1nto o cu\u00e1ntos. Se obtienen utilizando las escalas de medici\u00f3n de intervalo o de raz\u00f3n.</p> <p>En el caso de las variables cualitativas, el an\u00e1lisis estad\u00edstico es limitado. Se resumen contando el n\u00famero de observaciones o calculando la proporci\u00f3n de observaciones en cada categor\u00eda cualitativa. No se pueden realizar operaciones aritm\u00e9ticas con estos datos. En cambio, en las variables cuantitativas s\u00ed se pueden realizar operaciones aritm\u00e9ticas como suma y promedio.</p>"},{"location":"capitulo1/#datos-de-corte-transversal-y-de-series-de-tiempo","title":"Datos de corte transversal y de series de tiempo\u00b6","text":"<p>Existen dos tipos de datos seg\u00fan el tiempo en que se obtienen. Los datos de secci\u00f3n transversal se obtienen en el mismo momento o aproximadamente el mismo momento. Por otro lado, los datos de series de tiempo se obtienen a lo largo de varios periodos.</p> <p>Las gr\u00e1ficas de series de tiempo son comunes en las publicaciones sobre negocios y econom\u00eda. Estas gr\u00e1ficas ayudan a los analistas a entender lo que ocurri\u00f3 en el pasado, identificar tendencias en el tiempo y proyectar niveles futuros. Son f\u00e1ciles de entender e interpretar con un poco de estudio.</p> <p>La gr\u00e1fica (A) muestra las tasas de inter\u00e9s en Stafford Loans para estudiantes entre 2000 y 2006. Despu\u00e9s de 2000, las tasas de inter\u00e9s disminuyen y alcanzan su nivel m\u00e1s bajo en 2004, pero a partir de ese a\u00f1o aumentan significativamente.</p> <p>En la gr\u00e1fica (B) se observa un aumento preocupante en la deuda promedio por hogar en tarjetas de cr\u00e9dito durante un per\u00edodo de 10 a\u00f1os, de 1995 a 2005. La deuda promedio aumenta constantemente, lo que dificulta a los hogares pagar sus deudas.</p> <p>La gr\u00e1fica (C) muestra las tasas de ocupaci\u00f3n en los hoteles del sur de Florida durante un a\u00f1o. Las tasas m\u00e1s altas se encuentran en los meses de febrero y marzo, cuando el clima es atractivo para los turistas. Por otro lado, las tasas m\u00e1s bajas se observan de agosto a octubre, debido a las altas temperaturas y la temporada de huracanes. Gr\u00e1fica (A): Tasas de inter\u00e9s en los Stafford Loans para estudiantes. Las tasas disminuyen despu\u00e9s de 2000 y llegan al nivel m\u00e1s bajo en 2004, pero luego aumentan marcadamente en los a\u00f1os siguientes.</p> <p>Gr\u00e1fica (B): Adeudo promedio en tarjetas de cr\u00e9dito por hogar. Se observa un aumento constante en la deuda promedio durante un per\u00edodo de 10 a\u00f1os, de 1995 a 2005.</p> <p>Gr\u00e1fica (C): Tasas de ocupaci\u00f3n en hoteles de Florida del sur. Se observan tasas de ocupaci\u00f3n m\u00e1s altas en los meses de febrero y marzo, mientras que las tasas m\u00e1s bajas se encuentran de agosto a octubre.</p>"},{"location":"capitulo1/#13-fuentes-de-datos","title":"1.3 Fuentes de datos\u00b6","text":""},{"location":"capitulo1/#datos-de-corte-transversal-y-de-series-de-tiempo","title":"Datos de corte transversal y de series de tiempo\u00b6","text":"<p>Las empresas suelen contar con bases de datos internas que contienen informaci\u00f3n sobre empleados, clientes y operaciones comerciales. Los registros internos de personal proporcionan datos como salarios, edades y a\u00f1os de experiencia de los empleados. Otros registros internos contienen informaci\u00f3n sobre ventas, publicidad, distribuci\u00f3n, inventario y producci\u00f3n. Las empresas tambi\u00e9n pueden obtener datos externos econ\u00f3micos y comerciales a trav\u00e9s de organizaciones especializadas en la recolecci\u00f3n y almacenamiento de datos. Empresas como Dun &amp; Bradstreet, Bloomberg, Dow Jones &amp; Company, ACNielsen e Information Resources, Inc. proporcionan servicios de bases de datos a clientes. Otras fuentes de datos incluyen asociaciones industriales y organizaciones especializadas, como la asociaci\u00f3n Travel Industry Association of America, que proporciona informaci\u00f3n sobre viajes, y el Graduate Management Admission Council, que tiene datos sobre calificaciones en ex\u00e1menes y programas educativos para administradores. Internet se ha convertido en una fuente importante de datos y est\u00e1 disponible tanto a trav\u00e9s de las p\u00e1ginas web de empresas como a trav\u00e9s de plataformas especializadas que ofrecen una amplia variedad de informaci\u00f3n. Los gobiernos tambi\u00e9n son una fuente significativa de datos, como el Departamento del Trabajo de Estados Unidos, que proporciona datos sobre empleo, salarios, fuerza laboral, entre otros. Muchas agencias gubernamentales tambi\u00e9n ofrecen datos en l\u00ednea a trav\u00e9s de sus sitios web.</p>"},{"location":"capitulo1/#estudios-estadisticos","title":"Estudios estad\u00edsticos\u00b6","text":"<p>En algunos casos, los datos necesarios no est\u00e1n disponibles y se requiere realizar estudios estad\u00edsticos, ya sea experimentales u observacionales, para recopilar la informaci\u00f3n requerida. Los estudios experimentales buscan establecer una relaci\u00f3n causal entre variables, mientras que los estudios observacionales se centran en la observaci\u00f3n de fen\u00f3menos sin intervenir directamente en ellos. El an\u00e1lisis estad\u00edstico de los datos experimentales ayuda a determinar el efecto del nuevo medicamento sobre la presi\u00f3n sangu\u00ednea. En los estudios estad\u00edsticos no experimentales y observacionales, no se controlan las variables de inter\u00e9s. Un tipo com\u00fan de estudio observacional es la encuesta, donde se presenta un cuestionario a los individuos de la muestra para obtener informaci\u00f3n. Los estudios observacionales son utilizados en diversos \u00e1mbitos, como la industria de restaurantes, para recopilar datos sobre la calidad de los alimentos, el servicio, etc. Los directivos deben ser conscientes del tiempo y costo requeridos para obtener datos, y en casos de limitaciones de tiempo, es preferible utilizar fuentes de datos existentes. Es importante considerar los posibles errores en la adquisici\u00f3n de datos y asegurarse de que los datos utilizados sean precisos y representativos. Los errores en la adquisici\u00f3n de datos ocurren en diferentes formas y pueden afectar la validez y utilidad de los an\u00e1lisis estad\u00edsticos. Es fundamental utilizar m\u00e9todos precisos para evitar errores en la recopilaci\u00f3n de datos</p>"},{"location":"capitulo1/#errores-en-la-adquisicion-de-los-datos","title":"Errores en la adquisici\u00f3n de los datos\u00b6","text":"<p>Los errores en la adquisici\u00f3n de datos pueden ocurrir de diversas formas, como errores de escritura, malinterpretaci\u00f3n de preguntas o respuestas incorrectas dadas por el entrevistado. Los analistas de datos experimentados toman precauciones al recolectar y registrar los datos para evitar errores. Se utilizan procedimientos especiales para verificar la consistencia interna de los datos y revisar valores inusualmente altos o bajos, llamados observaciones at\u00edpicas, que pueden indicar posibles errores en los datos. Es importante adquirir datos precisos para evitar la toma de decisiones err\u00f3neas basadas en informaci\u00f3n desorientadora.</p>"},{"location":"capitulo1/#14-estadistica-descriptiva","title":"1.4 Estadistica Descriptiva\u00b6","text":"<p>La estad\u00edstica descriptiva es una forma de resumir y presentar datos en una forma f\u00e1cil de leer y entender, a trav\u00e9s de tablas, gr\u00e1ficos, o res\u00famenes num\u00e9ricos. Vuelva al conjunto de datos de la tabla 1.1 que presenta 25 de las empresas de S&amp;P 500. Los m\u00e9todos de la estad\u00edstica descriptiva pueden emplearse para resumir la informaci\u00f3n en este conjunto de datos:</p> <ol> <li><p>Resumen tabular: En la tabla 1.4 se presenta un resumen tabular de los datos de la variable bolsa de valores. Porcentualmente, se observa que el 80% de las acciones cotizan en la bolsa de Nueva York, mientras que el 20% cotiza en el Nasdaq.</p> </li> <li><p>Resumen gr\u00e1fico de barras: La figura 1.5 muestra un resumen gr\u00e1fico de barras de los datos de la variable bolsa de valores. Este tipo de gr\u00e1fico facilita la interpretaci\u00f3n y muestra claramente que la mayor parte de las acciones cotizan en la bolsa de Nueva York.</p> </li> <li><p>Resumen gr\u00e1fico de histograma: En la figura 1.6 se presenta un histograma de los datos de la variable cuantitativa precio por acci\u00f3n. El histograma muestra que los precios por acci\u00f3n var\u00edan de <code>$0</code> a <code>$100</code>, con una mayor concentraci\u00f3n entre <code>$20</code> y <code>$60</code>.</p> </li> <li><p>Estad\u00edstica descriptiva num\u00e9rica: Adem\u00e1s de los res\u00famenes tabulares y gr\u00e1ficos, se emplea la estad\u00edstica descriptiva num\u00e9rica. El estad\u00edstico descriptivo m\u00e1s com\u00fan es el promedio o media. En el caso de los datos de la variable ganancia por acci\u00f3n de las acciones S&amp;P, se calcula el promedio sumando las ganancias por acci\u00f3n de las 25 acciones y dividiendo entre 25.</p> </li> </ol>"},{"location":"capitulo1/#15-inferencia-estadistica","title":"1.5 Inferencia Estadistica\u00b6","text":"<p>es utilizada cuando se necesita obtener informaci\u00f3n sobre grupos grandes de elementos, como individuos, empresas, hogares, etc. Sin embargo, debido a limitaciones de tiempo, costo y otros factores, solo es posible recolectar datos de una peque\u00f1a parte de este grupo. A esta gran cantidad de elementos se le denomina poblaci\u00f3n, mientras que al grupo peque\u00f1o seleccionado se le llama muestra. En t\u00e9rminos formales, se definen estos conceptos de la siguiente manera:</p> <ul> <li>Muestra: Es un subconjunto representativo de la poblaci\u00f3n, obtenido para realizar un estudio o an\u00e1lisis.</li> <li>Poblaci\u00f3n: Es el conjunto completo de todos los elementos de inter\u00e9s en un estudio espec\u00edfico.</li> </ul>"},{"location":"capitulo1/#16-computadoras-y-analisis-estadistico","title":"1.6 Computadoras y an\u00e1lisis estad\u00edstico\u00b6","text":"<p>En el an\u00e1lisis estad\u00edstico, se utilizan grandes cantidades de datos, por lo que los analistas emplean software para facilitar este trabajo. Por ejemplo, en el caso del estudio de Norris Electronics, el c\u00e1lculo del tiempo promedio de vida \u00fatil de los focos ser\u00eda tedioso sin el uso de una computadora. Para facilitar su manejo, los datos utilizados en este libro se proporcionan en un disco compacto, en formatos compatibles con programas como Minitab y Excel.</p>"},{"location":"capitulo1/#17-mineria-de-datos","title":"1.7 Miner\u00eda de datos\u00b6","text":"<p>La miner\u00eda de datos es el proceso de convertir estos grandes vol\u00famenes de datos en informaci\u00f3n \u00fatil para la toma de decisiones. Utiliza t\u00e9cnicas de estad\u00edstica, matem\u00e1ticas y ciencias de la computaci\u00f3n para \"extraer\" informaci\u00f3n de los datos almacenados. Kurt Thearling, un experto en el campo, define la miner\u00eda de datos como la extracci\u00f3n automatizada de informaci\u00f3n predictiva de grandes bases de datos. Esta pr\u00e1ctica es especialmente prevalente en sectores orientados al consumidor, como el comercio minorista y las telecomunicaciones.</p> <p>Las aplicaciones de la miner\u00eda de datos incluyen la identificaci\u00f3n de patrones de compra en sitios como Amazon, donde se sugieren productos adicionales a los clientes, o la identificaci\u00f3n de consumidores propensos a gastar m\u00e1s en ciertas compras. La miner\u00eda de datos se basa en m\u00e9todos estad\u00edsticos como la regresi\u00f3n m\u00faltiple y log\u00edstica, pero tambi\u00e9n requiere una integraci\u00f3n creativa de inteligencia artificial y aprendizaje autom\u00e1tico.</p> <p>La implementaci\u00f3n de software de miner\u00eda de datos, desarrollado por empresas como Oracle, Teradata y SAS, implica una inversi\u00f3n significativa de tiempo y dinero. Los modelos estad\u00edsticos desempe\u00f1an un papel crucial en el desarrollo de modelos predictivos en la miner\u00eda de datos, pero tambi\u00e9n presentan desaf\u00edos como la confiabilidad y el riesgo de sobreajustar los modelos a los datos disponibles. La miner\u00eda de datos supera algunos de estos desaf\u00edos mediante la partici\u00f3n de los datos en conjuntos de entrenamiento y prueba para validar la confiabilidad de los modelos. Sin embargo, se requiere una interpretaci\u00f3n cuidadosa y pruebas adicionales para evitar conclusiones err\u00f3neas.</p>"},{"location":"capitulo1/#18-lineamientos-eticos-para-la-practica-estadistica","title":"1.8 Lineamientos \u00e9ticos para la pr\u00e1ctica estad\u00edstica\u00b6","text":"<p>Se recomienda actuar con justicia, meticulosidad, objetividad y neutralidad en todas las fases del trabajo estad\u00edstico, incluyendo la recopilaci\u00f3n de datos, an\u00e1lisis, presentaciones y redacci\u00f3n de informes. Adem\u00e1s, como consumidores de estad\u00edsticas, se aconseja mantener un escepticismo saludable sobre la informaci\u00f3n recibida, prestando atenci\u00f3n a su origen, prop\u00f3sito y objetividad.</p> <p>La American Statistical Association ha elaborado \"Ethical Guidelines for Statistical Practice\", un documento que establece pautas \u00e9ticas para profesionales y estudiantes en estad\u00edstica. Estas pautas cubren \u00e1reas como profesionalismo, responsabilidades hacia fundadores, clientes, empleadores, sujetos de investigaci\u00f3n, colegas, otros profesionales y cuestiones relacionadas con acusaciones de conducta poco \u00e9tica.</p> <p>Un ejemplo ilustrativo de comportamiento poco \u00e9tico es la manipulaci\u00f3n de resultados en estudios estad\u00edsticos, como en el caso de Norris Electronics, donde se altera la muestra para lograr un resultado deseado (vida \u00fatil promedio de focos). Este tipo de manipulaci\u00f3n es considerada poco \u00e9tica y un uso incorrecto de la estad\u00edstica.</p> <p>Otra pr\u00e1ctica poco \u00e9tica mencionada es el sesgo intencionado en la selecci\u00f3n de muestras, como en el ejemplo de estudios sobre fumadores en restaurantes. Tales pr\u00e1cticas pueden llevar a conclusiones enga\u00f1osas si se ignora el contexto de c\u00f3mo se recopil\u00f3 la muestra.</p> <p>El texto concluye sugiriendo que la lectura del informe de la American Statistical Association puede proporcionar una perspectiva m\u00e1s amplia sobre los problemas \u00e9ticos en estad\u00edstica, siendo \u00fatil tanto para expertos como para consumidores de estad\u00edsticas. Tambi\u00e9n insta a asegurar que las normas \u00e9ticas se mantengan en la pr\u00e1ctica de la estad\u00edstica.</p>"},{"location":"capitulo1/#resumen","title":"Resumen\u00b6","text":"<p>La estad\u00edstica es el arte y la ciencia de recopilar, analizar, presentar e interpretar datos. Es una materia que, en su mayor\u00eda, es necesaria para los estudiantes de negocios y econom\u00eda. En este libro, se describen las aplicaciones t\u00edpicas de la estad\u00edstica en estos campos.</p>"},{"location":"capitulo1/#ejercicios-complementarios","title":"Ejercicios complementarios\u00b6","text":""},{"location":"capitulo10/","title":"Capitulo 10","text":"<ul> <li>Sean $\\sigma_1$ y $\\sigma_2$ las medias poblacionales a estudiar.</li> <li>La inferencia se realiza sobre la diferencia de las medias $\\mu_1 - \\mu_2$.</li> <li>Se toma un tama\u00f1o de muestra para cada poblaci\u00f3n (muestra aleatoria simple e independiente) $n_1$ y $n_2$ respectivamente.</li> <li>Suponga que $\\sigma_1$ y $\\sigma_2$ son conocidas.</li> </ul> <p>Las medias poblacionales son te\u00f3ricas. En la pr\u00e1ctica se calculan las medias muestrales $\\bar{x_1}$ y $\\bar{x_2}$.</p> <p>An\u00e1lisis Demogr\u00e1fico de Clientes en Greystone Department Stores</p> <ul> <li><p>Introducci\u00f3n</p> <ul> <li>Greystone Department Stores ha observado una variaci\u00f3n en los patrones de venta entre sus tiendas en el centro de la ciudad y en un centro comercial suburbano en Buffalo, Nueva York. Se sospecha que las diferencias demogr\u00e1ficas entre los clientes de las dos tiendas, como la edad, educaci\u00f3n e ingreso, pueden influir en este fen\u00f3meno.</li> </ul> </li> <li><p>Objetivo del Estudio</p> <ul> <li>El estudio tiene como objetivo investigar si hay una diferencia significativa en las edades medias de los clientes entre las dos tiendas.</li> </ul> </li> <li><p>Metodolog\u00eda</p> <ul> <li>Se identifican dos poblaciones de clientes basadas en su ubicaci\u00f3n de compra.</li> <li>La estimaci\u00f3n puntual de la diferencia entre las medias poblacionales se obtiene a trav\u00e9s de la diferencia entre las medias muestrales, $ \\bar{X}_1 - \\bar{X}_2 $.</li> <li>El error est\u00e1ndar del estimador puntual, que indica la variabilidad en la distribuci\u00f3n de muestreo del estimador, se calcula como $ \\sigma_{\\bar{X}_1 - \\bar{X}_2} = \\sqrt{\\frac{\\sigma^2_1}{n_1} + \\frac{\\sigma^2_2}{n_2}} $.</li> <li>Se asume una distribuci\u00f3n normal de la diferencia entre las medias muestrales, especialmente si las poblaciones tienen una distribuci\u00f3n normal o los tama\u00f1os de muestra son grandes.</li> </ul> </li> <li><p>Conclusi\u00f3n Esperada</p> <ul> <li>La investigaci\u00f3n proporcionar\u00e1 una estimaci\u00f3n de la diferencia entre las medias de edad de los clientes, lo que podr\u00eda permitir ajustar las estrategias de marketing y mejorar la selecci\u00f3n de productos para cada tienda seg\u00fan su clientela.</li> </ul> </li> </ul> ESTIMADOR PUNTUAL DE LA DIFERENCIA ENTRE DOS MEDIAS POBLACIONALES              $$\\bar{x}_1 - \\bar{x}_2$$          (10.1) ERROR EST\u00c1NDAR DE $\\bar{x}_1 - \\bar{x}_2$                  $$\\sigma_{\\bar{x}_1 - \\bar{x}_2} = \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}}$$              (10.2) MARGEN DE ERROR                  $$\\text{Margen de error} = z_{\\alpha/2} \\sigma_{\\bar{x}_1 - \\bar{x}_2} = z_{\\alpha/2} \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}}$$              (10.3) ESTIMACI\u00d3N POR INTERVALO DE LA DIFERENCIA ENTRE DOS MEDIAS POBLACIONALES $\\sigma_1$ Y $\\sigma_2$ CONOCIDAS:                  $$\\bar{x}_1 - \\bar{x}_2 \\pm z_{\\alpha/2} \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}}$$              (10.4) <p>Estimaci\u00f3n por Intervalo para Greystone Department Stores</p> <ul> <li><p>Resumen de Datos</p> <ul> <li>Tienda del centro de la ciudad: $n_1 = 36$, $\\bar{x}_1 = 40$ a\u00f1os</li> <li>Tienda suburbana: $n_2 = 49$, $\\bar{x}_2 = 35$ a\u00f1os</li> <li>Desviaciones est\u00e1ndar conocidas: $\\sigma_1 = 9$ a\u00f1os, $\\sigma_2 = 10$ a\u00f1os</li> </ul> </li> <li><p>Estimaci\u00f3n Puntual</p> <ul> <li>La diferencia entre las medias muestrales es $\\bar{x}_1 - \\bar{x}_2 = 5$ a\u00f1os.</li> </ul> </li> <li><p>Error Est\u00e1ndar y Margen de Error</p> <ul> <li>Con un 95% de confianza y $z_{\\alpha/2} = z_{0.025} = 1.96$, el error est\u00e1ndar y el margen de error se calculan como:</li> </ul> </li> </ul> <p>$$ \\bar{x}_1 - \\bar{x}_2 \\pm z_{\\alpha/2} \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}} = 40 - 35 \\pm 1.96 \\sqrt{\\frac{9^2}{36} + \\frac{10^2}{49}} $$</p> <ul> <li>Esto resulta en un margen de error de $4.06$ y un intervalo de confianza al 95% para la diferencia entre las medias poblacionales de:</li> </ul> <p>$$ 5 \\pm 4.06 $$</p> <ul> <li>Lo que nos da un intervalo de $0.94$ a $9.06$ a\u00f1os.</li> </ul>                  $$ H_0 : \\mu_1 - \\mu_2 \\geq D_0 \\quad H_0: \\mu_1 - \\mu_2\\leq D_0 \\quad H_0: \\mu_1 - \\mu_2 = D_0$$ $$ H_a : \\mu_1 - \\mu_2 &lt; D_0 \\quad H_a: \\mu_1 - \\mu_2 &gt; D_0 \\quad H_a: \\mu_1 - \\mu_2 \\neq D_0$$              ESTAD\u00cdSTICO DE PRUEBA PARA PRUEBAS DE HIP\u00d3TESIS ACERCA DE $\\mu_1 - \\mu_2$: $\\sigma_1$  Y  $\\sigma_2 $ CONOCIDAS                  $$z = \\frac{(\\bar{x}_1 - \\bar{x}_2) - D_0}{\\sqrt{\\frac{\\sigma^2_1}{n_1} + \\frac{\\sigma^2_2}{n_2}}}$$              (10.5) <p>El estudio se centra en comparar la calidad educativa entre dos centros utilizando un examen estandarizado. Se define la media de las puntuaciones del centro A como $\\mu_1$ y del centro B como $\\mu_2$. La hip\u00f3tesis nula planteada es $\\mu_1 - \\mu_2 = 0$, indicando que no hay diferencia en la calidad de educaci\u00f3n entre los centros. Un rechazo de esta hip\u00f3tesis implicar\u00eda una diferencia significativa en la calidad educativa, llevando a una investigaci\u00f3n m\u00e1s profunda sobre las causas de esta discrepancia.</p>                  $$H_0: \\mu_1 - \\mu_2 = 0$$ $$H_a: \\mu_1 - \\mu_2 \\neq 0$$              <p>En un estudio con ex\u00e1menes estandarizados, se ha encontrado consistentemente una desviaci\u00f3n est\u00e1ndar de aproximadamente 10 puntos. Se asume que las desviaciones est\u00e1ndar poblacionales son $\\sigma_1 = \\sigma_2 = 10$. Con un nivel de significancia $\\alpha = 0.05$, se recolectaron muestras de 30 estudiantes del centro A y 40 del centro B, con medias muestrales de $\\bar{x}_1 = 82$ y $\\bar{x}_2 = 78$. La pregunta clave es si hay una diferencia estad\u00edsticamente significativa entre las medias poblacionales de los dos centros, lo cual se determinar\u00e1 usando la ecuaci\u00f3n (10.5).</p>                  $$ z = \\frac{(\\bar{x}_1 - \\bar{x}_2) - D_0}{\\sqrt{\\frac{\\sigma^2_1}{n_1} + \\frac{\\sigma^2_2}{n_2}}} = \\frac{(82 - 78) - 0}{\\sqrt{\\frac{10^2}{30} + \\frac{10^2}{40}}} = 1.66 $$              <p>Ejercicio 1. </p> <p>Los resultados siguientes provienen de muestras aleatorias simples independientes tomadas de dos poblaciones.</p> <p></p> Muestra 1 Muestra 2 $n_1 = 50 $ $n_2 = 35 $ $\\bar{x}_1 = 13,6 $ $\\bar{x}_2 = 11,6 $ $s_1 = 2,2 $ $s_2 = 3,0 $ <p>a) \u00bfCu\u00e1l es la estimaci\u00f3n puntual de la diferencia entre las dos medias poblacionales?</p> In\u00a0[1]: Copied! <pre># Datos de las muestras\nn1, x_bar1, s1 = 50, 13.6, 2.2\nn2, x_bar2, s2 = 35, 11.6, 3.0\n\n# Estimaci\u00f3n puntual de la diferencia de medias\npoint_estimate = x_bar1 - x_bar2\nprint(f\"Estimaci\u00f3n puntual (a): {point_estimate}\")\n</pre> # Datos de las muestras n1, x_bar1, s1 = 50, 13.6, 2.2 n2, x_bar2, s2 = 35, 11.6, 3.0  # Estimaci\u00f3n puntual de la diferencia de medias point_estimate = x_bar1 - x_bar2 print(f\"Estimaci\u00f3n puntual (a): {point_estimate}\")  <pre>Estimaci\u00f3n puntual (a): 2.0\n</pre> <p>b) Proporcione un intervalo de 90% de confianza para la diferencia entre las dos medias poblacionales.</p> In\u00a0[2]: Copied! <pre>from scipy import stats\nimport numpy as np\n\n# Datos proporcionados\nn1 = 50  # Tama\u00f1o de la muestra 1\nx1 = 13.6  # Media muestral 1\ns1 = 2.2  # Desviaci\u00f3n est\u00e1ndar muestral 1\n\nn2 = 35  # Tama\u00f1o de la muestra 2\nx2 = 11.6  # Media muestral 2\ns2 = 3.0  # Desviaci\u00f3n est\u00e1ndar muestral 2\n\nz = 0.90 # z al 90%\n\ndef calcular_intervalo_confianza(n1, x1, s1, n2, x2, s2, confianza):\n    # Estimaci\u00f3n puntual de la diferencia entre las medias poblacionales\n    estimacion_puntual = x1 - x2\n    \n    # Valor z para el intervalo de confianza dado\n    z_value = stats.norm.ppf(1 - (1 - confianza) / 2)\n    \n    # C\u00e1lculo del margen de error con el valor z\n    error_margin = z_value * np.sqrt((s1**2 / n1) + (s2**2 / n2))\n    \n    # Intervalo de confianza con el valor z\n    intervalo_confianza = (estimacion_puntual - error_margin, estimacion_puntual + error_margin)\n    print(\"Z: \",z_value)\n    print(\"Margen error Z: \",error_margin)\n    print(\"Intervalo confianza: \",intervalo_confianza)\n\ncalcular_intervalo_confianza(n1,x1,s1,n2,x2,s2,z)\n</pre> from scipy import stats import numpy as np  # Datos proporcionados n1 = 50  # Tama\u00f1o de la muestra 1 x1 = 13.6  # Media muestral 1 s1 = 2.2  # Desviaci\u00f3n est\u00e1ndar muestral 1  n2 = 35  # Tama\u00f1o de la muestra 2 x2 = 11.6  # Media muestral 2 s2 = 3.0  # Desviaci\u00f3n est\u00e1ndar muestral 2  z = 0.90 # z al 90%  def calcular_intervalo_confianza(n1, x1, s1, n2, x2, s2, confianza):     # Estimaci\u00f3n puntual de la diferencia entre las medias poblacionales     estimacion_puntual = x1 - x2          # Valor z para el intervalo de confianza dado     z_value = stats.norm.ppf(1 - (1 - confianza) / 2)          # C\u00e1lculo del margen de error con el valor z     error_margin = z_value * np.sqrt((s1**2 / n1) + (s2**2 / n2))          # Intervalo de confianza con el valor z     intervalo_confianza = (estimacion_puntual - error_margin, estimacion_puntual + error_margin)     print(\"Z: \",z_value)     print(\"Margen error Z: \",error_margin)     print(\"Intervalo confianza: \",intervalo_confianza)  calcular_intervalo_confianza(n1,x1,s1,n2,x2,s2,z)   <pre>Z:  1.6448536269514722\nMargen error Z:  0.978574361132911\nIntervalo confianza:  (1.021425638867089, 2.978574361132911)\n</pre> <p>c) Proporcione un intervalo de 95% de confianza para la diferencia entre las dos medias poblacionales.</p> In\u00a0[3]: Copied! <pre># Datos proporcionados\nn1 = 50  # Tama\u00f1o de la muestra 1\nx1 = 13.6  # Media muestral 1\ns1 = 2.2  # Desviaci\u00f3n est\u00e1ndar muestral 1\n\nn2 = 35  # Tama\u00f1o de la muestra 2\nx2 = 11.6  # Media muestral 2\ns2 = 3.0  # Desviaci\u00f3n est\u00e1ndar muestral 2\n\nz = 0.95 # z al 95%\ncalcular_intervalo_confianza(n1,x1,s1,n2,x2,s2,z)\n</pre> # Datos proporcionados n1 = 50  # Tama\u00f1o de la muestra 1 x1 = 13.6  # Media muestral 1 s1 = 2.2  # Desviaci\u00f3n est\u00e1ndar muestral 1  n2 = 35  # Tama\u00f1o de la muestra 2 x2 = 11.6  # Media muestral 2 s2 = 3.0  # Desviaci\u00f3n est\u00e1ndar muestral 2  z = 0.95 # z al 95% calcular_intervalo_confianza(n1,x1,s1,n2,x2,s2,z) <pre>Z:  1.959963984540054\nMargen error Z:  1.1660432713210558\nIntervalo confianza:  (0.8339567286789442, 3.1660432713210556)\n</pre> <p>Ejercicio 2. </p> <p>Considere la prueba de hip\u00f3tesis que se da a continuaci\u00f3n.</p> <p></p> <p>$$\\textbf{H}_0: \\mu_1 - \\mu_2 \\leq 0$$</p> <p>$$\\textbf{H}_a: \\mu_1 - \\mu_2 &gt; 0$$</p> <p>Los resultados siguientes se obtuvieron de dos muestras independientes tomadas de dos poblaciones.</p> Muestra 1 Muestra 2 $n_1 = 40 $ $n_2 = 50 $ $\\bar{x}_1 = 25,2 $ $\\bar{x}_2 = 22,8 $ $s_1 = 5,2 $ $s_2 = 6,0 $ <p>Pregunta 1: \u00bfCu\u00e1l es el valor del estad\u00edstico de prueba?</p> In\u00a0[4]: Copied! <pre>import numpy as np\n\n# Datos de las muestras\nx_bar1 = 25.2  # Media de la muestra 1\nx_bar2 = 22.8  # Media de la muestra 2\nsigma1 = 5.2  # Desviaci\u00f3n est\u00e1ndar poblacional 1\nsigma2 = 6.0  # Desviaci\u00f3n est\u00e1ndar poblacional 2\nn1 = 40  # Tama\u00f1o de la muestra 1\nn2 = 50  # Tama\u00f1o de la muestra 2\nD0 = 0  # Diferencia en las medias bajo la hip\u00f3tesis nula\n\n# C\u00e1lculo del estad\u00edstico z\nz_score = (x_bar1 - x_bar2 - D0) / np.sqrt(sigma1**2 / n1 + sigma2**2 / n2)\nz_score\n</pre> import numpy as np  # Datos de las muestras x_bar1 = 25.2  # Media de la muestra 1 x_bar2 = 22.8  # Media de la muestra 2 sigma1 = 5.2  # Desviaci\u00f3n est\u00e1ndar poblacional 1 sigma2 = 6.0  # Desviaci\u00f3n est\u00e1ndar poblacional 2 n1 = 40  # Tama\u00f1o de la muestra 1 n2 = 50  # Tama\u00f1o de la muestra 2 D0 = 0  # Diferencia en las medias bajo la hip\u00f3tesis nula  # C\u00e1lculo del estad\u00edstico z z_score = (x_bar1 - x_bar2 - D0) / np.sqrt(sigma1**2 / n1 + sigma2**2 / n2) z_score  Out[4]: <pre>2.0312741071965967</pre> <p>Pregunta 2: \u00bfCu\u00e1l es el valor-p?</p> In\u00a0[5]: Copied! <pre>from scipy import stats\n\n# Grados de libertad\ndf = n1 + n2 - 2\n\n# C\u00e1lculo del valor-p usando la distribuci\u00f3n t con los grados de libertad calculados\np_value = stats.t.sf(z_score, df)\np_value\n</pre> from scipy import stats  # Grados de libertad df = n1 + n2 - 2  # C\u00e1lculo del valor-p usando la distribuci\u00f3n t con los grados de libertad calculados p_value = stats.t.sf(z_score, df) p_value  Out[5]: <pre>0.022622177547503456</pre> <p>Pregunta 3: Si  \u03b1=0.05, \u00bfcu\u00e1l es la conclusi\u00f3n de la prueba de hip\u00f3tesis?</p> In\u00a0[6]: Copied! <pre># Nivel de significancia\nalpha = 0.05\n\n# Conclusi\u00f3n de la prueba de hip\u00f3tesis\nconclusion = \"Rechazamos la hip\u00f3tesis nula\" if p_value &lt; alpha else \"No rechazamos la hip\u00f3tesis nula\"\nconclusion\n</pre> # Nivel de significancia alpha = 0.05  # Conclusi\u00f3n de la prueba de hip\u00f3tesis conclusion = \"Rechazamos la hip\u00f3tesis nula\" if p_value &lt; alpha else \"No rechazamos la hip\u00f3tesis nula\" conclusion  Out[6]: <pre>'Rechazamos la hip\u00f3tesis nula'</pre> <p>Ejercicio 3. </p> <p>Considere la prueba de hip\u00f3tesis que se da a continuaci\u00f3n.</p> <p></p> <p>$$\\textbf{H}_0: \\mu_1 - \\mu_2 \\leq 0$$</p> <p>$$\\textbf{H}_a: \\mu_1 - \\mu_2 &gt; 0$$</p> <p>Los resultados siguientes se obtuvieron de dos muestras independientes tomadas de dos poblaciones.</p> Muestra 1 Muestra 2 $n_1 = 80 $ $n_2 = 70 $ $\\bar{x}_1 = 104 $ $\\bar{x}_2 = 106 $ $s_1 = 8,4 $ $s_2 = 7,6 $ <p>Pregunta 1: \u00bfCu\u00e1l es el valor del estad\u00edstico de prueba?</p> In\u00a0[7]: Copied! <pre>import numpy as np\n\n# Datos de las muestras\nx_bar1 = 104  # Media de la muestra 1\nx_bar2 = 106  # Media de la muestra 2\nsigma1 = 8.4  # Desviaci\u00f3n est\u00e1ndar poblacional 1\nsigma2 = 7.6  # Desviaci\u00f3n est\u00e1ndar poblacional 2\nn1 = 80  # Tama\u00f1o de la muestra 1\nn2 = 70  # Tama\u00f1o de la muestra 2\nD0 = 0  # Diferencia en las medias bajo la hip\u00f3tesis nula\n\n# C\u00e1lculo del estad\u00edstico z\nz_score = (x_bar1 - x_bar2 - D0) / np.sqrt(sigma1**2 / n1 + sigma2**2 / n2)\nz_score\n</pre> import numpy as np  # Datos de las muestras x_bar1 = 104  # Media de la muestra 1 x_bar2 = 106  # Media de la muestra 2 sigma1 = 8.4  # Desviaci\u00f3n est\u00e1ndar poblacional 1 sigma2 = 7.6  # Desviaci\u00f3n est\u00e1ndar poblacional 2 n1 = 80  # Tama\u00f1o de la muestra 1 n2 = 70  # Tama\u00f1o de la muestra 2 D0 = 0  # Diferencia en las medias bajo la hip\u00f3tesis nula  # C\u00e1lculo del estad\u00edstico z z_score = (x_bar1 - x_bar2 - D0) / np.sqrt(sigma1**2 / n1 + sigma2**2 / n2) z_score  Out[7]: <pre>-1.5307175553672936</pre> <p>Pregunta 2: \u00bfCu\u00e1l es el valor-p?</p> In\u00a0[8]: Copied! <pre>from scipy import stats\n\n# Grados de libertad\ndf = n1 + n2 - 2\n\n# C\u00e1lculo del valor-p usando la distribuci\u00f3n t con los grados de libertad calculados\np_value = stats.t.sf(z_score, df)\np_value\n</pre> from scipy import stats  # Grados de libertad df = n1 + n2 - 2  # C\u00e1lculo del valor-p usando la distribuci\u00f3n t con los grados de libertad calculados p_value = stats.t.sf(z_score, df) p_value  Out[8]: <pre>0.9360130639817974</pre> <p>Pregunta 3: Si  \u03b1=0.05, \u00bfcu\u00e1l es la conclusi\u00f3n de la prueba de hip\u00f3tesis?</p> In\u00a0[9]: Copied! <pre># Nivel de significancia\nalpha = 0.05\n\n# Conclusi\u00f3n de la prueba de hip\u00f3tesis\nconclusion = \"Rechazamos la hip\u00f3tesis nula\" if p_value &lt; alpha else \"No rechazamos la hip\u00f3tesis nula\"\nconclusion\n</pre> # Nivel de significancia alpha = 0.05  # Conclusi\u00f3n de la prueba de hip\u00f3tesis conclusion = \"Rechazamos la hip\u00f3tesis nula\" if p_value &lt; alpha else \"No rechazamos la hip\u00f3tesis nula\" conclusion  Out[9]: <pre>'No rechazamos la hip\u00f3tesis nula'</pre> <p>Ejercicio 4. </p> <p>Cond\u00e9 Nast Traveler realiza una encuesta anual en la que los lectores califican su crucero favorito. Los nav\u00edos se califican en una escala de 100 puntos, donde los valores m\u00e1s altos indican un mejor servicio. Una muestra de 37 cruceros que transportan menos de 500 pasajeros result\u00f3 con una calificaci\u00f3n promedio de 85.36 y una muestra de 44 nav\u00edos que transportan 500 o m\u00e1s pasajeros recibi\u00f3 una calificaci\u00f3n promedio de 81.40 (Cond\u00e9 Nast Traveler, febrero de 2008). Suponga que la desviaci\u00f3n est\u00e1ndar poblacional es 4.55 para los cruceros que transportan a menos de 500 pasajeros y 3.97 para los que transportan a 500 o m\u00e1s pasajeros.</p> <p></p> <p>a) \u00bfCu\u00e1l es la estimaci\u00f3n puntual de la diferencia entre la calificaci\u00f3n media poblacional de los nav\u00edos que transportan menos de 500 pasajeros y la calificaci\u00f3n media poblacional de los que transportan 500 o m\u00e1s personas?</p> In\u00a0[10]: Copied! <pre># Calificaciones medias de las muestras\nx_bar1 = 85.36  # Media de la muestra de cruceros con menos de 500 pasajeros\nx_bar2 = 81.40  # Media de la muestra de cruceros con 500 o m\u00e1s pasajeros\n\n# Diferencia de medias\ndiferencia_medias = x_bar1 - x_bar2\ndiferencia_medias\n</pre> # Calificaciones medias de las muestras x_bar1 = 85.36  # Media de la muestra de cruceros con menos de 500 pasajeros x_bar2 = 81.40  # Media de la muestra de cruceros con 500 o m\u00e1s pasajeros  # Diferencia de medias diferencia_medias = x_bar1 - x_bar2 diferencia_medias  Out[10]: <pre>3.9599999999999937</pre> <p>b) \u00bfCu\u00e1l es el margen de error con 95% de confianza?</p> In\u00a0[11]: Copied! <pre>from scipy.stats import norm\nimport numpy as np\n# Desviaciones est\u00e1ndar poblacionales\nsigma1 = 4.55  # Cruceros con menos de 500 pasajeros\nsigma2 = 3.97  # Cruceros con 500 o m\u00e1s pasajeros\n\n# Tama\u00f1os de muestra\nn1 = 37  # Cruceros con menos de 500 pasajeros\nn2 = 44  # Cruceros con 500 o m\u00e1s pasajeros\n\n# Z-score para 95% de confianza\nz_score = norm.ppf(0.975)  # Dos colas\n\n# Margen de error\nmargen_error = z_score * np.sqrt(sigma1**2 / n1 + sigma2**2 / n2)\nmargen_error\n</pre> from scipy.stats import norm import numpy as np # Desviaciones est\u00e1ndar poblacionales sigma1 = 4.55  # Cruceros con menos de 500 pasajeros sigma2 = 3.97  # Cruceros con 500 o m\u00e1s pasajeros  # Tama\u00f1os de muestra n1 = 37  # Cruceros con menos de 500 pasajeros n2 = 44  # Cruceros con 500 o m\u00e1s pasajeros  # Z-score para 95% de confianza z_score = norm.ppf(0.975)  # Dos colas  # Margen de error margen_error = z_score * np.sqrt(sigma1**2 / n1 + sigma2**2 / n2) margen_error  Out[11]: <pre>1.8776100003862883</pre> <p>c) \u00bfCu\u00e1l es la estimaci\u00f3n por intervalo de 95% de confianza para la diferencia entre las calificaciones medias poblacionales de ambos tama\u00f1os de cruceros?</p> In\u00a0[12]: Copied! <pre># Intervalo de confianza\nintervalo_confianza = (diferencia_medias - margen_error, diferencia_medias + margen_error)\nintervalo_confianza\n</pre> # Intervalo de confianza intervalo_confianza = (diferencia_medias - margen_error, diferencia_medias + margen_error) intervalo_confianza  Out[12]: <pre>(2.0823899996137056, 5.837610000386282)</pre> <p>Cuando enfrentamos el desaf\u00edo de comparar dos grupos sin conocer su variabilidad, la estad\u00edstica ofrece una soluci\u00f3n pr\u00e1ctica. Usamos las desviaciones est\u00e1ndar de muestras peque\u00f1as para estimar la dispersi\u00f3n real de los grupos. Para an\u00e1lisis m\u00e1s precisos, recurrimos a la distribuci\u00f3n t, que es especialmente dise\u00f1ada para trabajar con informaci\u00f3n incompleta. Este enfoque nos permite realizar comparaciones y pruebas de hip\u00f3tesis con confianza, incluso con datos limitados.</p> <p>Clearwater National Bank lleva a cabo un estudio para detectar diferencias en los saldos de cuentas de cheques entre dos sucursales, utilizando muestras donde las desviaciones est\u00e1ndar poblacionales son desconocidas:</p> <ul> <li>Una muestra aleatoria simple de 28 cuentas de la sucursal Cherry Grove.</li> <li>Una muestra aleatoria simple e independiente de 22 cuentas de la sucursal Beechmont.</li> </ul> <p>El objetivo es calcular el margen de error y proporcionar una estimaci\u00f3n por intervalo para la diferencia entre las medias poblacionales de los saldos de las cuentas.</p> Cherry Grove Beechmont Tama\u00f1o de la muestra \\( n_1 = 28 \\) \\( n_2 = 22 \\) Media muestral \\( \\bar{x}_1 = \\$1025 \\) \\( \\bar{x}_2 = \\$910 \\) Desviaci\u00f3n est\u00e1ndar muestral \\( s_1 = \\$150 \\) \\( s_2 = \\$125 \\) <p>Estimaci\u00f3n de Diferencia de Saldos entre Sucursales</p> <p>El banco busca calcular la diferencia entre los saldos promedio de las cuentas de Cherry Grove y Beechmont. Se utilizar\u00e1 un margen de error y una estimaci\u00f3n por intervalo para determinar esta diferencia, aplicando la f\u00f3rmula de estimaci\u00f3n por intervalo para las medias poblacionales cuando se conocen las desviaciones est\u00e1ndar poblacionales.</p> <p>La f\u00f3rmula utilizada es:</p> <p>$$ \\bar{x}_1 - \\bar{x}_2 \\pm z_{\\alpha/2} \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}} $$</p> <p>donde $ \\bar{x}_1 $ y $ \\bar{x}_2 $ son las medias muestrales, $ \\sigma_1^2 $ y $ \\sigma_2^2 $ son las varianzas poblacionales, $ n_1 $ y $ n_2 $ son los tama\u00f1os de las muestras, y $ z_{\\alpha/2} $ es el valor cr\u00edtico de la distribuci\u00f3n normal est\u00e1ndar.</p> <p>Nota: Cuando se estiman $ \\sigma_1 $ y $ \\sigma_2 $ mediante $ s_1 $ y $ s_2 $, se usa la distribuci\u00f3n t para hacer inferencias sobre la diferencia entre dos medias poblacionales.</p> <p>Cuando las desviaciones est\u00e1ndar poblacionales $ \\sigma_1 $ y $ \\sigma_2 $ son desconocidas, se utilizan las desviaciones est\u00e1ndar muestrales $ s_1 $ y $ s_2 $ para su estimaci\u00f3n. En este caso, el valor cr\u00edtico de la distribuci\u00f3n normal est\u00e1ndar $ z_{\\alpha/2} $ es reemplazado por el valor cr\u00edtico de la distribuci\u00f3n $ t_{\\alpha/2} $, y la f\u00f3rmula para la estimaci\u00f3n por intervalo de la diferencia entre dos medias poblacionales se ajusta acordemente.</p> ESTIMACI\u00d3N POR INTERVALO PARA LA DIFERENCIA ENTRE DOS MEDIAS POBLACIONALES: \\( \\sigma_1 \\) Y \\( \\sigma_2 \\) DESCONOCIDAS                  $$\\bar{x}_1 - \\bar{x}_2 \\pm t_{\\alpha/2} \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}$$                 $\\text{donde } 1 - \\alpha \\text{ es el coeficiente de confianza.}$              (10.6) <p>En esta expresi\u00f3n el uso de la distribuci\u00f3n t es una aproximaci\u00f3n, pero proporciona resultados excelentes y es relativamente f\u00e1cil de usar. La \u00fanica dificultad que se enfrenta al emplear la expresi\u00f3n (10.6) consiste en determinar los grados de libertad apropiados para $ t_{\\alpha/2} $ . El software estad\u00edstico los calcula autom\u00e1ticamente. La f\u00f3rmula que se usa es la siguiente.</p> GRADOS DE LIBERTAD: DISTRIBUCI\u00d3N t CON DOS MUESTRAS ALEATORIAS INDEPENDIENTES                  $$gl = \\frac{\\left(\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}\\right)^2}{\\frac{1}{n_1 - 1} \\left(\\frac{s_1^2}{n_1}\\right)^2 + \\frac{1}{n_2 - 1} \\left(\\frac{s_2^2}{n_2}\\right)^2}$$              (10.7) ESTAD\u00cdSTICO DE PRUEBA PARA PRUEBAS DE HIP\u00d3TESIS ACERCA DE $\\mu_1 - \\mu_2$: $\\sigma_1$ Y  $\\sigma_2$ DESCONOCIDAS                   $$ t = \\frac{(\\bar{x}_1 - \\bar{x}_2) - D_0}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}} $$              (10.8) <p>Ejemplo. </p> <p>En el ejemplo siguiente se muestra c\u00f3mo calcular el margen de error y obtener una estimaci\u00f3n por intervalo para la diferencia entre dos medias poblacionales cuando \u03c31 y \u03c32 no se conocen. Clearwater National Bank realiza un estudio para identifi car diferencias entre las cuentas de cheques de sus clientes en dos de sus sucursales. Toma una muestra aleatoria simple de 28 cuentas de la sucursal Cherry Grove y otra muestra aleatoria simple e independiente de 22 cuentas de cheques de la sucursal Beechmont. El saldo actual de las cuentas de cheques se registra para cada cuenta. A continuaci\u00f3n se presenta un resumen de los saldos en estas cuentas de cheques.</p> Cherry Grove Beechmont Tama\u00f1o de la muestra \\( n_1 = 28 \\) \\( n_2 = 22 \\) Media muestral \\( \\bar{x}_1 = \\$1025 \\) \\( \\bar{x}_2 = \\$910 \\) Desviaci\u00f3n est\u00e1ndar muestral \\( s_1 = \\$150 \\) \\( s_2 = \\$125 \\) <p>El banco desea estimar la diferencia entre el saldo medio en las cuentas de cheques de la poblaci\u00f3n de clientes de Cherry Grove y el saldo medio en las cuentas de cheques de la poblaci\u00f3n de clientes de Becchmont. Enseguida se calcular\u00e1 el margen de error y una estimaci\u00f3n por intervalo para la diferencia entre estas dos medias poblacionales.</p> <p>El c\u00e1lculo de los grados de libertad (gl ) para $t_{\\alpha/2}$</p> <p>$$ gl = \\frac{(s_1^2/n_1 + s_2^2/n_2)^2}{(s_1^2/n_1)^2/(n_1-1) + (s_2^2/n_2)^2/(n_2-1)}=\\frac{(150^2/28 + 125^2/22)^2}{(150^2/28)^2/(28-1) + (125^2/22)^2/(22-1)}=47.8 $$</p> <p>Como el resultado no es un n\u00famero entero, se redondea hacia abajo a 47 para obtener un valor t mayor y una estimaci\u00f3n por intervalo m\u00e1s prudente. En la tabla de la distribuci\u00f3n t para 47 grados de libertad se encuentra que $t_{0.025}$ = 2.012. Seg\u00fan la expresi\u00f3n (10.6), el intervalo de 95% de confi anza para la diferencia entre las dos medias poblacionales se calcula como sigue.</p> <p>$$\\overline{x}_1 - \\overline{x}_2 \\pm t_{\\alpha/2} \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}$$ $$ 1025 - 910 \\pm 2.012 \\sqrt{\\frac{150^2}{28} + \\frac{125^2}{22}}$$ $$115\\pm 78$$ La estimaci\u00f3n puntual de la diferencia entre las dos medias poblacionales de los saldos en las cuentas de cheques es $\\$115$. El margen de error es $\\$78$ y la estimaci\u00f3n por intervalo de 95% de confi anza para la diferencia entre las dos medias poblacionales es el que va de 115 - 78 = $\\$37$ a 115 + 78 = $\\$193$.</p> <p>Ahora se estudiar\u00e1n las pruebas de hip\u00f3tesis acerca de la diferencia entre las medias de dos poblaciones cuando no se conocen las desviaciones est\u00e1ndar poblacionales $\u03c3_1$ y $\u03c3_2$. Cuando no se conocen $\u03c3_1$ y $\u03c3_2$, se usa $s_l$ para estimar $\u03c3_1$ y $s_2$ para estimar $\u03c3_2$. Sea $D_0$ la diferencia hipot\u00e9tica entre $\u03bc_1$ y $\u03bc_2$.</p> ESTAD\u00cdSTICO DE PRUEBA PARA PRUEBAS DE HIP\u00d3TESIS ACERCA DE $\u03bc_1$-$\u03bc_2$: $\u03c3_1$ Y $\u03c3_2$ DESCONOCIDAS                  $$t = \\frac{\\overline{x}_1 - \\overline{x}_2 - D_0}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\\tag{10.8}$$              (10.4) <p>Ahora se demostrar\u00e1 el uso del estad\u00edstico de prueba en el ejemplo siguiente.</p> <p>Considere un nuevo software que ayuda a los analistas de sistemas a reducir el tiempo requerido para dise\u00f1ar, elaborar y poner en marcha un sistema de informaci\u00f3n. Para evaluar las ventajas del nuevo programa, se toma una muestra aleatoria de 24 analistas de sistemas. A cada analista se le proporciona informaci\u00f3n sobre un sistema de informaci\u00f3n hipot\u00e9tico. A 12 de ellos se les pide que elaboren el sistema de informaci\u00f3n usando la tecnolog\u00eda actual. A los otros 12 se les capacita para usar el nuevo software y se les instruye para que lo empleen en el desarrollo del sistema de informaci\u00f3n.</p> <p>En el estudio participan dos poblaciones: una de analistas de sistemas que usan la tecnolog\u00eda actual y otra de analistas de sistemas que aplican el nuevo software. En t\u00e9rminos del tiempo necesario para completar el proyecto del sistema de informaci\u00f3n, las medias poblacionales son las siguientes.</p> <ul> <li><p>$\u03bc_1$ = media del tiempo que necesitan para completar el proyecto los analistas que emplean la tecnolog\u00eda actual.</p> </li> <li><p>$\u03bc_2$ = media del tiempo que necesitan para completar el proyecto los analistas que emplean el nuevo software.</p> </li> </ul> <p>El investigador encargado de la evaluaci\u00f3n del nuevo software espera demostrar que con el nuevo programa se requiere menos tiempo para completar el proyecto del sistema de informaci\u00f3n. De manera que tratar\u00e1 de hallar evidencias que le permitan concluir que $\u03bc_2$ es menor que $\u03bc_1$,</p> <p> Tabla 10.1 Datos y resumen estad\u00edsticos del tiempo requerido en el estudio de la prueba de software </p> Tama\u00f1o de la muestral $n_1=12$ $n_2=12$ Media Muestral $\\bar{x}_1$=325 horas  $\\bar{x}_2$=286 horas Desviacion estandar muestral $s_1$=40 $s_2$=44 <p>caso en el que la diferencia entre las dos muestras poblacionales $\u03bc_1$ - $\u03bc_2$ ser\u00e1 mayor que cero. La hip\u00f3tesis de investigaci\u00f3n $\u03bc_1$ - $\u03bc_2$ &gt; 0 se establece como hip\u00f3tesis alternativa. Por ende, la prueba de hip\u00f3tesis ser\u00e1: $$ H_0: \\mu_1 - \\mu_2 \\leq0 $$ $$ H_1: \\mu_1 - \\mu_2 &gt;0 $$</p> <p>Como nivel de signifi cancia se usar\u00e1 \u03b1 = 0.05. Suponga que los resultados de los 24 analistas son los que se presentan en la tabla 10.1. Con el estad\u00edstico de prueba establecido en la ecuaci\u00f3n (10.8) tenemos:</p> <p>$$t = \\frac{\\overline{x}_1 - \\overline{x}_2 - D_0}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}=\\frac{325 - 286 - 0}{\\sqrt{\\frac{40^2}{12} + \\frac{44^2}{12}}}=2.27$$</p> <p>Con base en la ecuaci\u00f3n (10.7) los grados de libertad son: $$ gl = \\frac{(s_1^2/n_1 + s_2^2/n_2)^2}{(s_1^2/n_1)^2/(n_1-1) + (s_2^2/n_2)^2/(n_2-1)}=\\frac{(40^2/12 + 44^2/12)^2}{(40^2/12)^2/(12-1) + (44^2/12)^2/(12-1)}=21.8 $$ Al redondear hacia abajo se usar\u00e1 una distribuci\u00f3n t con 21 grados de libertad. La fi la correspondiente de la tabla de distribuci\u00f3n t =2.27.</p> <p> Consejo pr\u00e1ctico </p>  Los procedimientos aqu\u00ed presentados para estimaciones por intervalo y pruebas de hip\u00f3tesis son s\u00f3lidos y pueden usarse con muestras relativamente peque\u00f1as. En la mayor parte de las aplicaciones con muestras iguales o casi del mismo tama\u00f1o, y de manera que el tama\u00f1o total de la muestra, $n_1$ + $n_2$, sea por lo menos 20, se esperan muy buenos resultados aun cuando las poblaciones no sean normales. Si las distribuciones de las poblaciones son muy sesgadas o contienen valores at\u00edpicos, se recomiendan muestras m\u00e1s grandes. Las peque\u00f1as s\u00f3lo deben usarse cuando el analista est\u00e1 convencido de que las distribuciones de las poblaciones son aproximadamente normales.    Ejercicio 1  <p>  El departamento de zoolog\u00eda de la Universidad de Virginia llev\u00f3 a cabo un estudio para estimar la diferencia en la cantidad de ortof\u00f3sforo qu\u00edmico medido en dos estaciones diferentes del r\u00edo James. El ortof\u00f3sforo se mide en miligramos por litro. Se reunieron 15 muestras de la estaci\u00f3n 1 y se ontuvo una media de 3.84 con una desviaci\u00f3n est\u00e1ndar de 3.07 miligramos por litro, mientras que 12 muestras de la estaci\u00f3n 2 tuvieron un contenido promedio de 1.49 con una desviaci\u00f3n est\u00e1ndar 0.80 miligramos por litro. Encuentre un intervalo de confianza de 95% para la diferencia del contenido promedio real de ortof\u00f3sforo en estas dos estaciones, suponga que las observaciones vienen de poblaciones normales con varianzas diferentes. Sol. Datos</p> Estaci\u00f3n 1 Estaci\u00f3n 2 $n_1$=15  $n_2$=12 $\\bar{x}_1$=3.84 $\\bar{x}_2$=1.49 $s_1$=3.07 $s_2$=0.80 <p>Calculando los grados de libertad $$ gl = \\frac{(s_1^2/n_1 + s_2^2/n_2)^2}{(s_1^2/n_1)^2/(n_1-1) + (s_2^2/n_2)^2/(n_2-1)}=\\frac{(3.07^2/15 + 0.80^2/12)^2}{(3.07^2/15)^2/(15-1) + (0.80^2/12)^2/(12-1)}=16.3 $$</p> <p>al usar \u03b1=0.05, encontramos en la tabla con 16 grados de libertad que el valor de t es 2.120, por lo tanto: $$\\mu_1 - \\mu_2=\\overline{x}_1 - \\overline{x}_2 \\pm t_{\\alpha/2} \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}=3.84 - 1.49 \\pm  2.120 \\sqrt{\\frac{3.07^2}{15} + \\frac{0.80^2}{12}}$$ Asi,  $0.60\\leq\\mu_1 - \\mu_2\\leq4.10$ Por ello se tiene una confianza del 95% de que el intervalo de 0.60 a 4.10 miligramos por litro contiene la diferencia de los contenidos promedios reales de ortof\u00f3sforo para estos dos lugares.   Ejercicio 2 </p> <p></p>  Un fabricante de monitores prueba dos dise\u00f1os de microcircuitos para determinar si producen un flujo de corriente equivalente. El departamento de ingenier\u00eda ha obtenido los datos siguientes:  Dise\u00f1o 1 Dise\u00f1o 2 $n_1$=16  $n_2$=10 $\\bar{x}_1$=24.2  $\\bar{x}_2$=23.9 $s_1$=10 $s_2$=40 <p>con \u03b1=0.05, se desea determinar si existe alguna diferencia significativa en el flujo de corriente promedio entre los dos dise\u00f1os, donde se supone que las dos poblaciones son normales, pero no es posible suponer que las varianzas desconocidas sean iguales.</p> <p>Sol. $$ gl = \\frac{(s_1^2/n_1 + s_2^2/n_2)^2}{(s_1^2/n_1)^2/(n_1-1) + (s_2^2/n_2)^2/(n_2-1)}=\\frac{(10/16 + 40/10)^2}{(10/16)^2/(16-1) + (40/10)^2/(10-1)}=11.858 $$ Este valor se redondea al pr\u00f3ximo menor que ser\u00eda 11.</p> In\u00a0[13]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\nx = np.arange(-2.9, 2.9, 0.001)\n\n#pintar el fondo externo del grafico\nplt.figure(facecolor='#D4F8B7')\n\n#tama\u00f1o del grafico\n#plt.figure(figsize=(6,4))\n\n#area de sombreado rango\nx_filtered = x[(x &gt;= -1.00) &amp; (x &lt;= 1.00)]\n\n#pintar la linea curva del grafico\nplt.plot(x, norm.pdf(x, 0, 1), linewidth = 2, color = '#000')\n\n#pintar el area sombreada del grafico y graficar \nplt.fill_between(x_filtered, norm.pdf(x_filtered, 0, 1), color='#5CCB5F', alpha=0.5, edgecolor='black')\n\n#a\u00f1adir texto al grafico\nplt.text(-3.8, 0.08, (\"\u03b1/2=0.025\"))\nplt.text(-3.8, 0.10, (\"Regi\u00f3n de rechazo\"))\nplt.text(3, 0, (\"z\"))\n\n#bordes del grafico\nax = plt.gca()\nax.spines['top'].set_color('#009929')\nax.spines['top'].set_linewidth(2)\n#ancho del borde superior\nax.spines['top'].set_bounds(-4.5, 4.5)\nax.spines['bottom'].set_color('#009929')\nax.spines['bottom'].set_linewidth(2)\n#ancho del borde inferior\nax.spines['bottom'].set_bounds(-4.5, 4.5)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\n\n#pintar el fondo interno del grafico\nax.set_facecolor('#D4F8B7')\n\n#linea inferior del grafico\nplt.plot(x, [0]*len(x), color='black', linewidth=2)\n\n#centrar el grafico\nplt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)\n\n#plt.arrow(0.1, 0.1, 0.2, 0.2, width=0.05, color='black')\n\n#flecha\nplt.annotate(\" \", xytext = (-2.3, 0.1), xy = (-1.7, 0.03), arrowprops = dict(facecolor = 'black', width = 0.2, headwidth = 8),\n             horizontalalignment = 'center')\n\n#texto con flecha\nplt.text(2.7, 0.12, (\"Regi\u00f3n de rechazo\"))\nplt.annotate(\"\u03b1/2=0.025\", xytext = (3.2,0.1), \n             xy = (1.8, 0.03), arrowprops = dict(facecolor = 'black', width = 0.2, headwidth = 8),\n             horizontalalignment = 'center')\n\n#mostrar ejes x, y\nplt.text(-0.3, -0.05, (\"\\u03BC\u2081-\\u03BC\\u2082=0\"))\nplt.text(-1.5, -0.05, (\"t=-2.201\"))\nplt.text(0.8, -0.05, (\"t=2.201\"))\nplt.xticks([0], ['{:.2f}'.format(i) for i in []])\nplt.yticks([])\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm  x = np.arange(-2.9, 2.9, 0.001)  #pintar el fondo externo del grafico plt.figure(facecolor='#D4F8B7')  #tama\u00f1o del grafico #plt.figure(figsize=(6,4))  #area de sombreado rango x_filtered = x[(x &gt;= -1.00) &amp; (x &lt;= 1.00)]  #pintar la linea curva del grafico plt.plot(x, norm.pdf(x, 0, 1), linewidth = 2, color = '#000')  #pintar el area sombreada del grafico y graficar  plt.fill_between(x_filtered, norm.pdf(x_filtered, 0, 1), color='#5CCB5F', alpha=0.5, edgecolor='black')  #a\u00f1adir texto al grafico plt.text(-3.8, 0.08, (\"\u03b1/2=0.025\")) plt.text(-3.8, 0.10, (\"Regi\u00f3n de rechazo\")) plt.text(3, 0, (\"z\"))  #bordes del grafico ax = plt.gca() ax.spines['top'].set_color('#009929') ax.spines['top'].set_linewidth(2) #ancho del borde superior ax.spines['top'].set_bounds(-4.5, 4.5) ax.spines['bottom'].set_color('#009929') ax.spines['bottom'].set_linewidth(2) #ancho del borde inferior ax.spines['bottom'].set_bounds(-4.5, 4.5) ax.spines['right'].set_visible(False) ax.spines['left'].set_visible(False)  #pintar el fondo interno del grafico ax.set_facecolor('#D4F8B7')  #linea inferior del grafico plt.plot(x, [0]*len(x), color='black', linewidth=2)  #centrar el grafico plt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)  #plt.arrow(0.1, 0.1, 0.2, 0.2, width=0.05, color='black')  #flecha plt.annotate(\" \", xytext = (-2.3, 0.1), xy = (-1.7, 0.03), arrowprops = dict(facecolor = 'black', width = 0.2, headwidth = 8),              horizontalalignment = 'center')  #texto con flecha plt.text(2.7, 0.12, (\"Regi\u00f3n de rechazo\")) plt.annotate(\"\u03b1/2=0.025\", xytext = (3.2,0.1),               xy = (1.8, 0.03), arrowprops = dict(facecolor = 'black', width = 0.2, headwidth = 8),              horizontalalignment = 'center')  #mostrar ejes x, y plt.text(-0.3, -0.05, (\"\\u03BC\u2081-\\u03BC\\u2082=0\")) plt.text(-1.5, -0.05, (\"t=-2.201\")) plt.text(0.8, -0.05, (\"t=2.201\")) plt.xticks([0], ['{:.2f}'.format(i) for i in []]) plt.yticks([]) plt.show()   $$t = \\frac{\\overline{x}_1 - \\overline{x}_2 - D_0}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}=\\frac{24.2 - 23.9 - 0}{\\sqrt{\\frac{10}{16} + \\frac{40}{10}}}=0.1395$$  Como 0.1395 esta entre -2.201 y 2.201, no se rechaza Ho y se concluye con un \u03b1= 0.05, que no existe diferencia significativa en el flujo de corriente promedio entre los dos dise\u00f1os.  <p>Suponga que los empleados de una empresa de manufactura utilizan dos m\u00e9todos distintos para realizar una tarea de producci\u00f3n. Con el fin de maximizar la producci\u00f3n, la empresa desea identificar el m\u00e9todo con la menor media poblacional del tiempo necesario para completar esta tarea. Sea \u03bc<sub>1</sub> la media poblacional del tiempo empleando el m\u00e9todo 1, y \u03bc<sub>2</sub> la media poblacional del tiempo requerido para completar la tarea con el m\u00e9todo 2. Puesto que no hay ninguna indicaci\u00f3n de cu\u00e1l es el mejor m\u00e9todo, se empieza por suponer que con los dos se obtiene la misma media poblacional del tiempo requerido para completar la tarea. De esta manera, la hip\u00f3tesis nula es H<sub>0</sub> :  \u03bc<sub>1</sub> - \u03bc<sub>2</sub> = 0. Si se rechaza esta hip\u00f3tesis, se podr\u00e1 concluir que las medias poblacionales de los tiempos requeridos para realizar la tarea son diferentes con los dos m\u00e9todos. En tal caso se recomendar\u00e1 el que proporcione la menor media del tiempo para la realizaci\u00f3n de la tarea. Las hip\u00f3tesis nula y alternativa se expresan como sigue.</p> <p>$$ H_0 : \u03bc_1 - \u03bc_2 = 0 $$ $$ H_a : \u03bc_1 - \u03bc_2 \\neq 0 $$</p> <p>En la elecci\u00f3n del procedimiento de muestreo para obtener los datos y probar las hip\u00f3tesis se consideran dos dise\u00f1os alternos. Uno se basa en muestras independientes y el otro en muestras pareadas (o muestras por pares)</p> <p>Dise\u00f1o de muestras independientes. Se toma una muestra aleatoria simple de trabajadores y cada uno de ellos usa el m\u00e9todo 1. Se extrae una segunda muestra aleatoria simple independiente de trabajadores y cada uno usa el m\u00e9todo 2. El procedimiento que se utiliza para probar la diferencia entre las dos medias es el presentado en la secci\u00f3n 10.2.</p> <p>Dise\u00f1o de muestras pareadas. Se toma una muestra aleatoria simple de trabajadores. Cada trabajador usa primero uno de los m\u00e9todos y despu\u00e9s el otro. A cada sujeto se le asigna en forma aleatoria el orden en que aplicar\u00e1 los dos m\u00e9todos; algunos primero usar\u00e1n el m\u00e9todo 1 y otros el m\u00e9todo 2. Cada trabajador proporcionar\u00e1 un par de valores de datos, un valor para el m\u00e9todo 1 y otro para el m\u00e9todo 2. de en la distribuci\u00f3n normal est\u00e1ndar.</p> <p>En el dise\u00f1o de muestras pareadas los dos m\u00e9todos se prueban bajo condiciones similares (es decir, con los mismos trabajadores); por tanto, este dise\u00f1o suele conducir a errores muestrales m\u00e1s peque\u00f1os que el de muestras independientes. La raz\u00f3n principal se debe a que en el dise\u00f1o de muestras pareadas se elimina la variaci\u00f3n entre los trabajadores, ya que los mismos sujetos prueban los dos m\u00e9todos.</p> <p>A continuaci\u00f3n, con el empleo del dise\u00f1o de muestras pareadas se demostrar\u00e1 la diferencia entre las medias poblacionales para los dos m\u00e9todos de producci\u00f3n. Se emplea una muestra aleatoria de seis trabajadores. En la tabla 10.2 se indican los tiempos que requirieron los seis sujetos para realizar la tarea. Observe que de cada trabajador se obtuvieron dos datos, uno con cada m\u00e9todo de producci\u00f3n. Tambi\u00e9n observe que en la \u00faltima columna se proporciona, para cada sujeto de la muestra, la diferencia d<sub>i</sub> entre los tiempos para completar la tarea. Lo principal en el an\u00e1lisis de muestras pareadas consiste en darse cuenta de que \u00fanicamente hay que considerar la columna de las diferencias. De manera que se tienen seis valores de datos (0.6, 0.2, 0.5, 0.3, 0 y 0.6) que se usar\u00e1n para analizar la discrepancia entre las medias poblacionales de los dos m\u00e9todos de producci\u00f3n.</p> <p>Sea \u03bc<sub>d</sub> = la media de la diferencia en los valores de la poblaci\u00f3n de trabajadores. Con esta notaci\u00f3n, las hip\u00f3tesis nula y alternativa se expresan como sigue.</p> <p>$$ H_0 : \u03bc_d = 0 $$ $$ H_a : \u03bc_d \\neq 0 $$</p> <p>Si H<sub>0</sub> es rechazada, se concluye que las medias poblacionales difi eren en los tiempos requeridos para completar la tarea con los dos m\u00e9todos. La notaci\u00f3n d sirve para recordar que las muestras pareadas proporcionan datos que son diferencias. A continuaci\u00f3n se calcula la media y la desviaci\u00f3n est\u00e1ndar muestrales de las seis diferencias en los valores que se presentan en la tabla 10.2.</p> <p>$$\\overline{d} = \\frac{\u03a3d_i}{n} = \\frac{1.8}{6} = 0.30$$ $$S_d = \\sqrt{\\frac{\u03a3(d_i-\\overline{d})^2}{n-1}} = \\sqrt{\\frac{0.56}{5}} = 0.355$$</p> <p>TABLA 10.2 Tiempos para completar una tarea en un dise\u00f1o de muestras pareadas</p> Trabajador Tiempo de realizacion con el metodo 1 (minutos) Tiempo de realizacion con el metodo 2 (minutos) Diferencia en los tiempos de realizacion (d<sub>i</sub>) 1  6.0 5.4   0.6 2  5.0 5.2 -0.2 3 7.0   6.5  0.5  4  6.2  5.9  0.3 5  6.0  6.0  0  6  6.4  5.8 0.6  Como la muestra es peque\u00f1a, n = 6, es preciso suponer que la poblaci\u00f3n de las diferencias tiene una distribuci\u00f3n normal. Este supuesto es necesario para usar la distribuci\u00f3n t en la prueba de hip\u00f3tesis y para calcular la estimaci\u00f3n por intervalo. Con esta presunci\u00f3n, el estad\u00edstico de prueba siguiente tiene una distribuci\u00f3n t con n - 1 grados de libertad  <p>GRADOS DE LIBERTAD: DISTRIBUCI\u00d3N t CON DOS MUESTRAS ALEATORIAS INDEPENDIENTES</p> <p>$$ t = \\frac{\\overline{d} - \u03bc_d}{S_d/\\sqrt{n}} = \\frac{0.30 - 0}{0.335/\\sqrt{6}} = 2.20$$</p> <p>Ahora se calcular\u00e1 el valor-p para esta prueba de dos colas. Como t = 2.20 &gt; 0, el estad\u00edstico de prueba se encuentra en la cola superior de la distribuci\u00f3n t. Como t  2.20, el \u00e1rea en la cola superior a la derecha del estad\u00edstico de prueba se identifi ca usando la tabla de distribuci\u00f3n t con grados de libertad = n - l = 6 - l = 5. A continuaci\u00f3n se copia la informaci\u00f3n correspondiente a la fi la de la tabla de distribuci\u00f3n t para 5 grados de libertad</p> Trabajador 0.20 0.10 0.05 0.025 0.01 0.005 Valor-t(5 gl) 0.920 1.476 2.015 2.571 3.356 4.032 <p>Como se ve, el \u00e1rea en la cola superior est\u00e1 entre 0.05 y 0.025. Por tratarse de una prueba de dos colas, se duplica este valor y se concluye que el valor-p se ubica entre 0.10 y 0.05. Este valor-p es mayor que \u03b1 = 0.05. Por ende, no se rechaza la hip\u00f3tesis nula H<sub>0</sub>: \u03bc<sub>d</sub> = 0. Con Excel o Minitab y los datos de la tabla 10.2 se encuentra el valor-p exacto = 0.080. Adem\u00e1s, tambi\u00e9n se puede obtener un intervalo de confi anza para estimar la diferencia entre las dos medias poblacionales usando la metodolog\u00eda para una sola poblaci\u00f3n presentada en el cap\u00edtulo 8. A continuaci\u00f3n se presenta el c\u00e1lculo para obtener un intervalo de 95% de confi anza.</p> <p>$$\\overline{d} \\pm t_{0.025}\\frac{S_d}{\\sqrt{n}}$$ $$0.3 \\pm 2.571(\\frac{0.335}{\\sqrt{6}})$$ $$0.3 \\pm 0.35$$</p> <p>Por tanto, el margen de error es 0.35 y el intervalo de 95% de confi anza para estimar la diferencia entre las medias poblacionales de los dos m\u00e9todos de producci\u00f3n va de 0.05 minutos a 0.65 minutos.</p> In\u00a0[14]: Copied! <pre>import scipy.stats as stats\nimport numpy as np\n\n# Datos\ndiferencias = np.array([-1, -2, 0, 0, -2])\nn = len(diferencias)\nalfa = 0.05\n\n# Calcula la media, la desviaci\u00f3n est\u00e1ndar y el estad\u00edstico t\nmedia_d = np.mean(diferencias)\ndesviacion_estandar_d = np.std(diferencias, ddof=1)  # Usando ddof=1 para la correcci\u00f3n de Bessel\nt_estadistico = media_d / (desviacion_estandar_d / np.sqrt(n))\n\n# Grados de libertad\ngrados_libertad = n - 1\n\n# Calcula el valor p para una prueba t de dos colas\nvalor_p = 2 * (1 - stats.t.cdf(np.abs(t_estadistico), df=grados_libertad))\n\n# Imprime resultados\nprint(f\"Estad\u00edstico t: {t_estadistico}\")\nprint(f\"Valor p: {valor_p}\")\n\n# Compara con el nivel de significancia alfa\nif valor_p &lt; alfa:\n    print(\"Se rechaza la hip\u00f3tesis nula.\")\nelse:\n    print(\"No se rechaza la hip\u00f3tesis nula.\")\n</pre> import scipy.stats as stats import numpy as np  # Datos diferencias = np.array([-1, -2, 0, 0, -2]) n = len(diferencias) alfa = 0.05  # Calcula la media, la desviaci\u00f3n est\u00e1ndar y el estad\u00edstico t media_d = np.mean(diferencias) desviacion_estandar_d = np.std(diferencias, ddof=1)  # Usando ddof=1 para la correcci\u00f3n de Bessel t_estadistico = media_d / (desviacion_estandar_d / np.sqrt(n))  # Grados de libertad grados_libertad = n - 1  # Calcula el valor p para una prueba t de dos colas valor_p = 2 * (1 - stats.t.cdf(np.abs(t_estadistico), df=grados_libertad))  # Imprime resultados print(f\"Estad\u00edstico t: {t_estadistico}\") print(f\"Valor p: {valor_p}\")  # Compara con el nivel de significancia alfa if valor_p &lt; alfa:     print(\"Se rechaza la hip\u00f3tesis nula.\") else:     print(\"No se rechaza la hip\u00f3tesis nula.\")  <pre>Estad\u00edstico t: -2.23606797749979\nValor p: 0.08900934250008552\nNo se rechaza la hip\u00f3tesis nula.\n</pre> <p>Siendo p<sub>1</sub> la proporci\u00f3n de la poblaci\u00f3n 1 y p<sub>2</sub> la proporci\u00f3n de la poblaci\u00f3n 2, a continuaci\u00f3n se considerar\u00e1n inferencias acerca de la diferencia entre dos proporciones poblacionales: p<sub>1</sub> - p<sub>2</sub>. Para determinar las inferencias acerca de estas diferencias, se seleccionan dos muestras aleatorias independientes: una de n<sub>1</sub> unidades de la poblaci\u00f3n 1 y otra de n<sub>2</sub> unidades de la poblaci\u00f3n 2. </p>"},{"location":"capitulo10/","title":"\u00b6","text":"CAPITULO 10  Inferencia estad\u00edstica de medias y proporciones con 2 poblaciones Contenido del capitulo <p>10.1. INFERENCIAS ACERCA DE LA DIFERENCIA ENTRE DOS MEDIAS POBLACIONALES: (\\( \\sigma_1\\) Y  \\(\\sigma_2\\) CONOCIDAS)</p> <ul> <li>Estimaci\u00f3n por intervalo para: \\(\\mu_1 - \\mu_2\\)  </li> <li>Pruebas de hip\u00f3tesis acerca de \\(\\mu_1 - \\mu_2\\)</li> <li>Consejo pr\u00e1ctico</li> </ul> <p>10.2 INFERENCIAS ACERCA DE LA DIFERENCIA ENTRE DOS MEDIAS POBLACIONALES:\\( \\sigma_1\\) y  \\(\\sigma_2\\) DESCONOCIDAS</p> <ul> <li>Estimaci\u00f3n por intervalo para: \\(\\mu_1 - \\mu_2\\)  </li> <li>Pruebas de hip\u00f3tesis acerca de \\(\\mu_1 - \\mu_2\\)</li> <li>Consejo pr\u00e1ctico</li> </ul> <p>10.3 INFERENCIAS ACERCA DE LA DIFERENCIA ENTRE DOS MEDIAS POBLACIONALES: MUESTRAS PAREADAS</p> <p>10.4 INFERENCIAS ACERCA DE LA DIFERENCIA ENTRE DOS PROPORCIONES POBLACIONALES</p> <ul> <li>Estimaci\u00f3n por intervalo para: \\(p_1 - p_2\\)  </li> <li>Pruebas de hip\u00f3tesis acerca de \\(p_1 - p_2\\)</li> </ul>"},{"location":"capitulo10/#101-inferencias-acerca-de-la-diferencia-entre-dos-medias-poblacionales-sigma_1-y-sigma_2-conocidas","title":"10.1 Inferencias acerca de la diferencia entre dos medias poblacionales: $\\sigma_1$ y $\\sigma_2$ conocidas\u00b6","text":""},{"location":"capitulo10/#estimacion-por-intervalo-para-mu_1-mu_2","title":"Estimaci\u00f3n por intervalo para $\\mu_1 - \\mu_2$\u00b6","text":""},{"location":"capitulo10/#pruebas-de-hipotesis-acerca-de-mu_1-mu_2","title":"Pruebas de hip\u00f3tesis acerca de $\\mu_1 - \\mu_2$\u00b6","text":"<p>Ahora se ver\u00e1n las pruebas de hip\u00f3tesis acerca de la diferencia entre dos medias poblacionales. $D_0$ denota la diferencia hipot\u00e9tica entre $\\mu_1$ y $\\mu_2$. Las tres formas que puede adoptar una prueba de hip\u00f3tesis son las siguientes:</p>"},{"location":"capitulo10/#resultados-de-la-prueba-de-hipotesis","title":"Resultados de la Prueba de Hip\u00f3tesis\u00b6","text":"<p>En el an\u00e1lisis de la calidad educativa entre dos centros, se emple\u00f3 una prueba de hip\u00f3tesis de dos colas con un nivel de significancia de 0.05. El estad\u00edstico de prueba calculado fue $z = 1.66$. Utilizando la distribuci\u00f3n normal est\u00e1ndar, se obtuvo un valor-p de 0.0970, que es mayor que $\\alpha$, indicando que no hay suficiente evidencia para rechazar la hip\u00f3tesis nula. Por lo tanto, no se observa una diferencia estad\u00edsticamente significativa en la calidad de los centros de ense\u00f1anza.</p> <p>Se puede concluir que, tanto por el m\u00e9todo del valor-p como por el m\u00e9todo del valor cr\u00edtico, los datos no muestran diferencias significativas en la calidad educativa entre los dos centros analizados.</p> <p>Referencia: Para los c\u00e1lculos del estad\u00edstico de prueba y la interpretaci\u00f3n de resultados, v\u00e9ase la ecuaci\u00f3n (10.5) y las reglas de rechazo para pruebas de una cola presentadas en el cap\u00edtulo 9.</p>"},{"location":"capitulo10/#consejo-practico","title":"Consejo Pr\u00e1ctico\u00b6","text":"<p>Para estimaciones por intervalo y pruebas de hip\u00f3tesis, se recomienda que las muestras aleatorias sean de tama\u00f1o $n_1 \\geq 30$ y $n_2 \\geq 30$. En situaciones donde el tama\u00f1o de la muestra es menor a 30, es crucial asegurarse de que las distribuciones de las poblaciones sean aproximadamente normales para proceder con el an\u00e1lisis.</p>"},{"location":"capitulo10/#ejercicios","title":"Ejercicios\u00b6","text":""},{"location":"capitulo10/#videos-de-interes","title":"Videos de Inter\u00e9s\u00b6","text":""},{"location":"capitulo10/#102-inferencias-acerca-de-la-diferencia-entre-dos-medias-poblacionales-sigma_1-y-sigma_2-desconocidas","title":"10.2 Inferencias acerca de la diferencia entre dos medias poblacionales: $\\sigma_1$ y $\\sigma_2$ desconocidas\u00b6","text":""},{"location":"capitulo10/#estimacion-por-intervalo-mu_1-mu_2","title":"Estimaci\u00f3n por Intervalo $\\mu_1 - \\mu_2$\u00b6","text":""},{"location":"capitulo10/#pruebas-de-hipotesis-acerca-mu_1-mu_2","title":"Pruebas de hip\u00f3tesis acerca: $\\mu_1 - \\mu_2$\u00b6","text":"<p>Ahora se estudiar\u00e1n las pruebas de hip\u00f3tesis acerca de la diferencia entre las medias de dos poblaciones cuando no se conocen las desviaciones est\u00e1ndar poblacionales $\\sigma_1$  y  $\\sigma_2$.  Sea  $D_0$  la diferencia hipot\u00e9tica entre  $\\mu_1$  y  $\\mu_2$.  El estad\u00edstico de prueba utilizado cuando se conocen  $\\sigma_1$  y  $\\sigma_2$ es el siguiente: $$ z = \\frac{(\\bar{X}_1 - \\bar{X}_2) - D_0}{\\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}}} $$ El estad\u00edstico de prueba  z  sigue la distribuci\u00f3n normal est\u00e1ndar.</p>"},{"location":"capitulo10/#102-ejercicios","title":"10.2) Ejercicios\u00b6","text":""},{"location":"capitulo10/#103-inferencias-acerca-de-la-diferencia-entre-dos-medias-poblacionales-muestras-pareadas","title":"10.3 Inferencias acerca de la diferencia entre dos medias poblacionales: muestras pareadas\u00b6","text":""},{"location":"capitulo10/#103-ejercicios","title":"10.3) Ejercicios\u00b6","text":"METODOS <ol> <li>Considere la prueba de hipotesis siguiente.</li> </ol> <p>$$H_0 : \u03bc_d \\leq 0$$ $$H_a : \u03bc_d &gt; 0$$</p> <p>Los datos siguientes provienen de muestras pareadas tomadas de dos poblaciones.</p> Poblacion Poblacion Elemento 1 2 1 21 20 2 28 26 3 18 18 4 20 20 5 26 24 <p>(a) Calcule la diferencia en el valor de cada elemento</p> <p>(b) Determine $\\overline{d}$</p> <p>(c) Calcule la desviaci\u00f3n est\u00e1ndar $S_d$</p> <p>(d) Realice una prueba de hip\u00f3tesis usando \u03b1 = 0.05. \u00bfCu\u00e1l es su conclusi\u00f3n?</p>  Solucion: (a) Se calcula la diferencia en el valor de cada elemento: Para cada par de elementos, se resta el segundo valor del primero: <p>$d_i = x_{i2} - x_{i1}$</p> <p>$$d_1 = 20 - 21 = -1$$ $$d_2 = 26 - 28 = -2$$ $$d_3 = 18 - 18 = 0$$ $$d_4 = 20 - 20 = 0$$ $$d_5 = 24 - 26 = -2$$</p> <p>(b) Determine $\\overline{d}$:</p>  Calcular la media de las diferencias:  <p>$\\overline{d} = \\frac{\u03a3^{n}_{i=1}d_i}{n}$ $$\\overline{d} = \\frac{(-1)+(-2)+0+0+(-2)}{5} = -\\frac{5}{5} = -1$$</p> <p>(c) Calcule la desviaci\u00f3n est\u00e1ndar $S_d$ Primero, se calcula las diferencias al cuadrado: $(d_i - \\overline{d})^2 $ $$( - 1 - ( 1 ) )^2 = 0$$ $$( - 2 - (- 1 ) )^2 = 1$$ $$( 0 - ( - 1 ) )^2 = 1$$ $$( 0 - ( - 1 ) )^2 = 1$$ $$(-2-(-1))^2=1$$ Luego, se calcula la varianza $S^{2}_d$: $S^{2}_d = \\frac{\u03a3^{n}_{i=1}(d_i-\\overline{d})^2}{n-1}$ $$S^{2}_d = \\frac{0+1+1+1+1}{5-1} = \\frac{4}{4} = 1$$ Finalmente, la desviaci\u00f3n est\u00e1ndar $S_d:$ $$S_d = \\sqrt{S^{2}_d} = \\sqrt{1} = 1$$ (d) Realice una prueba de hip\u00f3tesis \u03b1 \u2264 0.05  Para realizar una prueba de hip\u00f3tesis, necesitas comparar el valor p calculado con el nivel de significancia \u03b1. El estad\u00edstico de prueba t se calcula como: $t = \\frac{\\overline{d}}{S_d/\\sqrt{n}}$ Para este ejemplo, asumamos que la hip\u00f3tesis alternativa es \"distinto de cero\". Utilizando una prueba t de dos colas y \u03b1=0.05, puedes comparar el valor p con \u03b1. Una forma de realizar la prueba es utilizar una tabla de distribuci\u00f3n t de Student o un software estad\u00edstico.</p>"},{"location":"capitulo10/#videos","title":"Videos\u00b6","text":""},{"location":"capitulo10/#104-inferencias-acerca-de-la-diferencia-entre-dos-proporciones-poblacionales","title":"10.4 Inferencias acerca de la diferencia entre dos proporciones poblacionales\u00b6","text":""},{"location":"capitulo10/#estimacion-por-intervalo-para-p1-p2","title":"Estimaci\u00f3n por intervalo para p<sub>1</sub> - p<sub>2</sub>\u00b6","text":"<p>En el ejemplo siguiente se mostrar\u00e1 c\u00f3mo calcular un margen de error y una estimaci\u00f3n por intervalo para la diferencia entre dos proporciones poblacionales. Una empresa que se dedica a elaborar declaraciones de impuestos desea comparar la calidad del trabajo que se realiza en dos de sus oficinas regionales. Con muestras aleatorias de las declaraciones de impuestos elaboradas en dichas ofi cinas y verificando la exactitud de los reportes, la empresa podr\u00e1 estimar la proporci\u00f3n de declaraciones con errores en que incurri\u00f3 cada una de estas ofi cinas. Interesa conocer la diferencia entre las proporciones siguientes:</p> $p_1$ = Proporci\u00f3n de declaraciones err\u00f3neas en la poblaci\u00f3n 1 (oficina 1) $p_2$ = Proporci\u00f3n de declaraciones err\u00f3neas en la poblaci\u00f3n 2 (oficina 2) $\\overline{p_1}$ = Proporci\u00f3n muestral en una muestra aleatoria simple de la poblaci\u00f3n 1 $\\overline{p_2}$ = Proporci\u00f3n muestral en una muestra aleatoria simple de la poblaci\u00f3n 2 <p>La diferencia entre las dos proporciones poblacionales est\u00e1 dada por p<sub>1</sub> - p<sub>2</sub>. La estimaci\u00f3n puntual de p<sub>1</sub> - p<sub>2</sub> se indica enseguida.</p> ESTIMADOR PUNTUAL DE LA DIFERENCIA ENTRE DOS PROPORCIONES POBLACIONALES              $$\\overline{p_1} - \\overline{p_2}$$          (10.10) <p>Por ende, el estimador puntual de la diferencia entre dos proporciones poblacionales es la diferencia entre las proporciones muestrales de dos muestras aleatorias simples independientes. Como ocurre con otros estimadores puntuales, el estimador puntual $\\overline{p_1} -  \\overline{p_2}$ tiene una distribuci\u00f3n de muestreo que refleja los valores que podr\u00eda asumir $\\overline{p_1} - \\overline{p_2}$ si se tomaran repetidamente dos muestras aleatorias simples independientes. La media de esta distribuci\u00f3n de muestreo es $p_1 - p_2$ y el error estandar $ \\overline{p_1} - \\overline{p_2}$ es el siguiente.</p> ERROR EST\u00c1NDAR DE $p_1$ - $p_2$              $$\\sigma_{\\overline{p_1}-\\overline{p_2}} = \\sqrt{\\frac{p_1(1-p_1)}{n_1}+\\frac{p_2(1-p_2)}{n_2}}$$          (10.11) <p>Si los tama\u00f1os de las muestras son suficientemente grandes para que $n_1p_1,n_1(1-p_1), n_2p_2$ y $n_2(1-p_2)$ todos mayores o iguales que 5, la distribuci\u00f3n de muestreo de $\\overline{p_1} - \\overline{p_2}$ puede ser aproximada por una distribuci\u00f3n normal. Como ya se indic\u00f3 antes, una estimaci\u00f3n por intervalo est\u00e1 dada por una estimaci\u00f3n puntual $\\pm$ un margen de error. En el c\u00e1lculo de la diferencia entre dos proporciones poblacionales, una estimaci\u00f3n por intervalo toma la forma siguiente.</p>              $$\\overline{p_1}-\\overline{p_2} \\pm  \\text{margen de error} $$           Al aproximar la distribuci\u00f3n de muestreo de $\\overline{p_1}-\\overline{p_2}$ mediante una distribuci\u00f3n normal, se podr\u00e1 usar como margen de error $Z_{\\alpha/2}\\sigma_{\\overline{p_1}-\\overline{p_2}}$. Sin embargo, como $\\sigma_{\\overline{p_1}-\\overline{p_2}}$ est\u00e1 dada por la ecuaci\u00f3n (10.11) no se puede usar directamente porque no se conoce ninguna de las dos proporciones poblacionales $p_1$ y $p_2$. Al usar la proporci\u00f3n muestral $\\overline{p_1}$ para estimar $p_1$ y la proporci\u00f3n muestral $$\\overline{p_2} para estimar $p_2$, el margen de error queda como sigue.                $$Margen\\ de\\ error = Z_{\\alpha/2}\\sqrt{\\frac{\\overline{p_1}(1-\\overline{p_1})}{n_1}+\\frac{\\overline{p_2}(1-\\overline{p_2})}{n_2}}$$          (10.12) <p>La forma general de una estimaci\u00f3n por intervalo para la diferencia entre dos proporciones poblacionales es la siguiente.</p> ESTIMACI\u00d3N POR INTERVALO DE LA DIFERENCIA ENTRE DOS PROPORCIONES POBLACIONALES              $$\\overline{p_1}-\\overline{p_2}\\pm Z_{\\alpha/2}\\sqrt{\\frac{\\overline{p_1}(1-\\overline{p_1})}{n_1}+\\frac{\\overline{p_2}(1-\\overline{p_2})}{n_2}}$$          (10.13) donde 1 - $\\alpha$ es el coeficiente de confianza. <p>De regreso al ejemplo de elaboraci\u00f3n de declaraciones de impuestos, se encuentra que de las muestras aleatorias simples independientes de las dos oficinas se obtienen los datos siguientes.</p> Oficina 1 Oficina 2 $n_1 = 250$ $n_2 = 300$ N\u00famero de declaraciones con errores = 35 N\u00famero de declaraciones  con errores = 27 <p>Las proporciones muestrales en cada una de las oficinas son las siguientes.</p>                  $$\\overline{p_1} = \\frac{35}{250} = 0.14$$                 $$\\overline{p_2} = \\frac{27}{300} = 0.09$$              <p>La estimaci\u00f3n puntual de la diferencia entre las proporciones de declaraciones con errores en las dos poblaciones es $\\overline{p_1} - \\overline{p_2} = 0.14 - 0.09 = 0.05$. Por tanto, se estima que la ofi cina 1 comete 0.05 o 5% m\u00e1s errores que la oficina 2. Ahora se puede usar la expresi\u00f3n (10.13) para calcular el margen de error y la estimaci\u00f3n por intervalo para la diferencia entre las dos proporciones poblacionales. Utilizando un intervalo de 90% de confianza con $Z_{\\alpha/2} - Z_{0.05} =$  1.645, tenemos</p>                  $$ \\overline{p_1} - \\overline{p_2} \\pm Z_{\\alpha/2}\\sqrt{\\frac{\\overline{p_1}(1-\\overline{p_1})}{n_1}+\\frac{\\overline{p_2}(1-\\overline{p_2})}{n_2}}$$                 $$ 0.14 - 0.09 \\pm 1.645\\sqrt{\\frac{0.14(1-0.14)}{250}+\\frac{0.09(1-0.09)}{300}}$$                 $$0.05\\pm 0.045$$              <p>El margen de error es 0.045 y el intervalo de 90% de confi anza va de 0.005 a 0.095.</p>"},{"location":"capitulo10/#prueba-de-hipotesis-acerca-de-p1-p2","title":"Prueba de hip\u00f3tesis acerca de p<sub>1</sub> - p<sub>2</sub>\u00b6","text":"<p>Ahora se considerar\u00e1n las pruebas de hip\u00f3tesis acerca de la diferencia entre las proporciones de dos poblaciones. Se analizar\u00e1n pruebas que comprenden el caso en que no hay diferencia entre las dos proporciones poblacionales. En tal situaci\u00f3n, las tres formas que adoptan las pruebas de hip\u00f3tesis son las siguientes.</p> <p>$$ H_0: p_1 - p_2 \\geq 0\\ \\quad H_0: p_1 - p_2 \\leq 0  \\quad H_0: p_1 - p_2 = 0$$ $$ H_a: p_1 - p_2 &lt; 0 \\quad H_a: p_1 - p_2 &gt; 0  \\quad H_a: p_1 - p_2 \\neq 0$$</p> <p>Si se supone que H<sub>0</sub>, considerada como igualdad, es verdadera, se tiene $ p_1 - p_2 = 0$, lo cual equivale a decir que dichas proporciones poblacionales son iguales, $ p_1 = p_2$. El estad\u00edstico de prueba se basar\u00e1 en la distribuci\u00f3n de muestreo del estimador puntual $ \\overline{p_1} - \\overline{p_2}$. En la ecuaci\u00f3n (10.11) se mostr\u00f3 que el error est\u00e1ndar de $ \\overline{p_1} - \\overline{p_2}$ est\u00e1 dado por:</p> <p>$$\\sigma_{\\overline{p_1}-\\overline{p_2}} = \\sqrt{\\frac{p_1(1-p_1)}{n_1}+\\frac{p_2(1-p_2)}{n_2}}$$</p> <p>Si se supone que H<sub>0</sub> es verdadera como igualdad, las proporciones poblacionales son iguales y p1 = p2 = p. En este caso, $\\sigma_{\\overline{p_1}-\\overline{p_2}}$ se convierte en la expresi\u00f3n que se presenta enseguida.</p> ERROR EST\u00c1NDAR DE $ \\overline{p_1}-\\overline{p_2}$ CUANDO p1 = p2 = p              $$\\sigma_{\\overline{p_1}-\\overline{p_2}} = \\sqrt{\\frac{p_1(1-p_1)}{n_1}+\\frac{p_2(1-p_2)}{n_2}} = \\sqrt{p(1-p)(\\frac{1}{n_1}+\\frac{1}{n_2})}$$          (10.14) <p>Como no se conoce p, se combinan los estimadores puntuales de las dos muestras $(\\overline{p_1}\\ y\\ \\overline{p_2})$ con objeto de obtener un solo estimador puntual de p como se indica a continuaci\u00f3n.</p> ESTIMADOR COMBINADO DE p CUANDO $p_1 = p_2 = p$              $$\\overline{p} = \\frac{n_1\\overline{p_1} + n_2\\overline{p_2}}{n_1 + n_2}$$          (10.15) <p>El estimador combinado de p es un promedio ponderado de $\\overline{p_1} y \\overline{p_2}$. Al sustituir $\\overline{p}$ por p en la ecuaci\u00f3n (10.14), se obtiene una estimaci\u00f3n del error est\u00e1ndar de $\\overline{p_1} - \\overline{p_2}$. Dicha estimaci\u00f3n se usa en el estad\u00edstico de prueba. La f\u00f3rmula general del estad\u00edstico de prueba para una prueba de hip\u00f3tesis acerca de la diferencia entre dos proporciones poblacionales es el estimador puntual dividido entre la estimaci\u00f3n de $\\sigma_{\\overline{p_1}-\\overline{p_2}}$.</p> ESTAD\u00cdSTICO DE PRUEBA PARA PRUEBAS DE HIP\u00d3TESIS ACERCA DE $p_1 - p_2$              $$Z = \\frac{(\\overline{p_1}-\\overline{p_2})}{\\sqrt{\\overline{p}(1-\\overline{p})(\\frac{1}{n_1}+\\frac{1}{n_2})}}$$          (10.16) <p>Tal estad\u00edstico de prueba se aplica en situaciones de muestras grandes en las que $n_1p_1 , n_1(1 - p_1), n_2p_2\\ y\\ n_2(l - p_2)$, son todos mayores o iguales que 5. En el ejemplo de la empresa que se dedica a elaborar declaraciones de impuestos, suponga que \u00e9sta desea realizar una prueba de hip\u00f3tesis para determinar si las proporciones de errores en las dos oficinas son diferentes. Para esto se requiere una prueba de dos colas. Las hip\u00f3tesis nula y alternativa son las siguientes.</p> <p>$$ H_0: p_1 - p_2 = 0$$ $$ H_a: p_1 - p_2 \\neq 0$$</p> <p>Si $H_0$ es rechazada, la empresa concluir\u00eda que la proporci\u00f3n de errores que se cometen en las dos oficinas es distinta. Como nivel de significancia se usar\u00e1 $\\alpha = 0.10$. En los datos muestrales recabados previamente se encuentra que $\\overline{p_1} = 0.14$ en la muestra de $n_1 = 250$ declaraciones de la oficina 1, y $\\overline{p_2} = 0.09$ en la muestra de $n_2 = 300$ declaraciones en la muestra de la oficina 2. A continuaci\u00f3n se calcular\u00e1 la estimaci\u00f3n combinada de p.</p> <p>$$\\overline{p} = \\frac{n_1\\overline{p_1}+n_2\\overline{p_2}}{n_1+n_2} = \\frac{250(0.14)+300(0.09)}{250+300} = 0.1127$$</p> <p>Con la estimaci\u00f3n combinada y la diferencia entre las proporciones muestrales, se obtiene el valor del estad\u00edstico de prueba como se indica a continuaci\u00f3n.</p> <p>$$Z = \\frac{(\\overline{p_1}-\\overline{p_2})}{\\sqrt{\\overline{p}(1-\\overline{p})(\\frac{1}{n_1}+\\frac{1}{n_2})}} = \\frac{(0.14 - 0.09)}{\\sqrt{0.1127(1-0.1127)(\\frac{1}{250}+\\frac{1}{300})}} = 1.85$$</p> <p>Al calcular el valor-p para esta prueba de dos colas se observa, primero, que z = 1.85 se encuentra en la cola superior de la distribuci\u00f3n normal est\u00e1ndar. Considerando z = 1.85 y la tabla de distribuci\u00f3n normal est\u00e1ndar, se encuentra que el \u00e1rea en la cola superior es 1.0000 - 0.9678 = 0.0322. Al multiplicar esta \u00e1rea por 2, dado que se trata de una prueba de dos colas, se tiene que el valor-p es 2(0.0322) = 0.0644. Como este valor es menor que $\\alpha$ = 0.10, se rechaza $H_0$ para el nivel de significancia 0.10. La empresa concluye que las proporciones de errores de las dos oficinas difieren. La conclusi\u00f3n de esta prueba de hip\u00f3tesis es consistente con los resultados de la estimaci\u00f3n por intervalo calculada antes, los cuales indicaban que la diferencia entre las proporciones poblacionales de errores en las dos oficinas estaba entre 0.005 y 0.095, siendo la oficina 1 la que arrojaba una mayor tasa de errores.</p>"},{"location":"capitulo10/#104-ejercicios","title":"10.4 Ejercicios\u00b6","text":"<p>Ejercicio 28. </p> <p>Considere los resultados siguientes obtenidos de muestras independientes tomadas de dos poblaciones</p> <p>$$Muestra\\ 1 \\quad  Muestra\\ 2$$ $$n_1 = 400 \\quad n_2 = 300$$ $$\\overline{p_1} = 0.48 \\quad \\overline{p_2} = 0.36$$</p> <p>(a) \u00bfCu\u00e1l es la estimaci\u00f3n puntual de la diferencia entre las dos proporciones poblacionales?</p> <p>(b) Calcule un intervalo de 90% de confianza para la diferencia entre las dos proporciones poblacionales.</p> <p>(c) Proporcione un intervalo de 95% de confianza para la diferencia entre las dos proporciones poblacionales.</p> <p>Para resolver esto, primero calculamos la estimaci\u00f3n puntual de la diferencia entre las proporciones poblacionales. Esto se hace simplemente restando $\\overline{p_2}$ de $\\overline{p_1}$.</p> <p>$$\\overline{p_1} - \\overline{p_2} = 0.48 - 0.36 = 0.12$$ Luego, para calcular un intervalo de confianza del 90% para la diferencia, necesitamos la desviaci\u00f3n est\u00e1ndar de la diferencia. La f\u00f3rmula para esto es: $$\\sqrt{\\frac{\\overline{p_1}(1-\\overline{p_1})}{n_1}+\\frac{\\overline{p_2}(1-\\overline{p_2})}{n_2}}$$</p> <p>Sustituyendo los valores dados obtenemos:</p> <p>$$\\sqrt{\\frac{0.48(1-0.48)}{400}+\\frac{0.36(1-0.36)}{300}} = 0.056$$</p> <p>Para un intervalo de confianza del 90%, usamos un valor Z de 1.645 (para una prueba de dos colas). Entonces, el intervalo de confianza es:</p> <p>$$(\\overline{p_1}-\\overline{p_2})\\pm Z * \\sqrt{\\frac{\\overline{p_1}(1-\\overline{p_1})}{n_1}+\\frac{\\overline{p_2}(1-\\overline{p_2})}{n_2}}$$</p> <p>Sustituyendo los valores obtenemos el intervalo de confianza del 90% para la diferencia entre las proporciones:</p> <p>$$0.12 \\pm 1.645 * 0.056 = (0.02, 0.22)$$</p> <p>Por lo tanto, con un 90% de confianza, la diferencia entre las dos proporciones de poblaci\u00f3n est\u00e1 entre 0.02 y 0.22.</p> <p>Para un intervalo de confianza del 95%, usamos un valor Z de 1.96 (para una prueba de dos colas). Entonces, el intervalo de confianza es:</p> <p>$$(\\overline{p_1}-\\overline{p_2})\\pm Z * \\sqrt{\\frac{\\overline{p_1}(1-\\overline{p_1})}{n_1}+\\frac{\\overline{p_2}(1-\\overline{p_2})}{n_2}}$$</p> <p>Sustituyendo los valores obtenemos el intervalo de confianza del 95% para la diferencia entre las proporciones:</p> <p>$$0.12 \\pm 1.96 * 0.056 = (-0.02, 0.26)$$</p> <p>Por lo tanto, con un 95% de confianza, la diferencia entre las dos proporciones de poblaci\u00f3n est\u00e1 entre -0.02 y 0.26.</p>"},{"location":"capitulo12/","title":"Capitulo 12","text":"<p>En esta secci\u00f3n se estudia el caso en que cada elemento de una poblaci\u00f3n corresponde a una y s\u00f3lo a una de varias clases o categor\u00edas. A una poblaci\u00f3n como esta se le denomina poblaci\u00f3n  multinomial, la cual se puede entender como una extensi\u00f3n de la distribuci\u00f3n binomial al caso en el que hay tres o m\u00e1s categor\u00edas de resultados. En cada ensayo de un experimento multinomial, uno y s\u00f3lo uno de los resultados ocurre. Se supone que cada ensayo es independiente y que en todos ellos las probabilidades para los resultados permanecen constantes.</p> <p>Como ejemplo, durante las primeras 13 semanas de la temporada de televisi\u00f3n en Bolivia se registraron las proporciones siguientes de audiencia los s\u00e1bados de 8:00 p.m. a 9:00 p.m.: Red Bolisi\u00f3n 29%, Unitel 28%, Red Uno 25% e independientes 18%.</p> <p>En este caso la poblaci\u00f3n de inter\u00e9s es multinomial y cada espectador se clasifica como televidentes de la cadena de televisi\u00f3n Bolivisi\u00f3n, Unitel, Red Uno o de los independientes. De manera que tenemos una poblaci\u00f3n multinomial con cuatro resultados. Para las proporciones se usa la siguiente notaci\u00f3n.</p> <p>$$P_{A} =  \\text{ Horas de audiencia de la cadena de televis\u00f3n Red Bolivisi\u00f3n}$$ $$P_{B} =  \\text{ Horas de audiencia de la cadena de televis\u00f3n Unitel}$$ $$P_{C} =  \\text{ Horas de audiencia de la cadena de televis\u00f3n Red Uno}$$ $$P_{D} =  \\text{ Horas de audiencia de la cadena de televis\u00f3n independientes}$$</p> <p>Se realizar\u00e1 un estudio muestral y calcular\u00e1 la proporci\u00f3n poblacional de la audiencia que prefiere ver una cadena de televisi\u00f3n. Despu\u00e9s aplicar\u00e1 una prueba de hip\u00f3tesis para ver para ver si en la temporada de televisi\u00f3n vario la audiencia de televidentes. Suponga que el producto no altera dicha participaci\u00f3n; entonces, las hip\u00f3tesis nula y alternativa ser\u00e1n las siguientes:</p> <p>$$H_{0}: p_{A}= 0.29; p_{B} = 0.28, p_{C}=0.25 \\text{ y } p_{D}=0.18$$ $$H_{a}: \\text{ las proporciones poblacionales no son}$$ $$p_{A}= 0.29; p_{B} = 0.28, p_{C}=0.25 \\text{ y } p_{D}=0.18$$</p> <p>Si los resultados muestrales llevan al rechazo de $H_0$, se tendr\u00e1 evidencias de que no han variado las proporciones en la audiencia de televidentes.</p> <p>Considere que para este estudio en una muestra de 300 hogares se obtuvieron las audiencias siguientes en s\u00e1bado por la noche: Bolivisi\u00f3n 95 hogares, Unitel 70, Red Uno 89, e independientes 46 hogares.</p> Frecuencia observada Bolivisi\u00f3n Unitel Red Uno Independientes 95 70 89 46 <p>Ahora se realiza la prueba de bondad de ajuste para determinar si la muestra de las 300 preferencias de la audiencia coincide con la hip\u00f3tesis nula. La prueba de bondad de ajuste se basa en la comparaci\u00f3n de los resultados muestrales observados con los resultados esperados bajo el supuesto de que la hip\u00f3tesis nula es verdadera. Por tanto, el paso siguiente es calcular las preferencias esperadas en las 300 audiencias asumiendo que $p_{A}= 0.29$; $p_{B} = 0.28$, $p_{C}=0.25$ y $p_{D}=0.18$. Al hacerlo, se tendr\u00e1n los resultados esperados.</p> Frecuencia esperada Bolivisi\u00f3n Unitel Red Uno Independientes 300(0.29) = 87 300(0.28) = 84 300(0.25) = 75 300(0.18) = 54 <p>Como se observa, la frecuencia esperada de cada categor\u00eda se encuentra al multiplicar el tama\u00f1o de la muestra, 300, por la proporci\u00f3n hipot\u00e9tica de esa categor\u00eda.</p> <p>En la prueba de bondad de ajuste lo que interesa son las diferencias entre frecuencias observadas y esperadas. Grandes diferencias entre estas frecuencias har\u00e1n dudar sobre el supuesto de que las proporciones o participaci\u00f3n de mercado hipot\u00e9tica son correctas.</p> <p>El siguiente estad\u00edstico de prueba ayuda a responder la pregunta de si las diferencias entre las frecuencias observadas y esperadas son \u201cgrandes\u201d o \u201cpeque\u00f1as\u201d.</p>  ESTAD\u00cdSTICO DE PRUEBA PARA LA BONDAD DE AJUSTE  <p>$$ \\chi^{2}=\\displaystyle\\sum^{k}_{i=1}\\frac{(f_{i}-e_{i})^{2}}{e_{i}}(12.1) $$</p> <p>donde: $$ f_{i} = \\text{ frecuencia observada en la categor\u00eda } i $$ $$ e_{i} =  \\text{frecuencia esperada en la categor\u00eda }  i $$ $$ k =  \\text{n\u00famero de categor\u00edas.}$$ Nota. El estad\u00edstico de prueba tiene una distribuci\u00f3n ji-cuadrada con $ k-1 $ grados de libertad, siempre que en todas las categor\u00edas las frecuencias esperadas sean 5 o m\u00e1s.</p> <p>Ahora, de regreso al ejemplo de Scott Marketing Research, los datos muestrales se emplear\u00e1n para probar la hip\u00f3tesis de que en la poblaci\u00f3n multinomial las proporciones sigan siendo $p_{A}= 0.29$; $p_{B} = 0.28$, $p_{C}=0.25$ y $p_{D}=0.18$. El nivel de significancia que se usar\u00e1 es $\\alpha = 0.05$. Mediante las frecuencias observadas y esperadas se calcula el valor del estad\u00edstico de prueba.Como las frecuencias esperadas son todas 5 o m\u00e1s, se calcula el estad\u00edstico de prueba ji-cuadrada como se indica en la tabla 12.1, y se obtiene $\\chi^{2} = 6.87$.</p> <p>La hip\u00f3tesis nula es rechazada si las diferencias entre las frecuencias observadas y esperadas son grandes. Estas diferencias dar\u00e1n un valor grande del estad\u00edstico de prueba. Entonces, la prueba de bondad de ajuste ser\u00e1 siempre una prueba de cola superior. El \u00e1rea en la cola superior se emplea en el estad\u00edstico de prueba y en el m\u00e9todo del valor-p para determinar si se puede rechazar la hip\u00f3tesis nula. Para $k - 1 = 4 - 1 = 3$ grados de libertad, la tabla de ji-cuadrada (tabla 3 del ap\u00e9ndice B) proporciona lo siguiente.</p> \u00c1rea en la cola superior 0.10 0.05 0.025 0.01 0.005 Valor $\\chi^{2} $(3 gl) 6.251 7.815 9.348 11.345 12.838 $ \\chi^{2}= 6.87$ <p>Tabla 12.1  C\u00e1lculo del estad\u00edstico de prueba ji-cuadrada</p> Categor\u00eda Proporci\u00f3n hipot\u00e9tica Frecuencia observada $(f_{i})$ Frecuencia esperada $ (e_{i}) $ Diferencia $ (f_{i}-e_{i}) $ Cuadrado de la diferencia $ (f_{i}-e_{i})^{2} $ Cuadrado de la diferencia dividido entre la frecuencia esperada $ (f_{i}-e_{i})^{2}/e_{i} $ Bolivisi\u00f3n 0.29 95 87 8 64 0.74 Unitel 0.28 70 84 -14 196 2.33 Red Uno 0.25 89 75 14 196 2.61 Independientes 0.18 46 54 -8 64 1.19 Total 300 $\\chi^{2}=6.87$  <p>Se realiz\u00f3 el c\u00e1lculo de lo que se muestra en la tabla, en c\u00f3digo en Python, usando la librer\u00eda scipy.stats. De esta manera, es m\u00e1s f\u00e1cil calcular el estad\u00edstico de prueba de la prueba chi-cuadrada y obtener el valor-p.</p> In\u00a0[2]: Copied! <pre>import scipy.stats as stats\nimport numpy as np\n\n#Se da los valores de la proporcion hipotetica y la frecuencia observada \np_hipotetica=np.array([0.29, 0.28, 0.25, 0.18])\nobservado = np.array([95, 70, 89, 46])\n\n#Se calcula la frecuencia esperada con la proporcion hipotetica y la suma total de la frecuencia\n#observada\nsuma=sum(observado)\nesperado = suma*p_hipotetica\n\n# Realiza la prueba de bondad de ajuste de chi-cuadrado\nresult = stats.chisquare(f_obs=observado, f_exp=esperado)\n\n# Imprime el estad\u00edstico y el valor p\nprint(f\"Estad\u00edstico de chi-cuadrado: {result.statistic:.2f}\")\nprint(f\"Valor-p: {result.pvalue:.4f}\")\n</pre> import scipy.stats as stats import numpy as np  #Se da los valores de la proporcion hipotetica y la frecuencia observada  p_hipotetica=np.array([0.29, 0.28, 0.25, 0.18]) observado = np.array([95, 70, 89, 46])  #Se calcula la frecuencia esperada con la proporcion hipotetica y la suma total de la frecuencia #observada suma=sum(observado) esperado = suma*p_hipotetica  # Realiza la prueba de bondad de ajuste de chi-cuadrado result = stats.chisquare(f_obs=observado, f_exp=esperado)  # Imprime el estad\u00edstico y el valor p print(f\"Estad\u00edstico de chi-cuadrado: {result.statistic:.2f}\") print(f\"Valor-p: {result.pvalue:.4f}\")  <pre>Estad\u00edstico de chi-cuadrado: 6.87\nValor-p: 0.0762\n</pre> <p>En la tabla ya mostrada, tambi\u00e9n se realiz\u00f3 un c\u00e1lculo en c\u00f3digo Python. Sin embargo, en este caso, se respeta el formato de resoluci\u00f3n que se indica en la tabla.</p> In\u00a0[3]: Copied! <pre>import scipy.stats as stats\nfrom scipy.stats import chi2\nimport numpy as np\n\n#Aca se va anotando los dos vectores de la proporcion hipotetica y de la frecuencia observada\nproporcion_hipotetica = np.array([0.29, 0.28, 0.25, 0.18])\nfrecuencia_observada = np.array([95, 70, 89, 46])\n\n#Se calcula aca la suma total de la frecuencia observada y se halla la frecuencia esperada\nsuma_f_o= sum(frecuencia_observada)\nfrecuencia_esperada = suma_f_o  * proporcion_hipotetica\n\n#Ahora hallamos la diferencia, su cuadrado y luego de eso lo dividimos por su frec. esperada\ndiferencia = frecuencia_observada - frecuencia_esperada\ndiferencia_2 = diferencia**2\ndividir_dif_2 = diferencia_2/frecuencia_esperada\nestadistico_chi2 = sum(dividir_dif_2)\nprint(f\"Estad\u00edstico de chi-cuadrado: {estadistico_chi2:.2f}\")\n\n#Ahora hallamos el valor-p\ngrados_de_libertad = len(frecuencia_observada)-1\np_valor = chi2.sf(estadistico_chi2, grados_de_libertad)\nprint(f\"Valor-p: {p_valor:.4f}\")\n</pre> import scipy.stats as stats from scipy.stats import chi2 import numpy as np  #Aca se va anotando los dos vectores de la proporcion hipotetica y de la frecuencia observada proporcion_hipotetica = np.array([0.29, 0.28, 0.25, 0.18]) frecuencia_observada = np.array([95, 70, 89, 46])  #Se calcula aca la suma total de la frecuencia observada y se halla la frecuencia esperada suma_f_o= sum(frecuencia_observada) frecuencia_esperada = suma_f_o  * proporcion_hipotetica  #Ahora hallamos la diferencia, su cuadrado y luego de eso lo dividimos por su frec. esperada diferencia = frecuencia_observada - frecuencia_esperada diferencia_2 = diferencia**2 dividir_dif_2 = diferencia_2/frecuencia_esperada estadistico_chi2 = sum(dividir_dif_2) print(f\"Estad\u00edstico de chi-cuadrado: {estadistico_chi2:.2f}\")  #Ahora hallamos el valor-p grados_de_libertad = len(frecuencia_observada)-1 p_valor = chi2.sf(estadistico_chi2, grados_de_libertad) print(f\"Valor-p: {p_valor:.4f}\") <pre>Estad\u00edstico de chi-cuadrado: 6.87\nValor-p: 0.0762\n</pre> <p>El estad\u00edstico de prueba $\\chi^{2}= 6.87$ lo encontramos entre 6.251 y 7.815. Por consiguiente, el \u00e1rea correspondiente en la cola superior o $valor-p$ debe estar entre $0.10$ y $0.05$. Como el $valor-p\\leq \\alpha = 0.05$, $H_0$ no es rechazada, no se concluye que las proporciones de audiencia hayan cambiado. C\u00f3mo se realiz\u00f3 un c\u00e1lculo previo para hallar el valor-p, con ayuda de Python, se pudo demostrar que $\\chi^{2} = 6.87$ da un $valor-p = 0.0762$.</p> <p>En lugar del m\u00e9todo del $valor-p$ se puede utilizar el m\u00e9todo del valor cr\u00edtico, con el que se llega a la misma conclusi\u00f3n. Como $\\alpha = 0.05 $ y los grados de libertad son 3, el valor cr\u00edtico para el estad\u00edstico de prueba es $\\chi^{2}_{0.05} = 7.814$. La regla de rechazo de la cola superior se convierte en Rechazar $H_{0}$ si $\\chi^{2} \\geq 7.814$</p> <p>Como 6.87 &lt; 7.814, no se rechaza $H_0$. Con los m\u00e9todos del valor cr\u00edtico o del valor-p se llega a la misma conclusi\u00f3n.</p> <p>A continuaci\u00f3n se presentan, en forma resumida, los pasos generales que se siguen en una prueba de bondad de ajuste para una distribuci\u00f3n poblacional multinomial hipot\u00e9tica.</p>  DISTRIBUCI\u00d3N MULTINOMIAL DE PRUEBAS DE BONDAD DE AJUSTE: RESUMEN 1. Establecer las hip\u00f3tesis nula y alternativa:  <p>$$H_0: \\text{ la poblaci\u00f3n tiene una distribuci\u00f3n multinomial con la}\\\\ \\text{ probabilidad espec\u00edfica de cada una de las } k \\text{ categor\u00edas}$$ $$H_a: \\text{ la poblaci\u00f3n no tiene una distribuci\u00f3n multinomial con la}\\\\ \\text{ probabilidad espec\u00edfica de cada una de las } k \\text{ categor\u00edas}$$</p> <ol> <li>Seleccionar una muestra aleatoria y anotar las frecuencias observadas $f_i$ en cada categor\u00eda.</li> <li>Suponer que la hip\u00f3tesis nula es verdadera y determinar la frecuencia esperada $e_i$ en cada categor\u00eda multiplicando la probabilidad de esa categor\u00eda por el tama\u00f1o de la muestra.</li> <li>Calcular el valor del estad\u00edstico de prueba. $$\\chi^{2}=\\displaystyle\\sum^{k}_{i=1}\\frac{(f_{i}-e_{i})^{2}}{e_{i}}$$</li> <li>Regla de rechazo: $$\\text{M\u00e9todo del valor-p: Rechazar } H_0 \\text{ si el valor-p}\\leq \\alpha$$ $$\\text{M\u00e9todo del valor cr\u00edtico: Rechazar} H_0 \\text{ si } \\chi^{2}\\geq \\chi^{2}_{\\alpha}$$ donde $\\alpha$ es el nivel de significancia utilizado para la prueba y se tienen $k - 1$ grados de libertad.</li></ol> <p>Otra aplicaci\u00f3n importante de la distribuci\u00f3n ji-cuadrada implica el uso de datos muestrales para probar la independencia de dos variables. Para ilustrar la prueba de independencia se considerar\u00e1 el siguiente ejercicio. Cuatro grupos de edad: 18-24, 25-34, 35-44, 45 y m\u00e1s. Al analizar el rango de edad de los cuatro grupos, el grupo de investigaci\u00f3n de Visa Card, se pregunt\u00f3 si la inclinaci\u00f3n de los consumidores categorizados en grupos de edad difer\u00eda entre la forma de pago pl\u00e1stico y cheque o efectivo. En caso de que las preferencias fueran independientes de la forma de pago del consumidor, se iniciar\u00eda una campa\u00f1a publicitaria para el uso de las tarjetas de cr\u00e9dito o d\u00e9bito. Pero si las preferencias por la forma de pago depend\u00edan del grupo de edad, Visa Card ajustar\u00eda sus promociones a los diferentes mercados meta.</p> <p>Se us\u00f3 una prueba de independencia para determinar si la preferencia por el grupo de edad (18-24, 25-34, 35-44, 45 y m\u00e1s) era independiente de la forma de pago (pl\u00e1stico, efectivo o cheque). Las hip\u00f3tesis fueron las siguientes. $$H_0: \\text{la preferencia por el grupo de edad es independiente de la forma de pago}$$ $$H_a: \\text{la preferencia por el grupo de edad no es independiente de la forma de pago}$$</p> <p>Para describir la situaci\u00f3n a estudiar se usa la tabla 12.2. Despu\u00e9s de identificar la poblaci\u00f3n como todos los del grupo de edad en su forma de paga, pl\u00e1stico y efectivo o cheque, se toma una muestra y a cada individuo se le pide que indique cu\u00e1l es su m\u00e9todo de paga favorito. Cada sujeto de la muestra se clasificar\u00e1 en una de las ocho celdas de la tabla. As\u00ed, por ejemplo, se puede tener la forma de paga pl\u00e1stico que prefiera el grupo de edad 25-34 [celda (1,2)], o que se quiera pagar en efectivo o cheque por el grupo de edad 18-24 [celda (2,1)], o en la forma de paga sea efectivo o cheque sea preferida por el grupo de edad 35-44 [celda (2,3)], y as\u00ed sucesivamente.</p> <p> TABLA 12.2 Tabla de contingencia de grupo de edad y la forma de pago del consumidor </p> Grupo de edad Forma de pago 18-24 25-34 35-44 45 y m\u00e1s Pl\u00e1stico celda(1,1) celda(1,2) celda(1,3) celda(1,4) Efectivo o cheque celda(2,3) celda(2,3) celda(2,3) celda(2,4) <p> TABLA 12.3 Resultados muestrales del tipo de grupo de edad y su forma de pago preferida pl\u00e1stico y efectivo o cheques (frecuencias observadas). </p> Grupo de edad Forma de pago 18-24 25-34 35-44 45 y m\u00e1s Total Pl\u00e1stico 21 27 27 36 111 Efectivo o cheque 21 36 42 90 189 Total 42 63 69 126 300 <p>Dado que en la tabla se han enumerado todas las posibles combinaciones de grupos de edad y forma de pago o, en otras palabras, todas las posibles contingencias, a la tabla 12.2 se le llama tabla de contingencia. Como en la prueba de independencia se usa el formato de este tipo de tabla, a esta prueba tambi\u00e9n se le suele llamar prueba de tabla de contingencia. Como en la prueba de independencia se usa el formato de este tipo de tabla, a esta prueba tambi\u00e9n se le suele llamar prueba de tabla de contingencia. Suponga que toma una muestra aleatoria simple de 300 consumidores. Cada individuo de la muestra prueba los cuatro grupos de edad y despu\u00e9s se le pide que indique cu\u00e1l prefiere o cu\u00e1l es su primera elecci\u00f3n. En la tabulaci\u00f3n cruzada de la tabla 12.3 se presenta el resumen de las respuestas recabadas en el estudio. Como se ve, los datos para la prueba de independencia se obtienen contando las cantidades o frecuencias correspondientes a cada celda o categor\u00eda. De las 300 personas de la muestra, 21 enla forma de pago pl\u00e1stico lo prefirieron los del grupo de edad 18-24, 27 el grupo de edad 25-34, 27 los del grupo 35-44, etc\u00e9tera.</p> <p>Los datos de la tabla 12.3 son las frecuencias observadas para cada una de las ocho clases o categor\u00edas. Si se determinan las frecuencias esperadas bajo el supuesto de independencia entre grupo de edad y forma de pago del consumidor, se puede emplear la distribuci\u00f3n ji-cuadrada para establecer si existe diferencia significativa entre las frecuencias observadas y las esperadas. Las frecuencias esperadas para las celdas de la tabla de contingencia se basan en la idea siguiente. Primero se supone que la hip\u00f3tesis nula es verdadera; es decir, que el grupo de edad es independiente de la forma de pago del consumidor. Despu\u00e9s se observa que en la muestra de 300 consumidores, 42 son del grupo de edad 18-24, 63 del grupo 25-34 , 69 del grupo 35-44 y 126 del grupo 45 y m\u00e1s. En t\u00e9rminos de proporciones se concluye que $ 42/300 = 7/50 $ de los consumidores son del grupo 18-24; $ 63/300 = 21/100 $ grupo de 25-34; $ 69/300 = 23/100 $ el grupo 35-44, y $ 126/300 = 21/50 $ del grupo 45 y m\u00e1s. Si el supuesto de independencia es correcto, estas proporciones ser\u00e1n las que se observen tanto entre las formas de pago pl\u00e1stico y efectivo o cheque.</p> <p>Por consiguiente, bajo el supuesto de independencia, es de esperarse que en la muestra de 111 sujetos en la forma de pago pl\u00e1stico, $(7/50)111 = 15.54$ del grupo 18-24, $(21/100)111 = 23.31$ del grupo 25-34, $(23/100)111 = 25.53$ del grupo 35-44 y $ (21/50)111 = 46.62$ del grupo 45 y m\u00e1s. Al aplicar las proporciones correspondientes a los 189 consumidores que prefieren pagar en efectivo o cheque, se obtienen las frecuencias esperadas que aparecen en la tabla 12.4.</p> <p> TABLA 12.4 Frecuencias esperadas si la preferencia por uno de los tipos de grupo de edad es independiente de la forma de pago del consumidor. </p> Grupo de edad Forma de pago 18-24 25-34 35-44 45 y m\u00e1s Total Pl\u00e1stico 15.54 23.31 25.53 46.62 111 Efectivo o cheque 26.46 39.69 43.47 79.38 189 Total 42.00 63.00 69.00 126.00 300 <p>Sea $e_{ij}$ la frecuencia esperada en la $f_i$ la $i$, columna $j$ de la tabla de contingencia. Mediante dicha notaci\u00f3n, ahora se reconsidera el c\u00e1lculo de la frecuencia esperada correspondiente a los que pagan con pl\u00e1stico (fila $i = 1$) que prefieren los del grupo 25-34(columna $j = 2$), es decir, la frecuencia esperada $e_{12}$. Siguiendo el argumento anterior para el c\u00e1lculo de esta frecuencia, vemos que</p> <p>$$e_{12}=(21/100)111=23.31$$</p> <p>Esta expresi\u00f3n se formula de una manera ligeramente diferente como</p> <p>$$e_{12}=(21/100)111 = (63/300)111= \\frac{(111)(63)}{300}=23.31$$</p> <p>Observe que en esta expresi\u00f3n, 111 es el n\u00famero total de la forma de pago con pl\u00e1stico (total de la fila 1), 63 es la cantidad total de individuos que estan en el grupo 25-34 (total de la columna 2) y 300 es el tama\u00f1o total de la muestra. Vemos entonces que</p> <p>$$e_{12}= \\frac{\\text{(total de la fila 1)(total de la columna 2)}}{\\text{tama\u00f1o de la muestra}}$$</p> <p>La generalizaci\u00f3n de esta expresi\u00f3n lleva a la f\u00f3rmula siguiente para obtener las frecuencias esperadas en una tabla de contingencia para una prueba de independencia.</p>  FRECUENCIAS ESPERADAS PARA TABLAS DE CONTINGENCIA BAJO EL SUPUESTO DE INDEPENDENCIA  <p>$$e_{12}= \\frac{\\text{(total de la fila i)(total de la columna j)}}{\\text{tama\u00f1o de la muestra}}(12.2)$$</p> <p>Al aplicar esta f\u00f3rmula para los que pagan con pl\u00e1stico que prefieren del grupo de edad 35-44, encontramos que la frecuencia esperada es $e_{13} = 111(69)/300 = 25.53$, como se ilustra en la tabla 12.4. Use la ecuaci\u00f3n (12.2) para verificar las otras frecuencias esperadas que se presentan en esta tabla. El procedimiento de prueba para comparar las frecuencias esperadas de la tabla 12.4 con las frecuencias observadas de la tabla 12.3 es semejante a los c\u00e1lculos para la prueba de bondad de ajuste de la secci\u00f3n 12.1. En concreto, el valor $\\chi^2$ que se basa en las frecuencias observadas y esperadas se calcula como se indica a continuaci\u00f3n.</p>  ESTAD\u00cdSTICO DE PRUEBA PARA INDEPENDENCIA  <p>$$\\chi^{2} = \\displaystyle \\sum_{i}\\sum_{j} \\frac{(f_{ij}-e_{ij})^{2}}{e_{ij}}(12.3)$$</p> <p>Donde:</p> <p>$ f_{ij} = $ frecuencia observada en la categor\u00eda de la fila $ i $ y la columna $ j $ de la tabla de contingencia. $ e_{ij} = $ frecuencia esperada en la categor\u00eda de la fila $ i $ y la columna $ j $ de la tabla de contingencia, basada en el supuesto de independencia.</p> <p>Nota. Si una tabla de contingencia tiene $ n $ filas y $ m $ columnas, el estad\u00edstico de prueba tiene una distribuci\u00f3n ji-cuadrada con $ (n-1)(m-1)$ grados de libertada, siempre y cuando las frecuencias esperadas sean cinco o m\u00e1s en todas las categor\u00edas.</p> <p>La doble sumatoria de la ecuaci\u00f3n (12.3) indica que el c\u00e1lculo debe efectuarse con todas las celdas que aparecen en la tabla de contingencia. En las frecuencias esperadas registradas en la tabla 12.4 se ve que en cada categor\u00eda esta frecuencia es de cinco o m\u00e1s. Por tanto, se puede proceder a calcular el estad\u00edstico de prueba ji-cuadrada. En la tabla 12.5 se presentan los c\u00e1lculos necesarios para obtener el estad\u00edstico de prueba ji-cuadrada que se utiliza para determinar si el grupo de edad es independiente de la forma de pago del consumidor. Como se observa, el valor del estad\u00edstico de prueba es $\\chi^2 = 6.12$. El n\u00famero de grados de libertad para la distribuci\u00f3n ji-cuadrada adecuada se obtiene al multiplicar el n\u00famero de filas menos 1 por el n\u00famero de columnas menos 1. Como se tienen dos filas y cuatro columnas, los grados de libertad son $(2 - 1)(4 - 1) = 3$. Igual que con la prueba de bondad de ajuste, en la prueba de independencia $H_0$ es rechazada si las diferencias entre frecuencias observadas y esperadas dan un valor grande para el estad\u00edstico de prueba. De manera que la prueba de independencia es tambi\u00e9n una prueba de cola superior. La tabla de la distribuci\u00f3n ji-cuadrada (tabla 3 del ap\u00e9ndice B), proporciona la informaci\u00f3n siguiente para 3 grados de libertad.</p> \u00c1rea en la cola superior 0.10 0.05 0.025 0.01 0.005 Valor $\\chi^{2} $(3 gl) 6.251 7.815 9.348 11.345 12.838 $ \\chi^{2}= 7.95$ <p>El estad\u00edstico de prueba $\\chi^2 = 7.95$ se encuentra entre 7.815 y 9.348. Por tanto, el \u00e1rea correspondiente en la cola superior o $valor-p$ est\u00e1 entre 0.05 y 0.025. Utilizando los procedimientos del lenguaje de programaci\u00f3n python que se presentan en el ap\u00e9ndice F, se obtiene el $valor-p = 0.0471$. Como el $valor-p \\leq \u03b1 = 0.05$, la hip\u00f3tesis nula es rechazada y se concluye que la forma de pago es independiente del rango de edad. Para simplifi car los c\u00e1lculos que se requieren en una prueba de independencia, se usa el lenguaje de programaci\u00f3n de python. La informaci\u00f3n a suministrar en estos procedimientos es la tabla de contingencia de las frecuencias observadas, como se indican en la tabla 12.3. Phyton calcula autom\u00e1ticamente las frecuencias esperadas, el valor del estad\u00edstico de prueba $\\chi^2$ y el $valor-p$. Aunque no se pueden obtener conclusiones adicionales como resultado de la prueba, es posible realizar una comparaci\u00f3n informal de las frecuencias observadas y esperadas para darse una idea de la dependencia entre grupo de edad y forma de pago. Al observar las tablas 12.3 y 12.4, es notorio que en la forma de paga por pl\u00e1stico las frecuencias observadas son m\u00e1s altas que las esperadas en los grupos de 18-24, 25-34, 35-44, mientras que en los pagos por efectivo o cheques la frecuencia observada en la elecci\u00f3n del grupo de edad 18-24 es mayor que la frecuencia esperada. Dichas observaciones permiten comprender las diferentes preferencias de la forma de pago entre pl\u00e1stico y efectivo o cheques.</p> <p>Tabla 12.5  C\u00e1lculo del estad\u00edstico de prueba ji-cuadrada para determinar el grupo de edad es independiente de la forma de pago del consumidor.</p> Forma de pago Grupo de edad Frecuencia observada $(f_{ij})$ Frecuencia esperada $ (e_{ij}) $ Diferencia $ (f_{ij}-e_{ij}) $ Cuadrado de la diferencia $ (f_{ij}-e_{ij})^{2} $ Cuadrado de la diferencia dividido entre la frecuencia esperada$ (f_{ij}-e_{ij})^{2}/e_{ij} $ Plastico 18-24 21 15.54 5.46 29.81 1.918 Plastico 25-34 27 23.31 3.69 13.62 0.584 Plastico 35-44 27 25.53 1.47 2.16 0.085 Plastico 45 y m\u00e1s 36 46.62 -10.62 112.78 2.419 Efectivo 18-24 21 26.46 -5.46 29.81 1.127 Efectivo 25-34 36 39.69 -3.69 13.62 0.343 Efectivo 35-44 42 43.47 -1.47 2.16 0.05 Efectivo 45 y m\u00e1s 90 79.38 10.62 112.78 1.421 Total 300 300.00 $\\chi^2 = 7.95$ <p>Se realizar\u00e1 el calculo de la tabla mediante el c\u00f3digo de programaci\u00f3n Phyton, para hallar el estad\u00edstico de prueba o la $\\chi^2$.</p> In\u00a0[4]: Copied! <pre>import numpy as np\nfrom scipy.stats import chi2_contingency\nfrecuencia_obs = np.array([[21, 27, 27, 36],[21, 36, 42, 90]])\nchi2, p, dof, expected = chi2_contingency(frecuencia_obs)\nprint(f\"El estadistico de prueba de chi-cuadrado es: {chi2:.2f}\")\nprint(f\"El valor-p: {p:.4f}\")\nprint(\"Los grados de libertad de la prueba son:\",dof)\nprint(\"La frecuencia esperada es: \")\nfor i in expected:\n    for j in i:\n        print(j,end=\"  \")\n    print()\n</pre> import numpy as np from scipy.stats import chi2_contingency frecuencia_obs = np.array([[21, 27, 27, 36],[21, 36, 42, 90]]) chi2, p, dof, expected = chi2_contingency(frecuencia_obs) print(f\"El estadistico de prueba de chi-cuadrado es: {chi2:.2f}\") print(f\"El valor-p: {p:.4f}\") print(\"Los grados de libertad de la prueba son:\",dof) print(\"La frecuencia esperada es: \") for i in expected:     for j in i:         print(j,end=\"  \")     print() <pre>El estadistico de prueba de chi-cuadrado es: 7.95\nEl valor-p: 0.0471\nLos grados de libertad de la prueba son: 3\nLa frecuencia esperada es: \n15.54  23.31  25.53  46.62  \n26.46  39.69  43.47  79.38  \n</pre> <p>Se volvera a hacer los calculos, respetando el procedimiento de la tabla.</p> In\u00a0[8]: Copied! <pre>import scipy.stats as stats\nfrom scipy.stats import chi2\nimport numpy as np\n\n#Se da valores a la frecuencia observada\nfrecuencia_obs = np.array([[21, 27, 27, 36],[21, 36, 42, 90]])\n\n#Se suma el total de la matriz\ntotal = 0\nfor i in frecuencia_obs:\n    total+=sum(i)\n\n#Se calcula el tamanio de la filas y las columnas de \nnum_fila = len(frecuencia_obs)\nnum_columna = len(frecuencia_obs[0])\n\n#Se suma el valor total de las filas i y las columnas j\nsuma_fila = [sum(i) for i in frecuencia_obs]\nsuma_columna = [sum(j) for j in zip(*frecuencia_obs)]\n\n#Se calcula la frecuencia esperada \nfrecuencia_esp = []\nfor i in range(num_fila):\n    fila = []\n    for j in range(num_columna):\n        valor = (suma_fila[i]*suma_columna[j])/total\n        fila.append(valor)\n    frecuencia_esp.append(fila)\n\n#Se calcula la diferencia entre la frecuencia observada y la esperada\ndiferencia = frecuencia_obs - frecuencia_esp\n\n#diferencia al cuadrado\ndif_2 = diferencia**2\n#aca lo redondeamos a 2 decimales\ndiferencia_2 = np.array([[round(i ,2) for i in j] for j in dif_2])\n\n#cuadrado de la diferencia dividido por la frecuencia esperada\ndif_2_div = diferencia_2/frecuencia_esp\n#redondeamos a 3 decimales\ndif_2_div = [[round(i ,3) for i in j] for j in dif_2_div]\n\n#Se suma el total de la diferencia dividido por la frecuencia\nestadistico_chi2 = 0\nfor i in dif_2_div:\n    estadistico_chi2 += sum(i)\n    \n#se calcula los grados de libertad\ngrados_de_libertad = (num_fila-1)*(num_columna-1)\n\n#calculamos el valor-p\np_valor = chi2.sf(estadistico_chi2, grados_de_libertad)\n\n#imprimimos los valores del estadistico de prueba, el valor-p, los grados de libertad y\n#la frecuencia esperada\nprint(f\"Estadistico de prueba de chi-cuadrado: {estadistico_chi2:.2f}\")\nprint(f\"Valor-p: {p_valor:.4f}\")\nprint(\"Los grados de libertad de la prueba son: \",grados_de_libertad)\nprint(\"La frecuencia esperada es: \")\nfor i in frecuencia_esp:\n    for j in i:\n        print(j, end=\" \")\n    print()\n</pre> import scipy.stats as stats from scipy.stats import chi2 import numpy as np  #Se da valores a la frecuencia observada frecuencia_obs = np.array([[21, 27, 27, 36],[21, 36, 42, 90]])  #Se suma el total de la matriz total = 0 for i in frecuencia_obs:     total+=sum(i)  #Se calcula el tamanio de la filas y las columnas de  num_fila = len(frecuencia_obs) num_columna = len(frecuencia_obs[0])  #Se suma el valor total de las filas i y las columnas j suma_fila = [sum(i) for i in frecuencia_obs] suma_columna = [sum(j) for j in zip(*frecuencia_obs)]  #Se calcula la frecuencia esperada  frecuencia_esp = [] for i in range(num_fila):     fila = []     for j in range(num_columna):         valor = (suma_fila[i]*suma_columna[j])/total         fila.append(valor)     frecuencia_esp.append(fila)  #Se calcula la diferencia entre la frecuencia observada y la esperada diferencia = frecuencia_obs - frecuencia_esp  #diferencia al cuadrado dif_2 = diferencia**2 #aca lo redondeamos a 2 decimales diferencia_2 = np.array([[round(i ,2) for i in j] for j in dif_2])  #cuadrado de la diferencia dividido por la frecuencia esperada dif_2_div = diferencia_2/frecuencia_esp #redondeamos a 3 decimales dif_2_div = [[round(i ,3) for i in j] for j in dif_2_div]  #Se suma el total de la diferencia dividido por la frecuencia estadistico_chi2 = 0 for i in dif_2_div:     estadistico_chi2 += sum(i)      #se calcula los grados de libertad grados_de_libertad = (num_fila-1)*(num_columna-1)  #calculamos el valor-p p_valor = chi2.sf(estadistico_chi2, grados_de_libertad)  #imprimimos los valores del estadistico de prueba, el valor-p, los grados de libertad y #la frecuencia esperada print(f\"Estadistico de prueba de chi-cuadrado: {estadistico_chi2:.2f}\") print(f\"Valor-p: {p_valor:.4f}\") print(\"Los grados de libertad de la prueba son: \",grados_de_libertad) print(\"La frecuencia esperada es: \") for i in frecuencia_esp:     for j in i:         print(j, end=\" \")     print() <pre>Estadistico de prueba de chi-cuadrado: 7.95\nValor-p: 0.0471\nLos grados de libertad de la prueba son:  3\nLa frecuencia esperada es: \n15.54 23.31 25.53 46.62 \n26.46 39.69 43.47 79.38 \n</pre>  A continuaci\u00f3n se resumen los pasos para una prueba de independencia de la tabla de contingencia.  <p>PRUEBA DE INDEPENDENCIA: RESUMEN</p> <ol> <li>Establecer las hip\u00f3tesis nula y alternativa:</li> </ol> <p>$$H_0: \\text{ la variable de las columnas es independiente de la variable de las filas }$$ $$H_a: \\text{ la variable de las columnas no es independiente de la variable de las filas }$$</p> <ol> <li>Seleccionar una muestra aleatoria y anotar las frecuencias observadas en cada celda de la tabla de contingencia.</li> <li>Utilizar la ecuaci\u00f3n (12.2) para calcular la frecuencia esperada de cada celda.</li> <li>Usar la ecuaci\u00f3n (12.3) para determinar el valor del estad\u00edstico de prueba. $$\\chi^{2} = \\displaystyle \\sum_{i}\\sum_{j} \\frac{(f_{ij}-e_{ij})^{2}}{e_{ij}}$$</li> <li>Regla de rechazo: $$\\text{M\u00e9todo del valor-p: Rechazar } H_0 \\text{ si el valor-p}\\leq \\alpha$$ $$\\text{M\u00e9todo del valor cr\u00edtico: Rechazar} H_0 \\text{ si } \\chi^{2}\\geq \\chi^{2}_{\\alpha}$$</li> </ol> <p>donde $\\alpha$ es el nivel de significancia, con $n$ filas y $m$ columnas que proporcionan $(n - l)(m - 1)$ grados de libertad.</p> <p>En la secci\u00f3n 12.1 se introdujo la prueba de bondad de ajuste para poblaciones multinomiales. En general, esta prueba puede usarse con cualquier distribuci\u00f3n de probabilidad hipot\u00e9tica. En esta secci\u00f3n se ilustra su uso para el caso en que tenemos la hip\u00f3tesis de que la poblaci\u00f3n tiene una distribuci\u00f3n de Poisson o una distribuci\u00f3n normal. Como ver\u00e1, en la prueba de bondad de ajuste y en el uso de la distribuci\u00f3n ji-cuadrada se sigue el mismo procedimiento general aplicado para la prueba de bondad de ajuste de la secci\u00f3n 12.1.</p> <p>$$H_{0}: \\text{el n\u00famero de clientes que entra en la tienda durante intervalos de}\\\\ \\text{5 minutos tiene una distribuci\u00f3n de probabilidad de Poisson}$$ $$H_{a}: \\text{el n\u00famero de clientes que entra en la tienda durante intervalos de}\\\\ \\text{5 minutos no tiene una distribuci\u00f3n de probabilidad de Poisson}$$</p> <p>Si una muestra de llegadas de clientes indica que no se puede rechazar H0, Dubeck\u2019s proceder\u00e1 a poner en marcha el proceso de programaci\u00f3n de la firma de consultor\u00eda. Pero si la muestra lleva a rechazar $H_0$, no se podr\u00e1 suponer que los arribos siguen una distribuci\u00f3n de Poisson y habr\u00e1 que considerar otro procedimiento de programaci\u00f3n. Para probar el supuesto de que las llegadas de los clientes en las ma\u00f1anas de los d\u00edas entre semana siguen una distribuci\u00f3n de Poisson, un empleado de la tienda toma una muestra aleatoria de 128 intervalos de 5 minutos en las ma\u00f1anas de tres semanas consecutivas. Durante cada uno de los intervalos de 5 minutos que forman la muestra, el empleado registra el n\u00famero de llegadas de clientes. Para resumir los datos, determina el n\u00famero de intervalos de 5 minutos en los que no hubo ninguna llegada, el n\u00famero de intervalos de 5 minutos en los que se registr\u00f3 una, el n\u00famero de intervalos de 5 minutos en los que hubo dos, y as\u00ed sucesivamente. Estos datos se presentan en la tabla 12.6.</p> <p> TABLA 12.6 Frecuencias observadas en las llegadas de los clientes a Dubek\u2019s en una muestra de 128 intervalos de 5 minutos.</p> N\u00famero de clientes que llegan $(x)$ Frecuenciaobservada 0 2 1 8 2 10 3 12 4 18 5 22 6 22 7 16 8 12 9 6 Total 128 <p>La tabla proporciona las frecuencias observadas en las 10 categor\u00edas. Ahora se usa la prueba de bondad de ajuste para determinar si la muestra de los 128 lapsos favorece la hip\u00f3tesis relacionada con la distribuci\u00f3n de Poisson. Para usar la prueba de bondad de ajuste se deben considerar las frecuencias esperadas para cada una de las 10 categor\u00edas, bajo el supuesto de que la distribuci\u00f3n de las llegadas sigue dicha distribuci\u00f3n. Es decir, si en realidad esto ocurre, es necesario calcular el n\u00famero esperado de lapsos en los que llegar\u00e1n cero clientes, un cliente, dos clientes, etc\u00e9tera. La funci\u00f3n de probabilidad de Poisson, que ya se present\u00f3 en el cap\u00edtulo 5, es $$f(x)=\\frac{\\mu^{x}e^{-\\mu}}{x!} (12.4)$$</p> <p>En esta funci\u00f3n, $\\mu$ representa la media o el n\u00famero esperado de clientes que llegan en lapsos de 5 minutos, x representa la variable aleatoria del n\u00famero de arribos en un lapso de 5 minutos y $f(x)$ es la probabilidad de que $x$ clientes llegar\u00e1n en un lapso de 5 minutos. Antes de usar la ecuaci\u00f3n (12.4) para calcular las probabilidades de Poisson, se necesita una estimaci\u00f3n de $\\mu$, el n\u00famero medio de llegadas de clientes en un lapso de 5 minutos. La media muestral de los datos de la tabla 12.6 proporciona esta estimaci\u00f3n. Como se tienen 2 lapsos de 5 minutos en los que no lleg\u00f3 ning\u00fan cliente, 8 lapsos de 5 minutos en los que lleg\u00f3 un cliente, etc., el n\u00famero total de clientes que llegan en los 128 lapsos de 5 minutos es $0(2)+ 1(8) +2(10)+ . . . +9(6) = 640$. Este total de arribos en los 128 lapsos de la muestra dan una media de llegadas de $\\mu = 640/128 = 5$ clientes por periodos de 5 minutos. Con este valor como media para la distribuci\u00f3n de Poisson, una estimaci\u00f3n de la funci\u00f3n de probabilidad de Poisson en el caso de Dubek\u2019s Food Market es $$f(x)=\\frac{5^{x}e^{-5}}{x!}  (12.5)$$</p> <p>Esta funci\u00f3n de probabilidad puede evaluarse para distintos valores de x y determinar as\u00ed la probabilidad que corresponde a las diferentes categor\u00edas de llegadas. En la tabla 12.7 se presentan tales probabilidades, las cuales se encuentran tambi\u00e9n en la tabla 7 del ap\u00e9ndice B. Por ejemplo, la probabilidad de que lleguen $0$ clientes en un lapso de cinco minutos es $f(0) = 0.0067$, la probabilidad del arribo de un cliente en un lapso de 5 minutos es $f(l) = 0.0337$, y as\u00ed sucesivamente. Como se vio en la secci\u00f3n 12.1, la frecuencia esperada en cada una de las categor\u00edas se encuentra al multiplicar su probabilidad por el tama\u00f1o de la muestra. Por ejemplo, el n\u00famero de lapsos de tiempo con 0 llegadas es $(0.0067)(128) = 0.86$; el n\u00famero esperado de lapsos con 1 llegada es $(0.0337)(128) = 4.31$, y as\u00ed sucesivamente.</p> <p> TABLA 12.7 Frecuencias esperadas en las llegadas de clientes a Dubek\u2019s, suponiendo que sigan una distribuci\u00f3n de Poisson con $\\mu = 5$.</p> N\u00famero de clientes que llegan $(x)$ Probabilidad de Poisson $f(x)$ N\u00famero esperado de lapsos de 5 minutos con $x$ llegadas,128 $f(x)$  0 0.0067 0.86 1 0.0337 4.31 2 0.0842 10.78 3 0.1404 17.97 4 0.1755 22.46 5 0.1755 22.46 6 0.1462 18.71 7 0.1044 13.36 8 0.0653 8.36 9 0.0363 4.65 10 0.0318 4.07 Total 128.00 In\u00a0[10]: Copied! <pre>#tabla 12.7\n\nimport scipy.stats as stats\nimport numpy as np\nfrom scipy.stats import poisson\nfrom scipy.stats import chi2\n# Frecuencias observadas\nfrecuencias = {\n    0: 2,\n    1: 8,\n    2: 10,\n    3: 12,\n    4: 18,\n    5: 22,\n    6: 22,\n    7: 16,\n    8: 12,\n    9: 6\n}\ntotal_frec_obs= sum(frecuencias.values())\n# Calcula la tasa de llegada (mu) como el promedio ponderado\nmu = sum(k * v for k, v in frecuencias.items()) / total_frec_obs\n\n# Calcula las probabilidades de Poisson\nprobabilidades = {k: poisson.pmf(k, mu) for k in frecuencias.keys()}\n\n#Se hara la prueba si la suma de las probabilidades de poisson llegan a uno\nsuma_prob_poisson = sum(probabilidades.values())\nif(suma_prob_poisson!=1):\n    probabilidades[list(probabilidades.keys())[-1]+1]=1-suma_prob_poisson\n    frecuencias[list(frecuencias.keys())[-1]+1] = 0\n\n#Ahora se hara el calculo de la tabla 12.7\n\n#Probabilidad de Poisson\nprint(f\"La tasa de llegada promedio (mu) es {mu}\")\nprint(\"Las probabilidades de Poisson son:\")\nfor k, p in probabilidades.items():\n    print(f\"{k}: {p:.4f}\")\n\n#Numero esperado de lapsos de 5 mins con x, llegadas 128f(x)\nnum_esp = list(probabilidades.values())\nnum_esp = np.array(num_esp)\nnumero_esp = total_frec_obs*num_esp\nprint(\"Numero esperado de lapsos de 5 mins con x \")\nfor i in numero_esp:\n    print(f\"{i:.2f}\")\nsuma_total_num_esp=sum(numero_esp)\nprint(\"Total: \",suma_total_num_esp)\n</pre> #tabla 12.7  import scipy.stats as stats import numpy as np from scipy.stats import poisson from scipy.stats import chi2 # Frecuencias observadas frecuencias = {     0: 2,     1: 8,     2: 10,     3: 12,     4: 18,     5: 22,     6: 22,     7: 16,     8: 12,     9: 6 } total_frec_obs= sum(frecuencias.values()) # Calcula la tasa de llegada (mu) como el promedio ponderado mu = sum(k * v for k, v in frecuencias.items()) / total_frec_obs  # Calcula las probabilidades de Poisson probabilidades = {k: poisson.pmf(k, mu) for k in frecuencias.keys()}  #Se hara la prueba si la suma de las probabilidades de poisson llegan a uno suma_prob_poisson = sum(probabilidades.values()) if(suma_prob_poisson!=1):     probabilidades[list(probabilidades.keys())[-1]+1]=1-suma_prob_poisson     frecuencias[list(frecuencias.keys())[-1]+1] = 0  #Ahora se hara el calculo de la tabla 12.7  #Probabilidad de Poisson print(f\"La tasa de llegada promedio (mu) es {mu}\") print(\"Las probabilidades de Poisson son:\") for k, p in probabilidades.items():     print(f\"{k}: {p:.4f}\")  #Numero esperado de lapsos de 5 mins con x, llegadas 128f(x) num_esp = list(probabilidades.values()) num_esp = np.array(num_esp) numero_esp = total_frec_obs*num_esp print(\"Numero esperado de lapsos de 5 mins con x \") for i in numero_esp:     print(f\"{i:.2f}\") suma_total_num_esp=sum(numero_esp) print(\"Total: \",suma_total_num_esp) <pre>La tasa de llegada promedio (mu) es 5.0\nLas probabilidades de Poisson son:\n0: 0.0067\n1: 0.0337\n2: 0.0842\n3: 0.1404\n4: 0.1755\n5: 0.1755\n6: 0.1462\n7: 0.1044\n8: 0.0653\n9: 0.0363\n10: 0.0318\nNumero esperado de lapsos de 5 mins con x \n0.86\n4.31\n10.78\n17.97\n22.46\n22.46\n18.72\n13.37\n8.36\n4.64\n4.07\nTotal:  128.0\n</pre> <p>Antes de hacer los c\u00e1lculos de ji-cuadrada habituales para comparar las frecuencias observadas y esperadas, hay que notar que en la tabla 12.7 hay cuatro categor\u00edas que tienen una frecuencia esperada menor que cinco. Esta condici\u00f3n incumple los requerimientos para el uso de la distribuci\u00f3n ji-cuadrada. Sin embargo, las categor\u00edas con frecuencias esperadas menores de cinco no son una difi cultad, ya que se pueden combinar categor\u00edas adyacentes para satisfacer la condici\u00f3n de que la frecuencia esperada sea \u201cpor lo menos de cinco\u201d. En particular, se combinan 0 y 1 en una sola categor\u00eda y tambi\u00e9n se combinan 9 y \u201c10 o m\u00e1s\u201d en otra categor\u00eda simple. De esta manera se satisface la regla de un m\u00ednimo de cinco como frecuencia esperada en cada categor\u00eda. En la tabla 12.8 se presentan las frecuencias observadas y las esperadas despu\u00e9s de combinar categor\u00edas.</p> <p>Como en la secci\u00f3n 12.1, la prueba de bondad de ajuste se centra en las diferencias entre frecuencias observadas y esperadas, $f_i = e_i$. Por tanto, para calcular el estad\u00edstico de prueba ji-cuadrada se usar\u00e1n las frecuencias observadas y esperadas de la tabla 12.8. $$\\chi^{2}=\\displaystyle\\sum^{k}_{i=1}\\frac{(f_{i}-e_{i})^{2}}{e_{i}}$$</p> <p> TABLA 12.8 Frecuencias observadas y esperadas en las llegadas de clientes a Dubek\u2019s, despu\u00e9s de combinar categor\u00edas. </p> N\u00famero de clientes que llegan $(x)$ Frecuenciaobservada $f_i$ Frecuenciaesperada $e_i$ 0 o 1 10 5.17 2 10 10.78 3 12 17.97 4 18 22.46 5 22 22.46 6 22 18.72 7 16 13.37 8 12 8.36 9 o m\u00e1s 6 8.72 Total 128 128.00 In\u00a0[12]: Copied! <pre>#tabla 12.8\n# convertimos el diccionario a una lista\nfrec = list(frecuencias.values())\nfrec = np.array(frec)\nfrec_esperada = []\nfrec_observada = []\n# se creara los vectores de frecuencias\ni = 0\nwhile i &lt; len(numero_esp):\n    aux = numero_esp[i]\n    aux1 = frec[i]\n    if aux &lt; 5:\n        if i == len(numero_esp) - 1:\n            frec_esperada[-1] +=aux\n            frec_observada[-1] +=aux1\n        else:\n            frec_esperada.append(aux + numero_esp[i + 1])\n            frec_observada.append(aux1 + frec[i + 1])\n            i += 1\n    else:\n        frec_esperada.append(aux)\n        frec_observada.append(aux1)\n    \n    i+=1\n\n#Se imprimiran las frecuencias observadas y esperadas\nfrec_observada = np.array(frec_observada)\nprint(\"Frecuencia observada: \")\nfor i in frec_observada:\n    print(f\"{i}\")\n\nfrec_esperada = np.array(frec_esperada)\nprint(\"Frecuencia esperada: \")\nfor i in frec_esperada:\n    print(f\"{i:.2f}\")\n</pre> #tabla 12.8 # convertimos el diccionario a una lista frec = list(frecuencias.values()) frec = np.array(frec) frec_esperada = [] frec_observada = [] # se creara los vectores de frecuencias i = 0 while i &lt; len(numero_esp):     aux = numero_esp[i]     aux1 = frec[i]     if aux &lt; 5:         if i == len(numero_esp) - 1:             frec_esperada[-1] +=aux             frec_observada[-1] +=aux1         else:             frec_esperada.append(aux + numero_esp[i + 1])             frec_observada.append(aux1 + frec[i + 1])             i += 1     else:         frec_esperada.append(aux)         frec_observada.append(aux1)          i+=1  #Se imprimiran las frecuencias observadas y esperadas frec_observada = np.array(frec_observada) print(\"Frecuencia observada: \") for i in frec_observada:     print(f\"{i}\")  frec_esperada = np.array(frec_esperada) print(\"Frecuencia esperada: \") for i in frec_esperada:     print(f\"{i:.2f}\") <pre>Frecuencia observada: \n10\n10\n12\n18\n22\n22\n16\n12\n6\nFrecuencia esperada: \n5.17\n10.78\n17.97\n22.46\n22.46\n18.72\n13.37\n8.36\n8.72\n</pre> <p> TABLA 12.9 C\u00e1lculo del estad\u00edstico de prueba ji-cuadrada para el estudio de Dubek\u2019s Food Market. </p> N\u00famero de clientes que llegan $(x)$  Frecuencia observada $(f_{i})$ Frecuencia esperada $ (e_{i}) $ Diferencia $ (f_{i}-e_{i}) $ Cuadrado de la diferencia $ (f_{i}-e_{i})^{2} $ Cuadrado de la diferencia dividido entre la frecuencia esperada$ (f_{i}-e_{i})^{2}/e_{i} $ 0 o 1 10 5.17 4.83 23.28 4.50 2 10 10.78 -0.78 0.61 0.06 3 12 17.97 -5.97 35.62 1.98 4 18 22.46 -4.46 19.89 0.89 5 22 22.46 -0.46 0.21 0.01 6 22 18.72 3.28 10.78 0.58 7 16 13.37 2.63 6.92 0.52 8 12 8.36 3.64 13.28 1.59 9 o m\u00e1s 6 8.72 -2.72 7.38 0.85 Total 128 128.00 $\\chi^2 = 10.96$ In\u00a0[13]: Copied! <pre>#Tabla 12.9 \n#Se calcula aca la suma total de la frecuencia observada y se halla la frecuencia esperada\nsuma_f_o= sum(frec_observada)\n#Ahora hallamos la diferencia, su cuadrado y luego de eso lo dividimos por su frec. esperada\ndiferencia = frec_observada - frec_esperada\ndiferencia_2 = diferencia**2\ndividir_dif_2 = diferencia_2/frec_esperada\nestadistico_chi2 = sum(dividir_dif_2)\nprint(f\"Estad\u00edstico de chi-cuadrado: {estadistico_chi2:.2f}\")\n\n#Ahora hallamos el valor-p\ngrados_de_libertad = len(frec_observada)-2\np_valor = chi2.sf(estadistico_chi2, grados_de_libertad)\nprint(f\"Valor-p: {p_valor:.4f}\")\n</pre> #Tabla 12.9  #Se calcula aca la suma total de la frecuencia observada y se halla la frecuencia esperada suma_f_o= sum(frec_observada) #Ahora hallamos la diferencia, su cuadrado y luego de eso lo dividimos por su frec. esperada diferencia = frec_observada - frec_esperada diferencia_2 = diferencia**2 dividir_dif_2 = diferencia_2/frec_esperada estadistico_chi2 = sum(dividir_dif_2) print(f\"Estad\u00edstico de chi-cuadrado: {estadistico_chi2:.2f}\")  #Ahora hallamos el valor-p grados_de_libertad = len(frec_observada)-2 p_valor = chi2.sf(estadistico_chi2, grados_de_libertad) print(f\"Valor-p: {p_valor:.4f}\") <pre>Estad\u00edstico de chi-cuadrado: 10.96\nValor-p: 0.1403\n</pre> <p>En la tabla 12.9 se muestran los c\u00e1lculos necesarios para obtener el valor del estad\u00edstico de prueba ji-cuadrada. El valor del estad\u00edstico de prueba es $\\chi^2= 10.96$. En general, en una prueba de bondad de ajuste la distribuci\u00f3n ji-cuadrada tiene $k - p - 1$ grados de libertad, donde $k$ es el n\u00famero de categor\u00edas y $p$ es el n\u00famero de par\u00e1metros poblacionales estimados a partir de los datos muestrales. Para la prueba de bondad de ajuste de la distribuci\u00f3n de Poisson, la tabla 12.9 indica que $k = 9$ categor\u00edas. Como los datos muestrales se usaron para estimar la media de la distribuci\u00f3n de Poisson, $p = 1$, por ende tenemos $k - p - 1 = k - 2 $grados de libertad. Como $k=9$, tenemos $9 - 2 = 7$ grados de libertad.</p> <p>Suponga que en la prueba de la hip\u00f3tesis nula de que la distribuci\u00f3n de probabilidad de las llegadas de los clientes es una distribuci\u00f3n de Poisson, se usa $0.05$ como nivel de significancia. Para probar esta hip\u00f3tesis, es necesario determinar el valor-p para el estad\u00edstico de prueba $\\chi^2 = 10.96$ hallando el \u00e1rea en la cola superior de la distribuci\u00f3n ji-cuadrada con 7 grados de libertad. En la tabla 3 del ap\u00e9ndice B se encuentra que $\\chi^2 = 10.96$ corresponde a un \u00e1rea en la cola superior mayor que 0.10. Por consiguiente, sabemos que el valor-p es mayor que 0.10. Con los procedimientos de Minitab y de Excel que se describen en el ap\u00e9ndice F se obtiene que el $valor-p = 0.1404$. Como el $valor-p &gt; \\alpha = 0.05$, no se puede rechazar $H_0$. En consecuencia, no se puede descartar el supuesto de que las llegadas de los clientes, en las ma\u00f1anas entre semana, sigan una distribuci\u00f3n de probabilidad de Poisson. De esta manera, los gerentes de Dubek\u2019s pueden continuar con el procedimiento de programaci\u00f3n para las ma\u00f1anas de los d\u00edas entre semana.</p>  PRUEBA DE BONDAD DE AJUSTE PARA LA DISTRIBUCI\u00d3N DE POISSON: RESUMEN  <ol> <li>Establecer las hip\u00f3tesis nula y alternativa:</li> </ol> <p>$$H_0: \\text{  la poblaci\u00f3n tiene una distribuci\u00f3n de Poisson }$$ $$H_a: \\text{ la poblaci\u00f3n no tiene una distribuci\u00f3n de Poisson }$$</p> <ol> <li>Tomar una muestra aleatoria y a) Registrar la frecuencia observada $f_i$ para cada valor de la variable aleatoria de Poisson. b) Calcular el n\u00famero medio $\\mu$ de las ocurrencias.</li> <li>Calcular, para cada valor de la variable aleatoria de Poisson, la frecuencia esperada $e_i$ de ocurrencias. Multiplicar el tama\u00f1o de la muestra por la probabilidad de Poisson de ocurrencia para cada valor de la variable aleatoria de Poisson. Si para alg\u00fan valor hay menos de cinco ocurrencias esperadas, combinar valores adyacentes y reducir el n\u00famero de categor\u00edas tanto como sea necesario.</li> <li>Determinar el valor del estad\u00edstico de prueba. $$\\chi^{2}=\\displaystyle\\sum^{k}_{i=1}\\frac{(f_{i}-e_{i})^{2}}{e_{i}}$$</li> <li>Regla de rechazo: $$\\text{M\u00e9todo del valor-p: Rechazar } H_0 \\text{ si el valor-p}\\leq \\alpha$$ $$\\text{M\u00e9todo del valor cr\u00edtico: Rechazar} H_0 \\text{ si } \\chi^{2}\\geq \\chi^{2}_{\\alpha}$$</li> </ol> <p>donde $\\alpha$ es el nivel de significancia y los grados de libertad son $k - 2$.</p> <p> TABLA 12.10 Puntuaciones obtenidas en una muestra aleatoria de 50 solicitantes de empleo en la prueba de aptitudes de Chemline. </p> 71 66 61 65 54 93 60 86 70 70 73 73 55 63 56 62 76 54 82 79 76 68 53 58 85 80 56 61 61 64 65 62 90 69 76 79 77 54 64 74 65 65 61 56 63 80 56 71 79 84 <p>$$\\bar{x}=\\frac{\\sum x_i}{n}=\\frac{3421}{50}=68.42$$</p> <p>$$s=\\sqrt{\\frac{\\sum \\left ( x_i -x\\right )^2}{n-1}}=\\sqrt{\\frac{5310.10}{49}}=10.41$$</p> In\u00a0[12]: Copied! <pre>import numpy as np\ndatos = [71, 66, 61, 65, 54, 93,\n        60, 86, 70, 70, 73, 73 ,\n        55, 63, 56, 62, 76, 54 ,\n        82, 79, 76, 68, 53, 58 ,\n        85, 80, 56, 61, 61, 64, \n        65, 62, 90, 69, 76, 79,\n        77, 54, 64, 74, 65, 65,\n        61, 56, 63, 80, 56, 71,\n        79, 84]\nmedia_resultado = datos\nmedia = sum(datos) / len(datos)\nsum_cuadrados_diferencias = sum((x - media)**2 for x in datos)\ndesviacion_estandar = round((sum_cuadrados_diferencias / (len(datos) - 1))**0.5,2)\nprint(f\"x\u0304: {media}\")\nprint(f\"s: {desviacion_estandar}\")\n</pre> import numpy as np datos = [71, 66, 61, 65, 54, 93,         60, 86, 70, 70, 73, 73 ,         55, 63, 56, 62, 76, 54 ,         82, 79, 76, 68, 53, 58 ,         85, 80, 56, 61, 61, 64,          65, 62, 90, 69, 76, 79,         77, 54, 64, 74, 65, 65,         61, 56, 63, 80, 56, 71,         79, 84] media_resultado = datos media = sum(datos) / len(datos) sum_cuadrados_diferencias = sum((x - media)**2 for x in datos) desviacion_estandar = round((sum_cuadrados_diferencias / (len(datos) - 1))**0.5,2) print(f\"x\u0304: {media}\") print(f\"s: {desviacion_estandar}\") <pre>x\u0304: 68.42\ns: 10.41\n</pre> <p>Con estos valores se establecen las siguientes hip\u00f3tesis acerca de la distribuci\u00f3n de las puntuaciones del examen de los aspirantes. $$H_0: \\text{la poblaci\u00f3n de las puntuaciones del examen tiene una distribuci\u00f3n normal,}\\\\ \\text{ con una media de 68.42 y una desviaci\u00f3n est\u00e1ndar de 10.41}$$ $$H_a: \\text{la poblaci\u00f3n de las puntuaciones del examen no tiene una distribuci\u00f3n normal,}\\\\ \\text{ con una media de 68.42 y una desviaci\u00f3n est\u00e1ndar de 10.41.}$$ En la figura 12.2 se ilustra esta distribuci\u00f3n normal hipot\u00e9tica.</p> <p> FIGURA 12.2 Distribuci\u00f3n normal hipot\u00e9tica de las puntuaciones de los ex\u00e1menes para los solicitantes de empleo en Chemline realizado en Python. </p> In\u00a0[13]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Generar datos para la distribuci\u00f3n normal\nx = np.linspace(media - 3*desviacion_estandar, media + 3*desviacion_estandar, 1000)\ny = norm.pdf(x, media, desviacion_estandar)\n\n# Graficando la Distribuci\u00f3n normal hipot\u00e9tica\nplt.plot(x, y, color='lightgreen', label='Distribuci\u00f3n Normal')\nplt.fill_between(x, y, color='lightgreen', alpha=0.3)\nplt.text(0.88, 0.72, r'$\\sigma=10.41$', verticalalignment='top', horizontalalignment='right',\n         transform=plt.gca().transAxes, fontsize=12)\nplt.text(0.5093, 0.07, r'\u2534', verticalalignment='top', horizontalalignment='right',\n         transform=plt.gca().transAxes, fontsize=12)\nplt.xlabel('Media 68.42')\nplt.ylabel('')\nplt.xticks([])  \nplt.yticks([])  \nplt.grid(True)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm  # Generar datos para la distribuci\u00f3n normal x = np.linspace(media - 3*desviacion_estandar, media + 3*desviacion_estandar, 1000) y = norm.pdf(x, media, desviacion_estandar)  # Graficando la Distribuci\u00f3n normal hipot\u00e9tica plt.plot(x, y, color='lightgreen', label='Distribuci\u00f3n Normal') plt.fill_between(x, y, color='lightgreen', alpha=0.3) plt.text(0.88, 0.72, r'$\\sigma=10.41$', verticalalignment='top', horizontalalignment='right',          transform=plt.gca().transAxes, fontsize=12) plt.text(0.5093, 0.07, r'\u2534', verticalalignment='top', horizontalalignment='right',          transform=plt.gca().transAxes, fontsize=12) plt.xlabel('Media 68.42') plt.ylabel('') plt.xticks([])   plt.yticks([])   plt.grid(True) plt.show() <p>Ahora se ver\u00e1 c\u00f3mo definir las categor\u00edas de una prueba de bondad de ajuste para una distribuci\u00f3n normal. En el caso de la distribuci\u00f3n de probabilidad discreta en la prueba para la distribuci\u00f3n de Poisson fue f\u00e1cil definir las categor\u00edas en t\u00e9rminos del n\u00famero de clientes que llegan, 0, 1, 2, etc. Sin embargo, para la distribuci\u00f3n de probabilidad normal continua es necesario emplear un procedimiento diferente para definir las categor\u00edas, esto es, en t\u00e9rminos de intervalos de puntuaciones de examen. Recuerde la regla de que en cada intervalo o categor\u00eda la frecuencia esperada debe ser por lo menos de cinco. Las categor\u00edas para las puntuaciones de examen se definen de manera que la frecuencia esperada en cada una sea por lo menos de cinco. Como el tama\u00f1o de la muestra es 50, una manera de establecer las categor\u00edas es dividir la distribuci\u00f3n normal en 10 intervalos con una misma probabilidad (vea la figura 12.3). Dado que el tama\u00f1o de la muestra es 50, se espera tener cinco resultados en cada intervalo o categor\u00eda, con lo que se satisface la regla de las frecuencias esperadas. Veamos m\u00e1s de cerca el procedimiento para calcular los l\u00edmites de las categor\u00edas. Como se trata de una distribuci\u00f3n de probabilidad normal, para determinar estos l\u00edmites se emplean las tablas de probabilidad normal est\u00e1ndar. Primero se determina la puntuaci\u00f3n de examen que</p> <p> FIGURA 12.3 Distribuci\u00f3n normal en el ejemplo de Chemline con 10 intervalos de probabilidad igual realizado en Python. </p> In\u00a0[14]: Copied! <pre># Generando datos para la distribuci\u00f3n normal\nx = np.linspace(media - 3*desviacion_estandar, media + 3*desviacion_estandar, 1000)\ny = norm.pdf(x, media, desviacion_estandar)\n\n# Graficando la Distribuci\u00f3n normal hipot\u00e9tica\nplt.plot(x, y, color='lightgreen', label='Distribuci\u00f3n Normal')\nplt.fill_between(x, y, color='lightgreen', alpha=0.3)\n\n# Agregar l\u00edneas verticales en puntos espec\u00edficos   \npuntos = [55.10, 81.74]\nfor punto in puntos:\n    plt.axvline(x=punto, color='black', linestyle='-', linewidth=1, ymax=0.44)\npuntos = [59.68, 77.16]\nfor punto in puntos:\n    plt.axvline(x=punto, color='black', linestyle='-', linewidth=1, ymax=0.67)\n    puntos = [63.01, 73.83]\nfor punto in puntos:\n    plt.axvline(x=punto, color='black', linestyle='-', linewidth=1, ymax=0.83)\n    puntos = [65.82, 71.02]\nfor punto in puntos:\n    plt.axvline(x=punto, color='black', linestyle='-', linewidth=1, ymax=0.92)\nplt.axvline(x=68.42, color='black', linestyle='-', linewidth=1, ymax=0.95)\nplt.ylabel('')\nplt.xticks([55.10, 59.68, 63.01, 65.82, 68.42, 71.02, 73.83, 77.16, 81.74],rotation=90)  \nplt.yticks([])  \nplt.show()\n</pre> # Generando datos para la distribuci\u00f3n normal x = np.linspace(media - 3*desviacion_estandar, media + 3*desviacion_estandar, 1000) y = norm.pdf(x, media, desviacion_estandar)  # Graficando la Distribuci\u00f3n normal hipot\u00e9tica plt.plot(x, y, color='lightgreen', label='Distribuci\u00f3n Normal') plt.fill_between(x, y, color='lightgreen', alpha=0.3)  # Agregar l\u00edneas verticales en puntos espec\u00edficos    puntos = [55.10, 81.74] for punto in puntos:     plt.axvline(x=punto, color='black', linestyle='-', linewidth=1, ymax=0.44) puntos = [59.68, 77.16] for punto in puntos:     plt.axvline(x=punto, color='black', linestyle='-', linewidth=1, ymax=0.67)     puntos = [63.01, 73.83] for punto in puntos:     plt.axvline(x=punto, color='black', linestyle='-', linewidth=1, ymax=0.83)     puntos = [65.82, 71.02] for punto in puntos:     plt.axvline(x=punto, color='black', linestyle='-', linewidth=1, ymax=0.92) plt.axvline(x=68.42, color='black', linestyle='-', linewidth=1, ymax=0.95) plt.ylabel('') plt.xticks([55.10, 59.68, 63.01, 65.82, 68.42, 71.02, 73.83, 77.16, 81.74],rotation=90)   plt.yticks([])   plt.show()  <p>separa el 10% inferior de las puntuaciones. En la tabla 1 del ap\u00e9ndice B se encuentra que el valor z correspondiente a esta puntuaci\u00f3n de examen es $-1.28$. Por tanto, la puntuaci\u00f3n $x = 68.42 - 1.28(10.41) = 55.10$ es el valor que separa el 10% inferior de las puntuaciones de examen. Para el 20% inferior tenemos $z = -0.84$ y, por tanto, $x = 68.42 - 0.84(10.41) = 59.68$. Al continuar de esta manera con la distribuci\u00f3n normal se obtienen los valores siguientes para las puntuaciones de examen.</p> Porcentaje z Puntueci\u00f3n de examen 10% -1.28 68.42 - 1.28(10.41) = 55.10 20% -0.84 68.42 - 0.84(10.41) = 59.68 30% -0.52 68.42 - 0.52(10.41) = 63.01 40% -0.25 68.42 - 0.25(10.41) = 65.82 50% 0.00 68.42 + 0(10.41) = 68.42 60% +0.25 68.42 + 0.25(10.41) = 71.02 70% +0.52 68.42 + 0.52(10.41) = 73.83 80% +0.84 68.42 + 0.84(10.41) = 77.16 90% +1.28 68.42 + 1.28(10.41) = 81.74 In\u00a0[15]: Copied! <pre># Porcentajes y z de la tabla\nporcentajes = [0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90]\npuntuaciones_z = [-1.28, -0.84, -0.52, -0.25, 0.00, 0.25, 0.52, 0.84, 1.28]\n\n# Calcular y mostrar las puntuaciones de examen\nfor porcentaje, z in zip(porcentajes, puntuaciones_z):\n    puntuacion_examen = round(media + z * desviacion_estandar, 2)\n    print(f\"{porcentaje*100}%: {puntuacion_examen}\")\n</pre> # Porcentajes y z de la tabla porcentajes = [0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90] puntuaciones_z = [-1.28, -0.84, -0.52, -0.25, 0.00, 0.25, 0.52, 0.84, 1.28]  # Calcular y mostrar las puntuaciones de examen for porcentaje, z in zip(porcentajes, puntuaciones_z):     puntuacion_examen = round(media + z * desviacion_estandar, 2)     print(f\"{porcentaje*100}%: {puntuacion_examen}\") <pre>10.0%: 55.1\n20.0%: 59.68\n30.0%: 63.01\n40.0%: 65.82\n50.0%: 68.42\n60.0%: 71.02\n70.0%: 73.83\n80.0%: 77.16\n90.0%: 81.74\n</pre> <p>En la gr\u00e1fica 12.3 se observan estos puntos de separaci\u00f3n o l\u00edmites de los intervalos. Una vez definidas las categor\u00edas o intervalos de las puntuaciones de examen y dado que la frecuencia esperada en cada categor\u00eda es de cinco, se usan los datos muestrales de la tabla 12.10 y se determinan las frecuencias observadas en estas categor\u00edas. Con esto se obtienen los resultados que aparecen en la tabla 12.11. Una vez que tenemos los resultados de la tabla 12.11, el c\u00e1lculo de la prueba de bondad de ajuste procede exactamente como antes. Es decir, se comparan los resultados observados y esperados calculando el valor de $X^2$. En la tabla 12.12 se indican los procedimientos necesarios para obtener el estad\u00edstico de prueba ji-cuadrada. Como se ve, el valor del estad\u00edstico de prueba es $X^2 = 7.2$. A efecto de determinar si este valor de 7.2 obtenido para $X^2$ es suficientemente grande para rechazar $H_0$, se necesita consultar la tabla de la distribuci\u00f3n ji-cuadrada. Al aplicar la regla para calcular el n\u00famero de grados de libertad en la prueba de bondad de ajuste tenemos, $k - p - 1 = 10 - 2 - 1 = 7$ grados de libertad, ya que hay 10 categor\u00edas y $p = 2$ par\u00e1metros (media y desviaci\u00f3n est\u00e1ndar) estimados mediante los datos muestrales. Suponga que se prueba la hip\u00f3tesis nula de que la distribuci\u00f3n de las puntuaciones de examen es una distribuci\u00f3n normal, utilizando 0.10 como nivel de signifi cancia. Para probar</p> <p> TABLA 12.11 Frecuencias observadas y esperadas para las puntuaciones de examen de los solicitantes de empleo en Chemline. </p> Intevalo de puntuaciones Frecuencia observada $(f_i)$ Frecuencia esperada $(e_i)$ Menores que 55.10 5 5 55.10 a 59.68 5 5 59.68 a 63.01 9 5 63.01 a 65.82 6 5 65.82 a 68.42 2 5 68.42 a 71.02 5 5 71.02 a 73.83 2 5 73.83 a 77.16 5 5 77.16 a 81.74 5 5 81.74 y m\u00e1s 6 5 Total 50 50 In\u00a0[16]: Copied! <pre>tabla_intervalos = [\n    (float('-inf'), 55.10),\n    (55.10, 59.68),\n    (59.68, 63.01),\n    (63.01, 65.82),\n    (65.82, 68.42),\n    (68.42, 71.02),\n    (71.02, 73.83),\n    (73.83, 77.16),\n    (77.16, 81.74),\n    (81.74, float('inf'))\n]\n\n# Inicializar frecuencias observadas\nfrecuencia_observada = [0] * len(tabla_intervalos)\n\n# Calcular frecuencias observadas\nfor dato in datos:\n    for i, (inf, sup) in enumerate(tabla_intervalos):\n        if inf &lt; dato &lt;= sup:\n            frecuencia_observada[i] += 1\n            break\n\n# Mostrar resultados\nfor (inf, sup), frecuencia in zip(tabla_intervalos, frecuencia_observada):\n    print(f\"| {inf} a {sup} | {frecuencia} |\")\n# Calcular y mostrar el total\ntotal = sum(frecuencia_observada)\nprint(f\"Total : {total}\")\n</pre> tabla_intervalos = [     (float('-inf'), 55.10),     (55.10, 59.68),     (59.68, 63.01),     (63.01, 65.82),     (65.82, 68.42),     (68.42, 71.02),     (71.02, 73.83),     (73.83, 77.16),     (77.16, 81.74),     (81.74, float('inf')) ]  # Inicializar frecuencias observadas frecuencia_observada = [0] * len(tabla_intervalos)  # Calcular frecuencias observadas for dato in datos:     for i, (inf, sup) in enumerate(tabla_intervalos):         if inf &lt; dato &lt;= sup:             frecuencia_observada[i] += 1             break  # Mostrar resultados for (inf, sup), frecuencia in zip(tabla_intervalos, frecuencia_observada):     print(f\"| {inf} a {sup} | {frecuencia} |\") # Calcular y mostrar el total total = sum(frecuencia_observada) print(f\"Total : {total}\")  <pre>| -inf a 55.1 | 5 |\n| 55.1 a 59.68 | 5 |\n| 59.68 a 63.01 | 9 |\n| 63.01 a 65.82 | 6 |\n| 65.82 a 68.42 | 2 |\n| 68.42 a 71.02 | 5 |\n| 71.02 a 73.83 | 2 |\n| 73.83 a 77.16 | 5 |\n| 77.16 a 81.74 | 5 |\n| 81.74 a inf | 6 |\nTotal : 50\n</pre> <p> TABLA 12.12 C\u00e1lculo del estad\u00edstico de prueba ji-cuadrada en el ejemplo de las puntuaciones de examen de los solicitantes de empleo en Chemline. </p> Intevalos depuntuaciones deexamen Frecuencia observada $(f_{i})$ Frecuencia esperada $ (e_{i}) $ Diferencia $ (f_{i}-e_{i}) $ Cuadrado de la diferencia $ (f_{i}-e_{i})^{2} $ Cuadrado de la diferencia dividido entre la frecuencia esperada$ (f_{i}-e_{i})^{2}/e_{i} $ Menos que 55.10 5 5 0 0 0.0 55.10 a 59.68 5 5 0 0 0.0 59.68 a 63.01 9 5 4 16 3.2 63.01 a 65.82 6 5 1 1 0.2 65.82 a 68.42 2 5 -3 9 1.8 68.42 a 71.02 5 5 0 0 0.00 71.02 a 73.83 2 5 -3 9 1.8 73.83 a 77.16 5 5 0 0 0.00 77.16 a 81.74 5 5 0 0 0.00 81.74 y m\u00e1s 6 5 1 1 0.2 Total 50 50 $\\chi^2 = 7.2$ In\u00a0[17]: Copied! <pre># Datos de la tabla\nfrecuencia_esperada = [5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n\n# Inicializar variables para los c\u00e1lculos\ndiferencias = []\ncuadrados_diferencias = []\ncuadrados_diferencias_divididos = []\n\n# Calcular diferencias y cuadrados de diferencias\nfor obs, esp in zip(frecuencia_observada, frecuencia_esperada):\n    diferencia = obs - esp\n    cuadrado_diferencia = diferencia ** 2\n    cuadrado_diferencia_dividido = cuadrado_diferencia / esp\n\n    diferencias.append(diferencia)\n    cuadrados_diferencias.append(cuadrado_diferencia)\n    cuadrados_diferencias_divididos.append(cuadrado_diferencia_dividido)\n\n# Calcular la suma de los cuadrados de las diferencias divididos\nsuma_cuadrados_divididos = sum(cuadrados_diferencias_divididos)\n\n# Mostrar los resultados\nfor obs, esp, dif, cuad_dif, cuad_dif_div in zip(frecuencia_observada, frecuencia_esperada, diferencias, cuadrados_diferencias, cuadrados_diferencias_divididos):\n    print(f\"| Menos que 55.10 | {obs} | {esp} | {dif} | {cuad_dif} | {cuad_dif_div:.1f} |\")\ntotal = sum(frecuencia_observada)\nx2 = sum(cuadrados_diferencias_divididos)\nprint(f\"           Total : {total} \" f\"         x\u00b2 : {x2}\")\n</pre> # Datos de la tabla frecuencia_esperada = [5, 5, 5, 5, 5, 5, 5, 5, 5, 5]  # Inicializar variables para los c\u00e1lculos diferencias = [] cuadrados_diferencias = [] cuadrados_diferencias_divididos = []  # Calcular diferencias y cuadrados de diferencias for obs, esp in zip(frecuencia_observada, frecuencia_esperada):     diferencia = obs - esp     cuadrado_diferencia = diferencia ** 2     cuadrado_diferencia_dividido = cuadrado_diferencia / esp      diferencias.append(diferencia)     cuadrados_diferencias.append(cuadrado_diferencia)     cuadrados_diferencias_divididos.append(cuadrado_diferencia_dividido)  # Calcular la suma de los cuadrados de las diferencias divididos suma_cuadrados_divididos = sum(cuadrados_diferencias_divididos)  # Mostrar los resultados for obs, esp, dif, cuad_dif, cuad_dif_div in zip(frecuencia_observada, frecuencia_esperada, diferencias, cuadrados_diferencias, cuadrados_diferencias_divididos):     print(f\"| Menos que 55.10 | {obs} | {esp} | {dif} | {cuad_dif} | {cuad_dif_div:.1f} |\") total = sum(frecuencia_observada) x2 = sum(cuadrados_diferencias_divididos) print(f\"           Total : {total} \" f\"         x\u00b2 : {x2}\") <pre>| Menos que 55.10 | 5 | 5 | 0 | 0 | 0.0 |\n| Menos que 55.10 | 5 | 5 | 0 | 0 | 0.0 |\n| Menos que 55.10 | 9 | 5 | 4 | 16 | 3.2 |\n| Menos que 55.10 | 6 | 5 | 1 | 1 | 0.2 |\n| Menos que 55.10 | 2 | 5 | -3 | 9 | 1.8 |\n| Menos que 55.10 | 5 | 5 | 0 | 0 | 0.0 |\n| Menos que 55.10 | 2 | 5 | -3 | 9 | 1.8 |\n| Menos que 55.10 | 5 | 5 | 0 | 0 | 0.0 |\n| Menos que 55.10 | 5 | 5 | 0 | 0 | 0.0 |\n| Menos que 55.10 | 6 | 5 | 1 | 1 | 0.2 |\n           Total : 50          x\u00b2 : 7.2\n</pre> <p>esta hip\u00f3tesis se necesita calcular el valor-p del estad\u00edstico de prueba $X^2 = 7.2$ determinando el \u00e1rea correspondiente en la cola superior de la distribuci\u00f3n ji-cuadrada con 7 grados de libertad. Al consultar la tabla 3 del ap\u00e9ndice B encontramos que el \u00e1rea en la cola superior correspondiente a $X^2 = 7.2$ es mayor que 0.10. Por consiguiente, sabemos que el valor-p es mayor que 0.10. Con los procedimientos de Minitab y Excel presentados en el ap\u00e9ndice F al final del libro, vemos que $X^2 = 7.2$ da un valor-p = 0.4084. Con el valor-p $&gt; \u03b1 = 0.10$ no se puede rechazar la hip\u00f3tesis nula de que la distribuci\u00f3n de probabilidad de las puntuaciones de examen de los solicitantes de empleo en Chemline sea una distribuci\u00f3n normal. Esta distribuci\u00f3n se puede usar como ayuda en la interpretaci\u00f3n de las puntuaciones de examen. A continuaci\u00f3n se presenta un resumen de la prueba de bondad de ajuste para una distribuci\u00f3n normal.</p>  PRUEBA DE BONDAD DE AJUSTE PARA LA DISTRIBUCI\u00d3N NORMAL: RESUMEN  <ol> <li>Establecer las hip\u00f3tesis nula y alternativa: H0: la poblaci\u00f3n tiene una distribuci\u00f3n normal Ha: la poblaci\u00f3n no tiene una distribuci\u00f3n normal</li> <li>Tomar una muestra aleatoria y a) Calcular la media muestral y la desviaci\u00f3n est\u00e1ndar muestral. b) Definir intervalos de valores de manera que la frecuencia esperada en cada intervalo sea por lo menos de cinco. Usar intervalos de probabilidad igual es un buen enfoque. c) En cada uno de los intervalos definidos, anotar la frecuencia observada fi en los valores de los datos.</li> <li>Calcular el n\u00famero esperado de ocurrencias ei para cada uno de los intervalos de valores definidos en el paso 2b). Multiplicar el tama\u00f1o de la muestra por la probabilidad de que una variable aleatoria normal pertenezca al intervalo.</li> <li>Determinar el valor del estad\u00edstico de prueba $$\\chi^{2}=\\sum_{i=1}^{k}\\frac{(f_i-e _i)^2}{e _i}$$</li> <li>Regla de rechazo: M\u00e9todo del valor-p :  Rechazar $H_0$ si el valor-p $\\leq \u03b1$% M\u00e9todo del valor cr\u00edtico :  Rechazar $H0$ si $X^2 \\geq X_\u03b1^2$ donde \u03b1 es el nivel de significancia y los grados de libertad son $k - 3$.</li></ol> Continuaci\u00f3n y Explicaci\u00f3n final:"},{"location":"capitulo12/","title":"\u00b6","text":"CAPITULO 12  Pruebas de bondad de ajuste e independencia CONTENIDO <p>12.1 PRUEBA DE BONDAD DE AJUSTE: UNA POBLACI\u00d3N MULTINOMIAL</p> <p>12.2 PRUEBA DE INDEPENDENCIA</p> <p>12.3 PRUEBA DE BONDAD DE AJUSTE: DISTRIBUCIONES DE POISSON Y NORMAL</p> <ul> <li>Distribuci\u00f3n de Poisson</li> <li>Distribuci\u00f3n normal</li> </ul>"},{"location":"capitulo12/#121-prueba-de-bondad-de-ajuste-una-poblacion-multinomial","title":"12.1 Prueba de bondad de ajuste: una poblaci\u00f3n multinomial\u00b6","text":""},{"location":"capitulo12/#122-prueba-de-independencia","title":"12.2 Prueba de independencia\u00b6","text":""},{"location":"capitulo12/#123-prueba-de-bondad-de-ajuste-distribuciones-de-poisson-y-normal","title":"12.3 Prueba de bondad de ajuste: distribuciones de Poisson y normal\u00b6","text":""},{"location":"capitulo12/#distribucion-de-poisson","title":"Distribuci\u00f3n de Poisson\u00b6","text":"<p>El uso de la prueba de bondad de ajuste se ilustra en el caso de una distribuci\u00f3n poblacional que hipot\u00e9ticamente tiene una distribuci\u00f3n de Poisson. Considere, por ejemplo, las llegadas de los clientes al Dubek\u2019s Food Market en Tallahassee, Florida. Debido a recientes problemas de personal, los gerentes solicitan los servicios de una firma de consultor\u00eda para que les ayude en la programaci\u00f3n de los empleados de caja. Despu\u00e9s de revisar el avance de las filas en las cajas, la fi rma de consultor\u00eda sugerir\u00e1 un procedimiento para la programaci\u00f3n de los empleados. Este procedimiento se basa en un an\u00e1lisis matem\u00e1tico de las fi las y s\u00f3lo es aplicable si el n\u00famero de clientes que llegan durante un determinado lapso sigue una distribuci\u00f3n de Poisson. Por tanto, antes de poner en marcha el procedimiento de programaci\u00f3n, habr\u00e1 que recabar datos sobre las llegadas de los clientes y realizar una prueba estad\u00edstica para ver si es razonable suponer que los arribos siguen una distribuci\u00f3n de Poisson.</p> <p>Las llegadas a la tienda se definen en t\u00e9rminos de cantidad de clientes que entran en el establecimiento durante intervalos de 5 minutos. Por tanto, las hip\u00f3tesis nula y alternativa que se indican enseguida son apropiadas para el estudio de Dubek\u2019s Food Market</p>"},{"location":"capitulo12/#distribucion-normal","title":"Distribuci\u00f3n normal\u00b6","text":"<p>La prueba de bondad de ajuste para la distribuci\u00f3n normal tambi\u00e9n se basa en el uso de la distribuci\u00f3n ji-cuadrada. Se sigue un procedimiento similar al aplicado para la distribuci\u00f3n de Poisson. Las frecuencias observadas en las diversas categor\u00edas de los datos muestrales se comparan con las frecuencias esperadas, en particular cuando se supone que la poblaci\u00f3n tiene una distribuci\u00f3n normal. Como esta distribuci\u00f3n es continua, es necesario modifi car la manera en que se defi nen las categor\u00edas y en que se calculan las frecuencias esperadas. La prueba de bondad de ajuste para una distribuci\u00f3n normal se ilustrar\u00e1 con los datos de los ex\u00e1menes presentados por las personas que solicitan empleo en Chemline, Inc. Estos datos se presentan en la tabla 12.10. Cada a\u00f1o Chemline contrata a cerca de 400 nuevos empleados para sus cuatro plantas en Estados Unidos. El director de personal se pregunta si la poblaci\u00f3n de puntuaciones de los ex\u00e1menes de los solicitantes tendr\u00e1 una distribuci\u00f3n normal. Si es as\u00ed, esta distribuci\u00f3n podr\u00eda servir para evaluar las puntuaciones; es decir, podr\u00edan identifi carse f\u00e1cilmente las que se ubican en el 20% superior, el 40% inferior, etc. Por tanto, se desea probar la hip\u00f3tesis nula de que la poblaci\u00f3n de las puntuaciones de estos ex\u00e1menes tiene una distribuci\u00f3n normal. Para empezar, se obtienen estimaciones de la media y la desviaci\u00f3n est\u00e1ndar de la distribuci\u00f3n normal que se considerar\u00e1 en la hip\u00f3tesis nula, considerando los datos de la tabla 12.10. La media muestral $\\bar{x}$ y la desviaci\u00f3n est\u00e1ndar muestral s se usan como estimadores puntuales de la media y la desviaci\u00f3n est\u00e1ndar de la distribuci\u00f3n normal. Los c\u00e1lculos son los siguientes.</p>"},{"location":"capitulo13/","title":"Capitulo 13","text":"CAPITULO 13  Dise\u00f1o de experimentos y an\u00e1lisis de varianza Contenido del capitulo <p>13.1 INTRODUCCION AL DISE\u00d1O DE EXPERIMENTOS Y AL AN\u00c1LISIS DE VARIANZA</p> <ul> <li>Recolecci\u00f3n de datos</li> <li>Supuestos para el an\u00e1lisis de varianza</li> <li>An\u00e1lisis de varianza: una perspectiva conceptual</li> </ul> <p>13.2 AN\u00c1LISIS DE VARIANZA Y EL DISE\u00d1O COMPLETAMENTE ALEATORIZADO</p> <ul> <li>Estimaci\u00f3n de la varianza poblacional entre tratamientos</li> <li>Estimaci\u00f3n de la varianza poblacional dentro de los tratamientos</li> <li>Comparaci\u00f3n de las estimaciones de las varianzas: la prueba F</li> <li>Tabla de ANOVA</li> <li>Resultados de computadora para el an\u00e1lisis de varianza</li> <li>Prueba para la igualdad de k medias poblacionales: un estudio observacional</li> </ul> <p>13.3 PROCEDIMIENTOS DE COMPARACI\u00d3N M\u00daLTIPLE</p> <ul> <li>Margen de error y estimaci\u00f3n por intervalo</li> <li>Consejo pr\u00e1ctico</li> </ul> <p>13.4 DISE\u00d1O DE BLOQUES ALEATORIZADO </p> <ul> <li>Prueba de estr\u00e9s para controladores de tr\u00e1fico a\u00e9reo</li> <li>Procedimiento ANOVA</li> <li>C\u00e1lculos y conclusiones</li> </ul> <p>13.5 EXPERIMENTO FACTORIAL</p> <ul> <li>Procedimiento ANOVA</li> <li>C\u00e1lculos y conclusiones</li> </ul> <p>Una vez realizado el dise\u00f1o del experimento, se procede a recolectar y analizar los datos. En el caso de Chemitech, se le explica a los trabajadores c\u00f3mo emplear el m\u00e9todo de ensamble que les ha sido asignado y empezar\u00e1n a armar los sistemas de fi ltraci\u00f3n con ese m\u00e9todo. En la tabla 13.1 se presenta el n\u00famero de unidades ensambladas por cada empleado en una semana. Tambi\u00e9n se proporciona la media muestral, la varianza muestral y la desviaci\u00f3n est\u00e1ndar muestral obtenidas con cada proceso de ensamble. As\u00ed, la media muestral del n\u00famero de unidades producidas con el m\u00e9todo A es 62; con el m\u00e9todo B es 66, y usando el m\u00e9todo C es 52. Con base en estos datos, parece que B proporciona las tasas m\u00e1s altas de producci\u00f3n que cualquiera de los otros m\u00e9todos.</p> <p>El punto a considerar es si cualquiera de las tres medias muestrales observadas difiere lo suficiente como para concluir que las medias poblacionales correspondientes a estos tres m\u00e9todos de ensamble son diferentes. Para escribir esto en t\u00e9rminos estad\u00edsticos, se introduce la notaci\u00f3n siguiente.</p> <p>$\\mu_1$: N\u00famero medio de unidades producidas por semana con el m\u00e9todo A.</p> <p>$\\mu_2$: N\u00famero medio de unidades producidas por semana con el m\u00e9todo B.</p> <p>$\\mu_3$: N\u00famero medio de unidades producidas por semana con el m\u00e9todo C.</p> <p>Tabla 13.1  N\u00famero de unidades producidas por 15 trabajadores</p> <p>Aunque nunca se podr\u00e1 saber cu\u00e1les son los verdaderos valores de $\u03bc1, \u03bc2$ y $\u03bc3$, se utilizan las medias muestrales para probar las hip\u00f3tesis siguientes.</p> <p>H\u2080:  $\\mu_1 = \\mu_2 = \\mu_3$</p> <p>H\u2090: No todas las medias poblacionales son iguales.</p> <p>Como se demostrar\u00e1 m\u00e1s adelante, el an\u00e1lisis de varianza (ANOVA) es el procedimiento estad\u00edstico que se emplea para determinar si las diferencias observadas entre las tres medias muestrales son lo sufi cientemente grandes para rechazar $H_0$.</p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Definimos los par\u00e1metros de la distribuci\u00f3n normal\nmedia = 0\ndesviacion_estandar = 1\n\n# Generamos una muestra de datos de la distribuci\u00f3n normal\ndatos = np.random.normal(media, desviacion_estandar, 1000)\n\n# Creamos la figura de matplotlib\nplt.figure()\n\n# Graficamos los datos\nplt.hist(datos, bins=100)\n\n# Establecemos los l\u00edmites del eje x\nplt.xlim([-5, 5])\n\n# Establecemos el t\u00edtulo de la figura\nplt.title(\"Distribuci\u00f3n normal\")\n\n# Mostramos la figura\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  # Definimos los par\u00e1metros de la distribuci\u00f3n normal media = 0 desviacion_estandar = 1  # Generamos una muestra de datos de la distribuci\u00f3n normal datos = np.random.normal(media, desviacion_estandar, 1000)  # Creamos la figura de matplotlib plt.figure()  # Graficamos los datos plt.hist(datos, bins=100)  # Establecemos los l\u00edmites del eje x plt.xlim([-5, 5])  # Establecemos el t\u00edtulo de la figura plt.title(\"Distribuci\u00f3n normal\")  # Mostramos la figura plt.show() <p>En el an\u00e1lisis de varianza, cada muestra provendr\u00e1 de la misma distribuci\u00f3n normal con media \u03bc y varianza \u03c3\u00b2. Recuerde que en el cap\u00edtulo 7 se vio que la distribuci\u00f3n muestral de la media muestral $\\bar{x}$ de una muestra aleatoria simple de tama\u00f1o n tomada de una poblaci\u00f3n normal tendr\u00e1 una distribuci\u00f3n normal con media \u03bc y varianza $\\frac{\\sigma^2}{n}$. En la figura 13.2 se ilustra una distribuci\u00f3n muestral de este tipo.</p> <p>Por consiguiente, si la hip\u00f3tesis nula es verdadera, se considera cada una de las tres medias muestrales, $\\bar{x}_1$, $\\bar{x}_2$ y $\\bar{x}_3 $ de la tabla 13.1, como valores obtenidos aleatoriamente de la distribuci\u00f3n muestral que aparece en la figura 13.2. En este caso, la media y la varianza de los tres valores $\\bar{x}$ se pueden usar para estimar la media y la varianza de la distribuci\u00f3n muestral.Cuando los tama\u00f1os de las muestras son iguales, como en el caso de Chemitech, la mejor estimaci\u00f3n de la media de la distribuci\u00f3n muestral de $\\bar{x}$ es la media o el promedio de las medias muestrales. Por tanto, en el experimento de Chemitech, una estimaci\u00f3n de la media de la distribuci\u00f3n muestral de $\\bar{x}$ es $ \\frac{62 + 66 + 52}{3} = 60 $, a la cual se le conoce como media muestral general. A su vez, una estimaci\u00f3n de la varianza de la distribuci\u00f3n muestral de $\\bar{x}$, $\\sigma_{\\bar{x}}^2$ se obtiene de la varianza de las tres medias muestrales.</p> <p>$s_{\\bar{x}}^2= \\frac {(62 - 60)^2 + (66 - 60)^2 + (52 - 60)^2}{3 - 1}=\\frac{104}{2}=52$</p> <p>Como $\\sigma_{\\bar{x}}^2=\\frac{\u03c3^2}{n}$, al resolver para $\u03c3^2$ obtenemos</p> <p>$\\sigma^2= n\\sigma_{\\bar{x}}^2$</p>  Por tanto,  <p>Estimaci\u00f3n de $\\sigma_{\\bar{x}}^2=n$ (estimaci\u00f3n de $\\sigma_{\\bar{x}}^2$) $=ns_{\\bar{x}}^2=$ 5(52)=260</p> <p>Al resultado, $ns_{\\bar{x}}^2 = 260$, se le conoce como estimaci\u00f3n de $\\sigma^2$ entre tratamientos. La estimaci\u00f3n $\\sigma^2$ entre tratamientos se basa en el supuesto de que la hip\u00f3tesis nula es verdadera. En este caso cada una de las muestras proviene de la misma poblaci\u00f3n y s\u00f3lo hay una</p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Definimos los par\u00e1metros de la distribuci\u00f3n normal\nmedia = 0\ndesviacion_estandar = 1\n\n# Generamos una muestra de datos de la distribuci\u00f3n normal\ndatos = np.random.normal(media, desviacion_estandar, 1000)\n\n# Creamos la figura de matplotlib\nplt.figure()\n\n# Graficamos los datos\nplt.hist(datos, bins=100)\n\n# Establecemos los l\u00edmites del eje x\nplt.xlim([-5, 5])\n\n# Establecemos el t\u00edtulo de la figura\nplt.title(\"Distribuci\u00f3n normal\")\n\n# A\u00f1adimos una l\u00ednea de media\nplt.axvline(media, color=\"red\")\n\n# A\u00f1adimos una l\u00ednea de desviaci\u00f3n est\u00e1ndar\nplt.axvline(media + desviacion_estandar, color=\"blue\")\nplt.axvline(media - desviacion_estandar, color=\"blue\")\n\n# A\u00f1adimos una l\u00ednea de dos desviaciones est\u00e1ndar\nplt.axvline(media + 2 * desviacion_estandar, color=\"green\")\nplt.axvline(media - 2 * desviacion_estandar, color=\"green\")\n\n# A\u00f1adimos una l\u00ednea de tres desviaciones est\u00e1ndar\nplt.axvline(media + 3 * desviacion_estandar, color=\"black\")\nplt.axvline(media - 3 * desviacion_estandar, color=\"black\")\n\n# Mostramos la figura\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  # Definimos los par\u00e1metros de la distribuci\u00f3n normal media = 0 desviacion_estandar = 1  # Generamos una muestra de datos de la distribuci\u00f3n normal datos = np.random.normal(media, desviacion_estandar, 1000)  # Creamos la figura de matplotlib plt.figure()  # Graficamos los datos plt.hist(datos, bins=100)  # Establecemos los l\u00edmites del eje x plt.xlim([-5, 5])  # Establecemos el t\u00edtulo de la figura plt.title(\"Distribuci\u00f3n normal\")  # A\u00f1adimos una l\u00ednea de media plt.axvline(media, color=\"red\")  # A\u00f1adimos una l\u00ednea de desviaci\u00f3n est\u00e1ndar plt.axvline(media + desviacion_estandar, color=\"blue\") plt.axvline(media - desviacion_estandar, color=\"blue\")  # A\u00f1adimos una l\u00ednea de dos desviaciones est\u00e1ndar plt.axvline(media + 2 * desviacion_estandar, color=\"green\") plt.axvline(media - 2 * desviacion_estandar, color=\"green\")  # A\u00f1adimos una l\u00ednea de tres desviaciones est\u00e1ndar plt.axvline(media + 3 * desviacion_estandar, color=\"black\") plt.axvline(media - 3 * desviacion_estandar, color=\"black\")  # Mostramos la figura plt.show() <p>distribuci\u00f3n muestral de $\\bar{x}$. Para ilustrar qu\u00e9 ocurre cuando $H_0$ es falsa, suponga que las medias poblacionales son todas diferentes. Observe que como las tres muestras provienen de poblaciones normales con medias diferentes, dar\u00e1n tres distribuciones muestrales distintas. En la figura 13.3 se advierte que en este caso las medias muestrales no est\u00e1n tan cerca unas de otras como cuando $H_0$ es verdadera. Entonces $s \\frac{2}{x}$ ser\u00e1 mayor, haciendo que la estimaci\u00f3n entre tratamientos de $\\sigma^2$ tambi\u00e9n lo sea. En general, cuando las medias poblacionales no son iguales, la estimaci\u00f3n entre tratamientos sobreestimar\u00e1 la varianza poblacional $\\sigma^2$. La variaci\u00f3n dentro de cada una de las muestras tambi\u00e9n tiene efecto sobre la conclusi\u00f3n a la que se arriba con el an\u00e1lisis de varianza. Cuando se selecciona una muestra aleatoria simple de cada poblaci\u00f3n, cada una de las varianzas muestrales proporciona una estimaci\u00f3n insesgada de $\\sigma^2$. Por tanto, se combinan o juntan las estimaciones individuales de $\\sigma^2$ en una general. A la estimaci\u00f3n de $\\sigma^2$ obtenida de esta manera se le conoce como estimaci\u00f3n conjunta o dentro de los tratamientos de $\\sigma^2$. Debido a que cada varianza muestral proporciona una estimaci\u00f3n de $\\sigma^2$ que se basa s\u00f3lo en la variaci\u00f3n dentro de cada muestra, a la estimaci\u00f3n de \u03c32 dentro de los tratamientos no le afecta que las medias poblacionales sean iguales. Cuando los tama\u00f1os de las muestras son iguales, la estimaci\u00f3n dentro de los tratamientos de $\\sigma^2$ se obtiene al calcular el promedio de las varianzas muestrales. En el experimento de Chemitech obtenemos</p> <p>En el experimento de Chemitech, la estimaci\u00f3n de $\\sigma^2$ entre los tratamientos (260) es mucho mayor que dentro de los tratamientos (28.33). De hecho, el cociente entre estas dos estimaciones es $\\frac{260}{28.33}=9.18$. Pero debe recordarse que el m\u00e9todo entre tratamientos s\u00f3lo proporciona una buena estimaci\u00f3n de $\\sigma^2$ si la hip\u00f3tesis nula es verdadera; si es falsa, este m\u00e9todo sobreestima $\\sigma^2$. El m\u00e9todo dentro de los tratamientos proporciona una buena estimaci\u00f3n de $\\sigma^2$ en cualquiera de los casos. Por tanto, si la hip\u00f3tesis nula es verdadera, las dos estimaciones ser\u00e1n semejantes y su cociente ser\u00e1 cercano a 1. Si la hip\u00f3tesis es falsa, la estimaci\u00f3n entre tratamientos ser\u00e1 mayor que la estimaci\u00f3n dentro de los tratamientos y su cociente ser\u00e1 grande. En la secci\u00f3n siguiente se muestra qu\u00e9 tan grande debe ser este cociente para que $H_0$ sea rechazada.</p> <p>En resumen, la l\u00f3gica detr\u00e1s del ANOVA se basa en obtener dos estimaciones independientes de la varianza poblacional com\u00fan de $\\sigma^2$. Una estimaci\u00f3n de $\\sigma^2$ se funda en la variabilidad entre las medias muestrales mismas y la otra en la variabilidad entre los datos dentro de cada muestra. Al comparar estas dos estimaciones de $\\sigma^2$, podr\u00e1 determinarse si las medias poblacionales son iguales.</p> 13.2\u00a0\u00a0Analisis de varianza y el dise\u00f1o completamente aleaterizado <p>En esta secci\u00f3n se muestra el uso del an\u00e1lisis de varianza para probar la igualdad de k medias poblacionales en un dise\u00f1o completamente aleatorizado. La forma general de esta prueba de11 hip\u00f3tesis es $$ H_0: \\mu_1 = \\mu_2 = \\ldots = \\mu_k $$ $$ H_a: \\text{no todas las medias poblacionales son iguales} $$ Se asume que de cada una de las k poblaciones o tratamientos se toma una muestra aleatoria simple de tama\u00f1o nj . Para los datos muestrales resultantes, sean</p> <ul> <li>$ x_{ij} $: valor de la observaci\u00f3n i de tratamiento j</li> <li>$ \\bar{x}_j $: media del tratamiento j</li> <li>$ n_j $: n\u00famero de observaciones en el tratamiento j</li> <li>$ s_{j}^2 $: varianza muestral del tratamiento j</li> <li>$ s_{j} $: desviaci\u00f3n est\u00e1ndar muestral del tratamiento j</li> </ul> <p>Las f\u00f3rmulas para la media muestral y la varianza muestral del tratamiento j son las siguientes: $$ \\bar{x_j} = \\frac{\\sum_{i=1}^{n_j} x_{ij}}{n_j}\\tag{13.1} $$</p> <p>$$ s^2_j = \\frac{\\sum_{i=1}^{n_j} (x_{ij} - \\bar{x_j})^2}{n_j-1} \\tag{13.2} $$</p> <p>La media muestral general, que se denota $$\\bar{\\bar{X}}$$, es la suma de todas las observaciones divididas entre la cantidad total de las observaciones. Es decir $$ \\bar{\\bar{X}} = \\frac{\\sum_{i=1}^{k} \\sum_{j=1}^{n_i} X_{ij}}{n_T}\\tag{13.3} $$</p> <p>donde $$ n_T = n_1 + n_2 + \\ldots + n_k\\tag{13.4} $$ Si el tama\u00f1o de cada muestra es de n, nT  kn, en este caso la ecuaci\u00f3n (13.3) se reduce a</p> <p>$$ \\bar{\\bar{X}} = \\frac{\\sum_{i=1}^{k} \\sum_{j=1}^{n_i} X_{ij}}{kn}= \\frac{\\sum_{i=1}^{k} \\sum_{j=1}^{n_i} {X_{ij}/n}}{k}=\\frac{\\sum_{j=1}^{k} \\bar{X_j}}{k}\\tag{13.5} $$</p> <p>En otras palabras, si todas las muestras son del mismo tama\u00f1o, la media muestral general es el promedio de las k medias muestrales.</p> <p>En el experimento de Chemitech, como todas las muestras constaban de n = 5 observaciones, la media muestral general se calcula utilizando la f\u00f3rmula (13.5). Con base en los datos de la tabla 13.1 obtenemos el siguiente resultado.</p> <p>$$ \\bar{\\bar{X}} = \\frac{62 + 66 + 52}{3} = 60 $$</p> <p>Si la hip\u00f3tesis nula es verdadera (\u03bc1 = \u03bc2 = \u03bc3 = \u03bc), la media muestral general de 60 es la mejor estimaci\u00f3n de la media poblacional \u03bc.</p> <p>Estimaci\u00f3n de la varianza poblacional entre tratamientos</p> <p>Se present\u00f3 el concepto de estimaci\u00f3n de $\u03c3^2$ entre tratamientos y se mostr\u00f3 c\u00f3mo calcularla cuando todas las muestras son del mismo tama\u00f1o. A esta estimaci\u00f3n de $\u03c3^2$ se le llama cuadrado medio debido a los tratamientos y se denota como CMTR. La f\u00f3rmula general para calcularlo es</p> <p>$$ CMTR = \\frac{\\sum_{j=1}^{k} n_j (\\bar{X}_j - \\bar{\\bar{X}})^2}{k-1}\\tag{13.6} $$</p> <p>Al numerador de la ecuaci\u00f3n (13.6) se le llama suma de cuadrados debido a los tratamientos y se denota SCTR. El denominador, k-1, representa los grados de libertad asociados con la SCTR. Por tanto, el cuadrado medio debido a los tratamientos se calcula con la f\u00f3rmula siguiente.</p> <p>Cuadrado Medio Debido a los Tratamientos $$ CMTR = \\frac{SCTR}{k-1} \\tag{13.7} $$</p> <p>donde</p> <p>$$ SCTR = \\sum_{i=1}^{k} n_j (\\bar{X}_j - \\bar{\\bar{X}})^2 \\tag{13.8}$$</p> <p>Si $H_0$ es verdadera, el CMTR proporciona una estimaci\u00f3n insesgada de $\u03c3^2$. No obstante, si las medias de las k poblaciones no son iguales, el CMTR no es un estimador insesgado de $\u03c3^2$; en este caso, de hecho, sobreestima $\u03c3^2$. Para los datos de Chemitech de la tabla 13.1 obtenemos los siguientes resultados.</p> <p>$$ SCTR = \\sum_{i=1}^{k} n_j (\\bar{X}_j - \\bar{\\bar{X}})^2 = 5(62-60)^2 + 5(66-60)^2 + 5(52-60)^2=520 $$</p> <p>$$ CMTR = \\frac{SCTR}{k-1} = \\frac{520}{2}=260 $$</p> <p>Estimaci\u00f3n de la varianza poblacional dentro de los tratamientos</p> <p>Ya se present\u00f3 el concepto de estimaci\u00f3n de $\u03c3^2$ dentro de los tratamientos y c\u00f3mo calcularla cuando todas las muestras son del mismo tama\u00f1o. A esta estimaci\u00f3n de $\u03c3^2$ se le llama cuadrado medio debido al error y se denota como CME. La f\u00f3rmula general para calcularlo es</p> <p>$$ CMTR = \\frac{\\sum_{j=1}^{k}(n_j - 1)s^2_j}{n_T-k} \\tag{13.9} $$</p> <p>Al numerador de la ecuaci\u00f3n (13.9) se le llama suma de cuadrados debido al error, y se denota como SCE. El denominador del CME son los grados de libertad correspondientes a la SCE. Por tanto, la f\u00f3rmula para el CME tambi\u00e9n se expresa como sigue.</p> <p>Cuadrado medio debido al error $$ CME = \\frac{SCE}{n_T-k} \\tag{13.10} $$ donde</p> <p>$$ SCE = \\sum_{j=1}^{k} (n_j - 1) s^2_j \\tag{13.11} $$</p> <p>Observe que el CME est\u00e1 basado en la variaci\u00f3n dentro de cada tratamiento; el que la hip\u00f3tesis nula sea o no verdadera no tiene ninguna infl uencia. Por tanto, el CME proporciona siempre una estimaci\u00f3n insesgada de $\u03c3^2$.</p> <p>Con base en los datos de la tabla 13.1 para el caso de Chemitech, obtenemos los resultados siguientes. $$ SCE = \\sum_{j=1}^{k} (n_j - 1)s^2_j= (5-1)27.5+(5-1)26.5+(5-1)31=340 $$ $$ CME= \\frac{SCE}{n_T-k} = \\frac{340}{15-3}=\\frac{340}{12}=28.33 $$</p> <p>Comparaci\u00f3n de las estimaciones de las varianzas: la prueba F</p> <p>Si la hip\u00f3tesis nula es verdadera, el CMTR y el CME proporcionan dos estimaciones insesgadas e independientes de $\u03c3^2$. Con base en lo estudiado en el cap\u00edtulo 11 sabemos que cuando se tienen poblaciones normales la distribuci\u00f3n muestral del cociente de dos estimaciones independientes de \u03c32 sigue una distribuci\u00f3n F. Por tanto, si la hip\u00f3tesis nula es verdadera y se satisfacen los supuestos del ANOVA, la distribuci\u00f3n muestral del CMTR/CME es una distribuci\u00f3n F con k - 1 grados de libertad en el numerador y nT - k grados de libertad en el denominador. En otras palabras, si la hip\u00f3tesis nula es verdadera, el valor del CMTR/CME parecer\u00e1 que es un valor tomado de esta distribuci\u00f3n F.</p> <p>No obstante, si la hip\u00f3tesis nula es falsa, el valor del CMTR/CME ser\u00e1 muy grande debido a que el CMTR sobreestima \u03c32. Por tanto, si el valor de CMTR/CME resulta ser demasiado grande para haber sido tomado de la distribuci\u00f3n F con k - 1 grados de libertad en el numerador y nT - k grados de libertad en el denominador, $H_0$ ser\u00e1 rechazada. Como la decisi\u00f3n de descartar $H_0$ est\u00e1 basada en el valor del CMTR/CME, el estad\u00edstico de prueba que se usa para probar la igualdad de k poblaciones es el siguiente.</p> <p>ESTADISTICO DE PRUEBA PARA LA IGUALDAD DE K MEDIAS POBLACIONALES $$ F = \\frac{CMTR}{CME}\\tag{13.12} $$ donde Este estad\u00edstico de prueba sigue una distribuci\u00f3n F con k - 1 grados de libertad en el numerador y nT -k grados de libertad en el denominador</p> <p>Ahora bien, en el experimento de Chemitech se usar\u00e1 $\u03b1=0.05$ como nivel de significancia para realizar la prueba de hip\u00f3tesis. El valor del estad\u00edstico de prueba es $$ F = \\frac{CMTR}{CME}= \\frac{260}{28.33}=9.18 $$</p> <p>Los grados de libertad en el numerador son $k - 1 = 3 - 1= 2$, y los grados de libertad para el denominador son $n_T - k = 15 - 3 = 12$. Como la hip\u00f3tesis nula s\u00f3lo ser\u00e1 rechazada si obtenemos un valor grande para el estad\u00edstico de prueba, el valor-p ser\u00e1 el \u00e1rea en la cola superior de la distribuci\u00f3n F a la derecha del estad\u00edstico de prueba $F = 9.18$. En la figura 13.4 se presenta la distribuci\u00f3n muestral de $F = CMTR/CME$, el valor del estad\u00edstico de prueba y el \u00e1rea en la cola superior que es el valor-p de esta prueba de hip\u00f3tesis.</p> <p>En la tabla 4 del ap\u00e9ndice B se encuentran las \u00e1reas siguientes en la cola superior de la distribuci\u00f3n F con 2 grados de libertad en el numerador y 12 grados de libertad en el denominador.</p> Area en la cola superior 0.10 0.05 0.025 0.01 Valor F( $$ gl_1 = 2 ; gl_2 = 12 $$                 )                  2.81 3.89 5.10 6.93 F = 9.18                  In\u00a0[42]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.interpolate import make_interp_spline\n\n# Definir los datos\nx = np.array([0, 2.81, 3.89, 5.10, 6.93])\ny = np.array([0, 0.10, 0.05, 0.025, 0.01])\n\n# Crear la figura y los ejes\nfig, ax = plt.subplots()\n        \n# Graficar los datos suavizados\nx_smooth = np.linspace(x.min(), x.max(), 200)\ny_smooth = make_interp_spline(x, y)(x_smooth)\nax.plot(x_smooth, y_smooth, color=\"#009929\", label=\"Datos suavizados\")\n\n# Graficar los datos originales\nax.scatter(x, y, color=\"#98F84A\", label=\"Datos originales\")\n\n# Cambiar el color del fondo\nax.set_facecolor(\"#D4F8B7\")\n\n# Pintar el fondo externo del gr\u00e1fico\nfig.patch.set_facecolor('#D4F8B7')\n\n# Agregar el sombreado\nax.fill_between(x, y, where=(x &gt;= 4.18), color=\"#98F84A\", alpha=0.2)\n# Agregar el texto\nax.text(5.81, -0.02, \"F = 9.18\", ha=\"center\")\nax.text(7.81, -0.03, \"CMTR/CME\", ha=\"center\")\n\nax.text(4.81, 0.1, \"Distribucion de muestreo\\n de CMTR/CME\",va='center', ha=\"center\")\nax.text(6.81, 0.025, \"valor - p\",va='center', ha=\"center\")\n\n\n# Agregar leyenda\nax.legend()\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np from scipy.interpolate import make_interp_spline  # Definir los datos x = np.array([0, 2.81, 3.89, 5.10, 6.93]) y = np.array([0, 0.10, 0.05, 0.025, 0.01])  # Crear la figura y los ejes fig, ax = plt.subplots()          # Graficar los datos suavizados x_smooth = np.linspace(x.min(), x.max(), 200) y_smooth = make_interp_spline(x, y)(x_smooth) ax.plot(x_smooth, y_smooth, color=\"#009929\", label=\"Datos suavizados\")  # Graficar los datos originales ax.scatter(x, y, color=\"#98F84A\", label=\"Datos originales\")  # Cambiar el color del fondo ax.set_facecolor(\"#D4F8B7\")  # Pintar el fondo externo del gr\u00e1fico fig.patch.set_facecolor('#D4F8B7')  # Agregar el sombreado ax.fill_between(x, y, where=(x &gt;= 4.18), color=\"#98F84A\", alpha=0.2) # Agregar el texto ax.text(5.81, -0.02, \"F = 9.18\", ha=\"center\") ax.text(7.81, -0.03, \"CMTR/CME\", ha=\"center\")  ax.text(4.81, 0.1, \"Distribucion de muestreo\\n de CMTR/CME\",va='center', ha=\"center\") ax.text(6.81, 0.025, \"valor - p\",va='center', ha=\"center\")   # Agregar leyenda ax.legend()  # Mostrar el gr\u00e1fico plt.show() <p>Como F = 9.18 es mayor que 6.93, el \u00e1rea en la cola superior correspondiente a F = 9.18 es menor que 0.01. Por tanto, el valor-p es menor que 0.01. Para obtener el valor-p exacto, que es 0.004, se puede usar Minitab o Excel. Como el valor-p &lt;= \u03b1 =  0.05, $H_0$ es rechazada. La prueba proporciona evidencias suficientes para concluir que las medias de las tres poblaciones no son iguales. En otras palabras, el an\u00e1lisis de varianza favorece la conclusi\u00f3n de que las medias poblacionales del n\u00famero de unidades producidas por semana con cada uno de los tres m\u00e9todos de ensamble no son iguales. Como en otros procedimientos de pruebas de hip\u00f3tesis, aqu\u00ed tambi\u00e9n puede emplearse el m\u00e9todo del valor cr\u00edtico. Como \u03b1  0.05, el valor cr\u00edtico de F es aquel que deja un \u00e1rea de 0.05 en la cola superior de la distribuci\u00f3n F con 2 y 12 grados de libertad. En las tablas de la distribuci\u00f3n F se encuentra F0.05  3.89. Por tanto, la regla de rechazo en el caso del experimento de Chemitech es</p> <p>$$Rechazar \\space{} H_0 \\space{} si \\space{} F \\geq 3.89 $$</p> <p>Con F = 9.18, $H_0$ es rechazada, y concluimos que las medias de las tres poblaciones no son iguales. A continuaci\u00f3n se presenta un resumen del procedimiento general para probar la igualdad de k medias poblacionales</p> <p>PRUEBA DE IGUALDAD DE K MEDIAS POBLACIONALES</p> <p>$ H_0: \\mu_1 = \\mu_2 = \\ldots = \\mu_k $</p> <p>$ H_a: \\text{no todas las medias poblacionales son iguales} $</p> <p>ESTADISTICO DE PRUEBA $$F = \\frac{CMTR}{CME}$$ REGLA DE RECHAZO</p> <p>Metodo del valor-p: Rechazar $ H_0 $ si el valor-p \u2264 a</p> <p>Metodo del valor critico: Rechazar $ H_0 $ si F \u2264 $ F_a $ </p> <p>donde el valor de $ F_a $ esta basado en una distribucion F con k - 1 grados de libertad en el numerador y $ n_t - k $ grados de libertad en el denominador.</p> <p>Tabla de ANOVA</p> <p>Los c\u00e1lculos anteriores se pueden presentar de manera adecuada en un instrumento conocido como tabla de an\u00e1lisis de varianza o tabla de ANOVA. En la tabla 13.2 se observa la forma general de una tabla ANOVA para un dise\u00f1o completamente aleatorizado; la tabla 13.3 corresponde a la tabla ANOVA del experimento de Chemitech. La suma de los cuadrados asociados con la fuente de variaci\u00f3n que se indica como \u201cTotal\u201d se conoce como suma total de cuadrados (STC). Observe que los resultados del experimento de Chemitech indican que STC  SCTR SCE, y que los grados de libertad que corresponden a este resultado es la suma de los grados de libertad correspondiente a la suma de cuadrados debido a los tratamientos m\u00e1s la suma de cuadrados debido al error. Cabe hacer notar que la STC dividida entre los grados de libertad nT - 1 no es otra cosa que la varianza muestral general que se obtendr\u00eda si se considerara la muestra de las 15 observaciones como un solo conjunto de datos. Si se toma todo el conjunto de datos como una sola muestra, la f\u00f3rmula para calcular la suma total de cuadrados, STC, es $$STC = \\sum_{j=1}^{k}\\sum_{i=1}^{n_j} (X_{ij} - \\bar{\\bar{X}})^2 \\tag{13.13}$$</p> <p>Se puede demostrar que estos resultados observados para el an\u00e1lisis de la tabla de varianza en el caso del experimento de Chemitech tambi\u00e9n son aplicables a otros problemas. Es decir, $$STC = SCTR + SCE \\tag{13.14}$$</p> <p>En otras palabras, la STC se particiona en dos sumas de cuadrados: la suma de cuadrados debido a los tratamientos y la suma de cuadrados debido al error. Observe, adem\u00e1s, que los grados de libertad que corresponden a la STC, $n_T - 1$, se pueden partir en grados de libertad correspondientes a SCTR, $k - 1$, y en grados de libertad correspondientes a SCE, $n_T - k$. El an\u00e1lisis de varianza se puede ver como el proceso de partici\u00f3n de la suma total de cuadrados y los grados de libertad en sus fuentes correspondientes: tratamientos y error. Al dividir las sumas de cuadrados entre los correspondientes grados de libertad, se obtienen las estimaciones de la varianza, el valor de F y el valor-p empleados en la prueba de hip\u00f3tesis de igualdad entre las medias poblacionales.</p> <p>Tabla 13.2 Tabla ANOVA para un dise\u00f1o completamente aleatorizado</p> Fuente de variacion Suma de cuadrados Grados de libertad Cuadrado medio F valor-p Tratamientos SCTR k - 1 $$CMTR=\\frac{SCRT}{k-1}$$ $$\\frac{CMTR}{CME}$$ Error SCE $$n_t - k$$ $$CME=\\frac{SCE}{n_t-k}$$ Total STC $$n_t - 1$$ <p>Tabla 13.3  Tabla de analisis de varianza para el experimento de Chemitech</p> Fuente de variacion Suma de cuadrados Grados de libertad Cuadrado medio F valor-p Tratamientos 520 2 260.00 9.18 0.004 Error 340 12 28.33 Total 860 14 <p>Tabla 13.3  Tabla de analisis de varianza para el experimento de Chemitech</p> Source DF SS MS F P Factor 2 520.0 260.0 9.8 0.004 Error 14 360.0 28.3 Total 16 840.0 Level N Mean StDev 1 5 10.2 3.4 2 5 15.1 2.7 3 5 20.3 2.9 <p> VIDEO DE YOUTUBE TABLA ANOVA</p> <p></p> <p>Resultados de computadora para el an\u00e1lisis de varianza</p> <p>Cuando se tienen muestras grandes o una cantidad grande de poblaciones, los c\u00e1lculos del an\u00e1lisis de varianza se realizan con m\u00e1s facilidad mediante software para estad\u00edstica. En los ap\u00e9ndices 13.1 a 13.3 se indican los pasos necesarios para realizar los c\u00e1lculos del an\u00e1lisis de varianza con Minitab, Excel y StarTools. En la fi gura 13.5, aplicado al experimento de Chemitech, se presenta la pantalla de resultados de Minitab. En la primera parte de la pantalla se observa el formato ya conocido de la tabla ANOVA. Si se compara la fi gura 13.5 con la tabla 13.3, vemos que la informaci\u00f3n disponible es la misma, aunque algunos encabezados son ligeramente diferentes. El encabezado Source se usa en la columna correspondiente a la fuente de variaci\u00f3n; Factor corresponde a la fi la de tratamientos, y las columnas de las sumas de cuadrados y los grados de libertad est\u00e1n intercambiados.</p> <p>Observe que, enseguida de la tabla ANOVA, la pantalla de la computadora proporciona los respectivos tama\u00f1os de las muestras, las medias muestrales y las desviaciones est\u00e1ndar. Adem\u00e1s, Minitab presenta una fi gura con la estimaci\u00f3n por intervalos de 95% de confi anza para cada una de las medias poblacionales. Para obtener la estimaci\u00f3n de estos intervalos, Minitab emplea el CME como estimaci\u00f3n de \u03c32 . Por tanto, la ra\u00edz cuadrada del CME proporciona la mejor estimaci\u00f3n de la desviaci\u00f3n est\u00e1ndar poblacional \u03c3. En la salida de la computadora esta estimaci\u00f3n de \u03c3 es Pooled StDev, y su valor es 5.323. Para ilustrar c\u00f3mo se calcula la estimaci\u00f3n por intervalos se har\u00e1 aqu\u00ed la estimaci\u00f3n por intervalo de 95% de confianza para la media poblacional del m\u00e9todo A. Con base en lo aprendido en el estudio de intervalos de confianza en el cap\u00edtulo 8, sabemos que la forma general de una estimaci\u00f3n por intervalo para una media poblacional es</p> <p>$$\\bar{x}=t_{a/2}\\frac{s}{\\sqrt{n}}$$</p> <p>donde s es la estimaci\u00f3n de la desviaci\u00f3n est\u00e1ndar poblacional \u03c3. Como la mejor estimaci\u00f3n de \u03c3 es la proporcionada por la Pooled StDev, se usa 5.323 en la expresi\u00f3n (13.15) como valor de s. Los grados de libertad para el valor de t son 12, los grados de libertad asociados con la suma de los cuadrados del error. Por tanto, como t0.025  2.179, obtenemos</p> <p>$$62\u00b12.179\\frac{5.323}{\\sqrt{5}}=62\u00b15.19$$</p> <p>As\u00ed, el intervalo de 95% de confi anza para el m\u00e9todo A va de 62 \u0004 5.19  56.81 a 62 5.19  67.19. Como en el experimento de Chemitech los tama\u00f1os muestrales son iguales, tambi\u00e9n los intervalos de confi anza para los m\u00e9todos B y C se obtienen al sumar y restar 5.19 de la respectiva media muestral. En la salida de Minitab se aprecia que los anchos de los intervalos de confi anza son los mismos.</p> <p>Prueba para la igualdad de k medias poblacionales: un estudio observacional </p> <p>Se ha revisado el uso del an\u00e1lisis de varianza para probar la igualdad de k medias poblacionales cuando se emplea un dise\u00f1o experimental completamente aleatorizado. Es importante notar que el ANOVA tambi\u00e9n se puede utilizar para probar la igualdad de tres o m\u00e1s medias poblacionales usando datos de un estudio observacional. Para dar un ejemplo, se considerar\u00e1 el caso de National Computer Products, Inc. (NCP). NCP fabrica impresoras y aparatos de fax en sus tres plantas situadas en Atlanta, Dallas y Seattle. Con el fi n de medir los conocimientos de los empleados de estas tres plantas acerca de la administraci\u00f3n de la calidad, se toma una muestra aleatoria de seis empleados de cada planta y se les aplica un examen acerca de su conocimiento sobre la calidad. En la tabla 13.4 se presentan las puntuaciones obtenidas en los ex\u00e1menes por los 18 sujetos. En esta tabla se indican tambi\u00e9n la media, la varianza y la desviaci\u00f3n est\u00e1ndar muestrales de cada grupo. Los gerentes de la empresa quieren usar estos datos para probar la hip\u00f3tesis de que la media de las puntuaciones de los ex\u00e1menes es la misma en las tres plantas. Como poblaci\u00f3n 1 se defi ne a los empleados de la planta en Atlanta, como poblaci\u00f3n 2 a los de la planta en Dallas y como poblaci\u00f3n 3 a los de Seattle. Sean</p> <p>$ \\mu_1 $ = media de las puntuaciones en los examenes de la poblacion 1</p> <p>$ \\mu_2 $ = media de las puntuaciones en los examenes de la poblacion 2</p> <p>$ \\mu_3 $ = media de las puntuaciones en los examenes de la poblacion 3</p> <p>Aunque los verdaderos valores de $\\mu_1, \\mu_2$ y $\\mu_3$ nunca puedan conocerse, se usar\u00e1n los resultados muestrales para probar las hip\u00f3tesis siguientes.</p> <p>$ H_0:\\mu_1 = \\mu_2= \\mu_3$  </p> <p>$ H_a: $ no todas las medias poblaciones son iguales.</p> <p>Observe que la prueba de hip\u00f3tesis para el estudio observacional de NCP es exactamente igual a la que se manej\u00f3 para el experimento de Chemitech. Tambi\u00e9n para analizar los datos del estudio</p> <p>Tabla 13.2 Tabla ANOVA para un dise\u00f1o completamente aleatorizado</p> Planta 1 Atlanta Planta 2 Dallas Planta 3 Seattle 85 71 59 75 75 64 76 74 69 71 69 75 85 82 67 Media Muestral 79 74 66 Varianza muestral 34 20 32 Desviacion estandar muestral 5.83 4.47 5.66 <p>observacional de NCP se emplea la misma metodolog\u00eda de an\u00e1lisis de varianza usada para el experimento de Chemitech.</p> <p>Aun cuando en ambos casos se utiliza la misma metodolog\u00eda del ANOVA, vale la pena observar la diferencia entre el estudio estad\u00edstico observacional de NCP y la investigaci\u00f3n estad\u00edstica experimental de Chemitech. Las personas que realizaron el estudio de NCP no tuvieron control sobre la asignaci\u00f3n de las plantas a cada uno de los empleados. Las plantas ya funcionaban y cada uno de los sujetos trabajaba en una de las tres. Lo \u00fanico que se pudo hacer en este caso fue tomar una muestra aleatoria de seis empleados de cada una de las plantas y aplicarles el examen de conocimiento sobre la calidad. Para clasifi carlo como un trabajo experimental, NPC tendr\u00eda que haber tomado al azar 18 empleados y despu\u00e9s, de manera aleatoria, asignar las plantas a cada uno.</p> NOTAS Y COMENTARIOS <ol> <li>La media muestral general tambi\u00e9n se calcula como media ponderada de las k medias muestrales.</li> </ol> <p>$$\\bar{\\bar{x}}=\\frac{n_1\\bar{x}_1 + n_2\\bar{x}_2 + \\ldots + n_k\\bar{x}_k }{n_T}$$</p> <p>En los problemas en que se proporcionan las medias muestrales, para calcular la media general es m\u00e1s sencillo utilizar esta f\u00f3rmula que la expresi\u00f3n (13.3)</p> <ol> <li>Si todas las muestras constan de n observaciones, la ecuaci\u00f3n (13.6) puede escribe como</li> </ol> <p>$$ CMTR = \\frac{n\u2211_{j=1}^{k} (\\bar{x}_j-\\bar{\\bar{x}})^2}{k - 1} = n [\\frac{n\u2211_{j=1}^{k} (\\bar{x}_j-\\bar{\\bar{x}})^2}{k - 1}]  = ns^2_{\\bar{x}} $$</p> <p>Observe que este resultado es el mismo que el presentado en la secci\u00f3n 13.1 cuando se estudi\u00f3 el concepto de estimaci\u00f3n de \u03c32 entre tratamientos. La ecuaci\u00f3n (13.6) es s\u00f3lo una generalizaci\u00f3n de este resultado para el caso de tama\u00f1os muestrales distintos.</p> <ol> <li>Si cada muestra tiene n observaciones, $n_T = kn$; por tanto, $ n_T - k $ = k(n - 1), y la ecuaci\u00f3n (13.9) se puede reescribir como</li> </ol> <p>$$ CMTR = \\frac{n\u2211_{j=1}^{k} (\\bar{x}_j-\\bar{\\bar{x}})^2}{k - 1} = n [\\frac{n\u2211_{j=1}^{k} (\\bar{x}_j-\\bar{\\bar{x}})^2}{k - 1}]  = ns^2_{\\bar{x}} $$</p> <p>En otras palabras, si los tama\u00f1os muestrales son iguales, el CME es simplemente el promedio de las k varianzas muestrales. Observe que \u00e9ste es el mismo resultado que se us\u00f3 en la secci\u00f3n 13.1 cuando se present\u00f3 el concepto de estimaci\u00f3n de \u03c32 dentro de los tratamientos.</p> 13.3\u00a0\u00a0Procedimientos de comparacion multiple <p>Cuando se emplea el an\u00e1lisis de varianza para probar si las medias de k poblaciones son iguales, rechazar la hip\u00f3tesis nula s\u00f3lo permite concluir que las medias poblacionales no son iguales. En algunos casos se necesita dar un paso m\u00e1s y determinar d\u00f3nde est\u00e1n las diferencias. El prop\u00f3sito de esta secci\u00f3n es mostrar el uso de procedimientos de comparaci\u00f3n m\u00faltiple para establecer comparaciones entre pares de medias poblacionales.</p> 13.4\u00a0\u00a0Dise\u00f1o de bloques aleatorizado <p>Hasta ahora s\u00f3lo se ha considerado el dise\u00f1o de experimentos completamente aleatorizado. Como recordar\u00e1, para probar la diferencia entre las medias de los tratamientos se calcula el valor de F mediante el cociente</p> <p>$$ F= \\frac{CMTR}{CME}\\tag{13.20} $$</p> <p>Sin embargo, puede surgir un problema por diferencias debido a factores ajenos (no considerados en el experimento) que ocasionen que el t\u00e9rmino CME en este cociente se vuelva m\u00e1s grande. En estos casos, el valor de F en la ecuaci\u00f3n (13.20) ser\u00e1 m\u00e1s peque\u00f1o, haciendo que se concluya que no hay diferencia entre las medias de los tratamientos cuando en realidad s\u00ed la hay.</p> <p>En esta secci\u00f3n se presenta un dise\u00f1o de experimentos conocido como dise\u00f1o de bloques aleatorizado, cuyo prop\u00f3sito es controlar algunas fuentes ajenas de variaci\u00f3n elimin\u00e1ndolas del t\u00e9rmino CME. Este dise\u00f1o tiende a proporcionar una mejor estimaci\u00f3n de la varianza del error y conduce a pruebas de hip\u00f3tesis m\u00e1s s\u00f3lidas en t\u00e9rminos de su capaciadad para detectar diferencias entre medias de tratamientos. Para ilustrar esto se retoma un estudio sobre el estr\u00e9s que experimentan los controladores del tr\u00e1fico a\u00e9reo.</p> <p>Prueba de estres para controladores de trafico a\u00e9reo </p> <p>Como resultado de un estudio para medir la fatiga y el estr\u00e9s de los controladores de tr\u00e1fi co a\u00e9reo, se propusieron modifi caciones y redise\u00f1os a su estaci\u00f3n de trabajo. Despu\u00e9s de evaluar diversos dise\u00f1os, se seleccionaron tres alternativas consideradas con el mayor potencial para reducir el estr\u00e9s en los controladores. La pregunta clave es: \u00bfen qu\u00e9 medida difi eren estas tres alternativas en su efecto sobre el estr\u00e9s de los sujetos de estudio? Para responder esta pregunta es necesario dise\u00f1ar un experimento que proporcione mediciones del estr\u00e9s de los controladores del tr\u00e1fi co a\u00e9reo bajo cada alternativa. Si se empleara un dise\u00f1o completamente aleatorizado, una muestra al azar de controladores ser\u00eda asignada a cada una de las alternativas de estaciones de trabajo. Sin embargo, se cree que los sujetos difi eren de forma signifi cativa en su habilidad para manejar situaciones estresantes. Lo que para un controlador implica una gran tensi\u00f3n, para otro puede ser s\u00f3lo un estr\u00e9s moderado e incluso peque\u00f1o. Por tanto, al considerar la fuente de variaci\u00f3n dentro del grupo (CME), hay que reconocer que esta variaci\u00f3n comprende tanto el error aleatorio como el error debido a las diferencias individuales de los sujetos. De hecho, los gerentes consideran que la variabilidad entre los controladores ser\u00e1 la contribuci\u00f3n principal al t\u00e9rmino CME. Una manera de hacer a un lado el efecto de las diferencias individuales es usar el dise\u00f1o de bloques aleatorizado, en el cual se identifi ca la variabilidad debido a las diferencias individuales de los controladores y se elimina del t\u00e9rmino CME. En el dise\u00f1o de bloques aleatorizado se emplea una sola muestra de controladores. Cada uno de ellos se prueba con cada una de las tres alternativas de puestos de trabajo. En la terminolog\u00eda del dise\u00f1o de experimentos, el puesto de trabajo es el factor de inter\u00e9s y los controladores son los bloques. Los tres tratamientos o poblaciones asociados con el factor puesto de trabajo son las tres alternativas de puesto de trabajo. Para simplifi car, a estas tres alternativas se les designar\u00e1 como sistema A, sistema B y sistema C. El aspecto aleatorizado del dise\u00f1o de bloques aleatorizado es el orden al azar en el que les son asignados los tratamientos (sistemas) a los controladores. Si cada sujeto probara los tres sistemas en el mismo orden, cualquier diferencia encontrada podr\u00eda deberse al orden de la prueba m\u00e1s que a las verdaderas diferencias entre los sistemas. Para obtener los datos necesarios, en el Centro de Control Cleveland en Oberlin, Ohio, se instalaron las tres alternativas de estaci\u00f3n de trabajo. Se seleccion\u00f3 a seis controladores en forma aleatoria y se le asign\u00f3 a cada sujeto uno de los sistemas para que lo operara. Despu\u00e9s de practicar una entrevista y un examen m\u00e9dico a cada uno de los participantes en el estudio, se obtuvieron las mediciones del estr\u00e9s de cada controlador en cada uno de los sistemas. En la tabla 13.5 se presentan estos datos con las etiquetas Blocks (bloques), Controller (controlador), System (sistema) y Treatments (tratamientos). En la tabla 13.6 aparece un resumen de los datos recabados sobre el estr\u00e9s. En ella se presentan los totales de las columnas (tratamientos) y los totales de las fi las (bloques), as\u00ed como</p> <p>Tabla 13.5  Dise\u00f1o de bloques aleatorizado para la prueba de estr\u00e9s en los controladores de tr\u00e1fico a\u00e9reo</p> Treatments System A System B System C Controller 1 15 15 18 Controller 2 14 14 14 Controller 3 10 11 15 Blocks Controller 4 13 12 17 Controller 5 16 13 16 Controller 6 13 13 13 <p>TABLA 13.6 Resumen de los datos recolectados para la prueba de estr\u00e9s en los controladores de tr\u00e1fico a\u00e9reo. de tr\u00e1fico a\u00e9reo</p> Tratamientos System A System B System C Totales de fila o de bloque Medias por bloque Controlador 1 15 15 18 48 $$ \\bar{x}_1 = 48/3 = 16.0 $$ Controlador 2 14 14 14 42 $$ \\bar{x}_2 = 42/3 = 14.0 $$ Controlador 3 10 11 15 36 $$ \\bar{x}_3 = 36/3 = 12.0 $$ Bloques Controlador 4 13 12 17 42 $$ \\bar{x}_4 = 42/3 = 14.0 $$ Controlador 5 16 13 16 45 $$ \\bar{x}_5 = 45/3 = 15.0 $$ Controlador 6 13 13 13 39 $$ \\bar{x}_6 = 39/3 = 13.0 $$ Totales de columna o de tratamiento 81 78 93 252 $$ \\bar{\\bar{x}} = \\frac{252}{18} = 14.0$$ Medias por tratamiento $$ \\bar{x}_1 = \\frac{81}{6} = 13.5 $$ $$ \\bar{x}_2 = \\frac{78}{6} = 13.0 $$ $$ \\bar{x}_3 = \\frac{93}{6} = 15.5 $$ <p>algunas medias muestrales necesarias que ser\u00e1n \u00fatiles para efectuar los c\u00e1lculos de la suma de cuadrados del ANOVA. Dado que los valores bajos de estr\u00e9s se consideran mejores, los datos muestrales parecen favorecer el sistema B, en el que la media de las mediciones del estr\u00e9s es 13. Sin embargo, la pregunta persiste: \u00bflos resultados muestrales justifi can la conclusi\u00f3n de que las medias poblacionales de los niveles de estr\u00e9s con estos tres sistemas difi eren? Es decir, \u00bflas diferencias son estad\u00edsticamente signifi cativas? Para responder esta pregunta se emplea un an\u00e1lisis del c\u00e1lculo de la varianza, similar al empleado en el dise\u00f1o completamente aleatorizado.</p> <p>Procedimiento ANOVA</p> <p>El procedimiento ANOVA para el dise\u00f1o de bloques aleatorizado requiere la partici\u00f3n de la suma total de los cuadrados (STC) en tres grupos: la suma de los cuadrados debido a los tratamientos (SCTR), la suma de los cuadrados debido a los bloques (SCBL) y la suma de los cuadrados debida al error (SCE). A continuaci\u00f3n se proporciona la f\u00f3rmula para este particionamiento.</p> <p>$$ STC = SCTR + SCBL + SCE  \\tag{13.21}  $$</p> <p>Esta suma de la partici\u00f3n de cuadrados se presenta en la tabla ANOVA para el dise\u00f1o de bloques aleatorizado como se muestra en la tabla 13.7. La notaci\u00f3n empleada es $$ k = numero de tratamientos $$ $$ b = numero de bloques $$ $$ n_t = tama\u00f1o muestral total (n_t = kb) $$</p> <p>Observe que en la tabla ANOVA tambi\u00e9n se indica la partici\u00f3n de los nT \u0004 1 grados de libertad totales de manera que k \u0004 1 grados de libertad correspondan a los tratamientos, b \u0004 1 a los bloques y (k \u0004 1)(b \u0004 1) al t\u00e9rmino del error. En la columna cuadrado medio se proporcionan las sumas de los cuadrados divididas entre los grados de libertad, y F  CMTR/CME es el cociente F que se usa para probar si hay diferencias signifi cativas entre las medias de los tratamientos. La contribuci\u00f3n m\u00e1s importante del dise\u00f1o de bloques aleatorizado radica en que, al emplear bloques, se eliminan del t\u00e9rmino CME las diferencias individuales de los controladores y se obtiene una prueba m\u00e1s s\u00f3lida para las diferencias de estr\u00e9s entre las tres alternativas de estaciones de trabajo.</p> <p>Tabla 13.7 Tabla ANOVA para el dise\u00f1o de bloques aleatorizado con k tratamientos y b bloques</p> Fuente de variacion Suma de cuadrados Grados de libertad Cuadrado medio F valor-p Tratamientos SCTR k - 1  $$ CMTR=\\frac{SCRT}{k-1} $$   $$ \\frac{CMTR}{CME} $$ Bloques SCBL b - 1                  $$                 CMBL=\\frac{SCBL}{b-1}                 $$                                   $$                 \\frac{CMTR}{CME}                 $$ Error SCE                  $$                     (k - 1)(b - 1)                 $$                                   $$                     CME=\\frac{SCE}{(k - 1)(b - 1)}                 $$ Total STC                  $$                 n_t - 1                 $$ <p>Calculos y conlusiones</p> <p>Para calcular el estad\u00edstico F requerido para probar si existe diferencia entre las medias de los tratamientos en un dise\u00f1o de bloques aleatorizado, se necesita calcular el CMTR y el CME. Para determinar estos dos cuadrados medios es preciso calcular primero la SCTR y la SCE; para esto tambi\u00e9n se calcula la SCBL y la STC. En forma m\u00e1s sencilla, estos procedimientos se realizan en cuatro pasos. Adem\u00e1s de la notaci\u00f3n k, b y $n_T$ ya definida, se usar\u00e1:</p> <p>$ x_{ij} $ = valor de la observaci\u00f3n correspondiente al tratamiento j en el bloque i</p> <p>$ \\bar{x}_j $ = media muestral del tratamiento j-\u00e9simo</p> <p>$ \\bar{x}_i $ = media muestral para el bloque i-\u00e9simo</p> <p>$ \\bar{\\bar{x}} $ = media muestral general</p> <p>Paso 1. Calcular la suma total de cuadrados (STC)</p> <p>$$ STC = \\sum_{i=1}^{b} \\sum_{j=1}^{k} (x_{ij} - \\bar{\\bar{x}})^2 \\tag{13.22}$$</p> <p>Paso 2. Estimar la suma de cuadrados debido a los tratamientos (SCTR).</p> <p>$$ STC = b\\sum_{j=1}^{k} (x_j - \\bar{\\bar{x}})^2 \\tag{13.23}$$</p> <p>Paso 3. Calcular la suma de cuadrados debido a los bloques (SCBL).</p> <p>$$ STC = k\\sum_{i=1}^{k} (x_i - \\bar{\\bar{x}})^2 \\tag{13.24}$$</p> <p>Paso 4. Determinar la suma de cuadrados debido al error (SCE).</p> <p>$$ SCE = STC \u2013 SCTR \u2013 SCBL \\tag{13.25} $$</p> <p>En el caso de los datos de la tabla 13.6 sobre los controladores del tr\u00e1fi co a\u00e9reo, con estos c\u00e1lculos se obtienen las sumas de los cuadrados siguientes.</p> <p>Paso 1. STC = (15 - 14)^2 + (15 - 14)^2 + (18 - 14)^2 + . . . + (13 - 14)^2 = 70</p> <p>Paso 2. SCTR = 6[(13.5 - 14)^2 + (13.0 - 14)^2 + (15.5 - 14)^2] = 21</p> <p>Paso 3. SCBL = 3[(16 - 14)^2 + (14 - 14)^2 + (12 _ 14)^2 + (14 - 14)^2 + (15 - 14)^2 + (13 - 14)^2] = 30</p> <p>Paso 4. SCE = 70 - 21 - 30 = 19</p> <p>Tabla 13.8  Tabla ANOVA para la prueba de estr\u00e9s de los controladores de tr\u00e1fico a\u00e9reo</p> Fuente de variacion Suma de cuadrados Grados de libertad Cuadrado medio F valor-p Tratamientos 21 2 10.5  10.5/1.9 = 5.53 0.024 Bloques 30 5 6.0 Total 70 17 <p>Las sumas de cuadrados divididas entre sus grados de libertad proporcionan los correspondientes cuadrados medios que se presentan en la tabla 13.8. Ahora, para realizar la prueba de hip\u00f3tesis se usar\u00e1 \u03b1  0.05 como nivel de signifi cancia. El valor del estad\u00edstico de prueba es</p> <p>$$ F = \\frac{CMTR}{CME} = \\frac{10.5}{1.9} = 5.53 $$</p> <p>Los grados de libertad en el numerador son $k - 1 = 3 - 1 = 2$, y en el denominador son $(k - 1)(b - 1) = (3 - 1)(6 - 1) = 10$. Como la prueba de hip\u00f3tesis nula es rechazada s\u00f3lo cuando los valores del estad\u00edstico de prueba son grandes, el valor-p es el \u00e1rea bajo la distribuci\u00f3n F a la derecha de $F= 5.53$. En la tabla 4 del ap\u00e9ndice B se puede ver que para 2 y 10 grados de libertad, $F = 5.53$ se encuentra entre $F_{0.025} = 5.46$ y $F_{0.01}=7.56$. Por tanto, el \u00e1rea en la cola superior, o valor-p, se ubica entre $0.01$ y $0.025$. Se puede usar tambi\u00e9n Excel o Minitab y encontrar que el valor-p exacto para $F = 5.53$ es $0.024$. Como el valor-p $\\le \\alpha =0.05$, se rechaza la hip\u00f3tesis nula $H_0: \\mu_1$ , $\\mu_2$, $\\mu_3$, y se concluye que las medias poblacionales de los niveles de estr\u00e9s en las tres alternativas de estaci\u00f3n de trabajo no son iguales. Acerca de este dise\u00f1o de bloques aleatorizado se pueden exponer algunos comentarios generales. El dise\u00f1o de experimentos descrito en esta secci\u00f3n es un dise\u00f1o de bloques completo; la palabra \u201ccompleto\u201d indica que cada bloque se somete a todos los k tratamientos. Es decir, todos los controladores (bloques) fueron probados con los tres sistemas (tratamientos). A los dise\u00f1os de experimentos en los que a cada bloque se le aplican algunos, pero no todos los tratamientos, se les llama dise\u00f1os de bloques incompleto. Su estudio queda fuera del alcance de este libro. Como en la prueba sobre el estr\u00e9s de los controladores de tr\u00e1fi co a\u00e9reo cada sujeto us\u00f3 todos los sistemas, este m\u00e9todo garantiza un dise\u00f1o de bloques completo. En algunos casos la formaci\u00f3n de los bloques se realiza con unidades experimentales \u201csimilares\u201d en cada bloque. Por ejemplo, suponga que en una prueba preliminar realizada a los controladores se divide la poblaci\u00f3n en grupos que van desde personas con mucho estr\u00e9s hasta individuos con estr\u00e9s sumamente bajo. Aqu\u00ed tambi\u00e9n se puede tener la formaci\u00f3n de bloques haciendo que en el estudio participen tres controladores de cada nivel de estr\u00e9s. En este caso, cada bloque consistir\u00e1 en tres sujetos de un mismo nivel de estr\u00e9s. El aspecto aleatorizado del dise\u00f1o de bloques ser\u00e1 la designaci\u00f3n aleatoria de los tres controladores de cada bloque a los tres sistemas. Por \u00faltimo, observe que en la tabla ANOVA que se presenta en la tabla 13.7, se proporciona un valor F para probar los efectos de los tratamientos pero no de los bloques. La raz\u00f3n estriba en que el experimento se dise\u00f1\u00f3 para probar un solo factor: el dise\u00f1o de la estaci\u00f3n de trabajo. La formaci\u00f3n de bloques basada en las diferencias del estr\u00e9s individuales se realiz\u00f3 para eliminar tal variaci\u00f3n del t\u00e9rmino CME. El estudio no se dise\u00f1\u00f3 para detectar las diferencias individuales de estr\u00e9s. Algunos analistas calculan $F=CMBL/CME$ y usan este estad\u00edstico para probar la signifi - cancia de los bloques. Despu\u00e9s utilizan los resultados como gu\u00eda para determinar si el mismo tipo de bloques puede ser \u00fatil en experimentos futuros. Sin embargo, si la diferencia en el estr\u00e9s de las personas ha de ser un factor en el estudio, deber\u00e1 emplearse un dise\u00f1o de experimentos diferente. Una prueba de signifi cancia sobre los bloques no debe hacerse como base para una conclusi\u00f3n acerca de un segundo factor.</p> NOTAS Y COMENTARIOS <p>En un dise\u00f1o de bloques aleatorizado, los grados de libertad del error son menos que en un dise\u00f1o completamente aleatorizado, debido a que en los b bloques se pierden b \u0004 1 grados de libertad. Si n es peque\u00f1o, los efectos potenciales debido a los bloques pueden quedar ocultos por la p\u00e9rdida de grados de libertad del error; con n grande, los efectos se minimizan.</p> <p>Tabla 13.9  Las nueve combinaciones de tratamiento en el experimento con dos factores del GMAT</p> Factor B: licenciatura Negocios Ingenieria Artes y ciencia Factor A Repaso de tres horas 1 2 3&gt;      programa programa de un d\u00eda 4 5 6 de preparaci\u00f3n Curso de 10 semanas 7 8 9 <p>factor B, tipo de licenciatura, habr\u00e1 un total de $3 \\cdot3=9$ combinaciones. En la tabla 13.9 se resumen estas combinaciones de tratamientos o condiciones experimentales.</p> <p>Suponga que se toma una muestra de dos sujetos para cada una de las combinaciones de tratamientos de la tabla 13.9: dos estudiantes de negocios participar\u00e1n en el repaso de tres horas, dos participar\u00e1n en el programa de un d\u00eda y otros dos en el curso de 10 semanas. Adem\u00e1s, dos estudiantes de ingenier\u00eda y dos de artes y ciencias participar\u00e1n en cada uno de los tres programas. En la terminolog\u00eda del dise\u00f1o de experimentos, el tama\u00f1o muestral de dos para cada combinaci\u00f3n de tratamientos indica que se tienen dos replicaciones. Se pueden usar tambi\u00e9n m\u00e1s replicaciones y tama\u00f1os muestrales mayores, pero elegimos minimizar los c\u00e1lculos para este ejemplo.</p> <p>En este dise\u00f1o de experimentos se requiere que de cada una de las licenciaturas (negocios,ingenier\u00eda y artes y ciencias) se tomen aleatoriamente seis estudiantes que pretendan realizar este examen de admisi\u00f3n. Despu\u00e9s, dos de cada licenciatura deben ser asignados de manera aleatoria a cada uno de los programas de preparaci\u00f3n para el examen, con lo que en total participan 18 sujetos en el estudio.</p> <p>Asumamos que los estudiantes seleccionados de manera aleatoria participaron en los programas de preparaci\u00f3n y luego tomaron el GMAT. En la tabla 13.10 se presentan las califi caciones obtenidas en el programa de preparaci\u00f3n (Preparation Program), que incluy\u00f3 repaso de tres horas (Three-hour review), programa de un d\u00eda (One-day program) y curso de 10 semanas (10-week course) para las licenciaturas (College) de negocios (Business), ingenier\u00eda (Engineering) y artes y ciencias (Arts and Sciences). Los c\u00e1lculos para el an\u00e1lisis de varianza con los datos de la tabla 13.10 dar\u00e1n respuesta a las siguientes preguntas.</p> <p>\u2022 Efecto principal (factor A). \u00bfLos programas de preparaci\u00f3n tienen efectos diferentes sobre la puntuaci\u00f3n obtenida en el GMAT?</p> <p>\u2022 Efecto principal (factor B). \u00bfLas licenciaturas tienen efectos diferentes sobre la puntuaci\u00f3n obtenida en el GMAT?</p> <p>\u2022 Efecto de interacci\u00f3n (factores A y B). \u00bfEs uno de los programas de preparaci\u00f3n mejor para los estudiantes que provienen de una de las tres licenciaturas, mientras que para los de otras licenciaturas es mejor otro de los programas?</p> <p>Tabla 13.10  Puntuaciones en el GMAT para el experimento de dos factores</p> Factor B: College Business Engineering Arts and Sciences Three-hour review 500 540 480&gt;      Factor A 580 460 400 Preparation One-day program 460 560 420 Program 540 620 480&gt;      10-week course 560 600 480 600 580 410 <p>Tabla 13.11  Tabla ANOVA para el experimento factorial de dos factores con $r$ replicaciones</p> Fuente de variaci\u00f3n Suma de cuadrados Grados de libertad Cuadrado medio F valor-p Factor A SCA  $a-1$  $CMA=\\frac{SCA}{-1}  $ $\\frac{CMA}{CME}$ Factor B SCB  $b-1$  $CMB=\\frac{SCB}{b-1}$ $\\frac{CMB}{CME}$ Interacci\u00f3n SCAB  $(a-1)(b-1)$  $CMAB=\\frac{SCAB}{(a-1)(b-1)}$ $\\frac{CMA}{CME}$ Error SCE  $ab(r-1)$  $CME=\\frac{SCE}{ab(r-1)} $ Total STC  $n_r-1$  <p>sobre las puntuaciones del GMAT, se podr\u00e1 concluir que el efecto del tipo de programa de preparaci\u00f3n depende de la licenciatura</p> <p>$valor-p$ de 0.350 correspondiente al efecto de la interacci\u00f3n es mayor que $\u03b1 = 0.05$, no hay un efecto signifi cativo de interacci\u00f3n. Por tanto, en este estudio no se encuentran razones para pensar que los tres programas de preparaci\u00f3n difi eren en su capacidad para capacitar a estudiantes de las distintas licenciaturas para el GMAT. Se encontr\u00f3 que la licenciatura s\u00ed es un factor significativo. Al revisar los c\u00e1lculos de la tabla 13.12, vemos que las medias muestrales son: estudiantes de negocios $x_1 = 540$, estudiantes de ingenier\u00eda $x_2 = 560$ y estudiantes de artes y ciencias $x_3 = 445$. Se pueden reali\u0002zar pruebas para los distintos tratamientos; sin embargo, despu\u00e9s de observar las tres medias muestrales es posible anticipar que no hay diferencia entre los alumnos con las licenciaturas de ingenier\u00eda y negocios. Pero los de artes y ciencias parecen estar menos preparados para este examen que los de las otras dos licenciaturas. Quiz\u00e1s esta observaci\u00f3n haga que la universidad busque otras opciones para ayudar a este grupo a prepararse para el GMAT.</p>"},{"location":"capitulo13/#131-introduccion-al-diseno-de-experimentos-y-al-analisis-de-varianza","title":"13.1 INTRODUCCION AL DISE\u00d1O DE EXPERIMENTOS Y AL AN\u00c1LISIS DE VARIANZA\u00b6","text":""},{"location":"capitulo13/#recoleccion-de-datos","title":"Recolecci\u00f3n de datos\u00b6","text":""},{"location":"capitulo13/#supuestos-para-el-analisis-de-varianza","title":"Supuestos para el an\u00e1lisis de varianza\u00b6","text":"<p>Los supuestos requeridos para usar el an\u00e1lisis de varianza son tres.</p> <ol> <li>En cada poblaci\u00f3n, la variable de respuesta est\u00e1 normalmente distribuida. Implicaci\u00f3n. En el experimento de Chemitech, el n\u00famero de unidades producidas por semana (variable de respuesta) debe estar normalmente distribuido para cada m\u00e9todo de ensamble.</li> <li>La varianza de la variable de respuesta, denotada como  $\\sigma^2$ , es la misma en todas las poblaciones. Implicaci\u00f3n. En el experimento de Chemitech, la varianza en el n\u00famero de unidades producido por semana debe ser el mismo para cada m\u00e9todo de ensamble.</li> <li>Las observaciones deben ser independientes. Implicaci\u00f3n. En el experimento de Chemitech la cantidad de unidades producida por semana por un empleado debe ser independiente del n\u00famero de unidades producidas por semana por cualquier otro empleado.</li> </ol>"},{"location":"capitulo13/#analisis-de-varianza-una-perspectiva-conceptual","title":"An\u00e1lisis de varianza: una perspectiva conceptual\u00b6","text":"<p>Si las medias de las tres poblaciones son iguales, se esperar\u00eda que las tres medias muestrales fueran muy parecidas. De hecho, entre m\u00e1s parecidas sean \u00e9stas, mayor ser\u00e1 la evidencia para concluir que las medias poblacionales son iguales. De otra forma, entre mayor sea la diferencia entre las medias muestrales, mayor ser\u00e1 la evidencia para concluir que las medias poblacionales no son iguales. Esto es, si la variabilidad entre las medias muestrales es \u201cpeque\u00f1a\u201d, esto favorece $H_0$; si la variabilidad entre las medias muestrales es \u201cgrande\u201d, esto favorece $H_a$.</p> <p>Si la hip\u00f3tesis nula, $H_0$: $\u03bc1 = \u03bc2 = \u03bc3$, es verdadera, se usa la variabilidad entre las medias muestrales para estimar $\\sigma^2$. Primero, observe que si se satisfacen los supuestos para el</p> <p> Figura 13.2 Distribuci\u00f3n muestral de $x$ si $H_0$ es verdadera </p>"},{"location":"capitulo13/#notas-y-comentarios","title":"NOTAS Y COMENTARIOS\u00b6","text":"<ol> <li>En el dise\u00f1o de experimentos, la aleatorizaci\u00f3n es an\u00e1loga al muestreo probabil\u00edstico en un estudio observacional.</li> <li>En muchos estudios m\u00e9dicos los sesgos potenciales se eliminan con el uso de un dise\u00f1o de experimento doble ciego en el cual ni el m\u00e9dico que aplica el tratamiento ni el paciente saben qu\u00e9 tratamiento se est\u00e1 administrando. Este tipo de dise\u00f1o tambi\u00e9n es \u00fatil en muchos otros tipos de experimentos.</li> <li>En esta secci\u00f3n se present\u00f3 una perspectiva conceptual de c\u00f3mo puede utilizarse el an\u00e1lisis de varianza para probar la igualdad de k medias poblacionales en un dise\u00f1o experimental completamente aleatorizado. Veremos que este mismo procedimiento tambi\u00e9n se usa para probar la igualdad de k medias poblacionales en un estudio observacional o no experimental.</li> <li>En las secciones 10.1 y 10.2 se presentaron m\u00e9todos estad\u00edsticos para probar las hip\u00f3tesis de que las medias de dos poblaciones son iguales. El ANOVA tambi\u00e9n puede utilizarse para probar estas mismas hip\u00f3tesis. Sin embargo, en la pr\u00e1ctica el an\u00e1lisis de varianza no es usualmente utilizado, excepto cuando se tienen tres o m\u00e1s medias poblacionales.</li> </ol>"},{"location":"capitulo13/#lsd-de-fisher","title":"<p> LSD de Fisher</p>\u00b6","text":"<p>Suponga que en un an\u00e1lisis de varianza se encuentran evidencias estad\u00edsticas para rechazar la hip\u00f3tesis nula que plantea la igualdad de las medias poblacionales. En tal caso, para determinar d\u00f3nde est\u00e1n las diferencias se puede emplear el procedimiento de la diferencia m\u00ednima signifi cativa (LSD, por sus siglas en ingl\u00e9s) de Fisher. Con el fin de ilustrar el uso del procedimiento de la LSD de Fisher para comparar pares de medias poblacionales, rem\u00edtase al experimento de Chemitech presentado en la secci\u00f3n 13.1. A partir del an\u00e1lisis de varianza se concluy\u00f3 que el n\u00famero medio de unidades producidas por semana no era el mismo con los tres m\u00e9todos de ensamble. En tal caso la siguiente pregunta es: se cree que hay diferencia entre los m\u00e9todos pero, \u00bfd\u00f3nde ocurren las diferencias? Es decir, las medias que difi eren, \u00bfson las de las poblaciones 1 y 2? \u00bfO las de las poblaciones 1 y 3? \u00bfO las de las poblaciones 2 y 3? </p> <p>En el cap\u00edtulo 10 se present\u00f3 un procedimiento estad\u00edstico para probar la hip\u00f3tesis de la igualdad de dos medias poblacionales. Con una ligera modifi caci\u00f3n en la manera de evaluar la varianza poblacional, el procedimiento de la LSD de Fisher se basa en el estad\u00edstico de prueba *t* presentado para el caso de dos poblaciones. En la tabla siguiente se resume el procedimiento de la LSD de Fisher.</p> <p>PROCEDIMIENTO DE LA LSD DE FISHER $$H_0: \\mu_i=\\mu_j$$ $$H_a:  \\mu_i \\neq \\mu_j$$ ESTAD\u00cdSTICO DE PRUEBA</p> <p>$$\\overbrace{t}^{\\text{Distribuci\u00f3n }  t} = \\frac{\\overbrace{\\bar{x}_i + \\bar{x}_j}^{\\text{Diferencias de medias poblacionales}}}{\\sqrt{CME\\left(\\frac{1}{n_i} + \\frac{1}{n_j}\\right)}}$$</p> (13.16) <p>REGLA DE RECHAZO Metodo del valor-p: Rechazar $H_0$ si el valor-p $\\le \\alpha$ Metodo del valor critico: Rechazar $H_0$ si $t \\le -t_{\\alpha/2}$ o $t \\ge t_{\\alpha/2}$ donde el valor de $t_{\\alpha/2}$ se basa en la distribuci\u00f3n t con $n_T -k $ grados de libertad </p> <p>A continuaci\u00f3n, se usar\u00e1 este procedimiento para determinar si existe alguna diferencia significativa entre la media de la poblaci\u00f3n 1 (m\u00e9todo A) y la media de la poblaci\u00f3n 2 (m\u00e9todo B) con \u03b1 = 0.05 como nivel de significancia. Seg\u00fan la tabla 13.1, las medias obtenidas con el m\u00e9todo A son 62 y con el m\u00e9todo B son 66. En la tabla 13.3 se observa que el valor del CME es 28.33; esta es la estimaci\u00f3n de $\u03c3^2$ con 12 grados de libertad. Con los datos de Chemitech, el valor que se obtiene para el estad\u00edstico de prueba es $$     t=\\frac{62-66}{\\sqrt{28.33(\\frac{1}{5}+\\frac{1}{5})}}=-1.19 $$ Como se trata de una prueba de dos colas, el valor-p es el doble del \u00e1rea bajo la curva de la distribuci\u00f3n t a la izquierda de $t= -1.19$.</p> \u00c1rea de cola superior 0.20 0.10 0.05 0.025 0.01 0.005 Valor de t (12 gl) 0.873 1.356 1.782 2179 2.681 3055 <p>La tabla de la distribuci\u00f3n t s\u00f3lo contiene valores positivos de t. Sin embargo, como la distribuci\u00f3n t es sim\u00e9trica, podemos determinar el \u00e1rea bajo la curva a la derecha de $t= 1.19$ y duplicarla para determinar el valor-p que corresponde a $t=-1.19$. En esta tabla vemos que $t=1.19$ se encuentra entre 0.20 y 0.10. Al duplicar estas cantidades, tenemos que el valor-p debe estar entre 0.40 y 0.20. Se puede usar Excel o Minitab para ver que el valor-p exacto es 0.2571. Como este valor es mayor que \u03b1 = 0.05, la hip\u00f3tesis nula no puede ser rechazada. Por tanto, no podemos concluir que la media poblacional del n\u00famero de unidades producidas por semana con el m\u00e9todo A sea diferente que la media poblacional del m\u00e9todo B. Muchas personas encuentran m\u00e1s f\u00e1cil determinar qu\u00e9 tan grande tiene que ser la diferencia entre las medias muestrales para que H0 sea rechazada. En este caso el estad\u00edstico de prueba es $\\bar{x_i}+\\bar{x_j}$, y la prueba se realiza siguiendo el procedimiento que se presenta a continuaci\u00f3n.</p> <p>PROCEDIMIENTO DE LA LSD FISHER BASADO EN EL ESTADISTICO DE PRUEBA EN EL ESTADISTICO DE PRUEBA $\\bar{x}_i-\\bar{x}_j$</p> <p>$$H_0 :\\mu_i = \\mu_j$$ $$H_a :\\mu_i\\neq\\mu_j$$ <p>ESTADISTICO DE PRUEBA</p> <p>$\\bar{x}_i-\\bar{x}_j$</p> <p>REGLA DE RECHAZO PARA EL NIVEL DE SIGNIFICANCIA $\\alpha$</p> <p>Rechazar $H_0$ si $\\left| \\bar{x}_i-\\bar{x}_j \\right| \\ge $ LSD</p> <p>donde</p> <p>LSD = $t_{\\alpha/2}\\sqrt{CME(\\frac{1}{n_i}+\\frac{1}{n_j})}$</p> <p>(13.17)</p></p>  En el experimento de Chemitech, el valor de la LSD es $$     LSD=2.179\\sqrt{28.73(\\frac{1}{5}+\\frac{1}{5})}=7.34 $$ Observe que si todos los tama\u00f1os muestrales son iguales, s\u00f3lo se necesita calcular un valor de la LSD. En tales casos, basta comparar la magnitud de la diferencia entre dos medias muestrales con el valor de la LSD. Por ejemplo, la diferencia entre las medias muestrales de la poblaci\u00f3n 1 (m\u00e9todo A) y de la poblaci\u00f3n 3 (m\u00e9todo C) es 62 - 52 = 10. Esta diferencia es mayor que la LSD = 7.34, lo que signifi ca que se puede rechazar la hip\u00f3tesis nula de que la media poblacional del n\u00famero de unidades producidas por semana con el m\u00e9todo A sea igual que la media poblacional del m\u00e9todo C. De manera similar, entre las medias muestrales de las poblaciones  2 y 3 la diferencia es $66 - 52 = 14 \\ge 7.34$, y se puede rechazar la hip\u00f3tesis de que la media poblacional obtenida con el m\u00e9todo B sea igual a la media poblacional del m\u00e9todo C. As\u00ed, la conclusi\u00f3n es que tanto el m\u00e9todo A como el B difi eren del m\u00e9todo C.  <p>La LSD de Fisher tambi\u00e9n se usa para obtener una estimaci\u00f3n mediante un intervalo de confianza de la diferencia entre las medias de dos poblaciones. El procedimiento general que se emplea es el siguiente.</p> <p>ESTIMACION POR INETRVALO DE CONFIANZA DE LA DIFERENCIA ENTRE DOS MEDIAS POBLACIONALES USANDO EL PROCEDIMIENTO DE LA LSD DE FISHER</p> <p>$\\bar{x}_i-\\bar{x}_j\\pm\\text{LSD}$</p> <p>(13.18)</p> <p>donde</p> <p>$\\text{LSD}=t_{\\alpha/2}\\sqrt{\\text{CME}(\\frac{1}{n_i}+\\frac{1}{n_j})}$</p> <p>(13.19)</p> <p>y $t_{\\alpha/2}$ pertenece a la distribucion t con $n_t-k$ grados de libertad</p> <p>Si el intervalo de confi anza hallado con la expresi\u00f3n (13.18) incluye el valor cero, no se puede rechazar la hip\u00f3tesis nula de que las dos medias poblacionales sean iguales. Pero si dicho intervalo no incluye al valor cero, podemos concluir que s\u00ed hay diferencia entre las medias poblacionales. En el caso del experimento de Chemitech, recuerde que la LSD = 7.34 (que corresponde a $t_{0.025} = 2.179$). Por tanto, una estimaci\u00f3n de la diferencia entre las medias poblacionales 1 y 2 empleando un intervalo de 95% de confi anza es $62 - 66 \\pm 7.34 = -4 \\pm 7.34 =$ $-11.34$ a $3.34$; como este intervalo incluye el cero, no se puede rechazar la hip\u00f3tesis de que las dos medias sean iguales.</p> Tasas de error tipo I <p>El estudio del procedimiento de la LSD de Fisher se inici\u00f3 con la premisa de que el an\u00e1lisis de varianza proporcionaba evidencias estad\u00edsticas para rechazar la hip\u00f3tesis nula de la igualdad entre medias poblacionales. Se mostr\u00f3 que en tales casos se puede emplear el procedimiento de la LSD de Fisher para determinar d\u00f3nde est\u00e1n las diferencias. T\u00e9cnicamente, a este procedimiento se le conoce como prueba restringida o protegida de la LSD debido a que s\u00f3lo se usa si primero se ha encontrado un valor F signifi cativo al aplicar el an\u00e1lisis de varianza. Para ver por qu\u00e9 es importante esta distinci\u00f3n en las pruebas de comparaci\u00f3n m\u00faltiple es necesario explicar la diferencia entre tasa de error tipo I por comparaci\u00f3n y tasa de error tipo I por experimentaci\u00f3n.</p> <p>En el experimento de Chemitech se usa el procedimiento de la LSD de Fisher para efectuar tres pares de comparaciones.</p> <p>Prueba 1</p> <p>$$H_0: \\mu_1 = \\mu_2 $$ $$H_a: \\mu_1 \\neq \\mu_2 $$</p> <p>Prueba 2</p> <p>$$H_0: \\mu_1 = \\mu_3 $$ $$H_a: \\mu_1 \\neq \\mu_3 $$</p> <p>Prueba 3</p> <p>$$H_0: \\mu_2 = \\mu_3 $$ $$H_a: \\mu_2 \\neq \\mu_3 $$</p> <p>En cada caso, el nivel de signifi cancia empleado es \u03b1 = 0.05. Por tanto, en cada prueba, si la hip\u00f3tesis nula es verdadera, la probabilidad de que se cometa un error tipo I es \u03b1 = 0.05; entonces, la probabilidad de no cometer un error tipo I es 1 - 0.05 = 0.95. En el estudio de los procedimientos de comparaci\u00f3n m\u00faltiple, a esta probabilidad de cometer un error tipo I (\u03b1 = 0.05) se le conoce como tasa de error tipo I por comparaci\u00f3n, la cual indica el nivel de signifi cancia que corresponde a una sola comparaci\u00f3n por pares.</p> <p>Considere ahora una cuesti\u00f3n ligeramente diferente. \u00bfCu\u00e1l es la probabilidad de que al hacer tres comparaciones por pares se cometa un error tipo I en por lo menos una de las tres pruebas? Para responder esta pregunta, observe que la probabilidad de que no se cometa un error tipo I en ninguna de las tres pruebas es (0.95) (0.95) (0.95) = 0.8574. Por tanto, la probabilidad de cometer por lo menos un error tipo I es 1 - 0.8574 = 0.1426. Entonces, cuando se usa el procedimiento de la LSD de Fisher para hacer los tres pares de comparaciones, la tasa de error tipo I correspondiente a este m\u00e9todo no es 0.05, sino 0.1426, y se le conoce como tasa de error tipo I por comparaci\u00f3n por experimentaci\u00f3n o general. Para evitar confusiones, la tasa de error tipo I por experimentaci\u00f3n se denota $\u03b1_{EW}$.</p> <p>La tasa de error tipo I por experimentaci\u00f3n es mayor en estudios con m\u00e1s poblaciones. Por ejemplo, en un problema con cinco poblaciones hay 10 pares de comparaciones. Si se prueban todas las comparaciones posibles por pares usando el procedimiento de la LSD de Fisher con una tasa de error por comparaci\u00f3n de \u03b1 = 0.05, la tasa de error tipo I por experimentaci\u00f3n ser\u00e1 $1 - (1 - 0.05)^{10} = 0.40$. En tales casos se prefi ere buscar otras alternativas que proporcionen un mejor control sobre la tasa de error por experimentaci\u00f3n.</p> <p>Una alternativa para controlar la tasa de error general por experimentaci\u00f3n, conocida como ajuste de Bonferroni, consiste en usar en cada prueba tasas de error por comparaci\u00f3n m\u00e1s peque\u00f1as. Por ejemplo, si se quieren probar C comparaciones por pares y se desea que la probabilidad m\u00e1xima de cometer un error tipo I en todo el experimento sea \u03b1EW, simplemente se usa una tasa de error por comparaci\u00f3n igual a \u03b1EW/C. En el experimento de Chemitech, si se desea emplear el procedimiento de la LSD de Fisher para probar los tres pares de comparaciones con una tasa de error m\u00e1ximo por experimentaci\u00f3n de $\u03b1_{EW} = 0.05$, se establece como tasa de error por comparaci\u00f3n $\u03b1 = 0.05/3 = 0.017$. En un problema con cinco poblaciones y 10 comparaciones por pares, el ajuste de Bonferroni sugerir\u00eda una tasa de error por comparaci\u00f3n de $0.05/10 = 0.005$. Recuerde que cuando se estudiaron las pruebas de hip\u00f3tesis en el cap\u00edtulo 9 se vio que para un tama\u00f1o de muestra dado, toda disminuci\u00f3n en la probabilidad de cometer un error tipo I aumenta la probabilidad de cometer un error tipo II, el cual corresponde a aceptar la hip\u00f3tesis de que las dos medias poblacionales son iguales cuando en realidad no lo son. Por tanto, suele haber renuencia a realizar pruebas individuales con una baja tasa de error tipo I por comparaci\u00f3n debido a que aumenta el riesgo de cometer un error tipo II.</p> <p>Como soluci\u00f3n para tales situaciones se han elaborado otras alternativas, como el procedimiento de Turkey y la prueba de rango m\u00faltiple de Duncan. Sin embargo, en la comunidad estad\u00edstica existe una gran controversia respecto de cu\u00e1l es el \u201cmejor\u201d procedimiento. La verdad es que no hay uno que sea el mejor para todo tipo de problemas.</p>"},{"location":"capitulo13/#135-experimento-factorial","title":"13.5 Experimento factorial\u00b6","text":"<p>Los dise\u00f1os de experimentos estudiados hasta ahora permiten formular conclusiones estad\u00edsticas acerca de un solo factor. Sin embargo, en algunos experimentos tal vez se quieran formular conclusiones acerca de m\u00e1s de una variable o factor. Un experimento factorial es un dise\u00f1o que permite obtener conclusiones simult\u00e1neas acerca de dos o m\u00e1s factores. El t\u00e9rmino factorial se utiliza porque las condiciones experimentales incluyen todas las posibles combinaciones de los factores. Por ejemplo, para a niveles de un factor A y b niveles de un factor B, el experimento incluir\u00e1 una colecci\u00f3n de datos en el tratamiento de las combinaciones ab. En esta secci\u00f3n mostraremos el an\u00e1lisis para un experimento factorial de dos factores. El enfoque b\u00e1sico puede ampliarse a m\u00e1s de dos factores. Como ilustraci\u00f3n de un experimento factorial de dos factores, veremos un estudio acerca del Examen de admisi\u00f3n de graduados en administraci\u00f3n (GMAT, por sus siglas en ingl\u00e9s), una prueba estandarizada que utilizan las escuelas de negocios para evaluar una habilidad de los aspirantes a cubrir un programa de grado en ese campo. Las puntuaciones del GMAT est\u00e1n en el rango de 200 a 800; las de nivel m\u00e1s elevado signifi can una aptitud m\u00e1s alta. Con la intenci\u00f3n de mejorar el desempe\u00f1o de los estudiantes en el GMAT, una de las principales universidades de Texas considera ofrecer los siguientes tres programas de preparaci\u00f3n para ese examen.</p> <ol> <li>Una sesi\u00f3n de repaso de tres horas, en la que se revisa el tipo de preguntas que suele encontrarse en el GMAT.</li> <li>Un programa de un d\u00eda en el que se ve el material m\u00e1s relevante del examen, junto con un examen muestra que se califi ca.</li> <li>Un curso intensivo de 10 semanas en el que se identifi can las debilidades de cada estudiante y se establecen programas individualizados de mejora.</li> </ol> <p>Por tanto, un factor en este estudio es el programa de preparaci\u00f3n, el cual tiene tres tratamientos: un repaso de tres horas, un programa de un d\u00eda y un curso de 10 semanas. Antes de seleccionar la opci\u00f3n a adoptar, m\u00e1s estudios llevar\u00e1n a determinar el efecto de cada uno de los programas sobre las puntuaciones obtenidas en este examen de admisi\u00f3n.</p> <p>Por lo general, los aplicantes del GMAT son estudiantes de tres licenciaturas: negocios, ingenier\u00eda y artes y ciencias. En consecuencia, el segundo factor de inter\u00e9s en el experimento es si la licenciatura infl uye en la califi caci\u00f3n del GMAT. Para este segundo factor hay tambi\u00e9n tres tratamientos: negocios, ingenier\u00eda y artes y ciencias. El dise\u00f1o factorial de este experimento con tres tratamientos para el factor A, programa de preparaci\u00f3n, y tres tratamientos para el</p>"},{"location":"capitulo13/#procedimiento-anova","title":"Procedimiento ANOVA\u00b6","text":"<p>El procedimiento ANOVA para el experimento factorial de dos factores requiere la partici\u00f3n de la suma total de cuadrados (STC) en cuatro grupos: suma de cuadrados del factor A (SCA), suma de cuadrados del factor B (SCB), suma de cuadrados de la interacci\u00f3n (SCAB) y suma de cuadrados debido al error (SCE). La f\u00f3rmula para esta partici\u00f3n se da a continuaci\u00f3n. \\begin{equation}    STC = SCA + SCB + SCAB + SCE \\end{equation}</p> <p>En la tabla 13.11 se resumen las particiones de las sumas de cuadrados y de los grados de libertad. Se emplea la notaci\u00f3n siguiente:</p> <p>$a$  n\u00famero de niveles del factor A</p> <p>$b$  n\u00famero de niveles del factor B</p> <p>$r$  n\u00famero de replicaciones</p> <p>$n_T$  n\u00famero total de observaciones realizadas en el experimento;$n_T=abr$</p>"},{"location":"capitulo13/#calculos-y-conclusiones","title":"C\u00e1lculos y conclusiones\u00b6","text":"<p>Para determinar los estad\u00edsticos F que se requieren en las pruebas de signifi cancia del factor A, del factor B y de la interacci\u00f3n, es necesario calcular CMA, CMB, CMAB y CME. Para obtener estos cuatro cuadrados medios se debe calcular primero SCA, SCB, SCAB y SCE; con esto se calcula tambi\u00e9n STC. Para simplificar la presentaci\u00f3n, los procedimientos se dividen en cinco pasos. Adem\u00e1s de $a, b, r$ y $n_T$ definidos previamente, se emplea la siguiente notaci\u00f3n.</p> <p>$x_{ijk} =$ observaci\u00f3n correspondiente a la k-\u00e9sima r\u00e9plica tomada del tratamiento i del factor A y del tratamiento j del factor B</p> <p>$\\bar{x}_i.$ media muestral de las observaciones en el tratamiento i (factor A)</p> <p>$\\bar{x}_{.j}=$ media muestral de las observaciones en el tratamiento j (factor B)</p> <p>$\\bar{x}_{ij} =$ media muestral de las observaciones correspondientes a la combinaci\u00f3n del tratamiento i (factor A) y el tratamiento j (factor B)</p> <p>$\\overline{\\overline{x}}=$ media muestral general de todas las $n_T$ observaciones</p> <p>Paso 1. Calcular la suma total de cuadrados (STC) \\begin{equation}     STC = \\sum_{i=1}^{a}\\sum_{j=1}^{b} \\sum_{k=1}^{r}  (x_{ijk}-\\overline{\\overline{x}})^2 \\end{equation}</p> <p>Paso 2. Estimar la suma de cuadrados debido a los tratamientos (SCTR).</p> <p>$SCA = br \\sum_{i=1}^{a} (\\bar{x}_i. - \\overline{\\overline{x}})^2$</p> <p>Paso 3. Calcular la suma de cuadrados debido a los bloques (SCBL).</p> <p>$SCA = ar \\sum_{i=1}^{a} \\sum_{j=1}^{b} (\\bar{x}_{.j} - \\overline{\\overline{x}})^2$</p> <p>Paso 4. Determinar la suma de cuadrados debido al error (SCE)</p> <p>$SCAB = r \\sum_{i=1}^{a} \\sum_{j=1}^{b} (\\bar{x}_{ij} -\\bar{x}_{i.}-\\bar{x}_{.j}- \\overline{\\overline{x}})^2$</p> <p>Paso 5. Calcular la suma de cuadrados debido al error.</p> <p>$SCE = STC - SCA - SCB - SCAB$</p> <p>Paso 1. $STC = (500-515)^2 + (580-515)^2 + (540-515)^2 + \\ldots + (410-515)^2 = 82450$</p> <p>Paso 2. $SCA = (3)(2)[(493.33 - 515)^2+  (513.33-515)^2+(538.33-515)^2] = 6100$</p> <p>Paso 3. $SCB = (3)(2)[(540 - 515)^2 +(560-515)^2 + (445 - 515)^2 ] = 45 300$</p> <p>Paso 4. $SCAB = 2[(540 - 493.33 - 540 + 515)^2 + (500 - 493.33 - 560 + 515)^2\\ldots(445 - 538.33 - 445 + 515)^2 ] = 11200$</p> <p>Paso 5. $SCE = 82450 - 6100- 45300 - 11200 = 19850$</p> <p>Estas sumas divididas entre sus correspondientes grados de libertad proporcionan los valores de los cuadrados medios apropiados para estimar los dos efectos principales (programas de preparaci\u00f3n y licenciatura) y el efecto de su interacci\u00f3n. Debido a la gran cantidad de c\u00e1lculos involucrada en cualquier experimento factorial desde uno modesto hasta uno de gran dimensi\u00f3n, usualmente la computadora juega un papel importante en la realizaci\u00f3n de los c\u00e1lculos necesarios en el an\u00e1lisis de varianza mostrado antes y en la obtenci\u00f3n de los valores-p que se emplean para tomar las decisiones en la prueba de hi\u0002p\u00f3tesis. En la fi gura 13.6 se presenta la pantalla de resultados de Minitab para el an\u00e1lisis de  varianza del experimento factorial de dos factores del GMAT. Para realizar la prueba de hip\u00f3te\u0002sis de dos factores en este estudio usaremos el resultado de Minitab y un nivel de significancia $\u03b1 = 0.05$. El valor-p utilizado para probar si hay diferencias significativas entre los tres progra\u0002mas de preparaci\u00f3n (factor A) es 0.299. Como este valor-p = 0.299 es mayor que $\u03b1 = 0.05$, no existe diferencia signifi cativa entre las medias de las puntuaciones obtenidas en el GMAT para  los tres programas de preparaci\u00f3n. Sin embargo, en relaci\u00f3n con el efecto de la licenciatura, el  valor-p = 0.005 es menor que $\u03b1 = 0.05$; por tanto, s\u00ed hay una diferencia signifi cativa en las  medias de las puntuaciones en el GMAT entre las tres licenciaturas. Por ultimo, debido a que el</p>  tres    Tabla 13.12 Resumen de los datos del examen para el experimento de dos factores Totales de combinacion de tratamiento <p>Factor B: Licenciatura</p> <p>Negocios</p> <p>Ingenier\u00eda</p> <p>Artes y Ciencias</p> Totales de Fila Medidas del Factor A Factor A: programa de preparacion Repaso de tres horas <p>500</p> <p>580</p> <p>1080</p> <p>$$\\bar{x}_{11}=\\frac{1080}{2}=500$$</p> <p>540</p> <p>460</p> <p>1000</p> <p>$$\\bar{x}_{12}=\\frac{1000}{2}=540$$</p> <p>480</p> <p>400</p> <p>880</p> <p>$$\\bar{x}_{13}=\\frac{880}{2}=440$$</p> 2960 <p>$$\\bar{x}_{1}.=\\frac{2960}{6}=493.33$$</p> Programa de un dia <p>460</p> <p>540</p> <p>1000</p> <p>$$\\bar{x}_{21}=\\frac{1000}{2}=500$$</p> <p>560</p> <p>620</p> <p>1180</p> <p>$$\\bar{x}_{22}=\\frac{1180}{2}=590$$</p> <p>420</p> <p>480</p> <p>900</p> <p>$$\\bar{x}_{23}=\\frac{900}{2}=450$$</p> 3080 <p>$$\\bar{x}_{2}.=\\frac{2960}{6}=493.33$$</p> Curso de 10 semanas <p>560</p> <p>600</p> <p>1160</p> <p>$$\\bar{x}_{31}=\\frac{1160}{2}=580$$</p> <p>600</p> <p>580</p> <p>1180</p> <p>$$\\bar{x}_{32}=\\frac{1180}{2}=590$$</p> <p>480</p> <p>410</p> <p>890</p> <p>$$\\bar{x}_{33}=\\frac{890}{2}=445$$</p> 3230 <p>$$\\bar{x}_{3}.=\\frac{2960}{6}=493.33$$</p> Total de Columna 3240 3360 2670 <p>$$9270\\longleftarrow$$ </p> <p>Total General</p> Medidas del factor B <p>$$\\bar{x}_{1}.=\\frac{3240}{6}=540$$</p> <p>$$\\bar{x}_{2}.=\\frac{3360}{6}=560$$</p> <p>$$\\bar{x}_{3}.=\\frac{2670}{6}=445$$</p> <p>$$\\bar{\\bar{x}}=\\frac{9070}{18}=515$$</p> Tabl a 13 .16Pantalla de resultados de Minitab para el dise\u00f1o de dos factores del examen GMAT SOURCE DF SS MS F P Factor A 2 6100 3050 1.38 0.299 Factor B 2 45300 22650 10.27 0.005 Interaction 4 11200 2800 1.27 0.350 Error 9 19850 2206 Total 17 82450 a el GMA"},{"location":"capitulo14/","title":"Capitulo 14","text":"CAPITULO 14 Regresi\u00f3n lineal simple CONTENIDO <ul> <li>14.1 MODELO DE REGRESI\u00d3N LINEAL SIMPLE <ul> <li>Modelo de regresi\u00f3n y ecuaci\u00f3n de regresi\u00f3n</li> <li>Ecuaci\u00f3n de regresi\u00f3n estimada</li> </ul> </li> <li>14.2 M\u00c9TODO DE M\u00cdNIMOS CUADRADOS</li> <li>14.3 COEFICIENTE DE DETERMINACI\u00d3N <ul> <li>Coeficiente de correlaci\u00f3n</li> </ul> </li> <li>14.4 SUPUESTOS DEL MODELO</li> <li>14.5 PRUEBA DE SIGNIFICANCIA <ul> <li>Estimaci\u00f3n de \u03c32</li> <li>Prueba t</li> <li>Intervalo de confianza para \u00041</li> <li>Prueba F</li> <li>Algunas advertencias acerca de la interpretaci\u00f3n de las pruebas de significancia</li> </ul> </li> <li>14.6 USO DE LA ECUACI\u00d3N DE REGRESI\u00d3N ESTIMADA PARA ESTIMACI\u00d3N Y PREDICCI\u00d3N <ul> <li>Estimaci\u00f3n puntual</li> <li>Estimaci\u00f3n por intervalo</li> <li>Intervalo de confianza para el valor medio de y</li> <li>Intervalo de predicci\u00f3n para un solo valor de y</li> </ul> </li> <li>14.7 SOLUCI\u00d3N POR COMPUTADORA</li> <li>14.8 AN\u00c1LISIS DE RESIDUALES: CONFIRMACI\u00d3N DE LOS SUPUESTOS DEL MODELO <ul> <li>Gr\u00e1fica de residuales contra x</li> <li>Gr\u00e1fica de residuales contra y\u02c6</li> <li>Residuales estandarizados</li> <li>Gr\u00e1fica de probabilidad normal</li> </ul> </li> <li>14.9 AN\u00c1LISIS DE RESIDUALES: OBSERVACIONES AT\u00cdPICAS Y OBSERVACIONES INFLUYENTES <ul> <li>Detecci\u00f3n de observaciones at\u00edpicas</li> <li>Detecci\u00f3n de observaciones influyentes</li> </ul> </li> </ul> <p>Con frecuencia las decisiones gerenciales se basan en la relaci\u00f3n entre dos o m\u00e1s variables. Por ejemplo, al analizar la relaci\u00f3n entre el gasto en publicidad y las ventas, un gerente de marketing puede tratar de predecir las ventas correspondientes a un determinado gasto en publicidad. En otro caso, una empresa de servicios p\u00fablicos establece la relaci\u00f3n entre la temperatura diaria y la demanda de electricidad para predecir la necesidad de fl uido el\u00e9ctrico considerando las temperaturas diarias que se esperan para el mes siguiente. Algunas veces los directivos se apoyan en la intuici\u00f3n para juzgar la relaci\u00f3n entre dos variables. Sin embargo, cuando los da tos est\u00e1n disponibles, puede emplearse un procedimiento estad\u00edstico llamado an\u00e1lisis de regresi\u00f3n para obtener una ecuaci\u00f3n que indique cu\u00e1l es la relaci\u00f3n entre las variables. En la terminolog\u00eda que se emplea en la regresi\u00f3n, la variable a predecir se llama variable dependiente, y a la variable o variables que se usan para predecir su valor se les llama variables independientes. Por ejemplo, al analizar el efecto de los gastos en publicidad sobre las ventas, como lo que busca el gerente de marketing es predecir estas \u00faltimas, las ventas ser\u00e1n la variable dependiente. En este cap\u00edtulo se estudia el tipo m\u00e1s sencillo de an\u00e1lisis de regresi\u00f3n en el que interviene una variable independiente y una variable dependiente donde la relaci\u00f3n entre estas variables se aproxima mediante una l\u00ednea recta. A este tipo de an\u00e1lisis se le conoce como regresi\u00f3n lineal simple. Al an\u00e1lisis en el que intervienen dos o m\u00e1s variables independientes se le llama an\u00e1lisis de regresi\u00f3n m\u00faltiple; \u00e9ste y los casos en los que la relaci\u00f3n es curvil\u00ednea se estudian en los cap\u00edtulos 15 y 16.</p> Modelo de regresi\u00f3n y ecuaci\u00f3n de regresi\u00f3n En el ejemplo de Armand\u2019s Pizza Parlors, la poblaci\u00f3n consta de todos los restaurantes de esta cadena. Para cada restaurante en la poblaci\u00f3n hay un valor x (poblaci\u00f3n estudiantil) y un valor correspondiente y (ventas trimestrales). La ecuaci\u00f3n que describe c\u00f3mo se relaciona y con x, y se da un t\u00e9rmino para el error, se llama modelo de regresi\u00f3n. El siguiente es el modelo que se emplea en la regresi\u00f3n lineal simple.      MODELO DE REGRESI\u00d3N LINEAL SIMPLE $$ y = \\beta_0 + \\beta_1 x + \\varepsilon $$<p>(14.1)</p> <p>$\\beta_0$ y $\\beta_1$ se conocen como par\u00e1metros del modelo, y $\\varepsilon$ es una variable aleatoria denominada t\u00e9rmino del error. Este \u00faltimo da cuenta de la variabilidad de $y$, que no puede ser explicada por la relaci\u00f3n lineal entre $x$ y $y$.</p> <p>La poblaci\u00f3n de los restaurantes Armand\u2019s puede verse tambi\u00e9n como un conjunto de subpoblaciones, una para cada uno de los valores de x. Por ejemplo, una subpoblaci\u00f3n est\u00e1 formada por todos los restaurantes Armand\u2019s localizados cerca de los campus universitarios con 8 000 estudiantes; otra subpoblaci\u00f3n consta de todos los restaurantes Armand\u2019s localizados cerca de los campus universitarios con 9 000 estudiantes, y as\u00ed sucesivamente. Para cada subpoblaci\u00f3n hay una distribuci\u00f3n de valores y. As\u00ed, hay una distribuci\u00f3n de valores y que corresponde a los restaurantes localizados cerca de los campus con 8 000 estudiantes y hay otra para los restaurantes ubicados cerca de los campus con 9 000 estudiantes, y as\u00ed sucesivamente. Cada una de estas distribuciones tiene su propia media o valor esperado. A la ecuaci\u00f3n que describe la relaci\u00f3n entre el valor esperado de y, que se denota E(y), y x se le llama ecuaci\u00f3n de regresi\u00f3n. La siguiente es la ecuaci\u00f3n de regresi\u00f3n para la regresi\u00f3n lineal simple.</p> MODELO DE REGRESI\u00d3N LINEAL SIMPLE $$ E(y) = \\beta_0 + \\beta_1 x $$<p>(14.2)</p> <p>La gr\u00e1fica de la ecuaci\u00f3n de regresi\u00f3n lineal simple es una recta; 0 es la intersecci\u00f3n de la recta de regresi\u00f3n con el eje y, 1 es la pendiente y E(y) es la media o valor esperado de y para un valor dado de x. En la figura 14.1 se presentan ejemplos de posibles rectas de regresi\u00f3n. La de la gr\u00e1fica A indica que el valor medio de y est\u00e1 relacionado positivamente con x, con los valores mayores de E(y) asociados a valores mayores de x. La recta de regresi\u00f3n de la gr\u00e1fica B indica que el valor medio de y est\u00e1 relacionado negativamente con x, con valores menores de E(y) que corresponden a valores mayores de x. La gr\u00e1fica C muestra el caso en el que el valor medio de y no est\u00e1 relacionado con x; es decir, el valor medio de y es el mismo para todos los valores de x.</p> Ecuaci\u00f3n de regresi\u00f3n estimada Si se conocieran los valores de los par\u00e1metros poblacionales $\u03b2_0$ y $\u03b2_1$, se podr\u00eda emplear la ecuaci\u00f3n (14.2) para calcular el valor medio de $y$ para un valor dado de $x$. Sin embargo, en la pr\u00e1ctica no se conocen los valores de estos par\u00e1metros y es necesario estimarlos usando datos muestrales. Se calculan estad\u00edsticos muestrales (que se denotan como $ \\hat{\u03b2}_0$ y $ \\hat{\u03b2}_1$) como estimaciones de los par\u00e1metros poblacionales $ \u03b2_0$ y $ \u03b2_1$. Al sustituir $ \\hat{\u03b2}_0$ y $ \\hat{\u03b2}_1$ por $ \u03b2_0$ y $ \u03b2_1$ en la ecuaci\u00f3n de      FIGURA 14.1 Ejemplos de l\u00edneas de regresi\u00f3n posibles en la regresi\u00f3n lineal simple  In\u00a0[3]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Par\u00e1metros\nbeta = 2\ncolor = '#009929'  # Color verde oscuro\nbackground_color = '#D4F8B7'  # Color de fondo\n\n# Datos x\nx = np.linspace(0, 10, 100)\n\n# Configurar estilo de los ejes\nplt.rcParams['xtick.bottom'] = plt.rcParams['xtick.labelbottom'] = False\nplt.rcParams['xtick.top'] = plt.rcParams['xtick.labeltop'] = False\nplt.rcParams['ytick.left'] = plt.rcParams['ytick.labelleft'] = False\nplt.rcParams['ytick.right'] = plt.rcParams['ytick.labelright'] = False\n\n# Crear subgr\u00e1ficos con fondo coloreado\nfig, axs = plt.subplots(1, 3, figsize=(12, 4), facecolor=background_color)\n\n# Gr\u00e1fico con pendiente positiva\ny_positiva = beta + 0.5 * x\naxs[0].plot(x, y_positiva, color=color, label='Pendiente positiva')\naxs[0].set_title('Gr\u00e1fica A\\nRelaci\u00f3n lineal positiva')\naxs[0].legend()\n\n# Gr\u00e1fico con pendiente negativa\ny_negativa = beta - 0.5 * x\naxs[1].plot(x, y_negativa, color=color, label='Pendiente negativa')\naxs[1].set_title('Gr\u00e1fica B\\nRelaci\u00f3n lineal negativa')\naxs[1].legend()\n\n# Gr\u00e1fico con pendiente horizontal\ny_horizontal = np.full_like(x, beta)\naxs[2].plot(x, y_horizontal, color=color, label='Pendiente horizontal')\naxs[2].set_title('Gr\u00e1fica C\\nNo hay relaci\u00f3n')\naxs[2].legend()\n\nplt.tight_layout()\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  # Par\u00e1metros beta = 2 color = '#009929'  # Color verde oscuro background_color = '#D4F8B7'  # Color de fondo  # Datos x x = np.linspace(0, 10, 100)  # Configurar estilo de los ejes plt.rcParams['xtick.bottom'] = plt.rcParams['xtick.labelbottom'] = False plt.rcParams['xtick.top'] = plt.rcParams['xtick.labeltop'] = False plt.rcParams['ytick.left'] = plt.rcParams['ytick.labelleft'] = False plt.rcParams['ytick.right'] = plt.rcParams['ytick.labelright'] = False  # Crear subgr\u00e1ficos con fondo coloreado fig, axs = plt.subplots(1, 3, figsize=(12, 4), facecolor=background_color)  # Gr\u00e1fico con pendiente positiva y_positiva = beta + 0.5 * x axs[0].plot(x, y_positiva, color=color, label='Pendiente positiva') axs[0].set_title('Gr\u00e1fica A\\nRelaci\u00f3n lineal positiva') axs[0].legend()  # Gr\u00e1fico con pendiente negativa y_negativa = beta - 0.5 * x axs[1].plot(x, y_negativa, color=color, label='Pendiente negativa') axs[1].set_title('Gr\u00e1fica B\\nRelaci\u00f3n lineal negativa') axs[1].legend()  # Gr\u00e1fico con pendiente horizontal y_horizontal = np.full_like(x, beta) axs[2].plot(x, y_horizontal, color=color, label='Pendiente horizontal') axs[2].set_title('Gr\u00e1fica C\\nNo hay relaci\u00f3n') axs[2].legend()  plt.tight_layout() plt.show()  <pre>\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[3], line 1\n----&gt; 1 import matplotlib.pyplot as plt\n      3 # Datos de la gr\u00e1fica\n      4 x = [1, 2, 3, 4, 5]\n\nModuleNotFoundError: No module named 'matplotlib'</pre> <p>regresi\u00f3n, se obtiene la ecuaci\u00f3n de regresi\u00f3n estimada. La ecuaci\u00f3n de regresi\u00f3n estimada de una regresi\u00f3n lineal simple se da a continuaci\u00f3n.</p> MODELO DE REGRESI\u00d3N LINEAL SIMPLE ESTIMADA $$ \\hat{y} = \\beta_0 + \\beta_1 x $$<p>(14.3)</p> <p>A la gr\u00e1fica de la ecuaci\u00f3n de regresi\u00f3n lineal simple estimada se le llama recta de regresi\u00f3n estimada; $b_0$ es la intersecci\u00f3n con el eje y, y $b_1$ es la pendiente. En la secci\u00f3n siguiente se muestra el uso del m\u00e9todo de m\u00ednimos cuadrados para calcular los valores de $b_0$ y $b_1$ en la ecuaci\u00f3n de regresi\u00f3n estimada.</p> <p>En general, $\\hat{y}$ es el estimador puntual de $E(y)$, el valor medio de las $y$ para un valor dado de $x$. Por tanto, para estimar la media o el valor esperado de las ventas trimestrales de todos los restaurantes situados cerca de los campus con 10,000 estudiantes, Armand\u2019s tendr\u00e1 que sustituir $x$ por 10,000 en la ecuaci\u00f3n (14.3).</p> <p>Sin embargo, en algunos casos a la cadena le interesar\u00e1 predecir las ventas de un determinado restaurante. Por ejemplo, suponga que desea pronosticar las ventas trimestrales del que se encuentra cerca de Talbot College, una escuela con 10,000 estudiantes. Resulta que la mejor estimaci\u00f3n de la $y$ que corresponde a un determinado valor de $x$ es tambi\u00e9n la proporcionada por $\\hat{y}$. Por tanto, para predecir las ventas trimestrales del restaurante en cuesti\u00f3n, Armand\u2019s tambi\u00e9n sustituir\u00e1 la $x$ de la ecuaci\u00f3n (14.3) por 10,000.</p> <p>Como el valor de $\\hat{y}$ proporciona tanto una estimaci\u00f3n puntual de $E(y)$ para un valor dado de $x$, como una estimaci\u00f3n puntual de un solo valor de $y$ para un valor dado de $x$, a $\\hat{y}$ se le llamar\u00e1 simplemente valor estimado de $y$. En la figura 14.2 se presenta en forma resumida el proceso de estimaci\u00f3n en la regresi\u00f3n lineal simple.</p> FIGURA 14.2 Proceso de estimaci\u00f3n en la regresi\u00f3n lineal simple Modelo de regresi\u00f3n $$ y = \\beta_0 + \\beta_1 x + \\varepsilon $$ Ecuaci\u00f3n de regresi\u00f3n $$ E(y) = \\beta_0 + \\beta_1 x $$ Par\u00e1metros desconocidos $$ \\beta_0 \\beta_1  $$<p>(1)</p> x y $x_1$ $y_1$ $x_2$ $y_2$ . . . . $x_n$ $y_n$ <p>(2)</p> b\u2080 y b\u2081 proporcionan estimaciones de B\u2080 y B\u2081. <p>(3)</p> Ecuaci\u00f3n de regresi\u00f3n estimada $$ \\hat{y} = \\beta_0 + \\beta_1 x $$ Estad\u00edsticos muestrales $$b_0, b_1$$<p> </p> FIGURA 14.3 Distribuci\u00f3n de muestreo de x en el estudio de \"Caf\u00e9 Sierra\" cuando la hip\u00f3tesis nula es verdadera como igualdad (\u03bc = 3)  In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Coordenadas proporcionadas\ncoordenadas = [(2, 60), (8, 85), (6, 105), (8, 120), (12, 120),\n               (16, 135), (20, 155), (20, 170), (22, 130), (26, 200)]\n\n# Separar las coordenadas en x e y\nx_points, y_points = zip(*coordenadas)\n\n# Crear la gr\u00e1fica de puntos\nplt.scatter(x_points, y_points, color='#009929')\n\n# Etiquetas de los ejes\nplt.xlabel('Poblaci\u00f3n de estudiantes (miles)')\nplt.ylabel('Ventas trimestrales (miles de bs)')\n\n# T\u00edtulo de la gr\u00e1fica\nplt.title('Relaci\u00f3n entre Poblaci\u00f3n de Estudiantes y Ventas Trimestrales')\n\n# Establecer el fondo de la gr\u00e1fica\nplt.gca().set_facecolor('#D4F8B7')\n\n# Mostrar la gr\u00e1fica\nplt.show()\n</pre> import matplotlib.pyplot as plt  # Coordenadas proporcionadas coordenadas = [(2, 60), (8, 85), (6, 105), (8, 120), (12, 120),                (16, 135), (20, 155), (20, 170), (22, 130), (26, 200)]  # Separar las coordenadas en x e y x_points, y_points = zip(*coordenadas)  # Crear la gr\u00e1fica de puntos plt.scatter(x_points, y_points, color='#009929')  # Etiquetas de los ejes plt.xlabel('Poblaci\u00f3n de estudiantes (miles)') plt.ylabel('Ventas trimestrales (miles de bs)')  # T\u00edtulo de la gr\u00e1fica plt.title('Relaci\u00f3n entre Poblaci\u00f3n de Estudiantes y Ventas Trimestrales')  # Establecer el fondo de la gr\u00e1fica plt.gca().set_facecolor('#D4F8B7')  # Mostrar la gr\u00e1fica plt.show()  $$ \\hat{y} = \\beta_0 + \\beta_1 x $$ <p>(14.4)</p> <p>donde</p> <ul> <li>$ \\hat{y}_i $: Valor estimado de las ventas trimestrales (en miles de d\u00f3lares) del i-\u00e9simo restaurante.</li> <li>$ b_0 $: Intersecci\u00f3n de la recta de regresi\u00f3n estimada con el eje y.</li> <li>$ b_1 $: Pendiente de la recta de regresi\u00f3n estimada.</li> <li>$ x_i $: Tama\u00f1o de la poblaci\u00f3n de estudiantes (en miles) del i-\u00e9simo restaurante.</li> </ul> <p>Como $y_i$ denota ventas observadas (reales) para el restaurante $i$, y $\\hat{y}_i$ representa el valor estimado de las ventas en la ecuaci\u00f3n (14.4), para cada uno de los restaurantes de la muestra habr\u00e1 un valor de ventas observadas $y_i$ y un valor de ventas estimadas $\\hat{y}_i$. Para que la recta de regresi\u00f3n estimada proporcione un buen ajuste a los datos, las diferencias entre los valores observados y estimados deben ser peque\u00f1as.</p> <p>En el m\u00e9todo de m\u00ednimos cuadrados se usan los datos muestrales para obtener los valores de $b_0$ y $b_1$ que minimicen la suma de los cuadrados de las desviaciones (diferencias) entre los valores observados de la variable dependiente $y_i$ y los valores estimados de la variable dependiente $\\hat{y}_i$. El criterio que se emplea en el m\u00e9todo de m\u00ednimos cuadrados se basa en la expresi\u00f3n (14.5).</p> CRITERIO DE MINIMOS CUADRADOS       \\[ \\min \\sum \\left( y_i - \\hat{y}_i \\right)^2 \\] <p>(14.5)</p>      Donde:   - $y_i$: Valor observado de la variable dependiente en la observaci\u00f3n i-\u00e9sima. - $\\hat{y}_i$: Valor estimado de la variable dependiente en la observaci\u00f3n i-\u00e9sima.  <p>Se pueden usar c\u00e1lculos diferenciales para demostrar (vea el ap\u00e9ndice 14.1) que los valores de $b_0$ y $b_1$ que minimizan la expresi\u00f3n (14.5) se pueden encontrar usando las ecuaciones (14.6) y (14.7).</p> PENDIENTE E INTERSECCI\u00d3N CON EL EJE y DE LA ECUACI\u00d3N DE REGRESI\u00d3N ESTIMADA       \\[ b_1 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2} \\]  <p>(14.5)</p>        \\[ b_0 = \\bar{y} - b_1\\bar{x} \\]  <p>(14.6)</p>      Donde: - $x_i$: Valor de la variable independiente en la observaci\u00f3n i-\u00e9sima. - $y_i$: Valor de la variable dependiente en la observaci\u00f3n i-\u00e9sima. - $x$: Media de la variable independiente. - $y$: Media de la variable dependiente. - $n$: N\u00famero total de observaciones. <p>En la tabla 14.2 se presentan algunos c\u00e1lculos necesarios para desarrollar la ecuaci\u00f3n de regresi\u00f3n estimada por m\u00ednimos cuadrados en el ejemplo de Armand\u2019s Pizza Parlors. Como la muestra es de 10 restaurantes, tenemos $n = 10$ observaciones. Dado que en las ecuaciones (14.6) y (14.7) se necesitan $x$ e $y$, se empieza por calcularlas.</p> <p>$$ x = \\frac{\\sum_{i=1}^{n} x_i}{n} = \\frac{140}{10} = 14 $$</p> <p>$$ x = \\frac{\\sum_{i=1}^{n} y_i}{n} = \\frac{1300}{10} = 130 $$</p> <p>Utilizando las ecuaciones (14.6) y (14.7) y la informaci\u00f3n de la tabla 14.2, se calcula la pendiente y la intersecci\u00f3n de la ecuaci\u00f3n de regresi\u00f3n estimada para Armand\u2019s Pizza Parlors. La pendiente $b_1$ se calcula como se muestra a continuaci\u00f3n.</p> Restaurante \\(x_i\\) \\(y_i\\) \\(x_i - \\bar{x}\\) \\(y_i - \\bar{y}\\) \\((x_i - \\bar{x})(y_i - \\bar{y})\\) \\((x_i - \\bar{x})^2\\) 1 2 58 -12 -72 864 144 2 6 105 -8 25 200 64 3 8 88 -6 42 252 36 4 8 118 -6 12 72 36 5 12 117 -2 13 26 4 6 16 137 2 7 14 4 7 20 157 6 27 162 36 8 20 169 6 39 234 36 9 22 149 8 19 152 64 10 26 202 12 72 864 144 totales 140 1300 2840 568 $ \\sum_{i=1}^{n} x_i  $ $ \\sum_{i=1}^{n} y_i  $ $ \\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y}) $ $ \\sum_{i=1}^{n} (x_i - \\bar{x})^2 $  <p>$$ b_1 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2} $$ $$ b_1 = \\frac{2840}{568} $$ $$=5$$</p> <p>La intersecci\u00f3n con el eje y $b_0$ se calcula como sigue. $$ b_0 = \\bar{y} - b_1 \\bar{x} $$ $$ b_0 = 130 - 5 \\times 14 = 60 $$ Por tanto, la ecuaci\u00f3n de regresi\u00f3n estimada es $$ \\hat{y} = 60 + 5x $$</p> <p>En la fi gura 14.4 se ilustra esta ecuaci\u00f3n grafi cada sobre el diagrama de dispersi\u00f3n. La pendiente de la ecuaci\u00f3n de regresi\u00f3n estimada $b_1=5$ es positiva, lo que implica que a medida que aumenta el tama\u00f1o de la poblaci\u00f3n de estudiantes, las ventas se incrementan. Se concluye (con base en las ventas dadas en miles de bs y el tama\u00f1o de la poblaci\u00f3n en miles) que un aumento de 1 000 en el tama\u00f1o de la poblaci\u00f3n de estudiantes corresponde a un incremento de bs5 000 en las ventas esperadas; es decir, se prev\u00e9 que las ventas trimestrales se incrementen bs5 por cada estudiante. Si se considera que la ecuaci\u00f3n de regresi\u00f3n estimada obtenida por el m\u00e9todo de m\u00ednimos cuadrados describe adecuadamente la relaci\u00f3n entre x y y, parecer\u00e1 razonable usar esta ecuaci\u00f3n a efecto de pronosticar el valor de y para un valor dado de x. Por ejemplo, si se quisieran predecir las ventas trimestrales de un restaurante ubicado cerca de un campo de 16 000 estudiantes, se calcular\u00eda, como sigue.</p> <p>$$ \\hat{y} = 60 + 5(16)= 140 $$</p> <p>De manera que las ventas trimestrales pronosticadas para este restaurante ser\u00edan de bs140 000. En las secciones siguientes se ver\u00e1n los m\u00e9todos para evaluar el uso correcto de la ecuaci\u00f3n de regresi\u00f3n para hacer estimaciones y predicciones.</p> In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\n# Coordenadas proporcionadas\ncoordenadas = [(2, 60), (8, 85), (6, 105), (8, 120), (12, 120),\n               (16, 135), (20, 155), (20, 170), (22, 130), (26, 200)]\n\n# Separar las coordenadas en x e y\nx_points, y_points = zip(*coordenadas)\n\n# Convertir a arrays de NumPy\nx_points = np.array(x_points).reshape(-1, 1)\ny_points = np.array(y_points)\n\n# Crear el modelo de regresi\u00f3n lineal\nmodelo = LinearRegression().fit(x_points, y_points)\n\n# Predecir los valores y con base en los valores x\ny_pred = modelo.predict(x_points)\n\n# Crear la gr\u00e1fica de puntos\nplt.scatter(x_points, y_points, color='#009929', label='Puntos')\n\n# Dibujar la l\u00ednea de regresi\u00f3n con el color solicitado\nplt.plot(x_points, y_pred, color='#98F84A', linewidth=2, label='Regresi\u00f3n Lineal')\n\n# Etiquetas de los ejes\nplt.xlabel('Poblaci\u00f3n de estudiantes (miles)')\nplt.ylabel('Ventas trimestrales (miles de bs)')\n\n# T\u00edtulo de la gr\u00e1fica\nplt.title('Relaci\u00f3n entre Poblaci\u00f3n de Estudiantes y Ventas Trimestrales')\n\n# Establecer el fondo de la gr\u00e1fica\nplt.gca().set_facecolor('#D4F8B7')\n\n# Etiquetas adicionales\nplt.text(10, 170, 'yhat = 60 + 5x', color='black', fontsize=12)\nplt.text(10, 160, 'Pendiente b_1 = 5', color='black', fontsize=12)\n\n# Mostrar la leyenda\nplt.legend()\n\n# Mostrar la gr\u00e1fica\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np from sklearn.linear_model import LinearRegression  # Coordenadas proporcionadas coordenadas = [(2, 60), (8, 85), (6, 105), (8, 120), (12, 120),                (16, 135), (20, 155), (20, 170), (22, 130), (26, 200)]  # Separar las coordenadas en x e y x_points, y_points = zip(*coordenadas)  # Convertir a arrays de NumPy x_points = np.array(x_points).reshape(-1, 1) y_points = np.array(y_points)  # Crear el modelo de regresi\u00f3n lineal modelo = LinearRegression().fit(x_points, y_points)  # Predecir los valores y con base en los valores x y_pred = modelo.predict(x_points)  # Crear la gr\u00e1fica de puntos plt.scatter(x_points, y_points, color='#009929', label='Puntos')  # Dibujar la l\u00ednea de regresi\u00f3n con el color solicitado plt.plot(x_points, y_pred, color='#98F84A', linewidth=2, label='Regresi\u00f3n Lineal')  # Etiquetas de los ejes plt.xlabel('Poblaci\u00f3n de estudiantes (miles)') plt.ylabel('Ventas trimestrales (miles de bs)')  # T\u00edtulo de la gr\u00e1fica plt.title('Relaci\u00f3n entre Poblaci\u00f3n de Estudiantes y Ventas Trimestrales')  # Establecer el fondo de la gr\u00e1fica plt.gca().set_facecolor('#D4F8B7')  # Etiquetas adicionales plt.text(10, 170, 'yhat = 60 + 5x', color='black', fontsize=12) plt.text(10, 160, 'Pendiente b_1 = 5', color='black', fontsize=12)  # Mostrar la leyenda plt.legend()  # Mostrar la gr\u00e1fica plt.show() SUMA DE CUADRADOS DEBIDO AL ERROR       $SCE = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$  <p>(14.8)</p> <p>El valor de la SCE es una medida del error al utilizar la ecuaci\u00f3n de regresi\u00f3n estimada para calcular los valores de la variable dependiente de la muestra.</p> <p>En la Tabla 14.3 se indican los procedimientos que se requieren para calcular la suma de cuadrados debido al error en el caso de Armand\u2019s Pizza Parlors. Por ejemplo, los valores de las variables independiente y dependiente del restaurante 1 son $x_1 = 2$ y $y_1 = 58$. El valor estimado para sus ventas trimestrales obtenido con la ecuaci\u00f3n de regresi\u00f3n estimada es $\\hat{y}_1 = 60 + 5(2) = 70$. Por consiguiente, para el restaurante 1, el error al usar $\\hat{y}_1$ para estimar $y_1$ es $y_1 - \\hat{y}_1 = 58 - 70 = -12$. El error al cuadrado, $(-12)^2 = 144$, aparece en la \u00faltima columna de la Tabla 14.3. Despu\u00e9s de calcular y elevar al cuadrado los residuales de cada uno de los restaurantes de la muestra, se suman y obtenemos que SCE = 1,530. Por tanto, esta suma mide el error que existe al utilizar la ecuaci\u00f3n de regresi\u00f3n estimada $\\hat{y} = 60 + 5x$ para predecir las ventas.</p> <p>Ahora suponga que se pide una estimaci\u00f3n de las ventas trimestrales sin conocer el tama\u00f1o de la poblaci\u00f3n de estudiantes. Sin tener conocimiento de ninguna otra variable relacionada, se emplear\u00eda la media muestral como una estimaci\u00f3n de las ventas trimestrales de cualquiera de</p> TABLA 14.3 C\u00e1lculo de SCE en el ejemplo de Armand\u2019s Pizza Parlors  Restaurante \\(x_i\\) (Poblaci\u00f3n de Estudiantes, miles) \\(y_i\\) (Ventas Trimestrales, miles de bs) Ventas Pronosticadas (\\(\\hat{y}_i = 60 + 5x\\)) Error (\\(y_i - \\hat{y}_i\\)) Error al Cuadrado (\\((y_i - \\hat{y}_i)^2\\)) 1 2 58 70 -12 144 2 6 105 90 15 225 3 8 88 100 -12 144 4 8 118 100 18 324 5 12 117 120 -3 9 6 16 137 140 -3 9 7 20 157 160 -3 9 8 20 169 160 9 81 9 22 149 170 -21 441 10 26 202 190 12 144 <p>$$SCE=1530$$</p> TABLA 14.4 C\u00e1lculo de la suma total de cuadrados en el ejemplo Armand\u2019s Pizza Parlors  Restaurante \\(x_i\\) (Poblaci\u00f3n de Estudiantes, miles) \\(y_i\\) (Ventas Trimestrales, miles de bs) Desviaci\u00f3n (\\(y_i - \\bar{y}\\)) Desviaci\u00f3n al Cuadrado (\\((y_i - \\bar{y})^2\\)) 1 2 58 -25 625 2 6 105 -42 1,764 3 8 88 -12 144 4 8 118 13 169 5 12 117 0 0 6 16 137 7 49 7 20 157 27 729 8 20 169 39 1,521 9 22 149 19 361 10 26 202 5 25 <p>$$STC=15730$$</p> <p>En la tabla 14.2 se mostr\u00f3 que con base en los datos de las ventas, $y_i = 1300$. As\u00ed, el valor medio de las ventas trimestrales en la muestra de los 10 restaurantes Armand\u2019s es $\\bar{y} = \\frac{1300}{10} = 130$. En la tabla 14.4 se presenta la suma de las desviaciones al cuadrado que se obtiene cuando se usa la media muestral $\\bar{y} = 130$ para estimar el valor de las ventas trimestrales de cada uno de los restaurantes. Para el restaurante $i$-\u00e9simo de la muestra, la diferencia $y_i - \\bar{y}$ proporciona una medida del error que implica usar $\\bar{y}$ para estimar las ventas. La correspondiente suma de cuadrados, llamada suma total de cuadrados, se denota $STC$.</p> SUMA DE CUADRADOS DEBIDO A LA REGRESI\u00d3N       $SCR = \\sum_{i=1}^{n} (\\hat{y}_i - y_i)^2$ <p>(14.10)</p> FIGURA 14.5 Desviaciones respecto de la l\u00ednea de regresi\u00f3n estimada y la l\u00ednea y  y en el ejemplo de Armand\u2019s Pizza Parlors In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\n# Coordenadas proporcionadas\ncoordenadas = [(2, 60), (8, 85), (6, 105), (8, 120), (12, 120),\n               (16, 135), (20, 155), (20, 170), (22, 130), (26, 200)]\n\n# Separar las coordenadas en x e y\nx_points, y_points = zip(*coordenadas)\n\n# Convertir a arrays de NumPy\nx_points = np.array(x_points).reshape(-1, 1)\ny_points = np.array(y_points)\n\n# Crear el modelo de regresi\u00f3n lineal\nmodelo = LinearRegression().fit(x_points, y_points)\n\n# Predecir los valores y con base en los valores x\ny_pred = modelo.predict(x_points)\n\n# Crear la gr\u00e1fica de puntos\nplt.scatter(x_points, y_points, color='#009929', label='Puntos')\n\n# Dibujar la l\u00ednea de regresi\u00f3n con el color solicitado\nplt.plot(x_points, y_pred, color='#98F84A', linewidth=2, label='Regresi\u00f3n Lineal')\n\n# Dibujar la l\u00ednea horizontal en la altura 130\nplt.axhline(y=130, color='#009929', linestyle='--', label='Altura 130')\n\n# Etiquetas de los ejes\nplt.xlabel('Poblaci\u00f3n de estudiantes (miles)')\nplt.ylabel('Ventas trimestrales (miles de bs)')\n\n# T\u00edtulo de la gr\u00e1fica\nplt.title('Relaci\u00f3n entre Poblaci\u00f3n de Estudiantes y Ventas Trimestrales')\n\n# Establecer el fondo de la gr\u00e1fica\nplt.gca().set_facecolor('#D4F8B7')\n\n# Etiquetas adicionales\nplt.text(10, 170, 'yhat = 60 + 5x', color='black', fontsize=12)\n\n# Mostrar la leyenda\nplt.legend()\n\n# Mostrar la gr\u00e1fica\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np from sklearn.linear_model import LinearRegression  # Coordenadas proporcionadas coordenadas = [(2, 60), (8, 85), (6, 105), (8, 120), (12, 120),                (16, 135), (20, 155), (20, 170), (22, 130), (26, 200)]  # Separar las coordenadas en x e y x_points, y_points = zip(*coordenadas)  # Convertir a arrays de NumPy x_points = np.array(x_points).reshape(-1, 1) y_points = np.array(y_points)  # Crear el modelo de regresi\u00f3n lineal modelo = LinearRegression().fit(x_points, y_points)  # Predecir los valores y con base en los valores x y_pred = modelo.predict(x_points)  # Crear la gr\u00e1fica de puntos plt.scatter(x_points, y_points, color='#009929', label='Puntos')  # Dibujar la l\u00ednea de regresi\u00f3n con el color solicitado plt.plot(x_points, y_pred, color='#98F84A', linewidth=2, label='Regresi\u00f3n Lineal')  # Dibujar la l\u00ednea horizontal en la altura 130 plt.axhline(y=130, color='#009929', linestyle='--', label='Altura 130')  # Etiquetas de los ejes plt.xlabel('Poblaci\u00f3n de estudiantes (miles)') plt.ylabel('Ventas trimestrales (miles de bs)')  # T\u00edtulo de la gr\u00e1fica plt.title('Relaci\u00f3n entre Poblaci\u00f3n de Estudiantes y Ventas Trimestrales')  # Establecer el fondo de la gr\u00e1fica plt.gca().set_facecolor('#D4F8B7')  # Etiquetas adicionales plt.text(10, 170, 'yhat = 60 + 5x', color='black', fontsize=12)  # Mostrar la leyenda plt.legend()  # Mostrar la gr\u00e1fica plt.show() <p>Por lo antes dicho, se esperar\u00eda que hubiera alguna relaci\u00f3n entre STC, SCR y SCE. En efecto, la relaci\u00f3n entre estas tres sumas de cuadrados constituye uno de los resultados m\u00e1s importantes de la estad\u00edstica.</p> RELACI\u00d3N ENTRE STC, SCR Y SCE      $$ STC,  SCR,  SCE$$  <p>(14.11)</p>     donde: STC=suma total de cuadrado SCR=suma de cuadrados debido a la regresi\u00f3n SCE=suma de cuadrados debido al error <p>La ecuaci\u00f3n (14.11) indica que la suma total de cuadrados puede ser dividida en dos componentes: la suma de cuadrados debido a la regresi\u00f3n y la suma de cuadrados debido al error. Por consiguiente, si se conocen los valores de dos de estas sumas, es f\u00e1cil calcular la tercera suma de cuadrados. Por ejemplo, en el caso de Armand\u2019s Pizza Parlors se conocen SCE  1 530 y STC  15 730; por tanto, al despejar SCR en la ecuaci\u00f3n (14.11), se encuentra que la suma de cuadrados debido a la regresi\u00f3n es</p> <p>$$SCR=STC-SCE=15730-1530=14200$$</p> <p>Ahora se ver\u00e1 c\u00f3mo se usan estas tres sumas de cuadrados, $STC$, $SCR$ y $SCE$, para obtener una medida de la bondad de ajuste de la ecuaci\u00f3n de regresi\u00f3n estimada. Esta ecuaci\u00f3n se ajustar\u00eda perfectamente a los datos si cada uno de los valores de la variable dependiente $y_i$ se encontrara sobre la recta de regresi\u00f3n. En este caso, para todas las observaciones se tendr\u00eda que $y_i - \\hat{y}_i$ ser\u00eda igual a 0, con lo que $SCE = 0$. Como $STC = SCR + SCE$, vemos que para que haya un ajuste perfecto, $SCR$ debe ser igual a $STC$, y el cociente $\\frac{SCR}{STC}$ debe ser igual a 1. Cuando los ajustes son malos, se tendr\u00e1n valores altos para $SCE$. Si en la ecuaci\u00f3n (14.11) despejamos esta, tenemos que $SCE = STC - SCR$. Por lo tanto, el valor m\u00e1s grande de $SCE$ (y, por tanto, el ajuste m\u00e1s pobre) se presenta cuando $SCR = 0$ y $SCE = STC$.</p> <p>El cociente $\\frac{SCR}{STC}$, que puede tomar valores entre 0 y 1, se usa para evaluar la bondad de ajuste de la ecuaci\u00f3n de regresi\u00f3n estimada. A este cociente se le llama coeficiente de determinaci\u00f3n y se denota como $r^2$.</p> COEFICIENTE DE DETERMINACI\u00d3N       $r^2 = \\frac{SCR}{STC}$  <p>(14.12)</p> <p>En el ejemplo de Armand\u2019s Pizza Parlors, el valor del coefi ciente de determinaci\u00f3n es $$r^2 = \\frac{SCR}{STC} = \\frac{14,200}{15,730} \\approx 0.9027$$</p> <p>Cuando se expresa el coeficiente de determinaci\u00f3n en forma de porcentaje, $r^2$ se puede interpretar como el porcentaje de la suma total de cuadrados que se explica mediante el uso de la ecuaci\u00f3n de regresi\u00f3n estimada. En el ejemplo de Armand\u2019s Pizza Parlors se concluye que 90.27% de la suma total de cuadrados se explica utilizando la ecuaci\u00f3n de regresi\u00f3n estimada $\\hat{y} = 60 - 5x$ para predecir las ventas trimestrales. En otras palabras, 90.27% de la variabilidad en las ventas se explica por la relaci\u00f3n lineal que existe entre \u00e9stas y el tama\u00f1o de la poblaci\u00f3n de estudiantes. Ser\u00eda satisfactorio encontrar un buen ajuste para la ecuaci\u00f3n de regresi\u00f3n estimada.</p> Coeficiente de correlaci\u00f3n  <p>En el cap\u00edtulo 3 se present\u00f3 el coeficiente de correlaci\u00f3n como una medida descriptiva de la intensidad de la relaci\u00f3n lineal entre dos variables $x$ e $y$. Los valores del coeficiente de correlaci\u00f3n siempre estar\u00e1n entre 1 y -1. Un valor de -1 indica que las dos variables $x$ e $y$ est\u00e1n perfectamente relacionadas en un sentido lineal positivo. Es decir, todos los puntos de los datos se encuentran en una l\u00ednea recta que tiene pendiente positiva. Un valor de 1 indica que $x$ e $y$ est\u00e1n perfectamente relacionadas en un sentido lineal negativo con todos los puntos de los datos en una recta con pendiente negativa. Los valores del coeficiente de correlaci\u00f3n cercanos a 0 indican que $x$ e $y$ no est\u00e1n relacionadas linealmente.</p> <p>En la secci\u00f3n 3.5 se present\u00f3 la ecuaci\u00f3n para calcular el coeficiente de correlaci\u00f3n muestral. Cuando se ha realizado un an\u00e1lisis de regresi\u00f3n y calculado el coeficiente de determinaci\u00f3n $r^2$, el coeficiente de correlaci\u00f3n muestral se puede obtener como se indica a continuaci\u00f3n.</p> COEFICIENTE DE CORRELACI\u00d3N MUESTRAL       \\[ r_{xy} = \\text{signo}(b_1) \\sqrt{r^2} \\]       \\[ \\text{signo}(b_1) \\sqrt{r^2} \\]       donde:       $b_1$=pendiente de la ecuaci\u00f3n de regresi\u00f3n estimada\\[ \\hat{y} = b_0 + b_1x \\] <p>(14.13)</p> <p>El signo del coeficiente de correlaci\u00f3n muestral es positivo si la ecuaci\u00f3n de regresi\u00f3n estimada tiene pendiente positiva ($b_1 \\neq 0$), y es negativo si la ecuaci\u00f3n de regresi\u00f3n estimada tiene pendiente negativa ($b_1 \\neq 0$).</p> <p>En el ejemplo de Armand\u2019s Pizza Parlor, el valor del coeficiente de determinaci\u00f3n correspondiente a la ecuaci\u00f3n de regresi\u00f3n estimada $\\hat{y} = 60 - 5x$ es 0.9027. Como la pendiente de esta ecuaci\u00f3n es positiva, la ecuaci\u00f3n (14.13) indica que el coeficiente de correlaci\u00f3n muestral es $0.9027$. Con este coeficiente $r_{xy} = 0.9027$, concluimos que existe una fuerte relaci\u00f3n lineal positiva entre $x$ e $y$.</p> <p>En el caso de una relaci\u00f3n lineal entre dos variables, tanto el coeficiente de determinaci\u00f3n como el coeficiente de correlaci\u00f3n muestral proporcionan medidas de la fuerza de la relaci\u00f3n. El primero provee una medida entre 0 y 1, mientras que el segundo proporciona una medida entre -1 y 1. Aunque el coeficiente de correlaci\u00f3n muestral est\u00e1 restringido a la relaci\u00f3n lineal entre dos variables, el coeficiente de determinaci\u00f3n puede emplearse para relaciones no lineales y para otras en las que hay dos o m\u00e1s variables independientes. Por tanto, ofrece un rango de aplicaci\u00f3n m\u00e1s amplio.</p> <p>La relaci\u00f3n entre $y$, $0$, $1x$, y el t\u00e9rmino de error $\\varepsilon$ se establece inicialmente como:</p> <p>$y = 0 + 1x + \\varepsilon$</p> <p>Luego, empleando el m\u00e9todo de m\u00ednimos cuadrados, se obtienen los valores de $b_0$ y $b_1$, que son las estimaciones de los par\u00e1metros del modelo $0$ y $1$, respectivamente. As\u00ed se llega a la ecuaci\u00f3n de regresi\u00f3n estimada:</p> <p>$\\hat{y} = b_0 + b_1x$</p> <p>Como vimos, el valor del coeficiente de determinaci\u00f3n ($r^2$) es una medida de la bondad de ajuste de la ecuaci\u00f3n de regresi\u00f3n estimada. Sin embargo, aun cuando se obtenga un valor grande para $r^2$, la ecuaci\u00f3n de regresi\u00f3n estimada no debe ser usada sino hasta que se realice un an\u00e1lisis para determinar si el modelo empleado es apropiado. Un paso importante para ver si el supuesto del modelo es adecuado consiste en probar la significancia de la relaci\u00f3n. Las pruebas de significancia en el an\u00e1lisis de regresi\u00f3n est\u00e1n basadas en los siguientes supuestos acerca del t\u00e9rmino de error $\\varepsilon$.</p> SUPUESTOS ACERCA DEL T\u00c9RMINO DEL ERROR $\\varepsilon$ EN EL MODELO DE REGRESI\u00d3N $y = 0 + 1x + \\varepsilon$  <ol> <li><p>El t\u00e9rmino del error $\\varepsilon$ es una variable aleatoria cuya media, o valor esperado, es cero; es decir, $E(\\varepsilon) = 0$.</p> <p>Implicaci\u00f3n: $0$ y $1$ son constantes, por tanto, $E(0) = 0$ y $E(1) = 1$; as\u00ed, para un valor dado de $x$, el valor esperado de $y$ es $$E(y) = b_0 + b_ix$$</p> <p>(14.14)</p> </li></ol> 1. Como ya se indic\u00f3, a la ecuaci\u00f3n (14.14) se le conoce como ecuaci\u00f3n de regresi\u00f3n.  <ol> <li><p>La varianza de $\\varepsilon$, que se denota como $\\sigma^2$, es la misma para todos los valores de $x$.</p> <ul> <li>Implicaci\u00f3n: La varianza de $y$ respecto de la recta de regresi\u00f3n es igual a $\\sigma^2$ y es la misma para todos los valores de $x$.</li> </ul> </li> <li><p>Los valores de $\\varepsilon$ son independientes.</p> <ul> <li>Implicaci\u00f3n: El valor de $\\varepsilon$ correspondiente a un determinado valor de $x$ no est\u00e1 relacionado con el valor de $\\varepsilon$ para cualquier otro valor de $x$; por tanto, el valor de $y$ correspondiente a un valor particular de $x$ no est\u00e1 relacionado con el valor de $y$ de ning\u00fan otro valor de $x$.</li> </ul> </li> <li><p>El t\u00e9rmino del error $\\varepsilon$ es una variable aleatoria distribuida normalmente.</p> <ul> <li>Implicaci\u00f3n: Como $y$ es una funci\u00f3n lineal de $\\varepsilon$, tambi\u00e9n $y$ es una variable aleatoria distribuida normalmente.</li></ul></li></ol> <p>En la figura 14.6 se ilustran los supuestos del modelo y sus implicaciones; observe que en esta interpretaci\u00f3n gr\u00e1fica el valor de $E(y)$ cambia con base en el valor espec\u00edfico de $x$ que se considere. Sin embargo, sea cual sea el valor de $x$, la distribuci\u00f3n de probabilidad de $\\varepsilon$ y, por tanto, la distribuci\u00f3n de probabilidad de $y$, son distribuciones normales que tienen todas la misma varianza. El valor espec\u00edfico del error $\\varepsilon$ en cualquier punto depende de si el valor real de $y$ es mayor o menor que $E(y)$.</p> <p>En este punto hay que tener presente que tambi\u00e9n se hace un supuesto o se tiene una hip\u00f3tesis acerca de la forma de la relaci\u00f3n entre $x$ y $y$. Es decir, se supone que la base de la relaci\u00f3n...</p> Estimaci\u00f3n de $\u03c3^2$ <p>Con base en el modelo de regresi\u00f3n y sus supuestos, podemos concluir que $\\sigma^2$, la varianza de $\\varepsilon$, representa tambi\u00e9n la varianza de los valores de $y$ respecto de la recta de regresi\u00f3n. Recuerde que a las desviaciones de los valores de $y$ respecto de la recta de regresi\u00f3n estimada se les conoce como residuales. Por tanto, SCE, la suma de los cuadrados de los residuales, es una medida de la variabilidad de las observaciones reales respecto de la l\u00ednea de regresi\u00f3n estimada.</p> <p>El error cuadrado medio (ECM) proporciona una estimaci\u00f3n de $\\sigma^2$; esta estimaci\u00f3n es de SCE dividida entre sus grados de libertad. Como $y\u02c6i = \\beta_0 + \\beta_1x_i$, SCE se puede expresar como</p> <p>$$SCE = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 = \\sum_{i=1}^{n} (y_i - \\beta_0 - \\beta_1x_i)^2$$</p> <p>Cada suma de cuadrados est\u00e1 asociada con un n\u00famero llamado grados de libertad. Los expertos en estad\u00edstica han demostrado que la SCE tiene $n - 2$ grados de libertad, porque para calcularla es necesario estimar dos par\u00e1metros ($\\beta_0$ y $\\beta_1$). El error cuadrado medio se calcula al dividir SCE entre $n - 2$. El ECM proporciona un estimador insesgado de $\\sigma^2$. Como el valor del ECM provee un estimado de $\\sigma^2$, se emplea tambi\u00e9n la notaci\u00f3n $s^2$.</p> ERROR CUADRADO MEDIO (ESTIMACI\u00d3N DE $\\sigma^2$       $s^2=MCE = \\frac{SCE}{n - 2}$  <p>(14.15)</p> <p>En la secci\u00f3n 14.3 se encontr\u00f3 que en el ejemplo de Armand\u2019s Pizza Parlors, SCE  1 530; por tanto, $$ s^2 = \\frac{1,530}{8} = 191.25 $$ proporciona un estimador insesgado de $\u03c3^2$. Para estimar \u03c3 se calcula la ra\u00edz cuadrada de $s^2$. Al valor que se obtiene, s, se le conocecomo error est\u00e1ndar de estimaci\u00f3n.</p> ERROR EST\u00c1NDAR DE ESTIMACI\u00d3N       $$ s = \\sqrt{\\frac{SCE}{n - 2}} $$  <p>(14.16)</p> <p>En el ejemplo de Armand's Pizza Parlors, si la desviaci\u00f3n est\u00e1ndar estimada $s$ es igual a la ra\u00edz cuadrada del Error Cuadrado Medio (ECM), entonces:</p> <p>$$s = \\sqrt{191.25} \\approx 13.829 $$</p> <p>El error est\u00e1ndar de estimaci\u00f3n se utiliza en el siguiente an\u00e1lisis acerca de las pruebas de significancia de la relaci\u00f3n entre $x$ e $y$.</p> Prueba t <p>El modelo de regresi\u00f3n lineal simple se expresa como $y = \\beta_0 + \\beta_1x + \\varepsilon$. Si $x$ e $y$ est\u00e1n relacionadas linealmente, entonces $\\beta_1 \\neq 0$. El objetivo de la prueba $t$ es determinar si se puede concluir que $\\beta_1 \\neq 0$. Para probar la hip\u00f3tesis siguiente acerca del par\u00e1metro $\\beta_1$, se emplear\u00e1n los siguientes datos muestrales.</p> <p>$$ H_0: \\beta_1 = 0 $$ $$ H_a: \\beta_1 \\neq 0 $$</p> <p>Si $H_0$ es rechazada, se concluir\u00e1 que $\\beta_1 \\neq 0$, indicando que entre las dos variables existe una relaci\u00f3n estad\u00edsticamente significativa. Si $H_0$ no es rechazada, habr\u00e1 evidencia insuficiente para concluir que esta relaci\u00f3n significativa existe. La base para esta prueba de hip\u00f3tesis la proporcionan las propiedades de la distribuci\u00f3n de muestreo de $\\hat{\\beta}_1$, el estimador de $\\beta_1$ obtenido mediante el m\u00e9todo de m\u00ednimos cuadrados.</p> <p>Primero, considere qu\u00e9 ocurrir\u00eda si para el mismo estudio de regresi\u00f3n se usara una muestra aleatoria diferente. Suponga, por ejemplo, que Armand's Pizza Parlors usa los registros de ventas de una muestra diferente de 10 restaurantes. El an\u00e1lisis de regresi\u00f3n de esta otra muestra dar\u00e1 como resultado una ecuaci\u00f3n de regresi\u00f3n parecida a la ecuaci\u00f3n de regresi\u00f3n anterior $y = 60 - 5x$. Sin embargo, no puede esperarse que se obtenga exactamente la misma ecuaci\u00f3n (una ecuaci\u00f3n en la que exactamente la intersecci\u00f3n con el eje $y$ sea 60 y la pendiente sea 5). Los estimadores $\\hat{\\beta}_0$ y $\\hat{\\beta}_1$, obtenidos por el m\u00e9todo de m\u00ednimos cuadrados, son estad\u00edsticos muestrales que tienen su propia distribuci\u00f3n de muestreo. A continuaci\u00f3n, se presentan las propiedades de la distribuci\u00f3n de muestreo de $\\hat{\\beta}_1$.</p> DISTRIBUCI\u00d3N DE MUESTREO DE $\\hat{\\beta}_1$  <ul> <li><p>Valor esperado: $$E(\\beta_1) = \\beta_1 $$</p> </li> <li><p>Desviaci\u00f3n est\u00e1ndar: $$ \\sigma_{{\\beta}_1} = \\frac{\\sigma}{\\sqrt{\\sum (x_i - \\bar{x})^2}} $$</p> </li> <li><p>Forma de distribuci\u00f3n: Normal</p> </li> </ul> <p>(14.17)</p> <p>Observe que el valor esperado de ${\\beta}_1$ es igual a $\\beta_1$, por lo que ${\\beta}_1$ es un estimador insesgado de $\\beta_1$.</p> <p>Como no se conoce el valor de $\\sigma$, se obtiene una estimaci\u00f3n de $\\sigma_{\\hat{\\beta}_1}$, que se denota $\\hat{\\sigma}_{\\hat{\\beta}_1}$, estimando $\\sigma$ mediante $s$ en la ecuaci\u00f3n (14.17). De esta manera, obtenemos el estimador siguiente de $\\sigma_{\\hat{\\beta}_1}$.</p> DESVIACI\u00d3N EST\u00c1NDAR ESTIMADA DE $b_i$       $ {s}_{\\hat{\\beta}_1} = \\frac{s}{\\sqrt{\\sum (x_i - \\bar{x})^2}} $ <p>(14.18)</p> <p>En el ejemplo de Armand\u2019s Pizza Parlors, $s = 13.829$. Por tanto, dado que $\\sum (x_i - \\bar{x})^2 = 568$, como se aprecia en la tabla 14.2, tenemos</p> <p>$$ \\hat{\\sigma}_{\\hat{\\beta}_1} = \\frac{s}{\\sqrt{\\sum (x_i - \\bar{x})^2}} = \\frac{13.829}{\\sqrt{568}} \\approx 0.5803 $$</p> <p>que es la desviaci\u00f3n est\u00e1ndar estimada de $\\hat{\\beta}_1$.</p> <p>La prueba t para determinar si la relaci\u00f3n es significativa se basa en el hecho de que el estad\u00edstico de prueba</p> <p>$$t = \\frac{\\hat{\\beta}_1 - 1}{\\hat{\\sigma}_{\\hat{\\beta}_1}} $$</p> <p>sigue una distribuci\u00f3n t con $n - 2$ grados de libertad. Si la hip\u00f3tesis nula es verdadera, entonces $\\beta_1 = 0$ y $t = \\frac{\\hat{\\beta}_1}{\\hat{\\sigma}_{\\hat{\\beta}_1}}$.</p> <p>Ahora se realizar\u00e1 esta prueba de significancia con los datos de Armand\u2019s Pizza Parlors empleando como nivel de significancia $\\alpha = 0.01$. El estad\u00edstico de prueba es</p> <p>$$ t = \\frac{{\\beta}_1}{\\hat{\\sigma}_{{s}_1}} = \\frac{5}{0.5803} \\approx 8.62 $$</p> <p>En las tablas de la distribuci\u00f3n t encontramos que para $n - 2 = 10 - 2 = 8$ grados de libertad, $t = 3.355$ proporciona un \u00e1rea de $0.005$ en la cola superior. Por tanto, el \u00e1rea en la cola superior de la distribuci\u00f3n t correspondiente al estad\u00edstico de prueba $t = 8.62$ debe ser menor de $0.005$. Como \u00e9sta es una prueba de dos colas, este valor se duplica y concluimos que el valor-p asociado con $t = 8.62$ debe ser menor a $2 \\times 0.005 = 0.01$. Empleando Excel o Minitab se encuentra el valor-p $= 0.000$. Dado que el valor-p es menor que $\\alpha = 0.01$, $H_0$ es rechazada y concluimos que $\\beta_1$ no es igual a cero. Esto es suficiente evidencia para asegurar que existe una relaci\u00f3n significativa entre la poblaci\u00f3n de estudiantes y las ventas trimestrales.</p>  PRUEBA t DE SIGNIFICANCIA PARA LA REGRESI\u00d3N LINEAL SIMPLE  <p>Hip\u00f3tesis Nula ($H_0$): $b_1 = 0$</p> <p>Hip\u00f3tesis Alternativa ($H_a$): $b_1 \\neq 0$</p> <p>Estad\u00edstico de Prueba $t$: $$ t = \\frac{b_1}{s_{b_1}} $$ REGLA DE RECHAZO</p> INTERVALO DE CONFIANZA PARA $\\beta_1$ <p>$$ \\text{Intervalo de Confianza} = \\beta_1 \\pm t_{\\alpha/2} \\cdot \\text{sb}_1 $$</p> <p>El estimador puntual es $b_1$ y el margen de error es $t_{\\alpha/2}\\text{sb}_1$. El coeficiente de confianza para este intervalo es $1 - \\alpha$, donde $t_{\\alpha/2}$ es el valor cr\u00edtico de la distribuci\u00f3n t con $n - 2$ grados de libertad.</p> <p>Supongamos, por ejemplo, que en el caso de Armand\u2019s Pizza Parlors se desea obtener una estimaci\u00f3n de $b_1$ mediante un intervalo de 99% de confianza. Seg\u00fan la tabla 2 del ap\u00e9ndice B, el valor cr\u00edtico $t_{0.005}$ correspondiente a $\\alpha = 0.01$ y $n - 2 = 8$ grados de libertad es $3.355$. Por lo tanto, la estimaci\u00f3n mediante un intervalo de 99% de confianza de $b_1$ es:</p> <p>$$ b_1 \\pm t_{\\alpha/2}\\text{sb}_1 = 5 \\pm 3.355 \\times 0.5803 = 5+-1.95 $$</p> <ul> <li>Hip\u00f3tesis nula ($H_0$): $b_1 = 0$</li> <li>Hip\u00f3tesis alternativa ($H_a$): $b_1 \\neq 0$ </li> </ul> <p>Al utilizar la prueba t de significancia con $\\alpha = 0.01$, se puede utilizar este intervalo de 99% de confianza como alternativa para llegar a la conclusi\u00f3n de la prueba de hip\u00f3tesis con los datos de Armand\u2019s. Como $0$, que es el valor hipot\u00e9tico de $b_1$, no est\u00e1 comprendido en el intervalo de confianza (3.05 a 6.95), se rechaza $H_0: b_1 = 0$, y se concluye que entre el tama\u00f1o de la poblaci\u00f3n de estudiantes y las ventas trimestrales s\u00ed existe una relaci\u00f3n estad\u00edsticamente significativa. En general, se puede utilizar un intervalo de confianza para probar cualquier hip\u00f3tesis de dos colas acerca de $b_1$. Si el valor hipot\u00e9tico de $b_1$ est\u00e1 contenido en el intervalo de confianza, $H_0$ no es rechazada. De lo contrario, es rechazada.</p> PRUEBA $F$ <p>La prueba F, basada en la distribuci\u00f3n de probabilidad F, tambi\u00e9n puede utilizarse para determinar la significancia global de la regresi\u00f3n. Cuando hay una \u00fanica variable independiente, la prueba F y la prueba t conducen a la misma conclusi\u00f3n. Es decir, si la prueba t indica que $b_1 \\neq 0$ y, por lo tanto, existe una relaci\u00f3n significativa, la prueba F tambi\u00e9n indicar\u00e1 la existencia de esta relaci\u00f3n.</p> <p>La l\u00f3gica detr\u00e1s del uso de la prueba F radica en el desarrollo de dos estimaciones independientes de $\\sigma^2$. ECM proporciona una estimaci\u00f3n de $\\sigma^2$, y si la hip\u00f3tesis nula $H_0: \\beta_1 = 0$ es verdadera, la suma de cuadrados debida a la regresi\u00f3n, SCR, dividida entre sus grados de libertad proporciona otra estimaci\u00f3n independiente de $\\sigma^2$. A esta estimaci\u00f3n se le conoce como el cuadrado medio debido a la regresi\u00f3n (CMR).</p> <p>En general, el CMR se calcula como:</p> <p>$$ CMR = \\frac{SCR}{\\text{grados de libertad de la regresi\u00f3n}} $$</p> <p>En los modelos considerados en este contexto, el n\u00famero de grados de libertad de la regresi\u00f3n es siempre igual al n\u00famero de variables independientes en el modelo.</p>       $$ CMR = \\frac{SCR}{\\text{n\u00famero de variables independientes}} $$  <p>(14.20)</p> <p>En este cap\u00edtulo se consideran modelos de regresi\u00f3n con una sola variable independiente. En este caso, el Cuadrado Medio de la Regresi\u00f3n (CMR) es igual a la Suma de Cuadrados de la Regresi\u00f3n (SCR) porque el n\u00famero de variables independientes es 1. En el ejemplo de Armand\u2019s Pizza Parlors, CMR es igual a SCR, que es 14,200.</p> <p>Si la hip\u00f3tesis nula ($H_0: \u03b21 = 0$) es verdadera, tanto CMR como ECM son dos estimaciones independientes de \u03c3^2. La distribuci\u00f3n de muestreo de CMR/ECM sigue una distribuci\u00f3n F, donde el n\u00famero de grados de libertad en el numerador es 1 y en el denominador es n - 2.</p> <p>Por lo tanto, si \u03b21 = 0, el valor de CMR/ECM deber\u00e1 ser cercano a 1. Pero si la hip\u00f3tesis nula es falsa (\u03b21 \u2260 0), CMR sobreestimar\u00e1 \u03c3^2 y el valor de CMR/ECM se inflar\u00e1. Valores grandes de CMR/ECM conducir\u00e1n al rechazo de H0, sugiriendo que la relaci\u00f3n entre x e y es estad\u00edsticamente significativa.</p> <p>En el ejemplo de Armand\u2019s Pizza Parlors, el estad\u00edstico de prueba para la prueba F es</p> <p>$$ F = \\frac{CMR}{ECM} = \\frac{14,200}{191.25} \\approx 74.25 $$</p> <p>En la tabla de la distribuci\u00f3n F (tabla 4 del ap\u00e9ndice B), con 1 grado de libertad en el numerador y n - 2 grados de libertad en el denominador (en este caso, 8 grados de libertad), se observa que el valor cr\u00edtico es $ F_{0.01} = 11.26 $, proporcionando un \u00e1rea de 0.01 en la cola superior.</p> <p>El estad\u00edstico de prueba F, calculado como $\\frac{CMR}{ECM} \\approx 74.25$, comparado con el valor cr\u00edtico de la distribuci\u00f3n F, sugiere que el valor-p asociado a este estad\u00edstico es $0.000$. Dado que el valor-p es menor que el nivel de significancia $ \\alpha = 0.01 $, rechazamos la hip\u00f3tesis nula (H0: $ \\beta_1 = 0 $).</p> <p>En resumen, la prueba F proporciona evidencia suficiente para concluir que hay una relaci\u00f3n significativa entre el tama\u00f1o de la poblaci\u00f3n de estudiantes y las ventas trimestrales en Armand\u2019s Pizza Parlors.</p> PRUEBA F DE SIGNIFICANCIA EN EL CASO DE LA REGRESI\u00d3N LINEAL SIMPLE <p>$$H0: \u03b2\u2081 = 0$$ $$Ha: \u03b2\u2081 \u2260 0$$</p> <p>ESTAD\u00cdSTICO DE PRUEBA $$F=CMR/EMC$$</p> <p>(14.21)</p>  REGLA DE RECHAZO  <p>M\u00e9todo del valor-p: Rechazar H0 si el $valor-p &lt; \u03b1$</p> <p>M\u00e9todo del valor cr\u00edtico: Rechazar H0 si $F &gt; F\u03b1$</p> <p>Donde F\u03b1 es un valor de distribuci\u00f3n F con 1 grado de libertad en el numerador y $n \u2265 2$ grados de libertad en el denominador.</p> <p>En el cap\u00edtulo 13 vimos que el an\u00e1lisis de varianza (ANOVA) y la tabla de ANOVA pueden utilizarse para proporcionar una visi\u00f3n resumida de los c\u00e1lculos que se emplean en el an\u00e1lisis de varianza. Una tabla de ANOVA similar se emplea para resumir los c\u00e1lculos de la prueba F de significancia para la regresi\u00f3n. En la tabla 14.5 se presenta la forma general de una tabla de ANOVA para la regresi\u00f3n lineal simple, y en la 14.6 la tabla de ANOVA con los c\u00e1lculos para la prueba F del ejemplo de Armand\u2019s Pizza Parlors. Regresi\u00f3n, error y total son las etiquetas de las tres fuentes de variaci\u00f3n, y SCR, SCE y STC son las sumas de cuadrados correspondientes que aparecen en la columna 2. En la columna 3 se indican los grados de libertad 1 para SCR, n \u2265 2 para SCE y n \u2265 1 para STC. Los valores de CMR y ECM aparecen en la columna 4, mientras que la 5 contiene el valor de F  CMR/ECM, y la 6 el valor-p que corresponde al valor de F de la columna 5. Casi todos los resultados proporcionados por computadora para el an\u00e1lisis de regresi\u00f3n incluyen un resumen de la tabla ANOVA de la prueba F de significancia.</p> Fuente de Variaci\u00f3n Suma de Cuadrados Grados de Libertad Media F Valor-p Regresi\u00f3n SCR 1 CMR=(SRC/1) F=(CMR/ECM) Valor-p<sub>CMR/ECM</sub> Error SCE n - 2 ECM=(SCE/(n-2)) Total STC n - 1 Algunas advertencias acerca de la interpretaci\u00f3n de las pruebas de significancia <p>Cuando la hip\u00f3tesis nula H0: \u03b2\u2081 = 0 es rechazada, determinar que la relaci\u00f3n que existe entre x e y es significativa no permite concluir que existe una relaci\u00f3n de causa y efecto entre x e y. Solo puede concluirse que existe esta relaci\u00f3n cuando el analista pueda dar justificaciones te\u00f3ricas de que, en efecto, la relaci\u00f3n es causal.</p> <p>En el ejemplo de Armand\u2019s Pizza Parlors, concluimos que existe una relaci\u00f3n significativa entre el tama\u00f1o de la poblaci\u00f3n de estudiantes x y las ventas trimestrales y; a\u00fan m\u00e1s, la ecuaci\u00f3n de regresi\u00f3n estimada y\u0302 = 60 - 5x proporciona una estimaci\u00f3n de la relaci\u00f3n obtenida por el m\u00e9todo de m\u00ednimos cuadrados. Sin embargo, por el solo hecho de que se haya encontrado que hay una relaci\u00f3n estad\u00edsticamente significativa entre x e y, no podemos concluir que cambios en la poblaci\u00f3n de estudiantes x causen cambios en las ventas trimestrales y. Lo apropiado de concluir que hay una relaci\u00f3n de causa y efecto se deja a las justificaciones te\u00f3ricas de soporte y al buen juicio de los analistas. Los gerentes de Armand\u2019s cre\u00edan que el aumento en la poblaci\u00f3n de estudiantes probablemente fuera una causa del aumento de las ventas trimestrales. Por tanto, el resultado de la prueba de significancia les permite concluir que hay una relaci\u00f3n de causa y efecto.</p> <p>Adem\u00e1s, el hecho de que se pueda rechazar H0: \u03b2\u2081 = 0 y demostrar que hay significancia estad\u00edstica no permite concluir que la relaci\u00f3n entre x e y sea lineal. Lo \u00fanico que se puede establecer es que x e y est\u00e1n relacionadas y que la relaci\u00f3n lineal explica una porci\u00f3n significativa de la variabilidad de y sobre el rango de los valores de x observados en la muestra. En la figura 14.7 se ilustra esta situaci\u00f3n. La prueba de significancia lleva al rechazo de la hip\u00f3tesis nula H0: \u03b2\u2081 = 0 y a la conclusi\u00f3n de que x e y est\u00e1n significativamente relacionadas, pero en la figura se observa que la verdadera relaci\u00f3n entre x e y no es lineal. Aunque la aproximaci\u00f3n.</p> TABLA 14.6 Tabla ANOVA para el ejemplo de Armand\u2019s Pizza Parlors Fuente de Variaci\u00f3n Suma de Cuadrados Grados de Libertad Media F Valor-p Regresi\u00f3n 14200 1 $(14200/1)=14200$ $(14200/191.25)=74.25$ 0 Error 1530 8 $(1530/8)=191.25$ Total 15730 9 FIGURA 14.7 Ejemplo de una aproximaci\u00f3n lineal para una relaci\u00f3n no lineal In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Funci\u00f3n no lineal cuadr\u00e1tica\ndef funcion_no_lineal(x):\n    return 2 * x**2 + 3 * x + 5 + np.random.normal(0, 5, size=x.shape)\n\n# Generar datos no lineales\nnp.random.seed(42)\nx_data = np.linspace(-5, 5, 100)\ny_data = funcion_no_lineal(x_data)\n\n# Aproximaci\u00f3n lineal usando polyfit\ngrado_aproximacion = 1  # Grado 1 para la aproximaci\u00f3n lineal\ncoeficientes_aproximacion = np.polyfit(x_data, y_data, grado_aproximacion)\n\n# Calcular valores aproximados\ny_aproximado = np.polyval(coeficientes_aproximacion, x_data)\n\n# Graficar resultados\nplt.figure(figsize=(10, 6))\n\n# Datos no lineales\nplt.scatter(x_data, y_data, label='Datos no lineales', color='#009929')\n\n# Aproximaci\u00f3n lineal\nplt.plot(x_data, y_aproximado, label=f'Aproximaci\u00f3n lineal (grado {grado_aproximacion})', color='#009929')\n\nplt.title('Aproximaci\u00f3n Lineal para una Relaci\u00f3n No Lineal')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.legend()\nplt.grid(True)\nplt.gca().set_facecolor('#D4F8B7')  # Color de fondo\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  # Funci\u00f3n no lineal cuadr\u00e1tica def funcion_no_lineal(x):     return 2 * x**2 + 3 * x + 5 + np.random.normal(0, 5, size=x.shape)  # Generar datos no lineales np.random.seed(42) x_data = np.linspace(-5, 5, 100) y_data = funcion_no_lineal(x_data)  # Aproximaci\u00f3n lineal usando polyfit grado_aproximacion = 1  # Grado 1 para la aproximaci\u00f3n lineal coeficientes_aproximacion = np.polyfit(x_data, y_data, grado_aproximacion)  # Calcular valores aproximados y_aproximado = np.polyval(coeficientes_aproximacion, x_data)  # Graficar resultados plt.figure(figsize=(10, 6))  # Datos no lineales plt.scatter(x_data, y_data, label='Datos no lineales', color='#009929')  # Aproximaci\u00f3n lineal plt.plot(x_data, y_aproximado, label=f'Aproximaci\u00f3n lineal (grado {grado_aproximacion})', color='#009929')  plt.title('Aproximaci\u00f3n Lineal para una Relaci\u00f3n No Lineal') plt.xlabel('X') plt.ylabel('Y') plt.legend() plt.grid(True) plt.gca().set_facecolor('#D4F8B7')  # Color de fondo plt.show()  <p>La aproximaci\u00f3n lineal proporcionada por $ \\hat{y} = b_0 + b_1x $ es buena en el rango de los valores de $ x $ observados en la muestra, pero se vuelve deficiente para valores de $ x $ fuera de ese rango.</p> <p>Dada una relaci\u00f3n significativa, la ecuaci\u00f3n de regresi\u00f3n estimada se puede usar con confianza para predicciones correspondientes a valores de $ x $ dentro del rango de los valores de $ x $ observados en la muestra. En el ejemplo de Armand\u2019s Pizza Parlors, este rango corresponde a los valores de $ x $ entre 2 y 26. A menos que haya otras razones que indiquen que el modelo es v\u00e1lido m\u00e1s all\u00e1 de este rango, las predicciones fuera del rango de la variable independiente deben realizarse con cuidado.</p> <p>En el ejemplo de Armand\u2019s Pizza Parlors, como se ha encontrado que la relaci\u00f3n de regresi\u00f3n es significativa al nivel de significancia de 0.01, se puede tener confianza de usarla para predecir las ventas de restaurantes en los que la poblaci\u00f3n de estudiantes correspondiente est\u00e9 en el intervalo de 2,000 a 26,000.</p> Estimaci\u00f3n puntual <p>En el ejemplo de Armand\u2019s Pizza Parlors, la ecuaci\u00f3n de regresi\u00f3n estimada $ \\hat{y} = 60 + 5x $ proporciona una estimaci\u00f3n de la relaci\u00f3n entre el tama\u00f1o de la poblaci\u00f3n de estudiantes $ x $ y las ventas trimestrales $ y $. Con la ecuaci\u00f3n de regresi\u00f3n estimada, se puede obtener una estimaci\u00f3n puntual del valor medio de $ y $ correspondiente a un determinado valor de $ x $, o se puede predecir el valor individual de $ y $ que corresponde a un valor determinado de $ x $. Por ejemplo, supongamos que los gerentes de Armand\u2019s desean una estimaci\u00f3n puntual de la media de las ventas trimestrales de todos los restaurantes que se encuentren cerca de campus universitarios con 10,000 estudiantes. Usando la ecuaci\u00f3n de regresi\u00f3n estimada $ \\hat{y} = 60 + 5x $, con $ x = 10 $ (o 10,000 estudiantes), obtenemos $ \\hat{y} = 60 + 5(10) = 110 $. Por lo tanto, una estimaci\u00f3n puntual de la media de las ventas trimestrales de todos los restaurantes de este ejemplo con 10,000 estudiantes es $110,000.</p> <p>Ahora supongamos que los gerentes de Armand\u2019s desean predecir las ventas de un determinado restaurante ubicado cerca de Talbot College, una escuela con 10,000 alumnos. En este caso, lo que interesa no es la media correspondiente a todos los restaurantes que est\u00e1n cerca de campus con 10,000 estudiantes, sino \u00fanicamente predecir las ventas trimestrales de uno en espec\u00edfico. En realidad, la estimaci\u00f3n puntual de un solo valor de $ y $ es igual a la estimaci\u00f3n puntual de la media de los valores de $ y $. As\u00ed, la predicci\u00f3n de las ventas trimestrales de este restaurante en particular ser\u00e1 $ \\hat{y} = 60 + 5(10) = 110 $ o $110,000.</p> estimacion por intervalo <p>Las estimaciones puntuales no proporcionan informaci\u00f3n alguna acerca de la precisi\u00f3n de una estimaci\u00f3n. Para eso es necesario obtener estimaciones por intervalo que son muy parecidas a las estudiadas en los cap\u00edtulos 8, 10 y 11. El primer tipo de estimaci\u00f3n por intervalo, el intervalo de confianza es una estimaci\u00f3n del valor medio de las y que corresponden a un valor dado de x. El segundo tipo, el intervalo de predicci\u00f3n, se usa cuando se necesita una estimaci\u00f3n por intervalo de un solo valor de y para un valor dado de x. La estimaci\u00f3n puntual del valor medio de y es igual a la estimaci\u00f3n puntual de un solo valor de y. Pero las estimaciones por intervalo que se obtienen para estos dos casos son diferentes. En un intervalo de predicci\u00f3n el margen de error es mayor.</p> Intervalo de confianza para el valor medio de y <p>Con la ecuaci\u00f3n de regresi\u00f3n estimada se obtiene una estimaci\u00f3n puntual del valor medio de $ y $ que corresponde a un valor dado de $ x $. Para desarrollar un intervalo de confianza se usa la notaci\u00f3n siguiente.</p> <ul> <li>$ x_p $: valor particular o determinado de la variable independiente $ x $</li> <li>$ y_p $: valor de la variable dependiente $ y $ que corresponde al valor dado $ x_p $</li> <li>$ E(y_p) $: valor medio o valor esperado de la variable dependiente $ y $ que corresponde al valor dado $ x_p $</li> <li>$ \\hat{y}_p $: $ b_0 + b_1x_p $, estimaci\u00f3n puntual de $ E(y_p) $ cuando $ x = x_p $</li> </ul> <p>Empleando esta notaci\u00f3n para estimar la media de las ventas de todos los restaurantes de Armand\u2019s que se encuentran cerca de un campus con 10,000 estudiantes, tenemos que $ x_p = 10 $, y $E(y_p) $ denota el valor medio desconocido de las ventas de todos los restaurantes para los que $ x_p = 10 $. La estimaci\u00f3n puntual de $ E(y_p) $ est\u00e1 dada por $ \\hat{y}_p = 60 + 5(10) = 110 $.</p> <p>En general, no se puede esperar que $ \\hat{y}_p $ sea exactamente igual a $ E(y_p) $. Para hacer una inferencia acerca de qu\u00e9 tan cerca est\u00e1 $ \\hat{y}_p $ de la media verdadera $ E(y_p) $, es necesario estimar la varianza de $ \\hat{y}_p $. La f\u00f3rmula para estimar la varianza de $ \\hat{y}_p $ para un $ x_p $ dado se denota como $ s^2_{\\hat{y}_p} $ y es</p>  $$ s^2_{\\hat{y}_p} = s^2 \\left(\\frac{1}{n}  + \\frac{(x_p - \\bar{x})^2}{\\sum (x_i - \\bar{x})^2} \\right) $$ <p>(14.22)</p> La estimaci\u00f3n de la desviaci\u00f3n est\u00e1ndar de $ \\hat{y}_p $ est\u00e1 dada por la ra\u00edz cuadrada de la ecuaci\u00f3n (14.22). $$ s_{\\hat{y}_p} = s \\sqrt{\\frac{1}{n} \\left(1 + \\frac{(x_p - \\bar{x})^2}{\\sum (x_i - \\bar{x})^2} \\right)} $$ <p>(14.23)</p> <p>En los resultados calculados en la secci\u00f3n 14.5 para el ejemplo de Armand\u2019s Pizza Parlors se tiene $ s = 13.829 $. Como $ x_p = 10 $, $ \\bar{x} = 14 $, y $ \\sum (x_i - \\bar{x})^2 = 568 $, usando la ecuaci\u00f3n (14.23) se obtiene:</p> <p>$ s_{\\hat{y}_p} = 13.829 \\sqrt{\\frac{1}{10} \\left(1 + \\frac{(10 - 14)^2}{568} \\right)} $</p> <p>$ s_{\\hat{y}_p} = 13.829 \\cdot \\sqrt{0.1282} \\approx 4.95 $</p> <p>A continuaci\u00f3n, se presenta la f\u00f3rmula general para obtener un intervalo de confianza.</p> $ \\text{INTERVALO DE CONFIANZA PARA } E(y_p) :$ $\\quad \\hat{y}_p \\pm t_{\\alpha/2} s_{\\hat{y}_p} $  <p>(14.24)</p> donde el coeficiente de confianza es $1 - \\alpha$ y $t_{\\alpha/2}$ se basa en una distribuci\u00f3n t con $n - 2$ grados de libertad.   <p>Para obtener, con la f\u00f3rmula (14.24), un intervalo de 95% de confianza para la media de las ventas trimestrales de todos los restaurantes Armand\u2019s ubicados cerca de campus con 10,000 estudiantes, se necesita el valor de t para $ \\alpha/2 = 0.025 $ y $ n - 2 = 10 - 2 = 8 $ grados de libertad. En la tabla 2 del ap\u00e9ndice B se encuentra $ t_{0.025} = 2.306 $. Por tanto, como $ \\hat{y}_p = 110 $ y el margen de error de $ t_{\\alpha/2}s_{\\hat{y}_p} = 2.306 \\cdot 4.95 = 11.415 $, la estimaci\u00f3n del intervalo de 95% de confianza es $$ 110 \\pm 11.415 $$.</p> <p>En d\u00f3lares, el intervalo de 95% de confianza para la media de las ventas trimestrales de todos los restaurantes que se encuentran cerca de un campus con 10,000 estudiantes es $110,000 \u00b1 $11,415. As\u00ed, el intervalo de confianza del 95% para la media de las ventas trimestrales cuando el tama\u00f1o de la poblaci\u00f3n es 10,000 es de $98,585 a $121,415.</p> <p>Observe que la desviaci\u00f3n est\u00e1ndar estimada de $ \\hat{y}_p $ dada por la ecuaci\u00f3n (14.23) es menor cuando $ x_p = x $ y la cantidad $ x_p - x = 0 $. En este caso, la desviaci\u00f3n est\u00e1ndar estimada de $ \\hat{y}_p $ se convierte en:</p> <p>$ s_{\\hat{y}_p} = \\frac{s}{\\sqrt{n}} $</p> <p>Este resultado implica que se obtiene la mejor o m\u00e1s precisa estimaci\u00f3n del valor medio de $ y $ cuando $ x_p = x $. De hecho, entre m\u00e1s alejado est\u00e9 $ x_p $ de $ x $, mayor ser\u00e1 $ x_p - x $. Como resultado, los intervalos de confianza para el valor medio de $ y $ son m\u00e1s amplios a medida que $ x_p $ se aleja de $ x $. En la figura 14.8 se muestra gr\u00e1fic</p> <p>$$ s_{\\hat{y}_p} = s \\sqrt{\\frac{1}{n}+ \\left( \\frac{(x_p - \\bar{x})^2}{\\sum (x_i - \\bar{x})^2} \\right)}$$</p> <p>$$s\\sqrt{\\frac{1}{n}}$$</p> <p>Este resultado implica que se obtiene la mejor o m\u00e1s precisa estimaci\u00f3n del valor medio de $ y $ cuando $ x_p = x $. De hecho, entre m\u00e1s alejado est\u00e9 $ x_p $ de $ x $, mayor ser\u00e1 $ x_p - x $. Como resultado, los intervalos de confianza para el valor medio de $ y $ son m\u00e1s amplios a medida que $ x_p $ se aleja de $ x $. En la figura 14.8 se muestra gr\u00e1ficamente este patr\u00f3n.</p> Intervalo de predicci\u00f3n para un solo valor de y <p>Suponga que, en lugar del valor medio de las ventas de todos los restaurantes Armand\u2019s que se encuentran cerca de campus con 10,000 estudiantes, se busque estimar las ventas de un solo restaurante que se encuentra cerca de Talbot College, una escuela de 10,000 alumnos. Como ya se indic\u00f3, la estimaci\u00f3n puntual de $ y_p $, el valor de $ y $ que corresponde a un valor dado $ x_p $, se obtiene</p> <p>mediante la ecuaci\u00f3n de regresi\u00f3n estimada $ \\hat{y}_p = b_0 + b_1x_p $. En el caso del establecimiento de Talbot College, como $ x_p = 10 $, las ventas trimestrales pronosticadas ser\u00e1n $ \\hat{y}_p = 60 - 5(10) = 110 $ o $110,000. Observa que este valor es el mismo que el obtenido como estimaci\u00f3n puntual de la media de las ventas en todos los restaurantes que se encuentran cerca de campus con 10,000 estudiantes.</p> <p>Para obtener un intervalo de predicci\u00f3n, es necesario determinar primero la varianza correspondiente al uso de $ \\hat{y}_p $ como estimaci\u00f3n de un valor individual de $ y $ cuando $ x = x_p $. Esta varianza est\u00e1 formada por la suma de los dos componentes siguientes:</p> <ol> <li>La varianza de los valores individuales de $ y $ respecto de la media $ E(y_p) $, para la cual una estimaci\u00f3n est\u00e1 dada por $ s^2 $.</li> <li>La varianza correspondiente al uso de $ \\hat{y}_p $ para estimar $ E(y_p) $, para la cual una estimaci\u00f3n est\u00e1 dada por $ s^2_{\\hat{y}_p} $.</li> </ol> <p>La f\u00f3rmula para estimar la varianza de un valor individual de $ y_p $, que se denota como $ s^2_{\\text{ind}} $, es</p> <p>$ s^2_{\\text{ind}} = {s^2}{+ s^2_{\\hat{y}_p}} $</p> <p>$ s^2 = {s^2}+{s + (\\frac{1}{n} \\left( \\frac{(x_p - \\bar{x})^2}{\\sum (x_i - \\bar{x})^2} \\right)}) $</p> $s^2(1 + \\frac{1}{n} + \\frac{(x_p - \\bar{x})^2}{\\sum{(x_i - \\bar{x})^2}})$  <p>(14.25)</p> Por tanto, una estimaci\u00f3n de la desviaci\u00f3n est\u00e1ndar de un solo valor de $y_p$ est\u00e1 dada por      $ s^2_{\\text{ind}} =s^2\\sqrt{(1 + \\frac{1}{n} + \\frac{(x_p - \\bar{x})^2}{\\sum{(x_i - \\bar{x})^2}}})$  <p>(14.26)</p> <p>En el ejemplo de Armand\u2019s Pizza Parlors, la desviaci\u00f3n est\u00e1ndar estimada que corresponde a la predicci\u00f3n de las ventas de un determinado restaurante ubicado cerca de un campus con 10 000 estudiantes se calcula como sigue</p> <p>$ s^2_{\\text{ind}} =s^2(\\sqrt{(1 + \\frac{1}{10} + \\frac{(10-14)^2}{568}})$</p> <p>$=13.829(\\sqrt{1.1282})$</p> <p>=14.69 La f\u00f3rmula general para un intervalo de predicci\u00f3n es la siguiente.</p> INTERVALO DE PREDICCI\u00d3N PARA $y_p$       $$\\hat{y}_p \\pm t_{\\frac{\\alpha}{2}} \\cdot s_{ind}$$  <p>(14.27)</p> donde el coeficiente de confianza es \\(1 - \\alpha\\) y \\(t_{\\frac{\\alpha}{2}}\\) se basa en una distribuci\u00f3n t con \\(n - 2\\) grados de libertad.   <p>El intervalo de predicci\u00f3n de 95% de las ventas trimestrales del restaurante de Talbot College se encuentra usando $t_{0.025} = 2.306$ y $s_{ind} = 14.69$. Por tanto, con $\\hat{y}_p = 110$ y un margen de error de $t_{\\frac{\\alpha}{2}} \\cdot s_{ind} = 2.306 \\cdot 14.69 = 33.875$, el intervalo de predicci\u00f3n de 95% es $110 \\pm 33.875$.</p> <p>En d\u00f3lares, este intervalo de predicci\u00f3n es de $110,000 a $33,875 o de $76,125 a $143,875. Observa que el intervalo de predicci\u00f3n para un solo restaurante cerca de un campus con 10,000 estudiantes es m\u00e1s amplio que el intervalo de confianza para la media de las ventas de todos los restaurantes ubicados cerca de campus con 10,000 estudiantes. Esta diferencia refleja el hecho de que se puede estimar con m\u00e1s precisi\u00f3n la media de y que un solo valor de y.</p> <p>Tanto las estimaciones mediante un intervalo de confianza como mediante un intervalo de predicci\u00f3n son m\u00e1s precisas cuando el valor de la variable independiente es $x_p \\leq x$. En la figura 14.9 se muestra la forma general de los intervalos de confianza y de predicci\u00f3n que son m\u00e1s anchos.</p> The regression equation is Sales = 60.0 + 5.00 Pop              $Ecuaci\u00f3n de regresi\u00f3n estimada$ Predictor Coef SE Coef T p Constant 60.000 9.226 6.50 0.000 Pop 5.0000 0.5803 8.62 0.000 S = 13.8293 R-sq = 90.3% R-sq(adj) = 89.1% Analysis of Variance SOURCE DF SS MS F p                                      $Tabla de ANOVA$   Regression 1 14200 14200 74.25 0.000 Residual Error 8 1530 191 Total 9 15730 Predicted Values for New Observations New Obs Fit SE Fit 95% C.I. 95% P.I.                            $Estimaciones de intervalo$  1 110.00 4.95 (98.58, 121.42) (76.13, 143.87) <p>Minitab muestra el error est\u00e1ndar de estimaci\u00f3n, $s = 13.8293$, as\u00ed como informaci\u00f3n acerca de la bondad de ajuste. Observa que \u201cR-sq = 90.3%\u201d es el coeficiente de determinaci\u00f3n expresado como porcentaje. El valor \u201cR-sq(adj) = 89.1%\u201d se ver\u00e1 en el cap\u00edtulo 15.</p> <ol> <li><p>La tabla ANOVA se presenta bajo el encabezado \"Analysis of Variance\". Minitab usa la etiqueta \"Residual Error\" para la fuente de variaci\u00f3n del error. Observa que DF son las siglas de degrees of freedom (grados de libertad) y que el CMR est\u00e1 dado como $14,200$ y ECM como $191$. El cociente de estos dos valores proporciona el valor F, que es $74.25$, y el correspondiente valor-p es $0.000$. Como el valor-p es cero (a tres posiciones decimales), la relaci\u00f3n entre ventas (Sales) y poblaci\u00f3n (Pop) se considera estad\u00edsticamente significativa.</p> </li> <li><p>La estimaci\u00f3n de las ventas esperadas mediante un intervalo de confianza del 95% y la estimaci\u00f3n de las ventas de un determinado restaurante cercano a un campus de 10,000 estudiantes mediante un intervalo de predicci\u00f3n del 95% se presentan abajo de la tabla ANOVA. El intervalo de confianza es $(98.58, 121.42)$ y el intervalo de predicci\u00f3n es $(76.13, 143.88)$, como se mostr\u00f3 en la secci\u00f3n 14.6.</p> </li> </ol> 14.8 An\u00e1lisis de residuales: confirmaci\u00f3n <p>de los supuestos del modelo</p> Como ya se indic\u00f3, el residual de la observaci\u00f3n i es la diferencia entre el valor observado de la variable dependiente ($y_i$) y el valor estimado de la variable dependiente ($\\hat{y}_i$).   RESIDUAL DE LA OBSERVACI\u00d3N i       $$y_i - \\hat{y}_i$$  <p>(14.28)</p> donde: $y_i$ - valor observado de la variable dependiente $\\hat{y}_i$ - valor estimado de la variable dependiente <p>En otras palabras, el residual i-\u00e9simo es el error que resulta de usar la ecuaci\u00f3n de regresi\u00f3n estimada para predecir el valor de la variable dependiente. En la tabla 14.7 se calculan los residuales correspondientes a los datos del ejemplo de Armand\u2019s Pizza Parlors. En la segunda columna de la tabla se presentan los valores observados de la variable dependiente, y en la tercera los valores estimados de la variable dependiente obtenidos con la ecuaci\u00f3n de regresi\u00f3n estimada (\\hat{y} = 60 - 5x). Un an\u00e1lisis de los residuales correspondientes, en la cuarta columna de la tabla, ayuda a determinar si los supuestos acerca del modelo de regresi\u00f3n son adecuados.</p> <p>A continuaci\u00f3n se revisan los supuestos de regresi\u00f3n en el ejemplo de Armand\u2019s Pizza Parlors. Se supuso un modelo de regresi\u00f3n lineal simple:</p>        $ y = \\beta_0 + \\beta_1 x + \\epsilon\\ $  <p>(14.29)</p> TABLA 14.7 Residuales en el ejemplo de Armand\u2019s Pizza Parlors Poblaci\u00f3n de Estudiantes (xi) Ventas Observadas (yi) Ventas Estimadas (\\(\\hat{y}\\) = 60 + 5xi) Residuales (yi - \\(\\hat{y}\\)i) 2 58 70 \\( -12 \\) 6 105 90 15 8 88 100 \\( -12 \\) 8 118 100 18 12 117 120 \\( -3 \\) 16 137 140 \\( -3 \\) 20 157 160 \\( -3 \\) 20 169 160 9 22 149 170 \\( -21 \\) 26 202 190 12 <p>Este modelo indica que se supone que las ventas trimestrales ($y$) son la funci\u00f3n lineal del tama\u00f1o de la poblaci\u00f3n de estudiantes ($x$) m\u00e1s un t\u00e9rmino del error ($\\epsilon$). En la secci\u00f3n 14.4 se plantearon los siguientes supuestos para el t\u00e9rmino del error ($\\epsilon$):</p> <ol> <li>$E(\\epsilon) = 0$.</li> <li>La varianza de $\\epsilon$, que se denota $\\sigma^2$, es la misma para todos los valores de $x$.</li> <li>Los valores de $\\epsilon$ son independientes.</li> <li>El t\u00e9rmino del error $\\epsilon$ tiene una distribuci\u00f3n normal.</li> </ol> <p>Estos supuestos constituyen la base te\u00f3rica para las pruebas t y F que se usan para determinar si la relaci\u00f3n entre $x$ y $y$ es significativa, y para las estimaciones de los intervalos de confianza y de predicci\u00f3n presentadas en la secci\u00f3n 14.6. Si los supuestos sobre el t\u00e9rmino del error $\\epsilon$ son dudosos, quiz\u00e1 las pruebas de hip\u00f3tesis acerca de la significancia de la relaci\u00f3n de regresi\u00f3n y los resultados de la estimaci\u00f3n por intervalo no sean v\u00e1lidos.</p> <p>Los residuales proporcionan la mejor informaci\u00f3n de $\\epsilon$; por tanto, su an\u00e1lisis es muy importante para determinar si los supuestos planteados acerca de $\\epsilon$ son apropiados. Gran parte del an\u00e1lisis residual se basa en examinar gr\u00e1ficas. En esta secci\u00f3n se estudiar\u00e1n las siguientes gr\u00e1ficas de residuales:</p> <ol> <li>Una gr\u00e1fica de residuales contra los valores de la variable independiente $x$.</li> <li>Una gr\u00e1fica de residuales contra los valores pronosticados para la variable dependiente $\\hat{y}$.</li> <li>Una gr\u00e1fica de residuales estandarizada.</li> <li>Una gr\u00e1fica de probabilidad normal.</li> </ol> Gr\u00e1fica de residuales contra x <p>En la gr\u00e1fica de residuales contra la variable independiente $x$, los valores de esta variable se representan en el eje horizontal y los valores de los residuales correspondientes se presentan en el eje vertical. Para cada residual se grafica un punto. La primera coordenada de cada punto est\u00e1 dada por el valor $x_i$ y la segunda, por el correspondiente valor del residual $y_i - \\hat{y}_i$. En la gr\u00e1fica de residuales contra $x$ obtenida con los datos de Armand\u2019s Pizza Parlors de la tabla 14.7, las coordenadas del primer punto son (2, $-12$), que corresponden a $x_1 = 2$ y $y_1 - \\hat{y}_1 = -12$; las coordenadas del segundo punto son (6, 15), que corresponden a $x_2 = 6$ y $y_2 - \\hat{y}_2 = 15$, y as\u00ed sucesivamente. En la figura 14.11 se muestra la gr\u00e1fica de residuales obtenida.</p> <p>Antes de interpretar los resultados se considerar\u00e1n algunas formas generales que pueden adoptar las gr\u00e1ficas de residuales. En la figura 14.12 se muestran tres ejemplos. Si el supuesto de que la varianza de $\\epsilon$ es el mismo para todos los valores de $x$ y el modelo de regresi\u00f3n empleado representa adecuadamente la relaci\u00f3n entre las variables, el aspecto general de la gr\u00e1fica de residuales ser\u00e1 el de una banda horizontal de puntos como en A. Pero si la varianza de $\\epsilon$ no es la misma para todos los valores $x$ (por ejemplo, si la variabilidad respecto de la l\u00ednea de regresi\u00f3n es mayor para valores de $x$ mayores) el aspecto de la gr\u00e1fica puede ser como en B. En este caso se viola el supuesto de que $\\epsilon$ tiene una varianza constante. En C se muestra otra forma que puede tomar la gr\u00e1fica de residuales. En este caso, se concluye que el modelo de regresi\u00f3n empleado no representa adecuadamente la relaci\u00f3n entre las variables, y deber\u00e1 considerarse un modelo de regresi\u00f3n curvil\u00edneo o m\u00faltiple.</p> <p>Regresando a la gr\u00e1fica de los residuales del ejemplo de Armand\u2019s Pizza Parlors de la figura 14.11, estos residuales parecen tener una forma que se aproxima a la de la banda horizontal de la gr\u00e1fica A de la figura 14.12. Por tanto, concluimos que esta gr\u00e1fica no muestra evidencias de que los supuestos formulados para el modelo de regresi\u00f3n de Armand\u2019s puedan ser dudosos. Concluimos que el modelo de regresi\u00f3n lineal simple empleado es v\u00e1lido.</p> FIGURA 14.11 Gr\u00e1fica de residuales contra la variable independiente x para Armand\u2019s Pizza Parlor In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Datos\npoblacion_estudiantes = [2, 6, 8, 8, 12, 16, 20, 20, 22, 26]\nventas_observadas = [58, 105, 88, 118, 117, 137, 157, 169, 149, 202]\nventas_estimadas = [70, 90, 100, 100, 120, 140, 160, 160, 170, 190]\nresiduales = [-12, 15, -12, 18, -3, -3, -3, 9, -21, 12]\n\n# Gr\u00e1fica de residuales contra la variable independiente x\nplt.scatter(poblacion_estudiantes, residuales, color='#009929', label='Residuales')\nplt.axhline(0, color='#009929', linestyle='--', linewidth=1)  # L\u00ednea base en y=0\nplt.xlabel('Poblaci\u00f3n de Estudiantes (x)')\nplt.ylabel('Residuales')\nplt.title('Gr\u00e1fica de Residuales contra la Variable Independiente x\\n(Armand\u2019s Pizza Parlors)')\nplt.legend()\n\n# Configuraci\u00f3n del color de fondo\nax = plt.gca()\nax.set_facecolor('#D4F8B7')\n\nplt.grid(True)\nplt.show()\n</pre> import matplotlib.pyplot as plt  # Datos poblacion_estudiantes = [2, 6, 8, 8, 12, 16, 20, 20, 22, 26] ventas_observadas = [58, 105, 88, 118, 117, 137, 157, 169, 149, 202] ventas_estimadas = [70, 90, 100, 100, 120, 140, 160, 160, 170, 190] residuales = [-12, 15, -12, 18, -3, -3, -3, 9, -21, 12]  # Gr\u00e1fica de residuales contra la variable independiente x plt.scatter(poblacion_estudiantes, residuales, color='#009929', label='Residuales') plt.axhline(0, color='#009929', linestyle='--', linewidth=1)  # L\u00ednea base en y=0 plt.xlabel('Poblaci\u00f3n de Estudiantes (x)') plt.ylabel('Residuales') plt.title('Gr\u00e1fica de Residuales contra la Variable Independiente x\\n(Armand\u2019s Pizza Parlors)') plt.legend()  # Configuraci\u00f3n del color de fondo ax = plt.gca() ax.set_facecolor('#D4F8B7')  plt.grid(True) plt.show()  <p>Para la adecuada interpretaci\u00f3n de las gr\u00e1fi cas de residuales, la experiencia y el criterio son muy importantes. Es raro que estas gr\u00e1fi cas tengan exactamente la forma de uno de los patrones mostrados en la fi gura 14.12. Sin embargo, los analistas que realizan frecuentemente estudios de regresi\u00f3n y gr\u00e1fi cas de residuales se vuelven expertos en reconocer las diferencias entre las formas razonables y las que indican que se puede dudar de los supuestos del modelo. Una gr\u00e1fi ca de residuales proporciona una t\u00e9cnica para evaluar la validez de los supuestos en un modelo de regresi\u00f3n.</p> Gr\u00e1fica de residuales contra $\\hat{y}$ <p>En otras gr\u00e1ficas de residuales, los valores pronosticados para la variable dependiente $\\hat{y}$ se representan en el eje horizontal y los valores de los residuales en el eje vertical. A cada residual corresponde un punto en la gr\u00e1fica. La primera coordenada de cada uno de los puntos est\u00e1 dada por $\\hat{y}_i$ y la segunda es el valor correspondiente del residual i-\u00e9simo, $y_i - \\hat{y}_i$. Con los datos de Armand\u2019s de la tabla 14.7, las coordenadas del primer punto son (70, $-12$), que corresponden a $\\hat{y}_1 = 70$ y $y_1 - \\hat{y}_1 = $-12; las coordenadas del segundo punto son (90, 15), y as\u00ed sucesivamente. En la figura 14.13 se presenta esta gr\u00e1fica de residuales. Observe que su forma es igual a la de la gr\u00e1fica de residuales contra la variable independiente $x$. Este no es un patr\u00f3n que pudiera llevar a dudar de los supuestos del modelo. En la regresi\u00f3n lineal simple, tanto la gr\u00e1fica de residuales contra $x$ como la gr\u00e1fica de residuales contra $\\hat{y}$ tienen la misma forma. En el an\u00e1lisis de regresi\u00f3n m\u00faltiple, la gr\u00e1fica de residuales contra $\\hat{y}$ se usa m\u00e1s debido a que se tiene m\u00e1s de una variable independiente.</p> Residuales estandarizados <p>Muchas gr\u00e1fi cas de residuales que se obtienen con software de computadora utilizan una versi\u00f3n estandarizada de los residuales. Como se demostr\u00f3 en el cap\u00edtulo anterior, una variable aleatoria se estandariza al sustraerle su media y dividir el resultado entre su desviaci\u00f3n est\u00e1ndar. Cuando se emplea el m\u00e9todo de m\u00ednimos cuadrados, la media de los residuales es cero. Por</p> FIGURA 14.12 Gr\u00e1fica de residuales de tres estudios de regresi\u00f3n In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Funci\u00f3n para crear un estudio de regresi\u00f3n\ndef create_regression_study(x, true_slope, true_intercept, residual_function):\n    y_true = true_slope * x + true_intercept\n    residuals = residual_function(x)\n    y_observed = y_true + residuals\n    return y_observed, residuals\n\n# Estudio 1: Patr\u00f3n Adecuado\nnp.random.seed(42)\nx1 = np.linspace(0, 10, 100)\nresidual_function1 = lambda x: np.random.normal(0, 2, len(x))\ny1_observed, residuals1 = create_regression_study(x1, 2, 1, residual_function1)\n\n# Estudio 2: Varianza No Constante\nx2 = np.linspace(0, 10, 100)\nresidual_function2 = lambda x: np.random.normal(0, x, len(x))\ny2_observed, residuals2 = create_regression_study(x2, 2, 1, residual_function2)\n\n# Estudio 3: Forma No Adecuada\nx3 = np.linspace(0, 10, 100)\nresidual_function3 = lambda x: 3 * np.sin(x) + np.random.normal(0, 2, len(x))\ny3_observed, residuals3 = create_regression_study(x3, 2, 1, residual_function3)\n\n# Gr\u00e1fica de Residuales para los Tres Estudios\nfig, axes = plt.subplots(3, 1, figsize=(8, 12))\n\n# Configuraci\u00f3n del color de fondo\nfor ax in axes:\n    ax.set_facecolor('#D4F8B7')\n\n# Estudio 1\naxes[0].scatter(x1, residuals1, color='#009929', label='Residuales Estudio 1')\naxes[0].axhline(0, color='#009929', linestyle='--', linewidth=1)\naxes[0].set_title('Estudio 1: Patr\u00f3n Adecuado')\n\n# Estudio 2\naxes[1].scatter(x2, residuals2, color='#009929', label='Residuales Estudio 2')\naxes[1].axhline(0, color='#009929', linestyle='--', linewidth=1)\naxes[1].set_title('Estudio 2: Varianza No Constante')\n\n# Estudio 3\naxes[2].scatter(x3, residuals3, color='#009929', label='Residuales Estudio 3')\naxes[2].axhline(0, color='#009929', linestyle='--', linewidth=1)\naxes[2].set_title('Estudio 3: Forma No Adecuada')\n\nplt.xlabel('Variable Independiente (x)')\nplt.ylabel('Residuales')\nplt.tight_layout()\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  # Funci\u00f3n para crear un estudio de regresi\u00f3n def create_regression_study(x, true_slope, true_intercept, residual_function):     y_true = true_slope * x + true_intercept     residuals = residual_function(x)     y_observed = y_true + residuals     return y_observed, residuals  # Estudio 1: Patr\u00f3n Adecuado np.random.seed(42) x1 = np.linspace(0, 10, 100) residual_function1 = lambda x: np.random.normal(0, 2, len(x)) y1_observed, residuals1 = create_regression_study(x1, 2, 1, residual_function1)  # Estudio 2: Varianza No Constante x2 = np.linspace(0, 10, 100) residual_function2 = lambda x: np.random.normal(0, x, len(x)) y2_observed, residuals2 = create_regression_study(x2, 2, 1, residual_function2)  # Estudio 3: Forma No Adecuada x3 = np.linspace(0, 10, 100) residual_function3 = lambda x: 3 * np.sin(x) + np.random.normal(0, 2, len(x)) y3_observed, residuals3 = create_regression_study(x3, 2, 1, residual_function3)  # Gr\u00e1fica de Residuales para los Tres Estudios fig, axes = plt.subplots(3, 1, figsize=(8, 12))  # Configuraci\u00f3n del color de fondo for ax in axes:     ax.set_facecolor('#D4F8B7')  # Estudio 1 axes[0].scatter(x1, residuals1, color='#009929', label='Residuales Estudio 1') axes[0].axhline(0, color='#009929', linestyle='--', linewidth=1) axes[0].set_title('Estudio 1: Patr\u00f3n Adecuado')  # Estudio 2 axes[1].scatter(x2, residuals2, color='#009929', label='Residuales Estudio 2') axes[1].axhline(0, color='#009929', linestyle='--', linewidth=1) axes[1].set_title('Estudio 2: Varianza No Constante')  # Estudio 3 axes[2].scatter(x3, residuals3, color='#009929', label='Residuales Estudio 3') axes[2].axhline(0, color='#009929', linestyle='--', linewidth=1) axes[2].set_title('Estudio 3: Forma No Adecuada')  plt.xlabel('Variable Independiente (x)') plt.ylabel('Residuales') plt.tight_layout() plt.show()  FIGURA 14.13 Gr\u00e1fica de residuales contra los valores pronosticados de y\u02c6 para Armand\u2019s Pizza Parlors In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Datos\npoblacion_estudiantes = [2, 6, 8, 8, 12, 16, 20, 20, 22, 26]\nventas_observadas = [58, 105, 88, 118, 117, 137, 157, 169, 149, 202]\nventas_estimadas = [70, 90, 100, 100, 120, 140, 160, 160, 170, 190]\nresiduales = [-12, 15, -12, 18, -3, -3, -3, 9, -21, 12]\n\n# Gr\u00e1fica de residuales contra la variable independiente x\nplt.scatter(poblacion_estudiantes, residuales, color='#009929', label='Residuales')\nplt.axhline(0, color='#009929', linestyle='--', linewidth=1)  # L\u00ednea base en y=0\nplt.xlabel('Poblaci\u00f3n de Estudiantes (x)')\nplt.ylabel('Residuales')\nplt.title('Gr\u00e1fica de Residuales contra la Variable Independiente x\\n(Armand\u2019s Pizza Parlors)')\nplt.legend()\n\n# Configuraci\u00f3n del color de fondo\nax = plt.gca()\nax.set_facecolor('#D4F8B7')\n\nplt.grid(True)\nplt.show()\n</pre> import matplotlib.pyplot as plt  # Datos poblacion_estudiantes = [2, 6, 8, 8, 12, 16, 20, 20, 22, 26] ventas_observadas = [58, 105, 88, 118, 117, 137, 157, 169, 149, 202] ventas_estimadas = [70, 90, 100, 100, 120, 140, 160, 160, 170, 190] residuales = [-12, 15, -12, 18, -3, -3, -3, 9, -21, 12]  # Gr\u00e1fica de residuales contra la variable independiente x plt.scatter(poblacion_estudiantes, residuales, color='#009929', label='Residuales') plt.axhline(0, color='#009929', linestyle='--', linewidth=1)  # L\u00ednea base en y=0 plt.xlabel('Poblaci\u00f3n de Estudiantes (x)') plt.ylabel('Residuales') plt.title('Gr\u00e1fica de Residuales contra la Variable Independiente x\\n(Armand\u2019s Pizza Parlors)') plt.legend()  # Configuraci\u00f3n del color de fondo ax = plt.gca() ax.set_facecolor('#D4F8B7')  plt.grid(True) plt.show() <p>Por consiguiente, para obtener el residual estandarizado, solo es necesario dividir cada residual entre su desviaci\u00f3n est\u00e1ndar.</p> <p>Se puede demostrar que la desviaci\u00f3n est\u00e1ndar del residual i depende del error est\u00e1ndar de la estimaci\u00f3n s y del valor correspondiente de la variable independiente $x_i$.</p> <p>Desviaci\u00f3n Est\u00e1ndar del Residual i-\u00e9simo:</p> <p>$$ \\text{sy}_i = \\frac{y_i - \\hat{y}_i}{s \\sqrt{1 - h_i}} $$</p> Desviaci\u00f3n Est\u00e1ndar del Residual i-\u00e9simo:       $$ \\text{sy}_i = s \\sqrt{1 - h_i} $$  <p>(14.30)</p> $s_{(y_i - \\hat{y}_i)}$=desviaci\u00f3n est\u00e1ndar del residual i s =error est\u00e1ndar de estimaci\u00f3n $h_i = \\frac{1}{n} + \\frac{(x_i - \\bar{x})^2}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2} $ <p>(14.31)</p> <p>Observa que la ecuaci\u00f3n (14.30) indica que la desviaci\u00f3n est\u00e1ndar del residual i-\u00e9simo depende de $x_i$ debido a la presencia de $h_i$ en la f\u00f3rmula. Una vez determinada la desviaci\u00f3n est\u00e1ndar de cada uno de los residuales, se pueden calcular los residuales estandarizados al dividir cada residual entre sus desviaciones est\u00e1ndar correspondientes.</p> TABLA 14.8 C\u00e1lculo de los residuales estandarizados del ejemplo de Armand\u2019s Pizza Parlors Restaurante i xi xi-xpromedio (xi-xpromedio)^2 (xi-xpromedio)^2/sumatoria(xi-xpromedio)^2 hi s_(y_i-yhat_i) Residuales Estandarizados 1 2 12 144 0.2535 0.3535 11.1193 1.0792 2 6 8 64 0.1127 0.2127 12.2709 1.2224 3 8 6 36 0.0634 0.1634 12.6493 0.9487 4 8 6 36 0.0634 0.1634 12.6493 1.4230 5 12 2 4 0.0070 0.1070 13.0682 0.2296 6 16 2 4 0.0070 0.1070 13.0682 0.2296 7 20 6 36 0.0634 0.1634 12.6493 0.2372 8 20 6 36 0.0634 0.1634 12.6493 0.7115 9 22 8 64 0.1127 0.2127 12.2709 1.7114 10 26 12 144 0.2535 0.3535 11.1193 1.0792 RESIDUAL ESTANDARIZADO DE LA OBSERVACI\u00d3N i       $$s_{yi} = \\frac{y_i - \\hat{y}_i}{s_{(y_i - \\hat{y}_i)}}$$  <p>(14.32)</p> <p>En la tabla 14.8 se presentan los c\u00e1lculos de los residuales estandarizados con el ejemplo de Armand\u2019s Pizza Parlors. Recuerde que ya en c\u00e1lculos previos se obtuvo $ s = 13.829 $. La figura 14.14 es la gr\u00e1fica de los residuales estandarizados contra la variable independiente $ x $. Esta gr\u00e1fica permite ver si es correcto el supuesto de que el t\u00e9rmino del error $ \\varepsilon $ tiene distribuci\u00f3n normal. Si este supuesto se satisface, debe parecer que la distribuci\u00f3n de los residuales estandarizados proviene de una distribuci\u00f3n de probabilidad normal est\u00e1ndar. Por tanto, al observar la gr\u00e1fica de los residuales estandarizados se espera encontrar que aproximadamente el 95% de ellos est\u00e9 entre 2 y $ -2 $. En la figura 14.14 vemos que en el ejemplo de Armand\u2019s todos los residuales estandarizados se encuentran entre 2 y $ -2 $. As\u00ed, con base en los residuales estandarizados, esta gr\u00e1fica no da razones para dudar del supuesto de que $ \\varepsilon $ tiene una distribuci\u00f3n normal.</p> <p>Debido al esfuerzo que significa calcular los valores estimados de $ \\hat{y} $, los residuales y los residuales estandarizados, la mayor\u00eda de los paquetes para estad\u00edstica proporcionan, de manera opcional, estos datos como parte de los resultados de la regresi\u00f3n. Por tanto, las gr\u00e1ficas de residuales se pueden obtener con facilidad. Trat\u00e1ndose de problemas grandes, el software de computadora es la \u00fanica opci\u00f3n pr\u00e1ctica para obtener las gr\u00e1ficas de residuales analizadas en esta secci\u00f3n.</p> Gr\u00e1fica de probabilidad normal <p>Otro enfoque para determinar la validez del supuesto de que el t\u00e9rmino del error tiene una distribuci\u00f3n normal es la gr\u00e1fica de probabilidad normal. Para mostrar c\u00f3mo se elabora, se presenta el concepto de puntos normales. Suponga que se toman aleatoriamente 10 valores de una distribuci\u00f3n de probabilidad normal donde la media es cero y la desviaci\u00f3n est\u00e1ndar es uno, y este proceso de muestreo se repite una y otra vez con los 10 valores de cada muestra ordenados de menor a mayor. Por ahora,</p> FIGURA 14.14 Gr\u00e1fica de residuales estandarizados contra la variable independiente x, obtenida con los datos de Armand\u2019s Pizza Parlors. In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Datos\npoblacion_estudiantes = [2, 6, 8, 8, 12, 16, 20, 20, 22, 26]\nventas_observadas = [58, 105, 88, 118, 117, 137, 157, 169, 149, 202]\nventas_estimadas = [70, 90, 100, 100, 120, 140, 160, 160, 170, 190]\nresiduales = [-12, 15, -12, 18, -3, -3, -3, 9, -21, 12]\n\n# Gr\u00e1fica de residuales contra la variable independiente x\nplt.scatter(poblacion_estudiantes, residuales, color='#009929', label='Residuales')\nplt.axhline(0, color='#009929', linestyle='--', linewidth=1)  # L\u00ednea base en y=0\nplt.xlabel('Poblaci\u00f3n de Estudiantes (x)')\nplt.ylabel('Residuales')\nplt.title('Gr\u00e1fica de Residuales')\nplt.legend()\n\n# Configuraci\u00f3n del color de fondo\nax = plt.gca()\nax.set_facecolor('#D4F8B7')\n\nplt.grid(True)\nplt.show()\n</pre> import matplotlib.pyplot as plt  # Datos poblacion_estudiantes = [2, 6, 8, 8, 12, 16, 20, 20, 22, 26] ventas_observadas = [58, 105, 88, 118, 117, 137, 157, 169, 149, 202] ventas_estimadas = [70, 90, 100, 100, 120, 140, 160, 160, 170, 190] residuales = [-12, 15, -12, 18, -3, -3, -3, 9, -21, 12]  # Gr\u00e1fica de residuales contra la variable independiente x plt.scatter(poblacion_estudiantes, residuales, color='#009929', label='Residuales') plt.axhline(0, color='#009929', linestyle='--', linewidth=1)  # L\u00ednea base en y=0 plt.xlabel('Poblaci\u00f3n de Estudiantes (x)') plt.ylabel('Residuales') plt.title('Gr\u00e1fica de Residuales') plt.legend()  # Configuraci\u00f3n del color de fondo ax = plt.gca() ax.set_facecolor('#D4F8B7')  plt.grid(True) plt.show() <p>Considerando \u00fanicamente el valor menor de cada muestra, la variable aleatoria que representa el valor menor de estos diversos muestreos se le conoce como estad\u00edstico de primer orden.</p> <p>Los expertos en estad\u00edstica han demostrado que, en muestras de tama\u00f1o 10 tomadas de una distribuci\u00f3n de probabilidad normal est\u00e1ndar, el valor esperado del estad\u00edstico de primer orden es 1.55. A este valor esperado se le conoce como punto normal. En el caso de una muestra de tama\u00f1o $ n = 10 $, hay 10 estad\u00edsticos de orden y 10 puntos normales (vea la tabla 14.9). En general, un conjunto de datos que conste de $ n $ observaciones tendr\u00e1 $ n $ estad\u00edsticos de orden y por tanto $ n $ puntos normales.</p> <p>A continuaci\u00f3n vemos el uso de estos 10 puntos normales para determinar si los residuales estandarizados de Armand\u2019s Pizza Parlors aparentemente provienen de una distribuci\u00f3n de probabilidad normal est\u00e1ndar. Para empezar, se ordenan los 10 residuales estandarizados de la tabla 14.8. En la tabla 14.10 se presentan juntos los 10 puntos normales y los residuales estandarizados ordenados. Si se satisface el supuesto de normalidad, el menor residual estandarizado deber\u00e1 tener un valor parecido al del menor punto normal, el siguiente residual deber\u00e1 tener un valor similar al del siguiente punto normal, y as\u00ed sucesivamente. En el caso en que los residuales estandarizados se encuentren distribuidos de una manera aproximadamente normal, en una gr\u00e1fica en la que los puntos normales correspondan al eje horizontal y los residuales estandarizados al eje vertical, los puntos estar\u00e1n situados cerca de una l\u00ednea recta de 45 grados que pase por el origen. A esta gr\u00e1fica se le conoce como gr\u00e1fica de probabilidad normal.</p> <p>La figura 14.15 ilustra la gr\u00e1fica de probabilidad normal del ejemplo de Armand\u2019s Pizza Parlors. Para determinar si el patr\u00f3n observado se desv\u00eda lo suficiente de la recta como para concluir que los residuales estandarizados no provienen de una distribuci\u00f3n de probabilidad normal, habr\u00e1 que emplear el propio criterio. En la figura, todos los puntos se agrupan cerca de esta recta. Se concluye, por tanto, que el supuesto de que los t\u00e9rminos del error tienen una distribuci\u00f3n de probabilidad normal es razonable. En general, entre m\u00e1s cerca de la recta a 45\u00b0 se agrupen los puntos, m\u00e1s fuerte es la evidencia a favor del supuesto de normalidad. Cualquier curvatura sustancial en la gr\u00e1fica es evidencia de que los residuales no provienen de una distribuci\u00f3n normal. Tanto los puntos normales como la correspondiente gr\u00e1fica de probabilidad normal pueden obtenerse f\u00e1cilmente empleando software como Minitab.</p> In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.stats import norm\n\n# Datos de los residuales estandarizados\nresiduales_estandarizados = [1.0792, 1.2224, 0.9487, 1.4230, 0.2296, 0.2296, 0.2372, 0.7115, 1.7114, 1.0792]\n\n# Ordenar los residuales estandarizados\nresiduales_estandarizados.sort()\n\n# Crear puntos normales te\u00f3ricos\npuntos_normales = norm.ppf(np.linspace(0, 1, len(residuales_estandarizados)))\n\n# Graficar\nplt.figure(figsize=(8, 6))\nplt.scatter(puntos_normales, residuales_estandarizados, color='#009929', label='Residuales Estandarizados')\nplt.plot([-2, 2], [-2, 2], linestyle='--', color='#009929', label='L\u00ednea de 45 grados')\n\n# Configuraci\u00f3n de la gr\u00e1fica\nplt.title('Gr\u00e1fica de Probabilidad Normal - Armand\u2019s Pizza Parlors')\nplt.xlabel('Puntos Normales Te\u00f3ricos')\nplt.ylabel('Residuales Estandarizados')\nplt.legend()\nplt.grid(True, linestyle='--', alpha=0.6)\nplt.axhline(0, color='black',linewidth=0.5)\nplt.axvline(0, color='black',linewidth=0.5)\n\n# Mostrar la gr\u00e1fica\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np from scipy.stats import norm  # Datos de los residuales estandarizados residuales_estandarizados = [1.0792, 1.2224, 0.9487, 1.4230, 0.2296, 0.2296, 0.2372, 0.7115, 1.7114, 1.0792]  # Ordenar los residuales estandarizados residuales_estandarizados.sort()  # Crear puntos normales te\u00f3ricos puntos_normales = norm.ppf(np.linspace(0, 1, len(residuales_estandarizados)))  # Graficar plt.figure(figsize=(8, 6)) plt.scatter(puntos_normales, residuales_estandarizados, color='#009929', label='Residuales Estandarizados') plt.plot([-2, 2], [-2, 2], linestyle='--', color='#009929', label='L\u00ednea de 45 grados')  # Configuraci\u00f3n de la gr\u00e1fica plt.title('Gr\u00e1fica de Probabilidad Normal - Armand\u2019s Pizza Parlors') plt.xlabel('Puntos Normales Te\u00f3ricos') plt.ylabel('Residuales Estandarizados') plt.legend() plt.grid(True, linestyle='--', alpha=0.6) plt.axhline(0, color='black',linewidth=0.5) plt.axvline(0, color='black',linewidth=0.5)  # Mostrar la gr\u00e1fica plt.show()  14.9 An\u00e1lisis de residuales: observaciones at\u00edpicas <p>y observaciones influyentes </p> En la secci\u00f3n 14.8 se mostr\u00f3 c\u00f3mo emplear el an\u00e1lisis de residuales para determinar violaciones a los supuestos del modelo de regresi\u00f3n. En esta secci\u00f3n se retoma este an\u00e1lisis para identifi car observaciones que se pueden clasifi car como at\u00edpicas o como especialmente infl uyentes sobre la ecuaci\u00f3n de regresi\u00f3n estimada. Tambi\u00e9n se analizan algunos pasos que deben seguirse cuando se presentan tales observaciones.  Detecci\u00f3n de observaciones at\u00edpicas <p>La figura 14.16 es un diagrama de dispersi\u00f3n de un conjunto de datos que contiene una observaci\u00f3n at\u00edpica, un dato (una observaci\u00f3n) que no sigue la tendencia del resto de los datos. Las observaciones at\u00edpicas representan observaciones sospechosas que requieren un an\u00e1lisis cuidadoso. Pueden consistir en datos err\u00f3neos; si es as\u00ed, deben corregirse. Tambi\u00e9n puede tratarse de una violaci\u00f3n a los supuestos del modelo; en ese caso, habr\u00e1 que considerar otro modelo. Por \u00faltimo, pueden ser simplemente valores inusuales que se presentan por casualidad. En este caso, esos valores deber\u00e1n conservarse.</p> <p>Para ilustrar el proceso de detecci\u00f3n de las observaciones at\u00edpicas, considere el conjunto de datos de la tabla 14.11; la figura 14.17 muestra el diagrama de dispersi\u00f3n respectivo. Con excepci\u00f3n de la observaci\u00f3n 4 (x4  3, y4  75), estos datos parecen seguir un patr\u00f3n que indica una relaci\u00f3n lineal negativa. De hecho, dado el patr\u00f3n del resto de los datos, se esperar\u00eda que y4 fuera mucho m\u00e1s peque\u00f1o, por lo que a esta observaci\u00f3n se le considera at\u00edpica. En el caso de la regresi\u00f3n lineal simple, las observaciones at\u00edpicas pueden detectarse mediante un simple examen del diagrama de dispersi\u00f3n.</p> <p>Para detectar observaciones at\u00edpicas tambi\u00e9n se usan los residuales estandarizados. Si una observaci\u00f3n se aleja mucho del patr\u00f3n del resto de los datos (por ejemplo, la observaci\u00f3n at\u00edpica de la figura 14.16), el valor absoluto del correspondiente residual estandarizado ser\u00e1 grande.</p> <p>Mucho del software identifi ca de manera autom\u00e1tica las observaciones cuyos residuales tienen un valor absoluto grande. En la fi gura 14.18 se presentan los resultados de Minitab para el an\u00e1lisis de regresi\u00f3n de los datos de la tabla 14.11. En la pen\u00faltima fi la se lee que el residual estandarizado de la observaci\u00f3n 4 es 2.67. Minitab proporciona una lista de todas las observaciones cuyo residual estandarizado sea menor a 2 o mayor a \u00042 en la secci\u00f3n Unusual Observations de la pantalla; en tales casos la observaci\u00f3n aparece en una fi la aparte con una R al lado del residual estandarizado, como se observa en la fi gura 14.18. Si los errores est\u00e1n distribuidos normalmente, s\u00f3lo 5% de los residuales estandarizados se encontrar\u00e1 fuera de estos l\u00edmites. Para decidir qu\u00e9 hacer con una observaci\u00f3n at\u00edpica, primero hay que verifi car si es correcta. Puede ser que se trate de un error incurrido al anotar los datos o al ingresarlos a la computadora. Suponga, por ejemplo, que al verifi car la observaci\u00f3n at\u00edpica de la fi gura 14.17, se encuentra que hubo un error; el valor correcto de la observaci\u00f3n 4 es x4  3, y4  30. En la fi - gura 14.19 se presenta el resultado que proporciona Minitab una vez corregido el valor de y4.</p> FIGURA 14.18 Resultado de Minitab para el an\u00e1lisis de regresi\u00f3n de un conjunto de datos con una observaci\u00f3n at\u00edpica    The regression equation is y = 65.0 - 7.33 x Predictor Coef SE Coef T p Constant 64.958 9.258 7.02 0.000 X -7.331 2.608 -2.81 0.023 S = 12.6704 R-sq = 49.7% R-sq(adj) = 43.4% Analysis of Variance SOURCE DF SS MS F p Regression 1 1268.2 1268.2 7.90 0.023 Residual Error 8 1284.3 160.5 Total 9 2552.5 Unusual Observations Obs x y Fit SE Fit Residual St Resid  4 3.00 75.00 42.97 4.04 32.03 2.67R R denotes an observation with a large standardized residual. FIGURA 14.19 Resultados de Minitab para un conjunto de datos con una observaci\u00f3n at\u00edpica ya corregida    The regression equation is Y = 59.2 - 6.95 X Predictor Coef SE Coef T p Constant 59.237 3.835 15.45 0.000 X -6.949 1.080 -6.43 0.000 S = 5.24808 R-sq = 83.8% R-sq(adj) = 81.8% Analysis of Variance SOURCE DF SS MS F p Regression 1 1139.7 1139.7 41.38 0.000 Residual Error 8 220.3 27.5 Total 9 1360.0  residual. <p>Se observa que el dato incorrecto afecta de forma significativa la bondad de ajuste. Con el dato correcto, el valor de R-sq aumenta de 49.7% a 83.8%, y el de b0 disminuye de 64.958 a 59.237. La pendiente de la recta cambia de 7.331 a 6.949. La identificaci\u00f3n de los datos at\u00edpicos permite corregir errores y mejora los resultados de la regresi\u00f3n.</p> Detecci\u00f3n de observaciones influyentes <p>A veces una o m\u00e1s observaciones tienen una influencia significativa sobre los resultados. En la figura 14.20 se muestra un ejemplo de una observaci\u00f3n influyente en una regresi\u00f3n lineal simple. La recta de regresi\u00f3n estimada tiene pendiente negativa, pero si la observaci\u00f3n influyente se elimina del conjunto de datos, la pendiente cambia a positiva y la intersecci\u00f3n con el eje y es menor. Es claro que esta sola observaci\u00f3n tiene mucha m\u00e1s influencia sobre la recta de regresi\u00f3n estimada que cualquiera otra; el efecto de la eliminaci\u00f3n de cualquiera de las otras observaciones sobre la ecuaci\u00f3n de regresi\u00f3n estimada es muy peque\u00f1o.</p> <p>Cuando solo se tiene una variable independiente, las observaciones influyentes pueden identificarse mediante un diagrama de dispersi\u00f3n. Una observaci\u00f3n de este tipo puede ser at\u00edpica (cuyo valor de y se desv\u00eda sustancialmente de la tendencia general), puede ser un valor de x muy alejado de la media (por ejemplo, vea la figura 14.20) o tratarse de la combinaci\u00f3n de estos dos factores (un valor de y algo fuera de la tendencia y un valor de x un poco extremo).</p> <p>Las observaciones influyentes deben examinarse con cuidado, dado el gran efecto que tienen sobre la ecuaci\u00f3n de regresi\u00f3n estimada. Lo primero que hay que hacer es verificar que no se haya cometido alg\u00fan error al recolectar los datos. Si se cometi\u00f3, se corrige y se obtiene una nueva ecuaci\u00f3n de regresi\u00f3n estimada. Si la observaci\u00f3n es v\u00e1lida, podemos considerarnos afortunados. Tal dato, cuando es correcto, contribuye a una mejor comprensi\u00f3n del modelo adecuado y conduce a una mejor ecuaci\u00f3n de regresi\u00f3n estimada. En la figura 14.20, la presencia de la observaci\u00f3n influyente, si es correcta, llevar\u00e1 a tratar de obtener datos con valores x intermedios que permitan comprender mejor la relaci\u00f3n entre x y y.</p> <p>Las observaciones en las que la variable independiente toma valores extremos se denominan puntos (datos, observaciones) de gran influencia. La observaci\u00f3n influyente de la figura 14.20 es un punto de gran influencia. La influencia de una observaci\u00f3n depende de qu\u00e9 tan lejos est\u00e1 el valor de la variable independiente de su media. En el caso de una sola variable independiente, la influencia de la observaci\u00f3n i, que se denota hi, se calcula mediante la ecuaci\u00f3n (14.33).</p> INFLUENCIA DE LA OBSERVACI\u00d3N i       $$h_i = \\frac{1}{n} + \\frac{(x_i - \\bar{x})^2}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}$$  <p>(14.33)</p> <p>Con base en esta f\u00f3rmula, es claro que entre m\u00e1s alejada se encuentre $x_i$ de su media $\\bar{x}$, mayor ser\u00e1 la influencia de la observaci\u00f3n $i$.</p> <p>Mucho del software para estad\u00edstica identifica autom\u00e1ticamente los puntos de gran influencia como parte de los resultados de regresi\u00f3n est\u00e1ndar. Para ilustrar c\u00f3mo Minitab identifica los puntos de gran influencia, se considerar\u00e1 el conjunto de datos de la tabla 14.12.</p> FIGURA 14.21 Diagrama de dispersi\u00f3n del conjunto de datos con un punto de gran influencia In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Datos de ejemplo\nx = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\ny = [2, 3, 5, 8, 11, 15, 20, 25, 30, 35]\n\n# \u00cdndice del punto de gran influencia\nindice_punto_influencia = 4\n\n# Configuraci\u00f3n del gr\u00e1fico\nplt.figure(figsize=(8, 6))\nplt.scatter(x, y, color='#009929', label='Datos')\n\n# Destacar el punto de gran influencia\nplt.scatter(x[indice_punto_influencia], y[indice_punto_influencia], color='red', label='Punto de Gran Influencia')\n\n# Configuraci\u00f3n adicional\nplt.title('Diagrama de Dispersi\u00f3n con Punto de Gran Influencia')\nplt.xlabel('Variable Independiente')\nplt.ylabel('Variable Dependiente')\nplt.legend()\nplt.grid(True)\n\n# Configuraci\u00f3n del color de fondo\nplt.gca().set_facecolor('#D4F8B7')\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import matplotlib.pyplot as plt  # Datos de ejemplo x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] y = [2, 3, 5, 8, 11, 15, 20, 25, 30, 35]  # \u00cdndice del punto de gran influencia indice_punto_influencia = 4  # Configuraci\u00f3n del gr\u00e1fico plt.figure(figsize=(8, 6)) plt.scatter(x, y, color='#009929', label='Datos')  # Destacar el punto de gran influencia plt.scatter(x[indice_punto_influencia], y[indice_punto_influencia], color='red', label='Punto de Gran Influencia')  # Configuraci\u00f3n adicional plt.title('Diagrama de Dispersi\u00f3n con Punto de Gran Influencia') plt.xlabel('Variable Independiente') plt.ylabel('Variable Dependiente') plt.legend() plt.grid(True)  # Configuraci\u00f3n del color de fondo plt.gca().set_facecolor('#D4F8B7')  # Mostrar el gr\u00e1fico plt.show()  <p>Al revisar la figura 14.21, que es el diagrama de dispersi\u00f3n del conjunto de datos presentado en la tabla 14.12, vemos que la observaci\u00f3n 7 (x 70, y 100) tiene un valor extremo de x. Por tanto, es de esperarse que sea identificado como un punto de gran influencia. La influencia de esta observaci\u00f3n se calcula usando la ecuaci\u00f3n (14.33) como sigue.</p> <p>$$ h_7 = \\frac{1}{n} \\left( \\frac{(x_7 - \\bar{x})^2}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2} \\right) = \\frac{1}{7} \\left( \\frac{(70 - 24.286)^2}{2621.43} \\right) \\approx 0.94 $$</p> <p>En el caso de la regresi\u00f3n lineal simple, Minitab identifica como observaciones de gran influencia aquellas para las que $ h_i &gt; 6/n $ o $ 0.99 $, lo que sea menor. En el conjunto de datos de la tabla 14.12, $ 6/n = 6/7 \\approx 0.86 $. Como $ h_7 = 0.94 &gt; 0.86 $, Minitab identificar\u00e1 la observaci\u00f3n 7 como una observaci\u00f3n cuyo valor de x tiene una gran influencia. En la figura 14.22 se presenta el resultado que proporciona Minitab para el an\u00e1lisis de regresi\u00f3n de este conjunto de datos. A la 7 (x 70, y 100) la identifica como una observaci\u00f3n de gran influencia y la presenta en una fila especial en la parte inferior de los resultados con una X en el margen derecho.</p> <p>Las observaciones influyentes debido a la interacci\u00f3n de una observaci\u00f3n de gran influencia y de residuales grandes suelen ser dif\u00edciles de detectar. Existen procedimientos de diagn\u00f3stico que toman en cuenta ambos aspectos para determinar si una observaci\u00f3n es influyente. En el cap\u00edtulo 15 se estudiar\u00e1 uno de estos procedimientos, el estad\u00edstico D de Cook.</p> FIGURA 14.22 Resultado de Minitab para el conjunto de datos con una observaci\u00f3n de gran influencia    The regression equation is y = 127 - 0.425 x Predictor Coef SE Coef T p Constant 127.466 2.961 43.04 0.000 X -0.42507 0.09537 -4.46 0.007 S = 4.88282 R-sq = 79.9% R-sq(adj) = 75.9% Analysis of Variance SOURCE DF SS MS F p Regression 1 473.65 473.65 19.87 0.007 Residual Error 5 119.21 23.84 Total 6 592.86 Unusual Observations Obs x y Fit SE Fit Residual St Resid  7 70.0 100.00 97.71 4.73 2.29 1.91 X X denotes an observation whose X value gives it large influence. In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Funci\u00f3n para crear un estudio de regresi\u00f3n\ndef create_regression_study(x, true_slope, true_intercept, residual_function):\n    y_true = true_slope * x + true_intercept\n    residuals = residual_function(x)\n    y_observed = y_true + residuals\n    return y_observed, residuals\n\n# Estudio 1: Patr\u00f3n Adecuado\nnp.random.seed(42)\nx1 = np.linspace(0, 10, 100)\nresidual_function1 = lambda x: np.random.normal(0, 2, len(x))\ny1_observed, residuals1 = create_regression_study(x1, 2, 1, residual_function1)\n\n# Estudio 2: Varianza No Constante\nx2 = np.linspace(0, 10, 100)\nresidual_function2 = lambda x: np.random.normal(0, x, len(x))\ny2_observed, residuals2 = create_regression_study(x2, 2, 1, residual_function2)\n\n# Estudio 3: Forma No Adecuada\nx3 = np.linspace(0, 10, 100)\nresidual_function3 = lambda x: 3 * np.sin(x) + np.random.normal(0, 2, len(x))\ny3_observed, residuals3 = create_regression_study(x3, 2, 1, residual_function3)\n\n# Gr\u00e1fica de Residuales para los Tres Estudios\nfig, axes = plt.subplots(3, 1, figsize=(8, 12))\n\n# Configuraci\u00f3n del color de fondo\nfor ax in axes:\n    ax.set_facecolor('#D4F8B7')\n\n# Estudio 1\naxes[0].scatter(x1, residuals1, color='#009929', label='Residuales Estudio 1')\naxes[0].axhline(0, color='#009929', linestyle='--', linewidth=1)\naxes[0].set_title('Estudio 1: Patr\u00f3n Adecuado')\n\n# Estudio 2\naxes[1].scatter(x2, residuals2, color='#009929', label='Residuales Estudio 2')\naxes[1].axhline(0, color='#009929', linestyle='--', linewidth=1)\naxes[1].set_title('Estudio 2: Varianza No Constante')\n\n# Estudio 3\naxes[2].scatter(x3, residuals3, color='#009929', label='Residuales Estudio 3')\naxes[2].axhline(0, color='#009929', linestyle='--', linewidth=1)\naxes[2].set_title('Estudio 3: Forma No Adecuada')\n\nplt.xlabel('Variable Independiente (x)')\nplt.ylabel('Residuales')\nplt.tight_layout()\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  # Funci\u00f3n para crear un estudio de regresi\u00f3n def create_regression_study(x, true_slope, true_intercept, residual_function):     y_true = true_slope * x + true_intercept     residuals = residual_function(x)     y_observed = y_true + residuals     return y_observed, residuals  # Estudio 1: Patr\u00f3n Adecuado np.random.seed(42) x1 = np.linspace(0, 10, 100) residual_function1 = lambda x: np.random.normal(0, 2, len(x)) y1_observed, residuals1 = create_regression_study(x1, 2, 1, residual_function1)  # Estudio 2: Varianza No Constante x2 = np.linspace(0, 10, 100) residual_function2 = lambda x: np.random.normal(0, x, len(x)) y2_observed, residuals2 = create_regression_study(x2, 2, 1, residual_function2)  # Estudio 3: Forma No Adecuada x3 = np.linspace(0, 10, 100) residual_function3 = lambda x: 3 * np.sin(x) + np.random.normal(0, 2, len(x)) y3_observed, residuals3 = create_regression_study(x3, 2, 1, residual_function3)  # Gr\u00e1fica de Residuales para los Tres Estudios fig, axes = plt.subplots(3, 1, figsize=(8, 12))  # Configuraci\u00f3n del color de fondo for ax in axes:     ax.set_facecolor('#D4F8B7')  # Estudio 1 axes[0].scatter(x1, residuals1, color='#009929', label='Residuales Estudio 1') axes[0].axhline(0, color='#009929', linestyle='--', linewidth=1) axes[0].set_title('Estudio 1: Patr\u00f3n Adecuado')  # Estudio 2 axes[1].scatter(x2, residuals2, color='#009929', label='Residuales Estudio 2') axes[1].axhline(0, color='#009929', linestyle='--', linewidth=1) axes[1].set_title('Estudio 2: Varianza No Constante')  # Estudio 3 axes[2].scatter(x3, residuals3, color='#009929', label='Residuales Estudio 3') axes[2].axhline(0, color='#009929', linestyle='--', linewidth=1) axes[2].set_title('Estudio 3: Forma No Adecuada')  plt.xlabel('Variable Independiente (x)') plt.ylabel('Residuales') plt.tight_layout() plt.show()  In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Datos\npoblacion_estudiantes = [2, 6, 8, 8, 12, 16, 20, 20, 22, 26]\nventas_observadas = [58, 105, 88, 118, 117, 137, 157, 169, 149, 202]\nventas_estimadas = [70, 90, 100, 100, 120, 140, 160, 160, 170, 190]\nresiduales = [-12, 15, -12, 18, -3, -3, -3, 9, -21, 12]\n\n# Gr\u00e1fica de residuales contra la variable independiente x\nplt.scatter(poblacion_estudiantes, residuales, color='#009929', label='Residuales')\nplt.axhline(0, color='#009929', linestyle='--', linewidth=1)  # L\u00ednea base en y=0\nplt.xlabel('Poblaci\u00f3n de Estudiantes (x)')\nplt.ylabel('Residuales')\nplt.title('Gr\u00e1fica de Residuales contra la Variable Independiente x\\n(Armand\u2019s Pizza Parlors)')\nplt.legend()\n\n# Configuraci\u00f3n del color de fondo\nax = plt.gca()\nax.set_facecolor('#D4F8B7')\n\nplt.grid(True)\nplt.show()\n</pre> import matplotlib.pyplot as plt  # Datos poblacion_estudiantes = [2, 6, 8, 8, 12, 16, 20, 20, 22, 26] ventas_observadas = [58, 105, 88, 118, 117, 137, 157, 169, 149, 202] ventas_estimadas = [70, 90, 100, 100, 120, 140, 160, 160, 170, 190] residuales = [-12, 15, -12, 18, -3, -3, -3, 9, -21, 12]  # Gr\u00e1fica de residuales contra la variable independiente x plt.scatter(poblacion_estudiantes, residuales, color='#009929', label='Residuales') plt.axhline(0, color='#009929', linestyle='--', linewidth=1)  # L\u00ednea base en y=0 plt.xlabel('Poblaci\u00f3n de Estudiantes (x)') plt.ylabel('Residuales') plt.title('Gr\u00e1fica de Residuales contra la Variable Independiente x\\n(Armand\u2019s Pizza Parlors)') plt.legend()  # Configuraci\u00f3n del color de fondo ax = plt.gca() ax.set_facecolor('#D4F8B7')  plt.grid(True) plt.show()  In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> SUMA DE CUADRADOS DEBIDO AL ERROR       $SCE = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$  <p>(14.8)</p> FIGURA 9.1 Distribuci\u00f3n de muestreo de x en el estudio de \"Caf\u00e9 Sierra\" cuando la hip\u00f3tesis nula es verdadera como igualdad (\u03bc = 3)  ESTADISTICO DE PRUEBA EN LAS PRUEBAS DE HIPOTESIS PARA LA MEDIA POBLACIONAL: $\\sigma$ DESCONOCIDA \\(\\large t = \\frac{\\bar{x} - \\mu}{s/\\sqrt{n}}\\) RESIDUAL DE LA OBSERVACI\u00d3N i       $$y_i - \\hat{y}_i$$  <p>(14.28)</p> donde: $y_i$ - valor observado de la variable dependiente $\\hat{y}_i$ - valor estimado de la variable dependiente In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"capitulo14/#141-modelo-de-regresion-lineal-simple-desconocida","title":"14.1 Modelo de regresi\u00f3n lineal simple: \u03c3 desconocida\u00b6","text":"Armand\u2019s Pizza Parlors es una cadena de restaurantes de comida italiana que abarca un \u00e1rea de cinco estados. Las ubicaciones con mayor \u00e9xito se encuentran cerca de los campus universitarios. Los gerentes creen que las ventas trimestrales de estos restaurantes (denotadas por y) est\u00e1n directamente relacionadas con el tama\u00f1o de la poblaci\u00f3n estudiantil (denotada por x); es decir, en los establecimientos que est\u00e1n cerca de alg\u00fan campus con una poblaci\u00f3n estudiantil grande se generan m\u00e1s ventas que en aquellos situados cerca de alg\u00fan campus con una poblaci\u00f3n estudiantil peque\u00f1a. Empleando el an\u00e1lisis de regresi\u00f3n, se puede desarrollar una ecuaci\u00f3n que muestre cu\u00e1l es la relaci\u00f3n de la variable dependiente y con la variable independiente x."},{"location":"capitulo14/#142-metodo-de-minimos-cuadrados-desconocida","title":"14.2 M\u00e9todo de m\u00ednimos cuadrados: \u03c3 desconocida\u00b6","text":"El m\u00e9todo de m\u00ednimos cuadrados es un procedimiento en el que se usan los datos muestrales para encontrar la ecuaci\u00f3n de regresi\u00f3n estimada. Para ilustrar este m\u00e9todo, supongamos que se recolectan datos de una muestra de 10 restaurantes Armand\u2019s Pizza Parlors ubicados todos cerca de campus universitarios. Para la i-\u00e9sima observaci\u00f3n o restaurante en la muestra, $x_1$ es el tama\u00f1o de la poblaci\u00f3n de estudiantes (en miles) en el campus, y $y_1$ son las ventas trimestrales (en miles de d\u00f3lares). En la tabla 14.1 se presentan los valores de $x_1$ y $y_1$ en esta muestra de 10 restaurantes. Como se puede ver, el restaurante 1, con $x_1 = 2$ y $y_1 = 58$, est\u00e1 cerca de un campus con 2,000 estudiantes y sus ventas trimestrales son de bs58,000. El restaurante 2, con $x_2 = 6$ y $y_2 = 105$, est\u00e1 cerca de un campus con 6,000 estudiantes y sus ventas trimestrales son de bs105,000. El valor mayor corresponde a las ventas del restaurante 10, que est\u00e1 cerca de un campus con 26,000 estudiantes y sus ventas trimestrales son de bs202,000. La figura 14.3 es el diagrama de dispersi\u00f3n de los datos de la tabla 14.1. La poblaci\u00f3n de estudiantes (Student Population) se indica en el eje horizontal (en miles) y las ventas trimestrales (Quarterly Sales) en el eje vertical (en miles de bs). Los diagramas de dispersi\u00f3n para el an\u00e1lisis de regresi\u00f3n se trazan colocando la variable independiente $x$ en el eje horizontal y la variable dependiente $y$ en el eje vertical. Este diagrama permite observar gr\u00e1ficamente los datos y obtener conclusiones acerca de la relaci\u00f3n entre las variables. \u00bfQu\u00e9 conclusi\u00f3n preliminar se puede formular de la figura 14.3? Las ventas trimestrales parecen ser mayores cerca de los campus en los que la poblaci\u00f3n de estudiantes es m\u00e1s grande. Adem\u00e1s, en estos datos se observa que la relaci\u00f3n entre el tama\u00f1o de la poblaci\u00f3n y las ventas parece que puede aproximarse mediante una l\u00ednea recta; en efecto, se observa que hay una relaci\u00f3n lineal positiva entre x y y. As\u00ed, para representar la relaci\u00f3n entre las ventas trimestrales y la poblaci\u00f3n de estudiantes, se elige el modelo de regresi\u00f3n lineal simple. Decidido esto, la tarea siguiente es usar los datos muestrales de la tabla 14.1 para determinar los valores d$b_ b0 $b_b1 en la ecuaci\u00f3n de regresi\u00f3n lineal simple estimada. Para el restaurante i\u00e9simo, la ecuaci\u00f3n de regresi\u00f3n simple estimada esva que hay una rea re va que hay una re"},{"location":"capitulo14/#143-coeficiente-de-determinacion-desconocida","title":"14.3 coeficiente de determinacion: \u03c3 desconocida\u00b6","text":"En el ejemplo de Armand\u2019s Pizza Parlors, para aproximar la relaci\u00f3n lineal entre el tama\u00f1o de la poblaci\u00f3n de estudiantes *x* y las ventas trimestrales *y*, se desarroll\u00f3 la ecuaci\u00f3n de regresi\u00f3n estimada $ \\hat{y} = 60 + 5x $. Ahora la pregunta es: \u00bfqu\u00e9 tan bien se ajusta a los datos la ecuaci\u00f3n de regresi\u00f3n estimada? En esta secci\u00f3n se muestra que el coeficiente de determinaci\u00f3n proporciona una medida de la bondad de ajuste para la ecuaci\u00f3n de regresi\u00f3n estimada.  <p>A la diferencia que existe en la observaci\u00f3n $i$-\u00e9sima entre el valor observado de la variable dependiente $y_i$, y el valor estimado de la variable dependiente $\\hat{y}_i$, se le llama residual $i$-\u00e9simo. Este representa el error que existe al usar $\\hat{y}_i$ para estimar $y_i$. Por tanto, para la observaci\u00f3n $i$-\u00e9sima, el residual es $y_i - \\hat{y}_i$. La suma de los cuadrados de estos residuales o errores es la cantidad que se minimiza empleando el m\u00e9todo de los m\u00ednimos cuadrados. Esta cantidad, tambi\u00e9n conocida como suma de cuadrados debido al error, se denota como SCE.</p>"},{"location":"capitulo14/#144-supuestos-del-modelo","title":"14.4 Supuestos del modelo: \u00b6","text":"En un an\u00e1lisis de regresi\u00f3n se empieza por hacer un supuesto acerca del modelo apropiado para  la relaci\u00f3n entre las variables dependientes e independientes. En el caso de la regresi\u00f3n lineal simple, se supone que el modelo de regresi\u00f3n es"},{"location":"capitulo14/#145-prueba-de-significancia","title":"14.5 Prueba de significancia\u00b6","text":"En una ecuaci\u00f3n de regresi\u00f3n lineal simple, la media o valor esperado de $y$ es una funci\u00f3n lineal de $x$: $E(y) = \\beta_0 + \\beta_1x$. Pero si el valor de $\\beta_1$ es cero, $E(y) = \\beta_0 + (0)x = \\beta_0$. En este caso, el valor medio de $y$ no depende del valor de $x$, y por tanto, podemos concluir que $x$ e $y$ no est\u00e1n relacionadas linealmente. De manera alterna, si el valor de $\\beta_1$ es distinto de cero, se concluir\u00e1 que las dos variables est\u00e1n relacionadas. As\u00ed, para probar si existe una relaci\u00f3n de regresi\u00f3n significativa, se debe realizar una prueba de hip\u00f3tesis a efecto de determinar si el valor de $\\beta_1$ es distinto de cero. Hay dos pruebas que son las m\u00e1s usadas. En ambas se requiere una estimaci\u00f3n de $\\sigma^2$, la varianza de $\\varepsilon$ en el modelo de regresi\u00f3n."},{"location":"capitulo14/#metodo-del-valor-p","title":"M\u00e9todo del valor-p:\u00b6","text":"<p>Rechazar $H_0$ si el valor-p $ \\leq \\alpha $</p>"},{"location":"capitulo14/#metodo-del-valor-critico","title":"M\u00e9todo del valor cr\u00edtico:\u00b6","text":"<p>Rechazar $H_0$ si $t \\leq -t_{\\alpha/2}$ o si $t \\geq t_{\\alpha/2}$</p> <p>Donde $t_{\\alpha/2}$ se toma de la distribuci\u00f3n t con $n - 2$ grados de libertad.</p> <p>(14.19)</p>"},{"location":"capitulo14/#146-uso-de-la-ecuacion-de-regresion-estimada-para-estimacion-y-prediccion","title":"14.6 Uso de la ecuaci\u00f3n de regresi\u00f3n estimada para estimaci\u00f3n y predicci\u00f3n\u00b6","text":"Al usar el modelo de regresi\u00f3n lineal simple se hace un supuesto acerca de la relaci\u00f3n entre x y y. Despu\u00e9s se usa el m\u00e9todo de m\u00ednimos cuadrados para obtener una ecuaci\u00f3n de regresi\u00f3n lineal simple estimada. Si existe una relaci\u00f3n signifi cativa entre x y y, y el coefi ciente de determinaci\u00f3n indica que el ajuste es bueno, la ecuaci\u00f3n de regresi\u00f3n estimada es \u00fatil para estimaci\u00f3n y predicci\u00f3n."},{"location":"capitulo14/#147-solucion-por-computadora","title":"14.7 Soluci\u00f3n por computadora\u00b6","text":"Realizar los c\u00e1lculos del an\u00e1lisis de regresi\u00f3n sin la ayuda de una computadora puede requerir mucho tiempo. En esta secci\u00f3n se ver\u00e1 c\u00f3mo puede minimizarse la complicaci\u00f3n de tantos c\u00e1lculos usando software de Minitab.  <p>Los datos sobre poblaci\u00f3n de estudiantes y ventas de Armand\u2019s Pizza Parlors se han ingresado en la hoja de c\u00e1lculo de Minitab. A la variable independiente se le ha llamado Pop y a la variable dependiente Sales (ventas), para facilitar la interpretaci\u00f3n de los resultados que proporciona la computadora. Usando Minitab para el ejemplo de Armand\u2019s se obtuvieron los resultados que se muestran en la figura 14.10.2. A continuaci\u00f3n se explica c\u00f3mo interpretarlos.</p> <ol> <li><p>Minitab muestra la ecuaci\u00f3n de regresi\u00f3n estimada como Sales = 60.0 - 5.00 * Pop.</p> </li> <li><p>Presenta tambi\u00e9n una tabla en la que indica el valor de los coeficientes b0 y b1, la desviaci\u00f3n est\u00e1ndar de cada coeficiente, el valor t obtenido al dividir cada coeficiente entre su desviaci\u00f3n est\u00e1ndar y el valor-p correspondiente a la prueba t. Como el valor-p es cero (a tres posiciones decimales), los resultados muestrales indican que debe rechazarse la hip\u00f3tesis nula (H0: \u03b21 = 0). O bien, se puede comparar 8.62 (que aparece en la columna t) con el valor cr\u00edtico apropiado. Este procedimiento para la prueba t se describi\u00f3 en la secci\u00f3n 14.5.</p> </li> </ol>"},{"location":"capitulo2/","title":"Capitulo 2","text":"<p>Se introduce el concepto de distribuci\u00f3n de frecuencia, que es un resumen tabular de datos que muestra el n\u00famero de elementos en cada una de varias clases que no se superponen. Se presenta un ejemplo pr\u00e1ctico utilizando una muestra de bebidas refrescantes para ilustrar la elaboraci\u00f3n e interpretaci\u00f3n de una distribuci\u00f3n de frecuencia. Se resalta la importancia de comprender c\u00f3mo se elaboran y c\u00f3mo deben interpretarse los res\u00famenes tabulares y gr\u00e1ficos de los datos.</p> T\u00edtulo de la f\u00f3rmula                  $$ frecuencia = \\frac{frecuencia de la clase}{n} $$              (0.0) <p>La frecuencia porcentual es la frecuencia multiplicada por 100. Una distribuci\u00f3n de frecuencia relativa da un resumen tabular de los datos que indica la frecuencia de cada clase.</p> In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Datos para el gr\u00e1fico de barras\ncategorias = ['Capital nacional', 'Capital internacional', 'Renta FIja']\nvalores = [65, 15, 20]\n\n# Crear la figura y los ejes\nfig, ax = plt.subplots()\n\n# Ajustar el color de fondo\nax.set_facecolor(\"#d4f8b7\")\n# Pintar el fondo externo del gr\u00e1fico\nfig.patch.set_facecolor('#D4F8B7')\n\n# Crear el gr\u00e1fico de barras\nplt.bar(categorias, valores, color='#5CCB5f', edgecolor='black', linewidth=1.5, width=0.45)\n\n# A\u00f1adir etiquetas y t\u00edtulo con texto en negrita\nplt.xlabel('Tipo de Fondo', fontsize=10, fontweight='bold')\nplt.ylabel('Frecuencia Porcentual', fontsize=10, fontweight='bold')\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import matplotlib.pyplot as plt  # Datos para el gr\u00e1fico de barras categorias = ['Capital nacional', 'Capital internacional', 'Renta FIja'] valores = [65, 15, 20]  # Crear la figura y los ejes fig, ax = plt.subplots()  # Ajustar el color de fondo ax.set_facecolor(\"#d4f8b7\") # Pintar el fondo externo del gr\u00e1fico fig.patch.set_facecolor('#D4F8B7')  # Crear el gr\u00e1fico de barras plt.bar(categorias, valores, color='#5CCB5f', edgecolor='black', linewidth=1.5, width=0.45)  # A\u00f1adir etiquetas y t\u00edtulo con texto en negrita plt.xlabel('Tipo de Fondo', fontsize=10, fontweight='bold') plt.ylabel('Frecuencia Porcentual', fontsize=10, fontweight='bold')  # Mostrar el gr\u00e1fico plt.show() <p> Figura 2.1.1 Ejemplo de Barras Estadistica</p> In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport matplotlib.gridspec as gridspec\n\n# Datos para el gr\u00e1fico de pastel\nnombres = ['Coke Classic', 'Pepsi', 'Diet Coke', 'Dr. Pepper', 'Sprite']\nporcentajes = [38, 26, 16, 10, 10]\ncolores = ['#5ccb5f', '#98f84a', '#e1ffaf', '#fff', '#e1ffaf']\n\n# Crear el gr\u00e1fico de pastel sin bordes\nfig = plt.figure(figsize=(5, 5))\ngs = gridspec.GridSpec(1, 1, width_ratios=[1], height_ratios=[1])\nax = plt.subplot(gs[0])\n\nwedges, texts, autotexts = ax.pie(porcentajes, labels=None, autopct=lambda p: f'{p:.1f}%\\n{nombres.pop(0)}', colors=colores)\n\n# Agregar bordes negros a las porciones del gr\u00e1fico\nfor wedge in wedges:\n    wedge.set_edgecolor('black')\n    wedge.set_linewidth(1)\n\n# Configurar el color de fondo externo\nfig.patch.set_facecolor('#D4F8B7')\n\n# Centrar el gr\u00e1fico en la p\u00e1gina\nplt.tight_layout()\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import matplotlib.pyplot as plt import matplotlib.patches as patches import matplotlib.gridspec as gridspec  # Datos para el gr\u00e1fico de pastel nombres = ['Coke Classic', 'Pepsi', 'Diet Coke', 'Dr. Pepper', 'Sprite'] porcentajes = [38, 26, 16, 10, 10] colores = ['#5ccb5f', '#98f84a', '#e1ffaf', '#fff', '#e1ffaf']  # Crear el gr\u00e1fico de pastel sin bordes fig = plt.figure(figsize=(5, 5)) gs = gridspec.GridSpec(1, 1, width_ratios=[1], height_ratios=[1]) ax = plt.subplot(gs[0])  wedges, texts, autotexts = ax.pie(porcentajes, labels=None, autopct=lambda p: f'{p:.1f}%\\n{nombres.pop(0)}', colors=colores)  # Agregar bordes negros a las porciones del gr\u00e1fico for wedge in wedges:     wedge.set_edgecolor('black')     wedge.set_linewidth(1)  # Configurar el color de fondo externo fig.patch.set_facecolor('#D4F8B7')  # Centrar el gr\u00e1fico en la p\u00e1gina plt.tight_layout()  # Mostrar el gr\u00e1fico plt.show()    <p> Figura 2.1.2 Pastel Estadistico</p> <p>Se presentan diferentes m\u00e9todos para resumir datos cuantitativos, incluyendo la distribuci\u00f3n de frecuencia, distribuciones relativas y porcentuales, diagramas de puntos, histogramas, distribuciones acumuladas y ojivas. Se presentan ejemplos pr\u00e1cticos que involucran el an\u00e1lisis de precios de acciones, mostrando la aplicaci\u00f3n de estas t\u00e9cnicas en el \u00e1mbito econ\u00f3mico y empresarial. Se destaca la importancia de comprender y saber interpretar los m\u00e9todos tabulares y gr\u00e1ficos para resumir datos.</p> T\u00edtulo de la f\u00f3rmula                  $$ Ancho de la clase aproximado = \\frac{valor de los datos mayor-valor de datos menos}{numero de clases} $$              (0.0) <p>Ejemplo 1. </p> <p>En una tienda de autos, se registra la cantidad de autos Toyota vendidos en cada d\u00eda del mes de Setiembre.</p> <p>0; 1; 2; 1; 2; 0; 3; 2; 4; 0; 4; 2; 1; 0; 3; 0; 0; 3; 4; 2; 0; 1; 1; 3; 0; 1; 2; 1; 2; 3</p> <p>Con los datos obtenidos, elaborar una tabla de frecuencias.</p> <p>Soluci\u00f3n:</p> <p>En la primera columna, colocamos los valores de nuestra variable, en la segunda la frecuencia absoluta, luego la frecuencia acumulada, seguida por la frecuencia relativa, y finalmente la frecuencia relativa acumulada. Ahora vamos a agregar la columna de frecuencia porcentual, y frecuencia porcentual acumulada.</p> <p>Tabla 2.2.1</p> Autos vendidos Frecuencia absoluta Frecuencia acumulada Frecuencia relativa Frec. relativa acumulada Frecuencia porcentual Frec. porcentual acumulada 0 8 8 0,267 0,267 26,7% 26,7% 1 7 15 0,233 0,500 23,3% 50,0% 2 7 22 0,233 0,733 23,3% 73,3% 3 5 27 0,167 0,900 16,7% 90,0% 4 3 30 0,100 1 10,0% 100% Total 30 1 100% <p>Grafica: </p> In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport matplotlib.gridspec as gridspec\n\n# Datos para el gr\u00e1fico de pastel\nnombres = ['0 autos vendidos', '1 autos vendidos', '2 autos vendidos', '3 autos vendidos', '4 autos vendidos']\nporcentajes = [26.7,23.3,23.3,16.7,10.0]\ncolores = ['#5ccb5f', '#98f84a', '#e1ffaf', '#fff', '#e1ffaf']\n\n# Crear el gr\u00e1fico de pastel sin bordes\nfig = plt.figure(figsize=(5, 5))\ngs = gridspec.GridSpec(1, 1, width_ratios=[1], height_ratios=[1])\nax = plt.subplot(gs[0])\n\nwedges, texts, autotexts = ax.pie(porcentajes, labels=None, autopct=lambda p: f'{p:.1f}%\\n{nombres.pop(0)}', colors=colores)\n\n# Agregar bordes negros a las porciones del gr\u00e1fico\nfor wedge in wedges:\n    wedge.set_edgecolor('black')\n    wedge.set_linewidth(1)\n\n# Configurar el color de fondo externo\nfig.patch.set_facecolor('#D4F8B7')\n\n# Centrar el gr\u00e1fico en la p\u00e1gina\nplt.tight_layout()\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import matplotlib.pyplot as plt import matplotlib.patches as patches import matplotlib.gridspec as gridspec  # Datos para el gr\u00e1fico de pastel nombres = ['0 autos vendidos', '1 autos vendidos', '2 autos vendidos', '3 autos vendidos', '4 autos vendidos'] porcentajes = [26.7,23.3,23.3,16.7,10.0] colores = ['#5ccb5f', '#98f84a', '#e1ffaf', '#fff', '#e1ffaf']  # Crear el gr\u00e1fico de pastel sin bordes fig = plt.figure(figsize=(5, 5)) gs = gridspec.GridSpec(1, 1, width_ratios=[1], height_ratios=[1]) ax = plt.subplot(gs[0])  wedges, texts, autotexts = ax.pie(porcentajes, labels=None, autopct=lambda p: f'{p:.1f}%\\n{nombres.pop(0)}', colors=colores)  # Agregar bordes negros a las porciones del gr\u00e1fico for wedge in wedges:     wedge.set_edgecolor('black')     wedge.set_linewidth(1)  # Configurar el color de fondo externo fig.patch.set_facecolor('#D4F8B7')  # Centrar el gr\u00e1fico en la p\u00e1gina plt.tight_layout()  # Mostrar el gr\u00e1fico plt.show() <p>Ejemplo 2 </p> <p>Se le pidi\u00f3 a un grupo de personas que indiquen su color favorito, y se obtuvo los siguientes resultados:</p> <p>Tabla 2.2.2 </p> 1 2 3 4 5 1 Negro Azul Amarillo Rojo Azul 2 Azul Rojo Negro Amarillo Rojo 3 Rojo Amarillo Amarillo Azul Rojo 4 Negro Azul Rojo Negro Amarillo <p>Con los resultados obtenidos, elaborar una tabla de frecuencias.</p> <p>Soluci\u00f3n:</p> <p>En la primera columna, colocamos los valores de nuestra variable, en la segunda la frecuencia absoluta, luego la frecuencia acumulada, seguida por la frecuencia relativa, y finalmente la frecuencia relativa acumulada. Por ser el primer problema, no haremos uso de las frecuencias porcentuales.</p> <p>Tabla 2.2.3</p> Color Frecuencia absoluta Frecuencia acumulada Frecuencia relativa Frec. relativa acumulada Negro 4 4 0,20 0,20 Azul 5 9 0,25 0,45 Amarillo 5 14 0,25 0,70 Rojo 6 20 0,30 1 Total 20 1 <p>Grafica: </p> In\u00a0[2]: Copied! <pre>import matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport matplotlib.gridspec as gridspec\n\n# Datos para el gr\u00e1fico de pastel\nnombres = ['Negro', 'Azul', 'Amarillo', 'Rojo']\nporcentajes = [20,25,25,30]\ncolores = ['#5ccb5f', '#98f84a', '#e1ffaf', '#fff', '#e1ffaf']\n\n# Crear el gr\u00e1fico de pastel sin bordes\nfig = plt.figure(figsize=(5, 5))\ngs = gridspec.GridSpec(1, 1, width_ratios=[1], height_ratios=[1])\nax = plt.subplot(gs[0])\n\nwedges, texts, autotexts = ax.pie(porcentajes, labels=None, autopct=lambda p: f'{p:.1f}%\\n{nombres.pop(0)}', colors=colores)\n\n# Agregar bordes negros a las porciones del gr\u00e1fico\nfor wedge in wedges:\n    wedge.set_edgecolor('black')\n    wedge.set_linewidth(1)\n\n# Configurar el color de fondo externo\nfig.patch.set_facecolor('#D4F8B7')\n\n# Centrar el gr\u00e1fico en la p\u00e1gina\nplt.tight_layout()\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import matplotlib.pyplot as plt import matplotlib.patches as patches import matplotlib.gridspec as gridspec  # Datos para el gr\u00e1fico de pastel nombres = ['Negro', 'Azul', 'Amarillo', 'Rojo'] porcentajes = [20,25,25,30] colores = ['#5ccb5f', '#98f84a', '#e1ffaf', '#fff', '#e1ffaf']  # Crear el gr\u00e1fico de pastel sin bordes fig = plt.figure(figsize=(5, 5)) gs = gridspec.GridSpec(1, 1, width_ratios=[1], height_ratios=[1]) ax = plt.subplot(gs[0])  wedges, texts, autotexts = ax.pie(porcentajes, labels=None, autopct=lambda p: f'{p:.1f}%\\n{nombres.pop(0)}', colors=colores)  # Agregar bordes negros a las porciones del gr\u00e1fico for wedge in wedges:     wedge.set_edgecolor('black')     wedge.set_linewidth(1)  # Configurar el color de fondo externo fig.patch.set_facecolor('#D4F8B7')  # Centrar el gr\u00e1fico en la p\u00e1gina plt.tight_layout()  # Mostrar el gr\u00e1fico plt.show() <p>Ejercicio 3. </p> <p>Las notas de 35 alumnos en el examen final de estad\u00edstica, calificado del 0 al 10, son las siguientes:</p> <p>0; 0; 0; 0; 1; 1; 1; 1; 2; 2; 2; 3; 3; 3; 3; 4; 4; 4; 4; 5; 5; 5; 5; 6; 6; 6; 7; 7; 7; 8; 8; 8; 9; 10; 10.</p> <p>Con los datos obtenidos, elaborar una tabla de frecuencias con 5 intervalos o clases. Soluci\u00f3n:</p> <p>\u2022\tHallamos el rango: R = Xmax\u2013 Xmin = 10 \u2013 0 = 10.</p> <p>\u2022\tEl n\u00famero de intervalos (k), me lo da el enunciado del problema: k = 5.</p> <p>\u2022\tCalculamos la amplitud de clase: A = R/k = 10/5 = 2.</p> <p>\u2022\tAhora hallamos los l\u00edmites inferiores y superiores de cada clase, y elaboramos la tabla de frecuencias.</p> <p>Tabla 2.2.4</p> Intervalo Marca de clase Frecuencia absoluta Frecuencia acumulada Frecuencia relativa Frec. relativa acumulada [0 \u2013 2) 1 8 8 0,229 0,229 [2 \u2013 4) 3 7 15 0,200 0,429 [4 \u2013 6) 5 8 23 0,229 0,658 [6 \u2013 8) 7 6 29 0,171 0,829 [8 \u2013 10] 9 6 35 0,171 1 Total - 35 - 1 - <p>Grafica: </p> In\u00a0[3]: Copied! <pre>import matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport matplotlib.gridspec as gridspec\n\n# Datos para el gr\u00e1fico de pastel\nnombres = ['[0-2)','[2-4)','[4-6)','[6-8)','[8-10]']\nporcentajes = [22.9,20.0,22.9,17.1,17.1]\ncolores = ['#5ccb5f', '#98f84a', '#e1ffaf', '#fff', '#e1ffaf']\n\n# Crear el gr\u00e1fico de pastel sin bordes\nfig = plt.figure(figsize=(5, 5))\ngs = gridspec.GridSpec(1, 1, width_ratios=[1], height_ratios=[1])\nax = plt.subplot(gs[0])\n\nwedges, texts, autotexts = ax.pie(porcentajes, labels=None, autopct=lambda p: f'{p:.1f}%\\n{nombres.pop(0)}', colors=colores)\n\n# Agregar bordes negros a las porciones del gr\u00e1fico\nfor wedge in wedges:\n    wedge.set_edgecolor('black')\n    wedge.set_linewidth(1)\n\n# Configurar el color de fondo externo\nfig.patch.set_facecolor('#D4F8B7')\n\n# Centrar el gr\u00e1fico en la p\u00e1gina\nplt.tight_layout()\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import matplotlib.pyplot as plt import matplotlib.patches as patches import matplotlib.gridspec as gridspec  # Datos para el gr\u00e1fico de pastel nombres = ['[0-2)','[2-4)','[4-6)','[6-8)','[8-10]'] porcentajes = [22.9,20.0,22.9,17.1,17.1] colores = ['#5ccb5f', '#98f84a', '#e1ffaf', '#fff', '#e1ffaf']  # Crear el gr\u00e1fico de pastel sin bordes fig = plt.figure(figsize=(5, 5)) gs = gridspec.GridSpec(1, 1, width_ratios=[1], height_ratios=[1]) ax = plt.subplot(gs[0])  wedges, texts, autotexts = ax.pie(porcentajes, labels=None, autopct=lambda p: f'{p:.1f}%\\n{nombres.pop(0)}', colors=colores)  # Agregar bordes negros a las porciones del gr\u00e1fico for wedge in wedges:     wedge.set_edgecolor('black')     wedge.set_linewidth(1)  # Configurar el color de fondo externo fig.patch.set_facecolor('#D4F8B7')  # Centrar el gr\u00e1fico en la p\u00e1gina plt.tight_layout()  # Mostrar el gr\u00e1fico plt.show() <p>Ejercicio 4. </p> <p>Un grupo de atletas se est\u00e1 preparando para una marat\u00f3n siguiendo una dieta muy estricta. A continuaci\u00f3n, viene el peso en kilogramos que ha logrado bajar cada atleta gracias a la dieta y ejercicios.</p> <p>Tabla 2.2.5 </p> 0,2 8,4 14,3 6,5 3,4 4,6 9,1 4,3 3,5 1,5 6,4 15,2 16,1 19,8 5,4 12,1 9,6 8,7 12,1 3,2 <p>Hallar la amplitud de clase.</p> <p>Soluci\u00f3n:</p> <p>\u2022\tHallamos el rango: R = Xmax\u2013 Xmin = 19,8 \u2013 0,2 = 19,6.</p> <p>\u2022\tEl n\u00famero de intervalos (k), lo calculamos usando la regla de Sturges: k = 1 + 3,322log(n) = 1 + 3,322.log(20) = 5,32. Podemos redondear el valor de k a 5</p> <p>\u2022\tCalculamos la amplitud de clase: A = R/k = 19,6/5 = 3,92. Redondeamos a 4.</p> <p>Ejercicio 5. </p> <p>Representa en un diagrama de puntos los siguientes datos obtenidos de las notas de un examen:</p> <p>Tabla de Notas de Examen por Estudiante </p> Estudiantes Nota Examen Estudiante 1 7 Estudiante 2 6 Estudiante 3 5 Estudiante 4 4 Estudiante 5 8 Estudiante 6 10 Estudiante 7 3 Estudiante 8 5 Estudiante 9 1 Estudiante 10 6 Estudiante 11 7 Estudiante 12 4 Estudiante 13 5 Estudiante 14 5 Estudiante 15 7 Estudiante 16 6 Estudiante 17 5 Estudiante 18 8 Estudiante 19 9 Estudiante 20 7 <p>En primer lugar, tenemos que dibujar una recta num\u00e9rica para poder representar los datos. As\u00ed que trazamos una l\u00ednea horizontal y en ella representamos todos los valores que aparecen en la muestra.</p> <p>Y ahora dibujamos un punto encima de cada n\u00famero por cada vez que aparece en la tabla de datos. Por ejemplo, el n\u00famero 4 est\u00e1 repetido dos veces, por lo tanto, representaremos dos puntos en la recta num\u00e9rica encima del n\u00famero 4.</p> <p>De esta forma ya hemos elaborado el gr\u00e1fico de puntos. Pero a\u00fan nos queda interpretar el diagrama de puntos obtenido.</p> <p>Para analizar el diagrama de puntos, debemos fijarnos en la distribuci\u00f3n de los datos, es decir, debemos fijarnos en la dispersi\u00f3n del diagrama de puntos. En este caso, las notas que m\u00e1s se repiten est\u00e1n en el centro del diagrama, por lo que la mayor\u00eda de alumnos han sacado notas entre el 5 y el 7. De hecho, la moda del diagrama de puntos es el n\u00famero cinco.</p> <p>Por otro lado, ning\u00fan alumno ha sacado un dos, ya que no aparece ni una sola vez en la tabla de valores. Por eso no tiene representado ning\u00fan punto encima.</p> <p>Finalmente, cabe destacar que los datos de este ejemplo se tratan de n\u00fameros enteros, pero tambi\u00e9n se puede hacer un diagrama de puntos con n\u00fameros decimales. Incluso se puede hacer un diagrama de puntos con datos cualitativos.</p> <p>Ejercicio 6. </p> <p>Se desea saber cu\u00e1ntos libros se leyeron 10 estudiantes en el verano.</p> <p>Tabla de Estudiantes y Libros </p> Estudiantes Libros Estudiante 1 5 Estudiante 2 1 Estudiante 3 2 Estudiante 4 5 Estudiante 5 8 Estudiante 6 0 Estudiante 7 3 Estudiante 8 2 Estudiante 9 2 Estudiante 10 1 <p>\u2022\tLo primero es organizar los datos de menor a mayor, sin importar que se repitan.</p> <p>0; 1; 1; 2; 2; 2; 3; 5; 5; 8.</p> <p>\u2022\tSegundo trazamos una recta num\u00e9rica con los n\u00fameros del cero (n\u00famero menor) hasta el ocho (n\u00famero mayor).</p> <p>\u2022\tTercero en la recta num\u00e9rica colocamos un punto en cada uno de los n\u00fameros que aparecen el primer paso, colocando en el cero un punto, en el uno dos puntos, en los dos tres puntos, en el tres un punto, el n\u00famero cuatro no se le ponen puntos y as\u00ed sucesivamente.</p> <p>Observa el siguiente video para que te quede un poco m\u00e1s claro c\u00f3mo construir los diagramas de puntos:</p> In\u00a0[1]: Copied! <pre>from IPython.display import YouTubeVideo\nyoutube_video = YouTubeVideo('bAY5zmtgjDI')\ndisplay(youtube_video)\n</pre> from IPython.display import YouTubeVideo youtube_video = YouTubeVideo('bAY5zmtgjDI') display(youtube_video) <p>Se presenta el concepto de diagrama de tallo y hoja como una herramienta para resumir datos cuantitativos y se explica c\u00f3mo construir uno. Se presentan ejemplos pr\u00e1cticos que involucran el an\u00e1lisis de datos de duraci\u00f3n de auditor\u00edas y se destaca la importancia de comprender y saber interpretar los diagramas de tallo y hoja para resumir datos. Adem\u00e1s, se mencionan otras herramientas de an\u00e1lisis exploratorio, como la tabla de frecuencia y el diagrama de caja y bigotes.</p> <p>Estas t\u00e9cnicas consisten en una aritm\u00e9tica simple y gr\u00e1ficas f\u00e1ciles de elaborar para resumir los datos r\u00e1pidamente, una de ellas es el tallo y hoja, donde muestra simult\u00e1neamente la clasificaci\u00f3n y la forma de un conjunto de datos. Tiene dos ventajas</p> <ol> <li>Es f\u00e1cil de elaborar a mano.</li> <li>Proporciona m\u00e1s informaci\u00f3n que el histograma</li> </ol> <p>Ejercicio 1. </p> <p>En la clase de Prec\u00e1lculo de primavera de Susan Dean las calificaciones del primer examen fueron las siguientes (de menor a mayor):</p> <p>33; 42; 49; 49; 53; 55; 55; 61; 63; 67; 68; 68; 69; 69; 72; 73; 74; 78; 80; 83; 88; 88; 88; 90; 92; 94; 94; 94; 94; 96; 100</p> <p>Tabla 2.3.1</p> Tallo Hoja 3 3 4 2 9 9 5 3 5 5 6 1 3 7 8 8 9 9 7 2 3 4 8 8 0 3 8 8 8 9 0 2 4 4 4 4 6 10 0 <p>El gr\u00e1fico de tallo muestra que la mayor\u00eda de las calificaciones fueron de 60, 70, 80 y 90. Ocho de las 31 calificaciones, es decir, aproximadamente el 26 % (8/31) estaban en los 90 o 100, un n\u00famero bastante alto de calificaciones con A.</p> <p>Ejercicio 2. </p> <p>El diagrama de tallo y hoja bilateral permite comparar los dos conjuntos de datos en dos columnas. En el diagrama de tallo y hoja bilateral dos conjuntos de hojas comparten el mismo tallo. Las hojas est\u00e1n a la izquierda y a la derecha de los tallos. La Tabla 1 y la Tabla 2 muestran las edades de los presidentes en su investidura y al momento de su muerte. Construya un diagrama de tallo y hoja bilateral utilizando estos datos.</p> <p>Tabla 2.3.2 Edades de los presidentes en su investidura</p> Presidente Edad Presidente Edad Presidente Edad Washington 57 Lincoln 52 Hoover 54 J. Adams 61 A. Johnson 56 F. Roosevelt 51 Jefferson 57 Grant 46 Truman 60 Madison 57 Hayes 54 Eisenhower 62 Monroe 58 Garfield 49 Kennedy 43 J. Q. Adams 57 Arthur 51 L. Johnson 55 Jackson 61 Cleveland 47 Nixon 56 Van Buren 54 B. Harrison 55 Ford 61 W. H. Harrison 68 Cleveland 55 Carter 52 Tyler 51 McKinley 54 Reagan 69 Polk 49 T. Roosevelt 42 G. H. W. Bush 64 Taylor 64 Taft 51 Clinton 47 Fillmore 50 Wilson 56 G. W. Bush 54 Pierce 48 Harding 55 Obama 47 Buchanan 65 Coolidge 51 <p>Tabla 2.3.3  Titulo de la Tabla</p> Presidente Edad Presidente Edad Presidente Edad Washington 67 Lincoln 56 Hoover 90 J. Adams 90 A. Johnson 66 F. Roosevelt 63 Jefferson 83 Grant 63 Truman 88 Madison 85 Hayes 70 Eisenhower 78 Monroe 73 Garfield 49 Kennedy 46 J. Q. Adams 80 Arthur 56 L. Johnson 64 Jackson 78 Cleveland 71 Nixon 81 Van Buren 79 B. Harrison 67 Ford 93 W. H. Harrison 68 Cleveland 71 Reagan 93 Tyler 71 McKinley 58 Polk 53 T. Roosevelt 60 Taylor 65 Taft 72 Fillmore 74 Wilson 67 Pierce 64 Harding 57 Buchanan 77 Coolidge 60 <pre></pre> <p>Tabla 2.3.4  Solucion</p> Edades en la investidura Edades al momento de la muerte 9 9 8 7 7 7 6 3 2 4 6 9 8 7 7 7 7 6 6 6 5 5 5 5 4 4 4 4 4 2 2 1 1 1 1 1 0 5 3 6 6 7 7 8 6 0 0 3 3 4 4 5 6 7 7 7 8 7 0 0 1 1 1 4 7 8 8 9 8 0 1 3 5 8 9 0 0 3 3 <p>Ejercicio 3. </p> <p>En las pruebas m\u00e9dicas de un instituto, se toma la altura de los cuarenta alumnos de una clase. El m\u00e9dico est\u00e1 interesado en representar gr\u00e1ficamente la variable y opta por el diagrama de tallo y hoja.</p> <p>Ordena las alturas en una tabla:</p> <p>Tabla 2.3.5</p> Altura de los Alumnos 145 147 149 152 153 154 154 156 157 158 162 162 162 163 163 164 164 165 167 167 168 169 169 170 171 171 172 173 174 174 175 176 176 179 180 181 183 185 185 186 <ol> <li><p>Los datos son tomados en cent\u00edmetros, por lo que tiene tres cifras cada n\u00famero. En este caso no se requiere redondear los datos, ya que se parte del n\u00famero de d\u00edgitos que se desea. Los dos primeros d\u00edgitos ser\u00e1n el tallo y el \u00faltimo la hoja.</p> </li> <li><p>Una vez preparados los datos, procede a construir el diagrama. Dibuja una tabla con dos columnas. En la primera columna coloca los tallos ordenados de menor a mayor. En este caso los tallos ser\u00e1n: 14, 15, 16, 17 y 18.</p> </li> <li><p>Se registra en la segunda columna todas las hojas, debidamente ordenadas, junto al tallo correspondiente:</p> </li> </ol> <p>Tabla 2.3.6 </p> Tallo Hoja 14 5 7 9 15 2 3 4 4 6 7 8 16 2 2 2 3 3 4 4 5 7 7 8 9 9 17 0 1 1 2 3 4 4 5 6 6 8 9 18 0 1 3 5 6 <p>Se mencionan diferentes herramientas para resumir datos cualitativos y cuantitativos, como la distribuci\u00f3n de frecuencia, distribuciones relativas y porcentuales, diagramas de puntos, histogramas, distribuciones acumuladas, ojivas, tabulaciones cruzadas y diagramas de dispersi\u00f3n. Se destaca la importancia de comprender y saber interpretar estos m\u00e9todos para el an\u00e1lisis estad\u00edstico en el \u00e1mbito empresarial y econ\u00f3mico. Adem\u00e1s, se menciona que con conjuntos de datos grandes, el software de computadora es fundamental para la elaboraci\u00f3n de res\u00famenes tabulares y gr\u00e1ficos de los datos.</p> <p>Tabla 2.3.4  Solucion</p> F\u00fatbol Baloncesto Masculino 20 30 Femenino 15 35 <p>En esta tabla, cada celda representa el n\u00famero de personas que cumplen con una combinaci\u00f3n espec\u00edfica de g\u00e9nero y preferencia de deporte. Por ejemplo, hay 20 personas masculinas que prefieren el f\u00fatbol, y 35 personas femeninas que prefieren el baloncesto.</p> <p>La tabulaci\u00f3n cruzada es \u00fatil para explorar y entender las relaciones entre dos variables categ\u00f3ricas. Adem\u00e1s, puede ser la base para realizar pruebas estad\u00edsticas como la prueba de independencia chi-cuadrado, que eval\u00faa si hay una asociaci\u00f3n significativa entre las dos variables.</p> <p>En t\u00e9rminos de software, puedes utilizar herramientas estad\u00edsticas como R, Python con pandas, o incluso software de hojas de c\u00e1lculo como Excel para realizar tabulaciones cruzadas.</p> <p>Ejercicio 1. </p> <p>En el ejemplo se supone que, en un d\u00eda de lluvia, un estudiante cuenta cu\u00e1ntas personas \"con\" y cu\u00e1ntas \"sin\" paraguas acuden a la clase de estad\u00edstica. Adem\u00e1s, el alumno anota el sexo de los estudiantes.</p> <p>Tabla de Paraguas por Sexo </p> Sexo Con Paraguas mujer S\u00ed hombre S\u00ed mujer S\u00ed mujer S\u00ed hombre S\u00ed hombre No mujer No hombre No mujer No mujer No hombre No mujer S\u00ed hombre S\u00ed mujer S\u00ed hombre S\u00ed hombre No mujer No hombre No mujer No mujer No mujer No <p>El resultado puede mostrarse ahora f\u00e1cilmente en una tabla de contingencia. La tabla de clasificaci\u00f3n cruzada contiene ahora las frecuencias absolutas de las respectivas combinaciones de caracter\u00edsticas. Esto se calcula como sigue:</p> <p>Tabla de Paraguas por Sexo </p> Con Paraguas sin Paraguas Total mujer 5 7 12 hombre 5 5 10 Total 10 12 22 <p>Por ejemplo, una investigaci\u00f3n sobre la intenci\u00f3n de voto arroja los siguientes resultados:</p> <p>G\u00e9nero de la poblaci\u00f3n investigada: Masculino 45% Femenino 55%</p> <p>\u00bfAsistir\u00e1 a votar? Si 70% No 30%</p> <p>Ante estos resultados, surge la interrogante: \u00bfQu\u00e9 porcentaje de hombres y de mujeres votar\u00e1n? O \u00bfQu\u00e9 porcentaje de hombre y mujeres se abstendr\u00e1n de votar?</p> <p>La tabulaci\u00f3n cruzada nos puede ayudar a resolver estas interrogantes, y una nueva tabla podr\u00eda quedar conformada de la siguiente manera, tomando de base los resultados obtenidos:</p> <p>Tabla de Votos por G\u00e9nero </p> G\u00e9nero / Voto Si No Total Femenino 33% 22% 55% Masculino 37% 8% 45% Total 70% 30% 100% <p>Y a partir de la tabla anterior, ya se pueden realizar an\u00e1lisis m\u00e1s profundos y llegar a conclusiones de mayor peso que solamente con la informaci\u00f3n que ten\u00edamos en un principio. Esto gracias a la Tabulaci\u00f3n Cruzada. Ocurre entonces, que en ocasiones tenemos una base de datos enorme, pero que no logramos encontrar la forma de obtener m\u00e1s informaci\u00f3n a partir de la misma, y es aqu\u00ed en donde el SPSS nos puede colaborar construyendo tabulaciones cruzadas con todas las variables que deseemos, y con un uso \u00f3ptimo del tiempo.</p> <p>Ejercicio 2. </p> <p>En la tabla siguiente se muestran los g\u00e9neros y el uso de las manos de una muestra poblacional de 12 individuos:</p> <p>Tabla de Uso de las Manos por G\u00e9nero </p> Muestra # G\u00e9nero Uso de las manos 1 Mujer Diestra/o 2 Var\u00f3n Zurda/o 3 Var\u00f3n Diestra/o 4 Mujer Diestra/o 5 Mujer Diestra/o 6 Var\u00f3n Diestra/o 7 Var\u00f3n Zurda/o 8 Var\u00f3n Diestra/o 9 Mujer Diestra/o 10 Mujer Zurda/o 11 Var\u00f3n Diestra/o 12 Mujer Diestra/o <p>La tabulaci\u00f3n cruzada conduce hacia la siguiente tabla de contingencia:</p> <p>Tabla de Uso de Manos por G\u00e9nero </p> Diestra/o Zurda/o Total Mujeres 5 1 6 Varones 4 2 6 Total 9 3 12 <p>La paradoja de Simpson</p> <p>Supongamos que se quiere realizar un estudio comparado de la efectividad de una cierta cirug\u00eda en dos hospitales A y B, para lo cual se obtienen los datos presentados en la Tabla 1. Se pide analizar los datos y determinar cu\u00e1l hospital da mayor tasa de supervivencia</p> <p>Tabla de Comparaci\u00f3n de Supervivencia a Cirug\u00eda </p> Hospital A Hospital B Mueren 63 16 Sobreviven 2037 784 Total pacientes operados 2100 800 <p>Si analizamos los datos de la Tabla 1, se puede observar que en el hospital A, muere el 3% (63/2100) de los pacientes que se somete a la cirug\u00eda y en el hospital B el 2% (16/800), por lo que inicialmente estos resultados nos podr\u00edan llevar a pensar que el hospital m\u00e1s seguro para someterse a dicha operaci\u00f3n ser\u00eda el hospital B. La paradoja aparece cuando controlamos los resultados teniendo en cuenta otras variables que influyen en la supervivencia, por ejemplo, el \u201cestado de salud de los pacientes antes de la operaci\u00f3n\u201d.</p> <p>Diferencias entre Cuantitativa y Cualitativa:</p> In\u00a0[2]: Copied! <pre>from IPython.display import YouTubeVideo\nyoutube_video = YouTubeVideo('uWxmy1vOS88')\ndisplay(youtube_video)\n</pre> from IPython.display import YouTubeVideo youtube_video = YouTubeVideo('uWxmy1vOS88') display(youtube_video) In\u00a0[3]: Copied! <pre>from IPython.display import YouTubeVideo\nyoutube_video = YouTubeVideo('nCszHELuwxk')\ndisplay(youtube_video)\n</pre> from IPython.display import YouTubeVideo youtube_video = YouTubeVideo('nCszHELuwxk') display(youtube_video) <p>Histogramas de frecuencia:</p> In\u00a0[4]: Copied! <pre>from IPython.display import YouTubeVideo\nyoutube_video = YouTubeVideo('-VZ4x_rLCHE')\ndisplay(youtube_video)\n</pre> from IPython.display import YouTubeVideo youtube_video = YouTubeVideo('-VZ4x_rLCHE') display(youtube_video) <p>Ojivas:</p> In\u00a0[6]: Copied! <pre>from IPython.display import YouTubeVideo\nyoutube_video = YouTubeVideo('p90bzl1cdDM')\ndisplay(youtube_video)\n</pre> from IPython.display import YouTubeVideo youtube_video = YouTubeVideo('p90bzl1cdDM') display(youtube_video) <p>Diagrama de tallos y hojas:</p> In\u00a0[5]: Copied! <pre>from IPython.display import YouTubeVideo\nyoutube_video = YouTubeVideo('DZWxasd0Exk')\ndisplay(youtube_video)\n</pre> from IPython.display import YouTubeVideo youtube_video = YouTubeVideo('DZWxasd0Exk') display(youtube_video) <p>Diagrama de dispercion:**</p> In\u00a0[7]: Copied! <pre>from IPython.display import YouTubeVideo\nyoutube_video = YouTubeVideo('hTIXDHrGs5A')\ndisplay(youtube_video)\n</pre> from IPython.display import YouTubeVideo youtube_video = YouTubeVideo('hTIXDHrGs5A') display(youtube_video) <p>Tabulacion cruzada:</p> In\u00a0[8]: Copied! <pre>from IPython.display import YouTubeVideo\nyoutube_video = YouTubeVideo('-x6UYTVyCns')\ndisplay(youtube_video)\n</pre> from IPython.display import YouTubeVideo youtube_video = YouTubeVideo('-x6UYTVyCns') display(youtube_video) <p>Ejercicio 1. </p> <p>Nielsen Home Technology Report informa sobre la tecnolog\u00eda en el hogar y su uso. Los datos siguientes son las horas de uso de computadora por semana en una muestra de 50 personas.</p> <p>Tabla de N\u00fameros Decimales </p> 1 2 3 4 5 6 7 8 9 10 11 12 4.1 1.5 10.4 5.9 3.4 5.7 1.6 6.1 3.0 3.7 3.1 4.8 2.0 14.8 5.4 4.2 3.9 4.1 11.1 3.5 4.1 4.1 8.8 5.6 4.3 3.3 7.1 10.3 6.2 7.6 10.8 2.8 9.5 12.9 12.1 0.7 4.0 9.2 4.4 5.7 7.2 6.1 5.7 5.9 4.7 3.9 3.7 3.1 6.1 3.1 <p>Resuma estos datos construyendo:</p> <p>a. Una distribuci\u00f3n de frecuencia porcentual. Utilice las clases 0.1 a 3; 3.1 a 6; etc.</p> <p>b. Un histograma.</p> <p>c. Una distribuci\u00f3n de frecuencia porcentual acumulada.</p> <p>d. Una ojiva.</p> <p>e. \u00bfQu\u00e9 porcentaje de personas utiliza la computadora 9 horas o menos?</p> <p>f. \u00bfSon datos de series de tiempo o datos de secci\u00f3n transversal?</p> <p>Ejercicio 2. </p> <p>Cada a\u00f1o en Reino Unido, aproximadamente 1.5 millones de los estudiantes de educaci\u00f3n superior presentan un examen de aptitud escolar. A continuaci\u00f3n se presentan las puntuaciones obtenidas en las \u00e1reas de matem\u00e1ticas y expresi\u00f3n verbal por una muestra de estudiantes durante la \u00faltima aplicaci\u00f3n de la prueba.</p> <p>Tabla de N\u00fameros </p> 1 2 3 4 5 6 7 8 9 10 11 12 13 1025 1042 1195 880 945 1102 845 1095 936 790 1097 913 1245 1040 998 998 940 1043 1048 1130 1017 1140 1030 1171 1035 <p>a. Presente una distribuci\u00f3n de frecuencia porcentual de estas puntuaciones. Utilice las clases 750-849, 850-949, etc.</p> <p>b. Presente una distribuci\u00f3n de frecuencia porcentual acumulada.</p> <p>c. Elabore una ojiva.</p> <p>d. \u00bfQu\u00e9 porcentaje de estudiantes obtuvo una calificaci\u00f3n menor a 950?</p> <p>e. \u00bfSon datos de series de tiempo o datos de secci\u00f3n transversal?</p> <p>Ejercicio 3. </p> <p>La universidad cuenta con estad\u00edsticas sobre las \u00e1reas que son m\u00e1s elegidas por los estudiantes de nuevo ingreso. Las cinco m\u00e1s elegidas son arte y humanidades (A), administraci\u00f3n de negocios (B), ingenier\u00eda (E), pol\u00edtica (P), ciencias sociales (S) y otras \u00e1reas (O). Las siguientes fueron las \u00e1reas elegidas por 40 estudiantes de reci\u00e9n ingreso de una muestra.</p> <p>Tabla de Letras Formando Palabras/Frases </p> 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 P P O O E E B B A S O A E B E O E \u0420 O S O B O A O E A B E O S A P O S O S O E A P O S O S O E <p>a. D\u00e9 una distribuci\u00f3n de frecuencia y otra de frecuencia porcentual.</p> <p>b. Elabore una gr\u00e1fica de barras.</p> <p>c. \u00bfCu\u00e1l es el \u00e1rea m\u00e1s elegida por los estudiantes de nuevo ingreso? \u00bfQu\u00e9 porcentaje de los estudiantes de nuevo ingreso elige esta \u00e1rea?</p> <p>d. \u00bfSon datos de series de tiempo o datos de secci\u00f3n transversal?</p> <p>e. \u00bfCu\u00e1l es la escala de medici\u00f3n adecuada para estos datos?</p>"},{"location":"capitulo2/","title":"\u00b6","text":"CAPITULO 2  Estadistica Descriptiva: Presentaciones tabulares Contenido del capitulo <p>2.1 Resumen de datos cualitativos</p> <ul> <li>Distribucion de frecuencia</li> <li>Distribuciones de frecuencia relativa y frecuencia potencial</li> <li>Gr\u00e1ficas de barras y circulares</li> </ul> <p>2.2 RESUMEN DE DATOS CUANTITATIVOS</p> <ul> <li>Distribucion de frecuencia</li> <li>Distribuciones de frecuencia relativa y frecuencia potencial</li> <li>Diagramas de puntos</li> <li>Histograma</li> <li>Distribuciones acumuladas</li> <li>Ojiva</li> </ul> <p>2.3 AN\u00c1LISIS DE DATOS EXPLORATORIOS: EL DIAGRAMA DE TALLO Y HOJA</p> <p>2.4 TABULACIONES CRUZADAS Y DIAGRAMAS DE DISPERSION</p> <ul> <li>Tabulacion cruzada</li> <li>La paradoja de Simpson</li> <li>Diagrama de dispersion y linea de tendencia</li> </ul> <p>2.5 EXTRA</p> <ul> <li>Glosario</li> <li>Formulas clave</li> <li>Videos</li> <li>Ejercicios propuestos</li> </ul>"},{"location":"capitulo2/#21-resume-de-datos-cualitativos","title":"2.1 RESUME DE DATOS CUALITATIVOS\u00b6","text":""},{"location":"capitulo2/#distribucion-de-frecuencia","title":"Distribucion de frecuencia\u00b6","text":"<p>La distribuci\u00f3n de frecuencia es una manera de organizar datos estad\u00edsticos para mostrar la frecuencia con la que ocurren ciertos valores en un conjunto de datos. B\u00e1sicamente, consiste en agrupar los datos en categor\u00edas y contar cu\u00e1ntas veces aparece cada valor en cada una de esas categor\u00edas.</p> <p>Esto se puede presentar en forma de tablas, gr\u00e1ficos de barras, histogramas o gr\u00e1ficos circulares para visualizar la frecuencia de cada valor o rango de valores en tus datos. Es una forma \u00fatil de resumir y entender mejor la distribuci\u00f3n y patrones dentro de un conjunto de datos.</p>"},{"location":"capitulo2/#distribucion-de-frecuencia-relativa-y-frecuencia-porcentual","title":"Distribucion de frecuencia relativa y frecuencia porcentual\u00b6","text":"<p>Una distribuci\u00f3n de frecuencia muestra el n\u00famero de elementos en cada clase que no se superpone, lo que interesa a menudo es la proporci\u00f3n de elementos que pertenecen a cada clase, se determina de la siguiente manera</p>"},{"location":"capitulo2/#grafica-de-barras-y-circula","title":"Grafica de barras y circula\u00b6","text":"<p>Es un dispositivo gr\u00e1fico que se usa para presentar datos cualitativos resumidos en una distribuci\u00f3n de frecuencia relativa o porcentual. En un eje se especifican las etiquetas a utilizar y en el otro eje se pone una escala de frecuencia relativa o porcentual, para los datos cualitativos las barras deben estar a una cierta distancia, esto para que cada clase este separada.</p> <p>EJEMPLO:</p>"},{"location":"capitulo2/#la-grafica-circular-o-de-pastel","title":"La grafica circular o de pastel\u00b6","text":"<p>es otro dispositivo gr\u00e1fico que presenta para las distribuciones para datos cualitativos. Para realizarla primero se traza un c\u00edrculo que represente todos los datos, luego se usan las frecuencias relativas para subdividir el c\u00edrculo en partes que representa la frecuencia relativa de cada clase.</p> <p>EJEMPLO:</p>"},{"location":"capitulo2/#22-resumen-de-datos-cuantitativos","title":"2.2 RESUMEN DE DATOS CUANTITATIVOS\u00b6","text":""},{"location":"capitulo2/#distribucion-de-frecuencia","title":"Distribucion de frecuencia\u00b6","text":"<p>Esta distribuci\u00f3n expresa la frecuencia de cada valor o categor\u00eda como una proporci\u00f3n del total de observaciones en el conjunto de datos. Se calcula dividiendo la frecuencia de cada valor entre el n\u00famero total de observaciones.</p> <p>La distribuci\u00f3n de frecuencia es una forma de organizar y resumir datos cuantitativos. Consiste en contar y clasificar la frecuencia con la que ocurren diferentes valores en un conjunto de datos. El objetivo es proporcionar una visi\u00f3n clara y concisa de c\u00f3mo se distribuyen los valores en el conjunto de datos.</p>"},{"location":"capitulo2/#distribucion-de-frecuencia-relativa-y-frecuencia-porcentual","title":"Distribucion de frecuencia relativa y frecuencia porcentual\u00b6","text":"<p>La distribuci\u00f3n de frecuencia relativa y la frecuencia porcentual son dos formas de expresar la frecuencia de ocurrencia de valores en un conjunto de datos en relaci\u00f3n con el total de datos.</p> <p>La distribuci\u00f3n de frecuencia relativa y la frecuencia porcentual son formas de expresar la frecuencia de los datos en relaci\u00f3n con el total del conjunto de datos. Estas medidas son \u00fatiles para entender la proporci\u00f3n de cada categor\u00eda o intervalo con respecto al conjunto completo.</p>"},{"location":"capitulo2/#ancho-de-clase","title":"Ancho de clase:\u00b6","text":"<p>Como regla general el ancho debe ser igual para todas las clases, por lo que el n\u00famero y ancho de la clase no son decisiones independientes, se utiliza la siguiente expresi\u00f3n para determinar el ancho de la clase:</p>"},{"location":"capitulo2/#histograma","title":"Histograma\u00b6","text":"<p>Un histograma es una representaci\u00f3n gr\u00e1fica de la distribuci\u00f3n de un conjunto de datos. Se utiliza com\u00fanmente en estad\u00edsticas para visualizar la frecuencia de ocurrencia de distintos valores en un conjunto de datos continuo. Aqu\u00ed hay una descripci\u00f3n b\u00e1sica de c\u00f3mo se construye un histograma:</p> <p>-Definici\u00f3n de clases: Divide el rango total de datos en intervalos o \"clases\". Cada clase representa un rango espec\u00edfico de valores. Los l\u00edmites de clase (inferior y superior) se definen para cada intervalo.</p> <p>-Conteo de frecuencias: Determina cu\u00e1ntas observaciones caen dentro de cada clase. Este conteo se conoce como la frecuencia de la clase.</p> <p>-Construcci\u00f3n del gr\u00e1fico: Dibuja un rect\u00e1ngulo para cada clase, cuya base es el intervalo de clase y la altura es proporcional a la frecuencia de esa clase. Puedes utilizar barras contiguas o separadas, dependiendo de tus preferencias o est\u00e1ndares.</p> <p>-Ejes del histograma: Etiqueta los ejes. El eje horizontal representa la variable que est\u00e1s midiendo (por ejemplo, valores), y el eje vertical representa la frecuencia o densidad de frecuencia.</p>"},{"location":"capitulo2/#limite-de-clase","title":"L\u00edmite de clase\u00b6","text":"<p>Es un concepto utilizado en estad\u00edstica, especialmente en la construcci\u00f3n de histogramas y en la organizaci\u00f3n de datos en intervalos. Cada conjunto de datos se divide en intervalos o clases, y el l\u00edmite de clase se refiere a los valores que definen el inicio y el final de cada intervalo.</p> <p>Hay dos tipos principales de l\u00edmites de clase:</p> <p>-L\u00edmite inferior de clase: Es el valor m\u00e1s peque\u00f1o que puede pertenecer a una clase. Es el l\u00edmite que separa una clase de la siguiente.</p> <p>-L\u00edmite superior de clase: Es el valor m\u00e1s grande que puede pertenecer a una clase. Es el l\u00edmite que separa una clase de la siguiente.</p> <p>Por ejemplo, si tienes datos agrupados en clases de 10 a 19, el l\u00edmite inferior de la clase es 10 y el l\u00edmite superior es 19. El l\u00edmite de clase ayuda a definir claramente los intervalos en los cuales se agrupan los datos.</p> <p>La longitud de clase se calcula restando el l\u00edmite inferior del l\u00edmite superior. Esto es importante al construir histogramas para asegurar que las barras se ajusten correctamente a los datos y proporcionen una representaci\u00f3n precisa de la distribuci\u00f3n.</p>"},{"location":"capitulo2/#diagrama-de-puntos","title":"Diagrama de puntos\u00b6","text":"<p>Un diagrama de puntos es una representaci\u00f3n gr\u00e1fica de datos unidimensionales en la que cada observaci\u00f3n se representa mediante un punto en una l\u00ednea. Este tipo de gr\u00e1fico es especialmente \u00fatil para visualizar la distribuci\u00f3n y concentraci\u00f3n de los valores en un conjunto de datos. El eje horizontal representa la variable de inter\u00e9s, mientras que el eje vertical muestra la frecuencia o la cantidad de veces que ocurre cada valor. Los puntos se colocan en la l\u00ednea de acuerdo con el valor de la observaci\u00f3n, permitiendo identificar patrones, tendencias o la dispersi\u00f3n de los datos.</p>"},{"location":"capitulo2/#distribuciones-acumuladas","title":"Distribuciones acumuladas\u00b6","text":"<p>Son \u00fatiles para analizar la posici\u00f3n relativa de un valor en un conjunto de datos, entender la cantidad o proporci\u00f3n de datos por debajo de cierto umbral y comparar la distribuci\u00f3n de diferentes conjuntos de datos.</p> <p>Estos datos se pueden representar visualmente mediante gr\u00e1ficos acumulados, como los gr\u00e1ficos de frecuencia acumulada o los diagramas de pol\u00edgono de frecuencia acumulada, que muestran la acumulaci\u00f3n de frecuencias a lo largo de los valores de los datos.</p>"},{"location":"capitulo2/#ojiva","title":"Ojiva\u00b6","text":"<p>La gr\u00e1fica de una distribuci\u00f3n, llamada ojiva, muestra los valores de los datos sobre eje horizontal y las frecuencias en el eje vertical.Es un tipo espec\u00edfico de gr\u00e1fico utilizado en estad\u00edsticas para representar la distribuci\u00f3n acumulada de frecuencias o porcentajes de un conjunto de datos. Tambi\u00e9n se conoce como gr\u00e1fico de frecuencia acumulada.</p> <p>Una ojiva se construye trazando puntos o marcando los extremos superiores de las barras de un histograma, y luego uniendo estos puntos sucesivamente con l\u00edneas suaves para formar una curva. Esta curva representa la acumulaci\u00f3n gradual de frecuencias o porcentajes a lo largo de los valores de los datos.</p> <p>La ojiva es \u00fatil para visualizar c\u00f3mo se acumulan los datos a lo largo de un rango de valores y proporciona una comprensi\u00f3n intuitiva de la distribuci\u00f3n de los datos en t\u00e9rminos de su posici\u00f3n relativa. Puede ser particularmente \u00fatil para identificar tendencias o patrones generales en la distribuci\u00f3n de los datos.</p> <p>Adem\u00e1s, la ojiva permite comparar f\u00e1cilmente varias distribuciones acumuladas y observar diferencias o similitudes entre conjuntos de datos diferentes. Esta representaci\u00f3n gr\u00e1fica es com\u00fanmente utilizada en an\u00e1lisis estad\u00edstico para comprender la distribuci\u00f3n acumulada de frecuencias o porcentajes en conjuntos de datos num\u00e9ricos.</p>"},{"location":"capitulo2/#ejercicios","title":"Ejercicios\u00b6","text":""},{"location":"capitulo2/#23-analisis-de-datos-exploratorios-el-diagrama-de-tallo-y-hoja","title":"2.3 \u00c1NALISIS DE DATOS EXPLORATORIOS: EL DIAGRAMA DE TALLO Y HOJA\u00b6","text":""},{"location":"capitulo2/#ejercicios","title":"Ejercicios\u00b6","text":""},{"location":"capitulo2/#24-tabulaciones-cruzadas-y-diagramas-de-dispersion","title":"2.4 TABULACIONES CRUZADAS Y DIAGRAMAS DE DISPERSI\u00d3N\u00b6","text":""},{"location":"capitulo2/#tabulacion-cruzada","title":"Tabulacion cruzada\u00b6","text":"<p>La tabulaci\u00f3n cruzada, tambi\u00e9n conocida como tabla de contingencia, es una herramienta estad\u00edstica que se utiliza para resumir y analizar la relaci\u00f3n entre dos variables categ\u00f3ricas. En una tabla de contingencia, los datos se organizan en filas y columnas, donde cada celda muestra la frecuencia o conteo de casos que caen en una categor\u00eda espec\u00edfica de ambas variables.</p> <p>A continuaci\u00f3n, te proporciono un ejemplo sencillo y c\u00f3mo se ver\u00eda en una tabla de contingencia:</p> <p>Supongamos que tienes dos variables categ\u00f3ricas: G\u00e9nero (Masculino/Femenino) y Preferencia de Deporte (F\u00fatbol/Baloncesto). Has recopilado datos sobre 100 personas.</p>"},{"location":"capitulo2/#la-paradoja-de-simpson","title":"La paradoja de Simpson\u00b6","text":"<p>La paradoja de Simpson es un fen\u00f3meno estad\u00edstico en el que una tendencia que aparece en diferentes grupos de datos desaparece o se invierte cuando se combinan estos grupos. Espec\u00edficamente, la paradoja ocurre cuando una relaci\u00f3n que es presente en subgrupos de datos se revierte cuando se agregan esos subgrupos.</p> <p>Esta paradoja puede surgir cuando las diferencias en los tama\u00f1os de los subgrupos no se tienen en cuenta adecuadamente al interpretar los resultados. Puede conducir a conclusiones err\u00f3neas si no se considera cuidadosamente la estructura de los datos.</p> <p>Un ejemplo cl\u00e1sico de la paradoja de Simpson se encuentra en el contexto de tasas de \u00e9xito en dos tratamientos diferentes. Puede suceder que, al observar cada subgrupo por separado, un tratamiento parezca ser m\u00e1s efectivo. Sin embargo, al combinar los grupos, el resultado general puede mostrar que el otro tratamiento es m\u00e1s efectivo. Esto puede ocurrir si los subgrupos tienen tama\u00f1os diferentes y las tasas de \u00e9xito y fallo var\u00edan significativamente entre ellos.</p> <p>La paradoja de Simpson destaca la importancia de considerar el tama\u00f1o de las muestras y las variables relevantes al interpretar datos y resultados estad\u00edsticos. Es un recordatorio de que las conclusiones basadas en agregados pueden no reflejar necesariamente las tendencias en subgrupos m\u00e1s peque\u00f1os y resalta la necesidad de un an\u00e1lisis m\u00e1s detallado y contextualizado.</p>"},{"location":"capitulo2/#diagrama-de-dispersion-y-linea-de-tendencia","title":"Diagrama de dispersi\u00f3n y l\u00ednea de tendencia\u00b6","text":"<p>Un diagrama de dispersi\u00f3n es una herramienta gr\u00e1fica que representa la relaci\u00f3n entre dos variables. Cada punto en el gr\u00e1fico corresponde a un par de valores de las dos variables. Este tipo de gr\u00e1fico es \u00fatil para visualizar patrones, tendencias y la fuerza de la relaci\u00f3n entre las variables.</p> <p>Aqu\u00ed est\u00e1 la descripci\u00f3n general de c\u00f3mo crear un diagrama de dispersi\u00f3n:</p> <p>-Ejes: Coloca una variable en el eje horizontal (eje x) y la otra en el eje vertical (eje y).</p> <p>-Puntos: Para cada observaci\u00f3n en tu conjunto de datos, coloca un punto en el gr\u00e1fico con coordenadas (x, y) seg\u00fan los valores de las dos variables.</p> <p>-Patrones y Tendencias: Examina la distribuci\u00f3n de los puntos para identificar patrones o tendencias. Si los puntos se agrupan en una direcci\u00f3n particular, puede indicar una relaci\u00f3n entre las variables.</p> <p>La l\u00ednea de tendencia es una l\u00ednea que intenta modelar la relaci\u00f3n general entre las dos variables. Puede ser una recta (regresi\u00f3n lineal) o una curva (regresi\u00f3n no lineal). La l\u00ednea de tendencia proporciona una representaci\u00f3n visual de la direcci\u00f3n y la fuerza de la relaci\u00f3n.</p>"},{"location":"capitulo2/#ejercicios","title":"Ejercicios\u00b6","text":""},{"location":"capitulo2/#25-extra","title":"2.5 Extra\u00b6","text":""},{"location":"capitulo2/#glosario","title":"Glosario\u00b6","text":"<ul> <li>Frecuencia porcentual: f\u00f3rmula para calcular la frecuencia porcentual de una clase en una distribuci\u00f3n de frecuencia. Se calcula multiplicando la frecuencia relativa por 100.</li> <li>Frecuencia acumulada: f\u00f3rmula para calcular la frecuencia acumulada de una clase en una distribuci\u00f3n de frecuencia. Se calcula sumando las frecuencias de todas las clases anteriores, incluyendo la propia.</li> <li>Frecuencia relativa acumulada: f\u00f3rmula para calcular la frecuencia relativa acumulada de una clase en una distribuci\u00f3n de frecuencia. Se calcula dividiendo la frecuencia acumulada de la clase entre el tama\u00f1o total de la muestra.</li> <li>Tabulaci\u00f3n cruzada: f\u00f3rmula para construir una tabla de frecuencia cruzada, que muestra la frecuencia conjunta de dos variables.</li> <li>Coeficiente de correlaci\u00f3n: f\u00f3rmula para calcular el coeficiente de correlaci\u00f3n entre dos variables en un diagrama de dispersi\u00f3n. Se calcula dividiendo la covarianza entre las desviaciones est\u00e1ndar de las dos variables.</li> <li>Recta de regresi\u00f3n: f\u00f3rmula para calcular la recta de regresi\u00f3n en un diagrama de dispersi\u00f3n. Se calcula utilizando la media y la desviaci\u00f3n est\u00e1ndar de las dos variables y el coeficiente de correlaci\u00f3n.</li> </ul>"},{"location":"capitulo2/#formulas-clave","title":"F\u00f3rmulas Clave\u00b6","text":"<p>-Uso del MiniTab para presentaciones tabulares y gr\u00e1ficas.- El uso de Minitab para presentaciones tabulares y gr\u00e1ficas es fundamental en el an\u00e1lisis estad\u00edstico. Minitab ofrece amplias capacidades para elaborar res\u00famenes tabulares y gr\u00e1ficos de los datos. Permite la elaboraci\u00f3n de varios res\u00famenes gr\u00e1ficos y tabulares, incluyendo el diagrama de puntos, el histograma, el diagrama de tallo y hoja, el diagrama de dispersi\u00f3n y la tabulaci\u00f3n cruzada. Adem\u00e1s, Minitab proporciona opciones para personalizar los gr\u00e1ficos, como ajustar el eje x para que los valores num\u00e9ricos aparezcan en los puntos medios de los rect\u00e1ngulos del histograma. Estas capacidades son esenciales para el an\u00e1lisis detallado de los datos y la presentaci\u00f3n visual de los resultados.</p> <p>-Uso del Excel para presentaciones tabulares y graficas.- El uso de Excel para presentaciones tabulares y gr\u00e1ficas es una herramienta com\u00fan en el an\u00e1lisis de datos. Excel ofrece la capacidad de crear una variedad de gr\u00e1ficos, incluyendo gr\u00e1ficos de barras, gr\u00e1ficos circulares, diagramas de dispersi\u00f3n, entre otros. Adem\u00e1s, Excel permite la creaci\u00f3n de tablas din\u00e1micas para resumir y analizar grandes conjuntos de datos de manera eficiente. Estas funciones son \u00fatiles para la presentaci\u00f3n visual de los datos y el an\u00e1lisis detallado de la informaci\u00f3n. Adem\u00e1s, Excel proporciona opciones para personalizar los gr\u00e1ficos, como ajustar los ejes y seleccionar diferentes estilos de gr\u00e1ficos. Estas capacidades hacen de Excel una herramienta vers\u00e1til para la presentaci\u00f3n y an\u00e1lisis de datos</p>"},{"location":"capitulo2/#videos","title":"Videos\u00b6","text":"<p>Espacio para videos que reforzaran nuestro conocimiento y aclarar dudas:</p>"},{"location":"capitulo2/#ejercicios","title":"Ejercicios\u00b6","text":""},{"location":"capitulo3/","title":"Capitulo 3","text":"MEDIA MUESTRAL                  $$ \\bar{x} = \\frac{\\sum x_i}{n}$$              (3.1)  Donde:  <ul> <li>$\\bar{x}$ es la media muestral.</li> <li>$x_i$ son las observaciones individuales.</li> <li>$ n $ es el n\u00famero total de observaciones.</li></ul> <p>Ejercicio 1. Se quiere calcular la media muestral de los sueldos mensuales iniciales para una muestra de 12 licenciados en administraci\u00f3n de empresas reci\u00e9n egresados de la Universidad Mayor de San Andres. Tendiendo los siguientes datos:</p> <p>Tabla 1.1  Sueldos mensuales</p> Egresado Sueldo (Bs) Egresado Sueldo (Bs) 1 3450 7 3470 2 3560 8 3540 3 3650 9 3600 4 3480 10 3360 5 3355 10 3510 6 3310 10 3500 <p>El c\u00e1lculo de la media muestral se realizar\u00e1 de la siguiente manera:</p> <p>$$ \\bar{x} = \\frac{\\sum_{i=1}^{n} x_i}{n}= \\frac{ x_1+x_2+x_3+...+x_n}{n} $$</p> <p>$$ \\bar{x} =  \\frac{ 3450+3560+3650+3480+3355+3310+3470+3540+3600+3360+3510+3500}{12} $$</p> <p>$$ \\bar{x} =  \\frac{41785}{12} $$</p> <p>$$ \\bar{x} =  3482.1 $$</p> <p>3482.1 Bs la media muestral de los sueldos de los 12 licenciados reci\u00e9n egresados.</p> <p>Ejercicio 2. La venta de vivienda en la ciudad de La Paz ha aumentado en los \u00faltimos 10 a\u00f1os. A continuaci\u00f3n, se presentan los datos muestrales con el precio de venta representativo para las casas usadas y las nuevas. Los datos se expresan en miles de d\u00f3lares. Tendiendo los siguientes datos:</p> <p>Tabla 2.1  Venta de las casas en la ciudad de La Paz</p> Casas Usadas Casas Nuevas 315.5 275.9 190.5 350.2 140.2 295.8 181.3 425.5 470.2 520.0 169.9 415.2 112.8 215.5 230.0 175.0 177.5 250.9 <p>Calcular la media muestral de la venta de las casas usadas y la media muestral de las casas nuevas</p> <p>a) Media muestral de las casas usadas: </p> <p>$$ \\bar{x} = \\frac{\\sum_{i=1}^{n} x_i}{n}= \\frac{ x_1+x_2+x_3+...+x_n}{n} $$</p> <p>$$ \\bar{x} =  \\frac{315.5+190.5+140.2+181.3+470.2+169.9+112.8+230.0+177.5}{9} $$</p> <p>$$ \\bar{x} =  \\frac{1987.9}{9} $$</p> <p>$$ \\bar{x} =  220.9 $$</p> <p>b) Media muestral de las casas nuevas: </p> <p>$$ \\bar{x} = \\frac{\\sum_{i=1}^{n} x_i}{n}= \\frac{ x_1+x_2+x_3+...+x_n}{n} $$</p> <p>$$ \\bar{x} =  \\frac{275.9+350.2+295.8+425.5+525.0+415.2+215.5+175.0+250.9}{9} $$</p> <p>$$ \\bar{x} =  \\frac{2929}{9} $$</p> <p>$$ \\bar{x} =  325.4 $$</p> <p>Media muestral de las casas usadas es de 220.9 miles de d\u00f3lares. Media muestral de las casas nuevas es de 325.4 miles de d\u00f3lares.</p> <p>Le ecuacion para los anteriores ejemplos se utiliz\u00f3 la Media muestral con $n$ observaciones. La formula para la Media Poblacional es muy similar, solo que se usa una notacion diferente.</p> MEDIA POBLACIONAL                  $$ \\mu = \\frac{\\sum x_i}{N} $$              (3.2)  Donde:  <ul> <li>$\\mu$ es la media poblacional.</li> <li>$x_i$ son las observaciones individuales.</li> <li>$ N $ es el n\u00famero total de la poblaci\u00f3n.</li></ul> <p>La aplicaci\u00f3n de esta f\u00f3rmula sigue el mismo procedimiento que se emple\u00f3 para calcular la media muestral. Su prop\u00f3sito es determinar la media de los datos de toda la poblaci\u00f3n en relaci\u00f3n con un aspecto espec\u00edfico que est\u00e9 siendo investigado.</p> <p>Importante  hacer notar que la media muestral $\\bar{x}$ es un estimador puntual de la media poblacional $\\mu$.</p> MEDIANA                  Ordene los datos de forma ascendente (del valor menor al valor mayor).                 <ol> <li> Para un n\u00famero impar de observaciones, la mediana es el valor de en medio.</li> <li> Para un n\u00famero par de observaciones, la mediana es el promedio de los dos valores de en medio.</li> </ol> <p>Esta definici\u00f3n se aplica para calcular la mediana de los tama\u00f1os de grupo para la muestra de cinco grupos de estudiantes universitarios. Al ordenar los datos de forma ascendente se ob- tiene la lista siguiente. $$32, 42, 46, 46, 54$$ Dado que n = 5 es impar, la mediana es el valor de en medio. Por tanto, la mediana del tama\u00f1o de grupo es 46 estudiantes.</p> <p>Suponga adem\u00e1s que se calcula la mediana de los sueldos iniciales para los 12 licenciados en administraci\u00f3n de empresas. Primero se acomodan los datos en orden ascendente. $$3 310,  3 355,  3 450,  3 480,  3 480,  3 490,  3 520,  3 540,  3 550,  3 650,  3 730,  3 925$$ Como n = 12 es par, se identifican los dos valores de en medio: la mediana es el promedio de estos dos valores. $$ Mediana =  \\frac{3490+3520}{2} = 3505 $$</p> MODA                  La moda es el valor que ocurre con mayor frecuencia.              <p>Ejemplo de Moda en Ingresos Mensuales en Bolivia </p> <pre><code>2000, 3000, 2500, 2000, 3500, 3000, 3000, 2500, 4000, 3000, 3500, 2500, 2500\nModa: 2500 (ocurre con mayor frecuencia)\n</code></pre> <p>En este ejemplo, los ingresos mensuales de 2500 son la moda, ya que son el valor que ocurre con mayor frecuencia en el conjunto de datos.</p> PERCENTIL                  El percentil p-\u00e9simo es un valor tal que por lo menos p por ciento de las observaciones es menor o igual que este valor, y por lo menos (100 - p) por ciento de las observaciones es mayor o igual que este valor.              <p>En estad\u00edsticas, el percentil es una medida que indica el valor por debajo del cual cae un porcentaje dado de observaciones en un conjunto de datos ordenado. Supongamos que tenemos las siguientes puntuaciones en un examen:</p> <p>$$[ 85, 90, 92, 95, 98, 100, 102, 105, 110, 120 ]$$</p> <p>Si queremos calcular el percentil 75 (denotado como ($ P_{75} $)), significa que el 75% de las puntuaciones son iguales o inferiores a este valor.</p> <p>La f\u00f3rmula para calcular el percentil es:</p> <p>$$ P_k = \\left( \\frac{k \\cdot (n + 1)}{100} \\right) $$</p> <p>Para el percentil 75 en nuestro ejemplo:</p> <p>$$ \\begin{align*}     P_{75} &amp;= \\left( \\frac{75 \\cdot (10 + 1)}{100} \\right) \\\\            &amp;= \\left( \\frac{825}{100} \\right) \\\\            &amp;= 8.25 \\end{align*} $$</p> <p>Por lo tanto, el percentil 75 de nuestras puntuaciones ser\u00eda el valor que est\u00e1 en la posici\u00f3n 8.25. Dado que no puede haber una fracci\u00f3n de posici\u00f3n, tomar\u00edamos el promedio de las observaciones en las posiciones 8 y 9.</p> <p>El percentil 75 en nuestro conjunto de datos ser\u00eda el promedio de las puntuaciones 105 y 110, es decir:</p> <p>$$ P_{75} = \\frac{105 + 110}{2} = 107.5 $$</p> <p>En este caso, el percentil 75 es 107.5, lo que significa que el 75% de las puntuaciones son iguales o inferiores a 107.5.</p> <p>Los cuartiles  Q1, Q2 y  Q3  son medidas que dividen un conjunto de datos ordenado en cuatro partes iguales.</p> <p>$$ \\begin{align*} &amp;- Q1 \\text{ es el valor que separa el 25\\% inferior de los datos.} \\\\ &amp;- Q2 \\text{, que es equivalente a la mediana, separa el 50\\% de los datos.} \\\\ &amp;- Q3 \\text{ es el valor que separa el 75\\% superior de los datos.} \\end{align*} $$</p> <p>$$ \\text{La f\u00f3rmula general para calcular los cuartiles es:} $$</p> <p>$$ Q_k = \\left( \\frac{k \\cdot (n + 1)}{100} \\right) $$</p> <p>$$ \\text{Donde } Q_k \\text{ es el cuartil deseado y } n \\text{ es el n\u00famero total de observaciones.} $$</p> <p>En el caso de  Q1  y Q3 , podr\u00eda ser necesario utilizar interpolaci\u00f3n para encontrar los valores exactos en los datos.</p> <p>$$ \\text{Por ejemplo, si tenemos 10 observaciones, los c\u00e1lculos ser\u00edan:} $$</p> <p>$$ \\begin{align*} &amp;- Q1 = \\left( \\frac{25 \\cdot (10 + 1)}{100} \\right) = 3.25 \\quad \\text{(Interpolaci\u00f3n requerida)} \\\\ &amp;- Q2 = \\left( \\frac{50 \\cdot (10 + 1)}{100} \\right) = 6 \\quad \\text{(Posici\u00f3n entera)} \\\\ &amp;- Q3 = \\left( \\frac{75 \\cdot (10 + 1)}{100} \\right) = 8.25 \\quad \\text{(Interpolaci\u00f3n requerida)} \\end{align*} $$</p> <p>Ejercicio 3. En un estudio antropom\u00e9trico en una ciudad de La Paz Bolivia, se recolectaron datos sobre la altura (en cent\u00edmetros) de un grupo de personas seleccionadas al azar. Los datos recopilados son los siguientes:</p> <p>Tabla 3.1  Tabla de las estaturas recopiladas</p> N Estaturas (cm) 1 160 2 165 3 155 4 170 5 160 6 165 7 160 8 155 9 180 10 175 11 170 12 165 13 160 14 165 15 145 <p>Grafica 3.1  estaturas recopiladas</p> In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Alturas de muestra en cent\u00edmetros\nalturas_bolivia = [160, 165, 155, 170, 175, 160, 165, 160, 155, 180, 175, 170, 165, 160, 165]\n\n# Crear la figura y los ejes\nfig, ax = plt.subplots()\n\n# Ajustar el color de fondo\nax.set_facecolor(\"#d4f8b7\")\n# Pintar el fondo externo del gr\u00e1fico\nfig.patch.set_facecolor('#D4F8B7')\n\n# Crear el gr\u00e1fico de barras\nplt.hist(alturas_bolivia, bins=10, color='#5CCB5f', edgecolor='black', linewidth=1.5)\n\n# A\u00f1adir etiquetas y t\u00edtulo con texto en negrita\nplt.xlabel('Alturas (cm)', fontsize=10, fontweight='bold')\nplt.ylabel('Frecuencia', fontsize=10, fontweight='bold')\nplt.title('Distribuci\u00f3n de Alturas', fontsize=12, fontweight='bold')\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import matplotlib.pyplot as plt  # Alturas de muestra en cent\u00edmetros alturas_bolivia = [160, 165, 155, 170, 175, 160, 165, 160, 155, 180, 175, 170, 165, 160, 165]  # Crear la figura y los ejes fig, ax = plt.subplots()  # Ajustar el color de fondo ax.set_facecolor(\"#d4f8b7\") # Pintar el fondo externo del gr\u00e1fico fig.patch.set_facecolor('#D4F8B7')  # Crear el gr\u00e1fico de barras plt.hist(alturas_bolivia, bins=10, color='#5CCB5f', edgecolor='black', linewidth=1.5)  # A\u00f1adir etiquetas y t\u00edtulo con texto en negrita plt.xlabel('Alturas (cm)', fontsize=10, fontweight='bold') plt.ylabel('Frecuencia', fontsize=10, fontweight='bold') plt.title('Distribuci\u00f3n de Alturas', fontsize=12, fontweight='bold')  # Mostrar el gr\u00e1fico plt.show() <p>a) Calcular la media muestral</p> <p>$$ \\bar{x} = \\frac{\\sum_{i=1}^{n} x_i}{n}= \\frac{ x_1+x_2+x_3+...+x_n}{n} $$</p> <p>$$ \\bar{x} =  \\frac{160+165+155+170+160+165+160+155+180+175+170+165+160+165+145}{15} $$</p> <p>$$ \\bar{x} =  \\frac{2285}{15} $$</p> <p>$$ \\bar{x} =  152 $$ b) Calcular la media poblacional</p> <p>Recordando que le media muestral es un estimador de la media poblacional entonces: $$\\mu = 152 $$</p> <p>c) Calcular la mediana Ordenando lso dato se tiene:</p>    $$145 ,155, 155, 160, 160, 160, 160, 165, 165, 165, 165,  170, 170, 175, 180$$  Como la cantidad de datos es impar se tomar\u00e1 la estuta que este en el centro: $$Mediana = 165 cm$$ <p>d) Calcular la moda Viendo la grafica podemos notar que la estatura que hay dos estaturas que mas se repiten siendo bimodal:</p> $$Moda = 160  cm $$ $$Moda = 165  cm $$ <p>e) Calcular el percentil 75 Ordenamos los valores: $$145 ,155, 155, 160, 160, 160, 160, 165, 165, 165, 165,  170, 170, 175, 180$$ Calculamos el indice i :</p> $$i = \\left(\\frac{75}{100}\\right) \\times 15$$ $$i = 11.25$$  redondeando al valor mas proximo:  $$i = 12$$ $$P_{75} = 170$$ <p>f) Calcular el primer cuartil Calculamos el indice i :</p> $$i = \\left(\\frac{25}{100}\\right) \\times 15+1$$ $$i = 4$$ Por lo tanto el cuartil 25 es:  $$ Q_1 = 160 $$    <p>Se tiene una muestra de 100 estudiantes de la Universidad Mayor de San Andr\u00e9s (UMSA) que se graduaron en 2022. Se desea comparar la variabilidad de los tiempos de graduaci\u00f3n entre los estudiantes de la carrera de Ingenier\u00eda de Sistemas y los estudiantes de la carrera de Derecho.</p> <p> ** Histogramas que muestran los tiempos de graduaci\u00f3n de los estudiantes** </p> In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Datos de Ingenier\u00eda de Sistemas\nis_tiempos = [10, 20, 25, 30, 35, 40, 45, 50]\n\n# Datos de Derecho\nd_tiempos = [5, 10, 15, 20, 25]\n\n# Figura\nfig, ax = plt.subplots(1, 2, figsize=(12, 5))\n\n# Histograma de Ingenier\u00eda de Sistemas\nax[0].hist(is_tiempos, bins=4, color='#5CCB5f', edgecolor='black', width=5, alpha=0.5)\nax[0].set_title('Ingenier\u00eda de Sistemas')\nax[0].set_xlabel('Tiempo de graduaci\u00f3n (a\u00f1os)', fontsize=10, fontweight='bold')\nax[0].set_ylabel('Frecuancia relativa', fontsize=10, fontweight='bold')\n#Color de fondo\nax[0].set_facecolor('#D4F8B7')\n\n# Histograma de Derecho\nax[1].hist(d_tiempos, bins=3, color='#5CCB5f', edgecolor='black', width=5, alpha=0.5)\nax[1].set_title('Derecho')\nax[1].set_xlabel('Tiempo de graduaci\u00f3n (a\u00f1os)', fontsize=10, fontweight='bold')\nax[1].set_ylabel('Frecuancia relativa', fontsize=10, fontweight='bold')\n#Color de fondo\nax[1].set_facecolor('#D4F8B7')\n\n\n\nfig = plt.gcf()\nfig.patch.set_facecolor('#D4F8B7')\n\n# Mostrar la figura\nplt.show()\n</pre> import matplotlib.pyplot as plt  # Datos de Ingenier\u00eda de Sistemas is_tiempos = [10, 20, 25, 30, 35, 40, 45, 50]  # Datos de Derecho d_tiempos = [5, 10, 15, 20, 25]  # Figura fig, ax = plt.subplots(1, 2, figsize=(12, 5))  # Histograma de Ingenier\u00eda de Sistemas ax[0].hist(is_tiempos, bins=4, color='#5CCB5f', edgecolor='black', width=5, alpha=0.5) ax[0].set_title('Ingenier\u00eda de Sistemas') ax[0].set_xlabel('Tiempo de graduaci\u00f3n (a\u00f1os)', fontsize=10, fontweight='bold') ax[0].set_ylabel('Frecuancia relativa', fontsize=10, fontweight='bold') #Color de fondo ax[0].set_facecolor('#D4F8B7')  # Histograma de Derecho ax[1].hist(d_tiempos, bins=3, color='#5CCB5f', edgecolor='black', width=5, alpha=0.5) ax[1].set_title('Derecho') ax[1].set_xlabel('Tiempo de graduaci\u00f3n (a\u00f1os)', fontsize=10, fontweight='bold') ax[1].set_ylabel('Frecuancia relativa', fontsize=10, fontweight='bold') #Color de fondo ax[1].set_facecolor('#D4F8B7')    fig = plt.gcf() fig.patch.set_facecolor('#D4F8B7')  # Mostrar la figura plt.show() <p>Como se puede observar, los histogramas muestran que la distribuci\u00f3n de los tiempos de graduaci\u00f3n de los estudiantes de Ingenier\u00eda de Sistemas es m\u00e1s dispersa que la distribuci\u00f3n de los tiempos de graduaci\u00f3n de los estudiantes de Derecho.</p> <p>Ahora se ver\u00e1 a la revisi\u00f3n de algunas medidas de variabilidad de uso com\u00fan.</p> RANGO                  $$Rango = valor mayor - valor menor$$              <p>Los datos sobre los sueldos iniciales para los licenciados en administraci\u00f3n de empresas reci\u00e9n egresados que hemos venido trabajando. El sueldo inicial mayor es de $3 925$ y el menor es de $3 310$. El rango es $3 925 - 3 310 = 615$. Aun cuando el rango es la medida de variabilidad m\u00e1s f\u00e1cil de calcular, pocas veces se usa como la \u00fanica medida debido a que se basa s\u00f3lo en dos de las observaciones y, por tanto, los valores extremos influyen mucho en \u00e9l. Suponga que uno de los licenciados reci\u00e9n egresados recibe un sueldo inicial de $10 000$ al mes. En este caso, el rango ser\u00eda $10 000 - 3 310 - 6 690$ en vez de $615$. Este valor mayor para el rango no describe con claridad la variabilidad de los datos debido a que 11 de los 12 sueldos iniciales se agrupan estrechamente entre $3 310$ y $3 730$.</p> <p>Ejemplo: Seg\u00fan un estudio realizado por el Instituto Nacional de Estad\u00edstica de Bolivia (INE) en 2022.</p> <p>Hombres</p> <ul> <li>Altura minima: 1,52 metros</li> <li>Altura maxima: 1,80 metros</li> </ul> <p>Mujeres</p> <ul> <li>Altura minima: 1,45 metros</li> <li>Altura maxima: 1,61 metros</li> </ul> RANGO               Rango = valor mayor - valor menor          RANGO HOMBRES               Rango hombres = 180 cm - 152 cm = 20 cm          RANGO MUJERES               Rango mujeres = 161 cm - 145 cm = 16 cm           En este caso, el rango de altura para los hombres es de 28 cent\u00edmetros, mientras que el rango para las mujeres es de 16 cent\u00edmetros.    In\u00a0[2]: Copied! <pre>%%html\n&lt;!DOCTYPE html&gt;\n&lt;html lang=\"es\"&gt;\n&lt;head&gt;\n    &lt;meta charset=\"UTF-8\"&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;\n    &lt;title&gt;Rango Intercuart\u00edlico&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n\n   &lt;button onclick=\"generarNumeros()\" type=\"button\" style=\"background-color:#009929\"&gt;Generar Ejercicio&lt;/button&gt;\n\n    &lt;p id=\"numerosAleatorios\"&gt;_&lt;/p&gt;\n\n    &lt;label for=\"inputMayor\"&gt;Ingresa el valor mayor:&lt;/label&gt;\n    &lt;input type=\"number\" id=\"inputMayor\" required style=\"background-color: #D4F8B7;\"&gt;\n    &lt;label for=\"inputMenor\"&gt;Ingresa el valor menor:&lt;/label&gt;\n    &lt;input type=\"number\" id=\"inputMenor\" required style=\"background-color: #D4F8B7;\"&gt;\n    &lt;label for=\"inputRango\"&gt;Ingresa el rango:&lt;/label&gt;\n    &lt;input type=\"number\" id=\"inputRango\" required style=\"background-color: #D4F8B7;\"&gt;\n\n    &lt;button onclick=\"verificar() \"type=\"button\" style=\"background-color:#009929\"&gt;Verificar&lt;/button&gt;\n    &lt;p id=\"resultado\"&gt;&lt;br&gt;&lt;/p&gt;\n\n    &lt;script&gt;\n        var numerosAleatorios = [];\n\n        function generarNumeros() {\n            // Generar 10 n\u00fameros aleatorios entre 1 y 100\n            numerosAleatorios = [];\n            for (var i = 0; i &lt; 10; i++) {\n                numerosAleatorios.push(Math.floor(Math.random() * 100) + 1);\n            }\n\n            // Mostrar los n\u00fameros aleatorios generados\n            document.getElementById(\"numerosAleatorios\").innerText = \"Considere una muestra con los datos  \" + numerosAleatorios.join(\", \");\n        }\n\n        function verificar() {\n            // Obtener valores ingresados por el usuario\n            var numeroMayor = parseInt(document.getElementById(\"inputMayor\").value);\n            var numeroMenor = parseInt(document.getElementById(\"inputMenor\").value);\n            var rangoEsperado = parseInt(document.getElementById(\"inputRango\").value);\n\n            // Verificar si los n\u00fameros generados cumplen con los criterios\n            var rangoCalculado = Math.max(...numerosAleatorios) - Math.min(...numerosAleatorios);\n\n            var resultado = \"\";\n\n            if (rangoCalculado === rangoEsperado &amp;&amp; Math.max(...numerosAleatorios) === numeroMayor &amp;&amp; Math.min(...numerosAleatorios) === numeroMenor) {\n                resultado += \"&lt;strong&gt;\u00a1Verificaci\u00f3n exitosa!&lt;/strong&gt;\";\n            } else {\n                resultado += \"&lt;strong&gt; Verificaci\u00f3n fallida. Por favor, verifica los valores ingresados.&lt;/strong&gt;\";\n            }\n\n            // Mostrar los resultados en el documento HTML\n            document.getElementById(\"resultado\").innerHTML = resultado;\n        }\n    &lt;/script&gt;\n\n&lt;/body&gt;\n&lt;/html&gt;\n</pre> %%html  Rango Intercuart\u00edlico Generar Ejercicio <p>_</p> Ingresa el valor mayor: Ingresa el valor menor: Ingresa el rango: Verificar <p></p> Rango Intercuart\u00edlico Generar Ejercicio <p>_</p> Ingresa el valor mayor: Ingresa el valor menor: Ingresa el rango: Verificar <p></p> <p>Una medida de la variabilidad que supera la dependencia sobre los valores extremos es el rango intercuart\u00edlico (RIC). Esta medida de la variabilidad es la diferencia entre el tercer cuartil, $Q_3$, y el primer cuartil, $Q_1$. En otras palabras, el rango intercuart\u00edlico es el rango de la media de $50\\%$ de los datos.</p> RANGO INTERCUART\u00cdLICO                  $$RIC = Q_3 - Q_1$$              (3.3) <p>Para los datos sobre los sueldos mensuales iniciales, los cuartiles son $Q_3 = 3 600$ y $Q_1 = 3 465$. Por tanto, el rango intercuart\u00edlico es $3 600 - 3 465 = 135$.</p> <p>**Ejemplo: **  </p> <p>Para calcular el RIC, primero se deben ordenar los datos de menor a mayor. Luego, se encuentran $Q_1$ y $Q_3$. $Q_1$ es el valor que divide la mitad inferior de los datos en dos partes iguales. $Q_3$ es el valor que divide la mitad superior de los datos en dos partes iguales.</p> <p>Por ejemplo, si un conjunto de datos tiene los siguientes valores:</p> <p>$$1, 2, 3, 4, 5, 6, 7, 8, 9, 10$$</p> <p>$Q_1$ es igual a 3 y $Q_3$ es igual a 8. Por lo tanto, el RIC es igual a 5:</p> RANGO INTERCUARTILICO              $$RIC = Q_3 - Q_1$$               $$RIC = 8 - 3 = 5$$          <p>El RIC se puede interpretar como el rango de valores que abarcan el 50% central de los datos. En el ejemplo anterior, el 50% de los datos se encuentran entre 3 y 8.</p> In\u00a0[3]: Copied! <pre>%%html\n&lt;!DOCTYPE html&gt;\n&lt;html lang=\"es\"&gt;\n&lt;head&gt;\n    &lt;meta charset=\"UTF-8\"&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;\n    &lt;title&gt;Rango Intercuart\u00edlico&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;button onclick=\"generarNumeros()\" type=\"button\" style=\"background-color:#009929\"&gt;Generar N\u00fameros&lt;/button&gt;\n\n    &lt;p id=\"numerosAleatorios\"&gt;&lt;/p&gt;\n\n    &lt;label for=\"inputMayor\"&gt;Ingresa Q&lt;sub&gt;3&lt;/sub&gt;:&lt;/label&gt;\n    &lt;input type=\"number\" id=\"inputMayor\" required style=\"background-color: #D4F8B7;\"&gt;\n    &lt;label for=\"inputMenor\"&gt;Ingresa Q&lt;sub&gt;1&lt;/sub&gt;:&lt;/label&gt;\n    &lt;input type=\"number\" id=\"inputMenor\" required style=\"background-color: #D4F8B7;\"&gt;\n    &lt;label for=\"inputRango\"&gt;Ingresa el rango intercuartilico:&lt;/label&gt;\n    &lt;input type=\"number\" id=\"inputRango\" required style=\"background-color: #D4F8B7;\"&gt;\n\n    &lt;button onclick=\"verificar()\" type=\"button\" style=\"background-color:#009929\"&gt;Verificar&lt;/button&gt;\n    &lt;p id=\"resultado\"&gt;&lt;br&gt;&lt;/p&gt;\n\n    &lt;script&gt;\n        var numerosAleatorios = [];\n\n        function generarNumeros() {\n            // Generar 10 n\u00fameros aleatorios entre 1 y 100\n            numerosAleatorios = [];\n            for (var i = 0; i &lt; 10; i++) {\n                numerosAleatorios.push(Math.floor(Math.random() * 100) + 1);\n            }\n\n            // Mostrar los n\u00fameros aleatorios generados\n            document.getElementById(\"numerosAleatorios\").innerText = \"N\u00fameros aleatorios generados: \" + numerosAleatorios.join(\", \");\n        }\n\n        function verificar() {\n            // Obtener valores ingresados por el usuario\n            var numeroMayor = parseInt(document.getElementById(\"inputMayor\").value);\n            var numeroMenor = parseInt(document.getElementById(\"inputMenor\").value);\n            var rangoEsperado = parseInt(document.getElementById(\"inputRango\").value);\n\n            // Verificar si los n\u00fameros generados cumplen con los criterios\n            // Ordenar los datos\n            var datosOrdenados = numerosAleatorios.slice().sort(function(a, b) {\n                return a - b;\n            });\n            \n            var Q1 = datosOrdenados[2];\n            var Q3 = datosOrdenados[7];\n\n            var iqrCalculado = Q3-Q1;\n\n            var resultado = \"\";\n\n            if (iqrCalculado === rangoEsperado &amp;&amp; Q3 === numeroMayor &amp;&amp; Q1 === numeroMenor) {\n                resultado += \"&lt;strong&gt;\u00a1Verificaci\u00f3n exitosa!&lt;/strong&gt;\";\n            } else {\n                resultado += \"&lt;strong&gt;Verificaci\u00f3n fallida. Por favor, verifica los valores ingresados.&lt;/strong&gt;\";\n            }\n\n            // Mostrar los resultados en el documento HTML\n            document.getElementById(\"resultado\").innerHTML = resultado;\n        }\n\n    &lt;/script&gt;\n\n&lt;/body&gt;\n&lt;/html&gt;\n</pre> %%html  Rango Intercuart\u00edlico Generar N\u00fameros <p></p> Ingresa Q<sub>3</sub>: Ingresa Q<sub>1</sub>: Ingresa el rango intercuartilico: Verificar <p></p> Rango Intercuart\u00edlico Generar N\u00fameros <p></p> Ingresa Q<sub>3</sub>: Ingresa Q<sub>1</sub>: Ingresa el rango intercuartilico: Verificar <p></p> In\u00a0[4]: Copied! <pre>from IPython.display import YouTubeVideo\n\nyoutube_video = YouTubeVideo('YRfpblzLTrA')\n\ndisplay(youtube_video)\n</pre> from IPython.display import YouTubeVideo  youtube_video = YouTubeVideo('YRfpblzLTrA')  display(youtube_video) <p>La varianza es una medida de la variabilidad que utiliza todos los datos. Se basa en la diferencia entre el valor de cada observaci\u00f3n $(x_i)$ y la media. La diferencia entre cada $x_i$ y la media($\\overline{x}$ para una muestra; \u03bc para una poblaci\u00f3n) se llama desviaci\u00f3n respecto de la media. Para una muestra, una desviaci\u00f3n respecto de la media se escribe ($x_i$ - $\\overline{x}$); para una poblaci\u00f3n, se escribe ($x_i$ - \u03bc). Si se desea calcular la varianza, las desviaciones respecto de la media se elevan al cuadrado.</p> <p>Si los datos pertenecen a una poblaci\u00f3n, el promedio de las desviaciones elevadas al cuadrado se llama varianza poblacional, la cual se denota por medio del s\u00edmbolo griego $\u03c3_2$. Para una poblaci\u00f3n de N observaciones con una media poblacional \u03bc, la definici\u00f3n de la varianza poblacional es la siguiente.</p>  VARIANZA POBLACIONAL              $$\\sigma^2 = \\frac{\\sum(x_i-\\mu)^2}{N}$$          (3.4)       donde:  <ul> <li>$ \\sigma^2 $ es la varianza poblacional.</li> <li>$ x_i $ es un dato de la poblaci\u00f3n.</li> <li>$ \\mu $ es la media poblacional.</li> <li>$ N $ es el tama\u00f1o de la poblaci\u00f3n.</li></ul> In\u00a0[5]: Copied! <pre>import matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\n# Crear la figura y el eje\nfig, ax = plt.subplots()\n\n#color\nfig.patch.set_facecolor('#D4F8B7')\n\n#formula\nax.text(0.25,0.3,r\"$\\sigma^2 = \\frac{\\sum(x_i-\\mu)^2}{N}$\",fontsize=30)\n\n# Agregar el texto y las flechas\nax.text(0.2, 0.6, 'Varianza poblacional', fontsize=12, ha='center', va='center')\narrow_n = patches.FancyArrowPatch((0.2, 0.56), (0.27, 0.4), mutation_scale=15, color='#5CCB5f')\nax.add_patch(arrow_n)\n\nax.text(0.4, 0.7, 'Dato de la poblacion', fontsize=12, ha='center', va='center')\narrow_n = patches.FancyArrowPatch((0.4, 0.66), (0.54, 0.44), mutation_scale=15, color='#5CCB5f')\nax.add_patch(arrow_n)\n\nax.text(0.8, 0.7, 'Media poblacional', fontsize=12, ha='center', va='center')\narrow_mean = patches.FancyArrowPatch((0.8, 0.65), (0.68, 0.44), mutation_scale=15, color='#5CCB5f')\nax.add_patch(arrow_mean)\n\nax.text(0.8, 0.1, 'Tama\u00f1o de la Poblaci\u00f3n', fontsize=12, ha='center', va='center')\narrow_summation = patches.FancyArrowPatch((0.8, 0.15), (0.62, 0.27), mutation_scale=15, color='#5CCB5f')\nax.add_patch(arrow_summation)\n\n# Ajustar l\u00edmites y mostrar la imagen\nax.set_xlim(0, 1)\nax.set_ylim(0, 0.8)\n\n# Ocultar ejes\nax.axis('off')\n\nplt.show()\n</pre> import matplotlib.pyplot as plt import matplotlib.patches as patches  # Crear la figura y el eje fig, ax = plt.subplots()  #color fig.patch.set_facecolor('#D4F8B7')  #formula ax.text(0.25,0.3,r\"$\\sigma^2 = \\frac{\\sum(x_i-\\mu)^2}{N}$\",fontsize=30)  # Agregar el texto y las flechas ax.text(0.2, 0.6, 'Varianza poblacional', fontsize=12, ha='center', va='center') arrow_n = patches.FancyArrowPatch((0.2, 0.56), (0.27, 0.4), mutation_scale=15, color='#5CCB5f') ax.add_patch(arrow_n)  ax.text(0.4, 0.7, 'Dato de la poblacion', fontsize=12, ha='center', va='center') arrow_n = patches.FancyArrowPatch((0.4, 0.66), (0.54, 0.44), mutation_scale=15, color='#5CCB5f') ax.add_patch(arrow_n)  ax.text(0.8, 0.7, 'Media poblacional', fontsize=12, ha='center', va='center') arrow_mean = patches.FancyArrowPatch((0.8, 0.65), (0.68, 0.44), mutation_scale=15, color='#5CCB5f') ax.add_patch(arrow_mean)  ax.text(0.8, 0.1, 'Tama\u00f1o de la Poblaci\u00f3n', fontsize=12, ha='center', va='center') arrow_summation = patches.FancyArrowPatch((0.8, 0.15), (0.62, 0.27), mutation_scale=15, color='#5CCB5f') ax.add_patch(arrow_summation)  # Ajustar l\u00edmites y mostrar la imagen ax.set_xlim(0, 1) ax.set_ylim(0, 0.8)  # Ocultar ejes ax.axis('off')  plt.show() <p>**Ejemplo: **  </p> In\u00a0[6]: Copied! <pre>from IPython.display import YouTubeVideo\n\nyoutube_video = YouTubeVideo('A7xDMQ6CQj0')\n\ndisplay(youtube_video)\n</pre> from IPython.display import YouTubeVideo  youtube_video = YouTubeVideo('A7xDMQ6CQj0')  display(youtube_video) <p>En la mayor\u00eda de las aplicaciones estad\u00edsticas, los datos que se analizan provienen de una muestra. Cuando se calcula una varianza muestral, a menudo lo que interesa es usarla para estimar la varianza poblacional $\u03c3^2$.Esta mostrarse que si la suma de las desviaciones respecto de la media al cuadrado se divide entre $n - 1$, y no entre $n$, la varianza muestral resultante proporciona un estimador insesgado de la varianza poblacional. Por esta raz\u00f3n, la varianza muestral, denotada por $s^2$, se define como sigue.</p> <p>La varianza muestral es una medida estad\u00edstica que describe la dispersi\u00f3n de un conjunto de datos en relaci\u00f3n con la media de una muestra. Se representa com\u00fanmente por el s\u00edmbolo $s^2$. La f\u00f3rmula para calcular la varianza muestral es la siguiente:</p> <p>Formula para la Varianza Muestral</p> <p>$s^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})$</p> <p>Donde:</p> <ul> <li>$s^2$ es la varianza muestral.</li> <li>$n$ es el tama\u00f1o de la muestra.</li> <li>$x_i$ son los valores individuales en la muestra.</li> <li>$\\bar{x}$ es la media de la muestra.</li> </ul> <p>Ejercicios</p> <p>Seg\u00fan la recopilaci\u00f3n de datos realizada por la Divisi\u00f3n de Estad\u00edstica de Delitos contra la Propiedad en Bolivia durante los meses de enero a febrero de 2021, se ha elaborado una tabla que refleja la incidencia de robos agravados. A continuaci\u00f3n, utilizaremos los datos proporcionados en esta tabla para calcular la varianza muestral</p> Departamento Robos Agrabados Beni 34 Chuquisaca 38 Cochabamba 107 La Paz 17 Oruro 11 Pando 17 Potos\u00ed 25 Santa Cruz 130 Tarija 35 <p>Paso 1: Calcular la media $\\bar{x}$:</p> <p>$ \\bar{x} = \\frac{34 + 38 + 107 + 17 + 11 + 17 + 25 + 130 + 35}{9} \\approx 46 $</p> <p>Paso 2: Calcular las diferencias y elevar al cuadrado:</p> <p>$ (34 - 46)^2 = 144 $</p> <p>$ (38 - 46)^2 = 64 $</p> <p>$ (107 - 46)^2 = 3961 $</p> <p>$ (17 - 46)^2 = 841 $</p> <p>$ (11 - 46)^2 = 1225 $</p> <p>$ (17 - 46)^2 = 841 $</p> <p>$ (25 - 46)^2 = 441 $</p> <p>$ (130 - 46)^2 = 7921 $</p> <p>$ (35 - 46)^2 = 121 $</p> <p>Paso 3: Calcular la varianza muestral $s^2$:</p> <p>$$ s^2 = \\frac{(34 - 46)^2 + (38 - 46)^2 + \\ldots + (35 - 46)^2}{8} = \\frac{144 + 64 + 3961 + 841 + 1225 + 841 + 441 + 7921 + 121}{8} \\approx 2250.5 $$</p> <p>Como conclusion, un valor m\u00e1s alto de varianza sugiere una mayor variabilidad en la cantidad de robos agravados entre los departamentos. Esta medida estad\u00edstica es \u00fatil para comprender la amplitud de la distribuci\u00f3n y para identificar patrones de variabilidad en los datos.</p> In\u00a0[7]: Copied! <pre>from IPython.display import YouTubeVideo\n\nyoutube_video = YouTubeVideo('https://www.youtube.com/watch?v=hLmsEFNaOgY&amp;list=PLeySRPnY35dE25b7mIEUlsMCQqlhJFhyG')\n\ndisplay(youtube_video)\n</pre> from IPython.display import YouTubeVideo  youtube_video = YouTubeVideo('https://www.youtube.com/watch?v=hLmsEFNaOgY&amp;list=PLeySRPnY35dE25b7mIEUlsMCQqlhJFhyG')  display(youtube_video) <p>Desviaci\u00f3n est\u00e1ndar muestral</p> <p>La desviaci\u00f3n est\u00e1ndar muestral es una medida estad\u00edstica que cuantifica la dispersi\u00f3n o variabilidad de un conjunto de datos en relaci\u00f3n con la media muestral. Es particularmente \u00fatil para comprender cu\u00e1n dispersos est\u00e1n los valores individuales con respecto a la media aritm\u00e9tica de la muestra.</p> <p>La f\u00f3rmula para la desviaci\u00f3n est\u00e1ndar muestral ($s$) es:</p> <p>Formula de la Desviacion Estandar Muestral</p> <p>$$s = \\sqrt{s^2} $$</p> <p>Donde:</p> <ul> <li>$s^2$ es la Desviacion estandar muestral.</li> </ul> <p>Desviacion Estandar Poblacional</p> <p>La desviaci\u00f3n est\u00e1ndar poblacional es una medida estad\u00edstica que cuantifica la dispersi\u00f3n o variabilidad de un conjunto de datos en relaci\u00f3n con la media poblacional. A diferencia de la desviaci\u00f3n est\u00e1ndar muestral, la desviaci\u00f3n est\u00e1ndar poblacional utiliza la media de la poblaci\u00f3n en lugar de la media muestral.</p> <p>La f\u00f3rmula para la desviaci\u00f3n est\u00e1ndar poblacional ($\\sigma$) es:</p> <p>Formula de la Desviacion Estandar Poblacional</p> <p>$\\sigma = \\sqrt{\\sigma^2}$</p> <p>Donde:</p> <ul> <li>$\\sigma^2$ es la  Desviacion estandar poblacional.</li> </ul> <p>Ejercicios</p> <p>Calcular la Desvicion estandar muestral del ejemplo mencionado anteriormente.</p> <p>$$s = \\sqrt{s^2} = \\sqrt{2250.5} \\approx 47.44$$</p> In\u00a0[8]: Copied! <pre>from IPython.display import YouTubeVideo\n\nyoutube_video = YouTubeVideo('A7xDMQ6CQj0')\n\ndisplay(youtube_video)\n</pre> from IPython.display import YouTubeVideo  youtube_video = YouTubeVideo('A7xDMQ6CQj0')  display(youtube_video) <p>El coeficiente de variaci\u00f3n es una medida estad\u00edstica que proporciona informaci\u00f3n sobre la variabilidad relativa de un conjunto de datos en comparaci\u00f3n con su media. Esta medida es especialmente \u00fatil cuando se trabaja con diferentes escalas o unidades. La f\u00f3rmula para calcular el (CV) se expresa como:</p> <p>$$CV = (\\left( \\frac{\\text{Desviaci\u00f3n est\u00e1ndar}}{\\text{Media}} \\right) \\times 100)\\%$$</p> <p>El (CV) se presenta como un porcentaje y cuantifica la dispersi\u00f3n de los datos en relaci\u00f3n con su valor promedio, permitiendo una comparaci\u00f3n m\u00e1s significativa entre  de datos con magnitudes diferentes.</p> <p>Ejemplo</p> <p>Vamos a utilizar un ejemplo hipot\u00e9tico relacionado con las alturas de estudiantes en dos escuelas diferentes en Bolivia para calcular el coeficiente de variaci\u00f3n.</p> <p>Supongamos que tenemos las alturas de los estudiantes de dos escuelas (en cent\u00edmetros):</p> <p>Escuela A: 150, 155, 160, 165, 170 Escuela B: 140, 145, 160, 175, 180</p> <p>Primero, calculemos el coeficiente de variaci\u00f3n utilizando la formula anterior.</p> In\u00a0[9]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Alturas de estudiantes en cent\u00edmetros\nalturas_escuela_a = np.array([150, 155, 160, 165, 170])\nalturas_escuela_b = np.array([140, 145, 160, 175, 180])\n\n# Calcular la media y la desviaci\u00f3n est\u00e1ndar para cada escuela\nmedia_a = np.mean(alturas_escuela_a)\ndesviacion_estandar_a = np.std(alturas_escuela_a)\ncv_a = (desviacion_estandar_a / media_a) * 100\n\nmedia_b = np.mean(alturas_escuela_b)\ndesviacion_estandar_b = np.std(alturas_escuela_b)\ncv_b = (desviacion_estandar_b / media_b) * 100\n\n# Gr\u00e1fico comparativo\nfig, axs = plt.subplots(1, 2, figsize=(12, 5))\n\n# Escuela A\naxs[0].hist(alturas_escuela_a, edgecolor=\"black\", color=\"#5CCB5F\")\naxs[0].axvline(x=media_a, color='red', linestyle='dashed', linewidth=2, label=f'Media: {media_a:.2f}')\naxs[0].set_title(f\"Escuela A CV: {cv_a:.2f}%\", color=\"#5CCB5F\")\naxs[0].set_xlabel(\"Alturas (cm)\")\naxs[0].set_ylabel(\"Frecuencia relativa\")\naxs[0].legend()\naxs[0].set_facecolor('#D4F8B7')\n\n# Escuela B\naxs[1].hist(alturas_escuela_b, edgecolor=\"black\", color=\"#5CCB5F\")\naxs[1].axvline(x=media_b, color='red', linestyle='dashed', linewidth=2, label=f'Media: {media_b:.2f}')\naxs[1].set_title(f\"Escuela B CV: {cv_b:.2f}%\", color=\"#5CCB5F\")\naxs[1].set_xlabel(\"Alturas (cm)\")\naxs[1].set_ylabel(\"Frecuencia relativa\")\naxs[1].legend()\naxs[1].set_facecolor('#D4F8B7')\n\n# Ajustes generales\nfig.patch.set_facecolor('#D4F8B7')\nplt.suptitle(\"Comparaci\u00f3n de Alturas de Estudiantes en Escuelas A y B\", fontsize=16, color=\"#5CCB5F\")\n\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  # Alturas de estudiantes en cent\u00edmetros alturas_escuela_a = np.array([150, 155, 160, 165, 170]) alturas_escuela_b = np.array([140, 145, 160, 175, 180])  # Calcular la media y la desviaci\u00f3n est\u00e1ndar para cada escuela media_a = np.mean(alturas_escuela_a) desviacion_estandar_a = np.std(alturas_escuela_a) cv_a = (desviacion_estandar_a / media_a) * 100  media_b = np.mean(alturas_escuela_b) desviacion_estandar_b = np.std(alturas_escuela_b) cv_b = (desviacion_estandar_b / media_b) * 100  # Gr\u00e1fico comparativo fig, axs = plt.subplots(1, 2, figsize=(12, 5))  # Escuela A axs[0].hist(alturas_escuela_a, edgecolor=\"black\", color=\"#5CCB5F\") axs[0].axvline(x=media_a, color='red', linestyle='dashed', linewidth=2, label=f'Media: {media_a:.2f}') axs[0].set_title(f\"Escuela A CV: {cv_a:.2f}%\", color=\"#5CCB5F\") axs[0].set_xlabel(\"Alturas (cm)\") axs[0].set_ylabel(\"Frecuencia relativa\") axs[0].legend() axs[0].set_facecolor('#D4F8B7')  # Escuela B axs[1].hist(alturas_escuela_b, edgecolor=\"black\", color=\"#5CCB5F\") axs[1].axvline(x=media_b, color='red', linestyle='dashed', linewidth=2, label=f'Media: {media_b:.2f}') axs[1].set_title(f\"Escuela B CV: {cv_b:.2f}%\", color=\"#5CCB5F\") axs[1].set_xlabel(\"Alturas (cm)\") axs[1].set_ylabel(\"Frecuencia relativa\") axs[1].legend() axs[1].set_facecolor('#D4F8B7')  # Ajustes generales fig.patch.set_facecolor('#D4F8B7') plt.suptitle(\"Comparaci\u00f3n de Alturas de Estudiantes en Escuelas A y B\", fontsize=16, color=\"#5CCB5F\")  plt.show() <p>Escuela A</p> <p>En la Escuela A, hemos recopilado las siguientes alturas de estudiantes:</p> <ul> <li>Alturas: [150, 155, 160, 165, 170]</li> <li>Media: 162.00 cm</li> <li>Desviaci\u00f3n Est\u00e1ndar: 6.24 cm</li> <li>Coeficiente de Variaci\u00f3n (CV): 3.85%</li> </ul> <p>En el histograma correspondiente, la l\u00ednea roja punteada indica la media de las alturas.</p> <p>Escuela B</p> <p>En la Escuela B, los datos de alturas son los siguientes:</p> <ul> <li>Alturas: [140, 145, 160, 175, 180]</li> <li>Media: 160.00 cm</li> <li>Desviaci\u00f3n Est\u00e1ndar: 15.13 cm</li> <li>Coeficiente de Variaci\u00f3n (CV): 9.46%</li> </ul> <p>Nuevamente, en el gr\u00e1fico de alturas de la Escuela B, la l\u00ednea roja punteada destaca la media.</p> <p>Comparaci\u00f3n</p> <p>Al comparar las dos escuelas, observamos que la Escuela A tiene una menor variabilidad en las alturas con un CV del 3.85%, mientras que la Escuela B muestra una mayor variabilidad con un CV del 9.46%.</p> <p>Esta informaci\u00f3n nos proporciona una comprensi\u00f3n inicial de la dispersi\u00f3n de las alturas en ambas escuelas.</p> In\u00a0[10]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Datos para un histograma sesgado a la derecha\ndatos_sesgo_derecha = np.random.exponential(scale=2, size=1000)\n\n# Datos para un histograma sesgado a la izquierda\ndatos_sesgo_izquierda = -np.random.exponential(scale=2, size=1000)\n\n# Datos para un histograma sin sesgo\ndatos_sin_sesgo = np.random.normal(loc=0, scale=2, size=1000)\n\n# Gr\u00e1ficos\nfig, axs = plt.subplots(1, 3, figsize=(15, 5))\n\n# Histograma sesgado a la derecha\naxs[0].hist(datos_sesgo_derecha, bins=30, color=\"#FFD700\", edgecolor=\"black\")\naxs[0].set_title(\"Sesgo a la Derecha\")\naxs[0].set_xlabel(\"Valores\")\naxs[0].set_ylabel(\"Frecuencia relativa\")\n\n# Histograma sesgado a la izquierda\naxs[1].hist(datos_sesgo_izquierda, bins=30, color=\"#FFD700\", edgecolor=\"black\")\naxs[1].set_title(\"Sesgo a la Izquierda\")\naxs[1].set_xlabel(\"Valores\")\naxs[1].set_ylabel(\"Frecuencia relativa\")\n\n# Histograma sin sesgo\naxs[2].hist(datos_sin_sesgo, bins=30, color=\"#FFD700\", edgecolor=\"black\")\naxs[2].set_title(\"Sin Sesgo\")\naxs[2].set_xlabel(\"Valores\")\naxs[2].set_ylabel(\"Frecuencia relativa\")\n\n# Ajustes generales\nfig.patch.set_facecolor('#D4F8B7')\nplt.suptitle(\"Ejemplos de Sesgo en Histogramas\", fontsize=16, color=\"#5CCB5F\")\n\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  # Datos para un histograma sesgado a la derecha datos_sesgo_derecha = np.random.exponential(scale=2, size=1000)  # Datos para un histograma sesgado a la izquierda datos_sesgo_izquierda = -np.random.exponential(scale=2, size=1000)  # Datos para un histograma sin sesgo datos_sin_sesgo = np.random.normal(loc=0, scale=2, size=1000)  # Gr\u00e1ficos fig, axs = plt.subplots(1, 3, figsize=(15, 5))  # Histograma sesgado a la derecha axs[0].hist(datos_sesgo_derecha, bins=30, color=\"#FFD700\", edgecolor=\"black\") axs[0].set_title(\"Sesgo a la Derecha\") axs[0].set_xlabel(\"Valores\") axs[0].set_ylabel(\"Frecuencia relativa\")  # Histograma sesgado a la izquierda axs[1].hist(datos_sesgo_izquierda, bins=30, color=\"#FFD700\", edgecolor=\"black\") axs[1].set_title(\"Sesgo a la Izquierda\") axs[1].set_xlabel(\"Valores\") axs[1].set_ylabel(\"Frecuencia relativa\")  # Histograma sin sesgo axs[2].hist(datos_sin_sesgo, bins=30, color=\"#FFD700\", edgecolor=\"black\") axs[2].set_title(\"Sin Sesgo\") axs[2].set_xlabel(\"Valores\") axs[2].set_ylabel(\"Frecuencia relativa\")  # Ajustes generales fig.patch.set_facecolor('#D4F8B7') plt.suptitle(\"Ejemplos de Sesgo en Histogramas\", fontsize=16, color=\"#5CCB5F\")  plt.show()  <p>En una distribuci\u00f3n sim\u00e9trica, la media y la mediana son iguales. Cuando los datos est\u00e1n sesgados positivamente, la media por lo general ser\u00e1 mayor que la mediana; cuando est\u00e1n sesgados negativamente, la media ser\u00e1 menor que la mediana.</p> <p>El valor Z, tambi\u00e9n conocido como puntaje Z o estad\u00edstico Z, es una medida estandarizada que indica cu\u00e1ntas desviaciones est\u00e1ndar un punto de datos est\u00e1 del promedio de un conjunto. Este valor Z es esencial en estad\u00edsticas, ya que proporciona una forma de comparar y entender la posici\u00f3n relativa de un dato dentro de una distribuci\u00f3n.</p> <p>El c\u00e1lculo del valor Z se realiza utilizando la siguiente f\u00f3rmula: $$Z =  \\frac{\\text{X - \u03bc}}{\\text{\u03c3}} $$</p> <p>donde:</p> <ul> <li>X es el valor individual</li> <li>\u03bc es la media de la poblaci\u00f3n</li> <li>\u03c3 es la desviaci\u00f3n est\u00e1ndar de la poblaci\u00f3n.</li> </ul> <p>Un valor Z positivo indica que el dato est\u00e1 por encima de la media, mientras que un valor Z negativo indica que est\u00e1 por debajo de la media.</p> <p>Ejemplo Rendimiento en Ex\u00e1menes</p> <ul> <li><p>Grupo A:</p> </li> <li><p>Media de puntajes: 75</p> </li> <li><p>Desviaci\u00f3n est\u00e1ndar: 10</p> </li> <li><p>Puntaje de Estudiante X en Grupo A: 85</p> </li> <li><p>Grupo B:</p> </li> <li><p>Media de puntajes: 65</p> </li> <li><p>Desviaci\u00f3n est\u00e1ndar: 8</p> </li> <li><p>Puntaje de Estudiante Y en Grupo B: 72</p> </li> </ul> In\u00a0[11]: Copied! <pre>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.table import Table\n\n# Datos\ndata = {\n    'Grupo': ['A', 'B'],\n    'Media': [75, 65],\n    'Desviaci\u00f3n Est\u00e1ndar': [10, 8],\n    'Puntaje del Estudiante': [85, 72],\n    'Valor Z del Estudiante': [1, 0.875]\n}\n\n# Crear un DataFrame\ndf = pd.DataFrame(data)\n\n# Crear la figura y los ejes\nfig, ax = plt.subplots(figsize=(8, 4))\n\n# Ocultar ejes\nax.set_axis_off()\n\n# Convertir el DataFrame a una tabla de matplotlib\ntabla = Table(ax, bbox=[0, 0, 1, 1])\n\n# Ajustar autom\u00e1ticamente el ancho de las columnas\ntabla.auto_set_column_width([0, 1, 2, 3, 4])\n\n# A\u00f1adir filas y columnas a la tabla\ntabla.auto_set_font_size(False)\ntabla.set_fontsize(10)\ntabla.scale(1.2, 1.2)  # Ajustar el tama\u00f1o de la tabla\n\n# Encabezados de columna\nfor i, key in enumerate(df.keys()):\n    tabla.add_cell(0, i, 0.1, 0.1, text=key, loc='center', facecolor='#5CCB5F')\n\n# Datos y colores\ncolors = [\n    ['#5CCB5F', '#5CCB5F', '#D4F8B7', '#D4F8B7', '#D4F8B7'],\n    ['#5CCB5F', '#5CCB5F', '#D4F8B7', '#D4F8B7', '#D4F8B7']\n]\nfor i in range(len(df)):\n    for j, key in enumerate(df.keys()):\n        tabla.add_cell(i+1, j, 0.1, 0.1, text=str(df.iloc[i, j]), loc='center', facecolor=colors[i][j])\n\n# A\u00f1adir la tabla al eje\nax.add_table(tabla)\n\nplt.show()\n</pre> import pandas as pd import numpy as np import matplotlib.pyplot as plt from matplotlib.table import Table  # Datos data = {     'Grupo': ['A', 'B'],     'Media': [75, 65],     'Desviaci\u00f3n Est\u00e1ndar': [10, 8],     'Puntaje del Estudiante': [85, 72],     'Valor Z del Estudiante': [1, 0.875] }  # Crear un DataFrame df = pd.DataFrame(data)  # Crear la figura y los ejes fig, ax = plt.subplots(figsize=(8, 4))  # Ocultar ejes ax.set_axis_off()  # Convertir el DataFrame a una tabla de matplotlib tabla = Table(ax, bbox=[0, 0, 1, 1])  # Ajustar autom\u00e1ticamente el ancho de las columnas tabla.auto_set_column_width([0, 1, 2, 3, 4])  # A\u00f1adir filas y columnas a la tabla tabla.auto_set_font_size(False) tabla.set_fontsize(10) tabla.scale(1.2, 1.2)  # Ajustar el tama\u00f1o de la tabla  # Encabezados de columna for i, key in enumerate(df.keys()):     tabla.add_cell(0, i, 0.1, 0.1, text=key, loc='center', facecolor='#5CCB5F')  # Datos y colores colors = [     ['#5CCB5F', '#5CCB5F', '#D4F8B7', '#D4F8B7', '#D4F8B7'],     ['#5CCB5F', '#5CCB5F', '#D4F8B7', '#D4F8B7', '#D4F8B7'] ] for i in range(len(df)):     for j, key in enumerate(df.keys()):         tabla.add_cell(i+1, j, 0.1, 0.1, text=str(df.iloc[i, j]), loc='center', facecolor=colors[i][j])  # A\u00f1adir la tabla al eje ax.add_table(tabla)  plt.show()  <p>Para el estudiante X en el Grupo A:</p> <p>$$Z =  \\frac{\\text{85 - 75}}{\\text{10}} = 1$$</p> <p>El valor Z de 1 indica que el puntaje del estudiante X est\u00e1 a una desviaci\u00f3n est\u00e1ndar por encima de la media del Grupo A.</p> <p>Para el estudiante Y en el Grupo B:</p> <p>$$Z =  \\frac{\\text{72 - 65}}{\\text{8}} = 0.875$$</p> <p>El valor Z de 0.875 indica que el puntaje del estudiante Y est\u00e1 a aproximadamente 0.88 desviaciones est\u00e1ndar por encima de la media del Grupo B.</p> <p>Estos valores Z proporcionan una forma estandarizada de comparar el rendimiento relativo de los estudiantes en diferentes grupos.</p> <p>El Teorema de Chebyshev es un principio estad\u00edstico que proporciona informaci\u00f3n sobre la dispersi\u00f3n de datos en cualquier conjunto de datos, independientemente de su forma de distribuci\u00f3n. Este teorema es especialmente \u00fatil cuando no conocemos la forma exacta de la distribuci\u00f3n de los datos. La formulaci\u00f3n general del Teorema de Chebyshev es la siguiente:</p> <p>Para cualquier conjunto de datos, la proporci\u00f3n de observaciones dentro de $k$ desviaciones est\u00e1ndar de la media es al menos $1 -  \\frac{\\text{1}}{\\text{k\u00b2}}$ , donde $k &gt; 1.$</p> <p>En otras palabras, al menos $1 -  \\frac{\\text{1}}{\\text{k\u00b2}}$ del total de los datos se encuentra dentro de $k$ desviaciones est\u00e1ndar de la media.</p> <p>Ejemplo Supongamos que tenemos un conjunto de datos con una media de 50 y una desviaci\u00f3n est\u00e1ndar de 10. Utilizaremos el teorema para calcular el porcentaje de datos que se encuentra dentro de 2 y 3 desviaciones est\u00e1ndar de la media.</p> In\u00a0[12]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image, display\n\n# Generar datos ficticios\nnp.random.seed(42)\ndatos = np.random.normal(loc=50, scale=10, size=1000)\n\n# Crear histograma con color de fondo personalizado\nfig, ax = plt.subplots()\nax.hist(datos, bins=30, color=\"#5CCB5F\", edgecolor=\"black\")\nax.axvline(np.mean(datos), color='red', linestyle='dashed', linewidth=2, label=f'Media: {np.mean(datos):.2f}')\nax.axvline(np.mean(datos) + 2 * np.std(datos), color='orange', linestyle='dashed', linewidth=2, label='+2 Desviaciones')\nax.axvline(np.mean(datos) - 2 * np.std(datos), color='orange', linestyle='dashed', linewidth=2, label='-2 Desviaciones')\nax.set_title(\"Teorema de Chebyshev\")\nax.set_xlabel(\"Datos\")\nax.set_ylabel(\"Frecuencia relativa\")\nax.legend()\n\n# Configurar el color de fondo\nfig.patch.set_facecolor('#D4F8B7')\n\n# Guardar el gr\u00e1fico como imagen\nplt.savefig(\"teorema_chebyshev.png\")\n\n# Mostrar la imagen en Colab\ndisplay(Image(filename=\"teorema_chebyshev.png\"))\n</pre> import numpy as np import matplotlib.pyplot as plt from IPython.display import Image, display  # Generar datos ficticios np.random.seed(42) datos = np.random.normal(loc=50, scale=10, size=1000)  # Crear histograma con color de fondo personalizado fig, ax = plt.subplots() ax.hist(datos, bins=30, color=\"#5CCB5F\", edgecolor=\"black\") ax.axvline(np.mean(datos), color='red', linestyle='dashed', linewidth=2, label=f'Media: {np.mean(datos):.2f}') ax.axvline(np.mean(datos) + 2 * np.std(datos), color='orange', linestyle='dashed', linewidth=2, label='+2 Desviaciones') ax.axvline(np.mean(datos) - 2 * np.std(datos), color='orange', linestyle='dashed', linewidth=2, label='-2 Desviaciones') ax.set_title(\"Teorema de Chebyshev\") ax.set_xlabel(\"Datos\") ax.set_ylabel(\"Frecuencia relativa\") ax.legend()  # Configurar el color de fondo fig.patch.set_facecolor('#D4F8B7')  # Guardar el gr\u00e1fico como imagen plt.savefig(\"teorema_chebyshev.png\")  # Mostrar la imagen en Colab display(Image(filename=\"teorema_chebyshev.png\"))  <p>Ten en cuenta que el Teorema de Chebyshev proporciona una estimaci\u00f3n conservadora y no precisa de la dispersi\u00f3n de datos, pero es \u00fatil en situaciones donde no conocemos la forma exacta de la distribuci\u00f3n.</p> <p>Una de las ventajas del teorema de Chebyshev estriba en que se aplica a cualquier conjunto de datos sin importar su forma de distribuci\u00f3n. De hecho, podr\u00eda usarse con cualquiera de las distribuciones. Sin embargo, en muchas aplicaciones pr\u00e1cticas los conjuntos de datos exhiben una distribuci\u00f3n sim\u00e9trica con forma de pila o de campana. Cuando se piensa que los datos se aproximan a esta distribuci\u00f3n, la regla emp\u00edrica se usa para determinar el porcentaje de valores de datos que deben estar dentro de un n\u00famero espec\u00edfico de desviaciones est\u00e1ndar de la media.</p> In\u00a0[13]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Generar datos ficticios con una distribuci\u00f3n normal\nnp.random.seed(42)\ndatos = np.random.normal(loc=0, scale=1, size=1000)\n\n# Crear histograma con color de fondo personalizado\nfig, ax = plt.subplots()\nn, bins, patches = ax.hist(datos, bins=30, density=True, color=\"#5CCB5F\", edgecolor=\"black\", alpha=0.7)\n\n# Ajustar la curva de campana (distribuci\u00f3n normal)\nfrom scipy.stats import norm\nmedia, desviacion_estandar = np.mean(datos), np.std(datos)\nx = np.linspace(min(bins), max(bins), 100)\ny = norm.pdf(x, media, desviacion_estandar)\nax.plot(x, y, 'k--', linewidth=2)\n\n# Configurar el color de fondo\nfig.patch.set_facecolor('#D4F8B7')\n\n# Configurar etiquetas y t\u00edtulo\nax.set_title(\"Distribuci\u00f3n Normal (Campana de Gauss)\", fontsize=16, color=\"#5CCB5F\")\nax.set_xlabel(\"Datos\")\nax.set_ylabel(\"Densidad de Probabilidad\")\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  # Generar datos ficticios con una distribuci\u00f3n normal np.random.seed(42) datos = np.random.normal(loc=0, scale=1, size=1000)  # Crear histograma con color de fondo personalizado fig, ax = plt.subplots() n, bins, patches = ax.hist(datos, bins=30, density=True, color=\"#5CCB5F\", edgecolor=\"black\", alpha=0.7)  # Ajustar la curva de campana (distribuci\u00f3n normal) from scipy.stats import norm media, desviacion_estandar = np.mean(datos), np.std(datos) x = np.linspace(min(bins), max(bins), 100) y = norm.pdf(x, media, desviacion_estandar) ax.plot(x, y, 'k--', linewidth=2)  # Configurar el color de fondo fig.patch.set_facecolor('#D4F8B7')  # Configurar etiquetas y t\u00edtulo ax.set_title(\"Distribuci\u00f3n Normal (Campana de Gauss)\", fontsize=16, color=\"#5CCB5F\") ax.set_xlabel(\"Datos\") ax.set_ylabel(\"Densidad de Probabilidad\")  # Mostrar el gr\u00e1fico plt.show()  <p>Ejemplo</p> <p>Los envases de detergente l\u00edquido se llenan autom\u00e1ticamente en una l\u00ednea de producci\u00f3n. Los pesos de llenado suelen tener una distribuci\u00f3n en forma de campana. Si el peso medio de llenado es de 16 onzas y la desviaci\u00f3n est\u00e1ndar de 0.25 onzas, se utiliza la regla em- p\u00edrica para formular las conclusiones siguientes. tro de dos desviaciones est\u00e1ndar de la media).</p> <ul> <li>Aproximadamente 68% de los envases llenos pesar\u00e1 entre 15.75 y 16.25 onzas (dentro de una desviaci\u00f3n est\u00e1ndar de la media).</li> <li>Aproximadamente 95% de los envases llenos pesar\u00e1 entre 15.50 y 16.50 onzas (den-</li> </ul> <ul> <li>Casi todos los envases llenos pesar\u00e1n entre 15.25 y 16.75 onzas (dentro de tres desvia- ciones est\u00e1ndar de la media).</li> </ul> <p>Un conjunto de datos a veces tiene una o m\u00e1s observaciones con valores inusualmente grandes o sumamente peque\u00f1os. Estos valores extremos se llaman observaciones at\u00edpicas. Los expertos en estad\u00edstica experimentados emprenden acciones para identificar observaciones at\u00edpicas y luego revisan cada una con detalle. Una observaci\u00f3n at\u00edpica suele ser un valor de datos que se registr\u00f3 incorrectamente; si esto ocurre, el error se corrige antes de un an\u00e1lisis posterior. Tambi\u00e9n puede ser una observaci\u00f3n que se introdujo de forma incorrecta en el conjunto de datos; si este es el caso, se elimina.</p> <p>Por \u00faltimo, puede consistir en un valor de datos inusual que se registr\u00f3 correctamente y pertenece al conjunto de datos. En tal caso, debe conservarse. Los valores estandarizados (puntuaciones z), se utilizan para identificar observaciones at\u00edpicas. Recuerde que la regla emp\u00edrica permite concluir que cuando los datos tienen una dis- tribuci\u00f3n en forma de campana, casi todos los valores de datos est\u00e1n dentro de tres desviaciones est\u00e1ndar de la media. Por tanto, al usar puntuaciones z para identificar observaciones extremas, se recomienda tomar en cuenta como una observaci\u00f3n at\u00edpica cualquier valor de datos con una puntuaci\u00f3n z menor que -3 o mayor que +3. La exactitud de estos valores debe verificarse y determinar si pertenecen al conjunto de datos.</p> <p>Ejemplo</p> In\u00a0[14]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Generar datos ficticios con algunos valores at\u00edpicos\nnp.random.seed(42)\ndatos = np.concatenate([np.random.normal(0, 1, 50), np.random.normal(10, 1, 5)])\n\n# Crear un gr\u00e1fico de caja\nfig, ax = plt.subplots()\nax.boxplot(datos, vert=False, widths=0.7, patch_artist=True, medianprops={'color': 'red'})\n\n# Configurar el color de fondo\nfig.patch.set_facecolor('#D4F8B7')\n\n# Configurar etiquetas y t\u00edtulo\nax.set_title(\"Gr\u00e1fico de Caja con Observaciones At\u00edpicas\", fontsize=16, color=\"#5CCB5F\")\nax.set_xlabel(\"Datos\")\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  # Generar datos ficticios con algunos valores at\u00edpicos np.random.seed(42) datos = np.concatenate([np.random.normal(0, 1, 50), np.random.normal(10, 1, 5)])  # Crear un gr\u00e1fico de caja fig, ax = plt.subplots() ax.boxplot(datos, vert=False, widths=0.7, patch_artist=True, medianprops={'color': 'red'})  # Configurar el color de fondo fig.patch.set_facecolor('#D4F8B7')  # Configurar etiquetas y t\u00edtulo ax.set_title(\"Gr\u00e1fico de Caja con Observaciones At\u00edpicas\", fontsize=16, color=\"#5CCB5F\") ax.set_xlabel(\"Datos\")  # Mostrar el gr\u00e1fico plt.show() <p>En este ejemplo, observamos un conjunto de datos con 50 valores normales distribuidos alrededor de 0 y 5 valores at\u00edpicos distribuidos alrededor de 10.</p> <p>En el cap\u00edtulo 2 se introdujo el diagrama de tallo y hoja como una t\u00e9cnica de an\u00e1lisis exploratorio de datos. Recuerde que dicho an\u00e1lisis permite usar operaciones aritm\u00e9ticas simples y representaciones gr\u00e1ficas f\u00e1ciles de dibujar para resumir los datos. En esta secci\u00f3n contin\u00faa el an\u00e1lisis exploratorio de datos considerando res\u00famenes de cinco n\u00fameros y diagramas de caja.</p> <p>En un resumen de cinco n\u00fameros, los cinco siguientes se usan para resumir los datos.</p> <ul> <li>Valor menor</li> <li>Primer cuartil $(Q_1)$</li> <li>Mediana $(Q_2)$</li> <li>Tercer cuartil $(Q_3)$</li> <li>Valor mayor</li> </ul> <p>Ejemplo</p> <p>La mediana de 3 505 y los cuartiles Q1 = 3 465 y Q3 = 3 600 se calcularon en la secci\u00f3n 3.1. Al revisar los datos se observa un valor menor de 3 310 y un valor mayor de 3 925. Por tanto, el resumen de cinco n\u00fameros para los datos de los sueldos iniciales es 3 310, 3 465, 3 505, 3 600 y 3 925. Entre los n\u00fameros adyacentes de un resumen de cinco n\u00fameros se encuentra aproximadamente un cuarto, o 25%, de las observaciones.</p> <p>Un diagrama de caja es un resumen gr\u00e1fico de los datos basado en un resumen de cinco n\u00fa- meros. La clave para elaborar de un diagrama de caja es el c\u00e1lculo de la mediana y los cuartiles $Q_1$ y $Q_3$. El rango intercuart\u00edlico $RIC = Q_3 - Q_1$.</p> <p>Los pasos que se siguen para elaborarlo se presentan a continuaci\u00f3n.</p> <ul> <li>Se traza una caja con sus extremos ubicados en el primer y tercer cuartiles.</li> <li>Se traza una l\u00ednea vertical en el cuadro donde se ubica la mediana.</li> <li>Al usar el rango intercuart\u00edlico, se localizan los l\u00edmites.</li> <li>Usando las l\u00edneas punteadas se trazan desde los extremos de la caja hasta los valores menor y mayor dentro de los l\u00edmites calculados en el paso 3.</li> <li>Por \u00faltimo, la ubicaci\u00f3n de cada observaci\u00f3n at\u00edpica se se\u00f1ala con un asterisco.</li> </ul> <p>Ejemplo</p> In\u00a0[15]: Copied! <pre>import numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Generar datos ficticios con algunos valores at\u00edpicos\nnp.random.seed(42)\ndatos = np.concatenate([np.random.normal(0, 1, 50), np.random.normal(10, 1, 5)])\n\n# Crear un diagrama de caja con Seaborn\nsns.set(style=\"whitegrid\")\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Configurar el color de fondo\nfig.patch.set_facecolor('#D4F8B7')\n\n# Crear el diagrama de caja\nsns.boxplot(x=datos, color=\"#5CCB5F\", width=0.5)\n\n# Agregar puntos at\u00edpicos\nsns.stripplot(x=datos, color=\"red\", size=8, jitter=0.3)\n\n# Configurar etiquetas y t\u00edtulo\nax.set_title(\"Diagrama de Caja con Observaciones At\u00edpicas\", fontsize=16, color=\"#5CCB5F\")\nax.set_xlabel(\"Datos\")\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import numpy as np import seaborn as sns import matplotlib.pyplot as plt  # Generar datos ficticios con algunos valores at\u00edpicos np.random.seed(42) datos = np.concatenate([np.random.normal(0, 1, 50), np.random.normal(10, 1, 5)])  # Crear un diagrama de caja con Seaborn sns.set(style=\"whitegrid\") fig, ax = plt.subplots(figsize=(8, 6))  # Configurar el color de fondo fig.patch.set_facecolor('#D4F8B7')  # Crear el diagrama de caja sns.boxplot(x=datos, color=\"#5CCB5F\", width=0.5)  # Agregar puntos at\u00edpicos sns.stripplot(x=datos, color=\"red\", size=8, jitter=0.3)  # Configurar etiquetas y t\u00edtulo ax.set_title(\"Diagrama de Caja con Observaciones At\u00edpicas\", fontsize=16, color=\"#5CCB5F\") ax.set_xlabel(\"Datos\")  # Mostrar el gr\u00e1fico plt.show()  <p>En este ejemplo, utilizando Seaborn para crear un diagrama de caja (boxplot) y agregando puntos at\u00edpicos (stripplot) en rojo.</p> <p>Hasta ahora hemos examinado los m\u00e9todos num\u00e9ricos que resumen los datos de una variable a la vez. Un gerente o quien toma decisiones se interesa con frecuencia en la relaci\u00f3n entre dos variables. En esta secci\u00f3n se presentan la covarianza y la correlaci\u00f3n como medidas descriptivas de la relaci\u00f3n entre dos variables.</p> <p>Covarianza Muestral</p> <p>La covarianza muestral es una medida estad\u00edstica que eval\u00faa la relaci\u00f3n lineal entre dos variables aleatorias en una muestra de datos. Proporciona informaci\u00f3n sobre la direcci\u00f3n de la relaci\u00f3n (positiva o negativa). En el contexto de la estad\u00edstica, la covarianza es un indicador de c\u00f3mo cambian dos variables juntas.</p> <p>La f\u00f3rmula de la covarianza muestral $$s_{xy}$$ entre dos variables X e Y en una muestra de datos es:</p> <p>$$s_{xy} = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{X})(y_i - \\bar{Y})}{n-1}$$</p> <p>donde:</p> <ul> <li>n es el tama\u00f1o de la muestra</li> <li>$$x_i \\text{ y } y_i$$ son los valores individuales de las dos variables en la muestra</li> <li>$$\\bar{X} \\text{ y } \\bar{Y}$$ son las medias muestrales de las dos variables, respectivamente</li> </ul> <p>La covarianza toma valores positivos cuando las variables tienden a aumentar o disminuir juntas, negativos cuando una variable tiende a aumentar mientras que la otra disminuye, y cercanos a cero cuando no hay una clara relaci\u00f3n lineal entre las variables.</p> <p>Es importante destacar que la covarianza muestral puede ser afectada por la escala de las variables, lo cual puede dificultar su interpretaci\u00f3n. Por esta raz\u00f3n, se utiliza a menudo el coeficiente de correlaci\u00f3n, que es la covarianza normalizada, para proporcionar una medida m\u00e1s estandarizada de la relaci\u00f3n entre dos variables.</p> <p>Ejemplo</p> <p>Covarianza Muestral en Bolivia</p> <p>En el contexto de un estudio sobre diferentes regiones de Bolivia, hemos recopiladolos siguientes datos sobre el ingreso per c\u00e1pita (en d\u00f3lares) y la tasa de alfabetizaci\u00f3n (en porcentaje) en cinco regiones diferentes. Queremos entender c\u00f3mo estas dos variables se relacionan entre s\u00ed.</p> In\u00a0[16]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom tabulate import tabulate\n\n# Datos ficticios\ningreso_per_capita = np.array([5000, 6000, 4500, 7000, 5500])\ntasa_alfabetizacion = np.array([85, 88, 78, 92, 80])\n\n# Calcular las medias muestrales\nmedia_ingreso = np.mean(ingreso_per_capita)\nmedia_alfabetizacion = np.mean(tasa_alfabetizacion)\n\n# Calcular la covarianza muestral\ncovarianza_muestral = np.cov(ingreso_per_capita, tasa_alfabetizacion, ddof=1)[0, 1]\n\n# Crear la tabla con colores\ntabla_info = [\n    [\"\", \"Media\", \"Covarianza Muestral\"],\n    [\"Ingreso Per C\u00e1pita\", f\"{media_ingreso:.2f}\", \"\"],\n    [\"Tasa de Alfabetizaci\u00f3n\", f\"{media_alfabetizacion:.2f}\", f\"{covarianza_muestral:.2f}\"]\n]\n\n# Mostrar la tabla en la consola con colores\nprint(tabulate(tabla_info, headers=\"firstrow\", tablefmt=\"fancy_grid\", colalign=(\"center\", \"center\", \"center\")))\n\n# Graficar los datos con el color de fondo #D4F8B7\nfig, ax = plt.subplots()\nax.scatter(ingreso_per_capita, tasa_alfabetizacion, color='#5CCB5F', edgecolor=\"black\")\nax.set_xlabel('Ingreso Per C\u00e1pita')\nax.set_ylabel('Tasa de Alfabetizaci\u00f3n')\nax.axhline(y=media_alfabetizacion, color='red', linestyle='dashed', linewidth=2, label=f'Media Alfabetizaci\u00f3n: {media_alfabetizacion:.2f}')\nax.axvline(x=media_ingreso, color='blue', linestyle='dashed', linewidth=2, label=f'Media Ingreso: {media_ingreso:.2f}')\nax.legend()\nax.set_facecolor('#D4F8B7')\nfig.patch.set_facecolor('#D4F8B7')\nplt.suptitle(\"Dispersi\u00f3n entre Ingreso Per C\u00e1pita y Tasa de Alfabetizaci\u00f3n\", fontsize=16, color=\"#5CCB5F\")\n\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from tabulate import tabulate  # Datos ficticios ingreso_per_capita = np.array([5000, 6000, 4500, 7000, 5500]) tasa_alfabetizacion = np.array([85, 88, 78, 92, 80])  # Calcular las medias muestrales media_ingreso = np.mean(ingreso_per_capita) media_alfabetizacion = np.mean(tasa_alfabetizacion)  # Calcular la covarianza muestral covarianza_muestral = np.cov(ingreso_per_capita, tasa_alfabetizacion, ddof=1)[0, 1]  # Crear la tabla con colores tabla_info = [     [\"\", \"Media\", \"Covarianza Muestral\"],     [\"Ingreso Per C\u00e1pita\", f\"{media_ingreso:.2f}\", \"\"],     [\"Tasa de Alfabetizaci\u00f3n\", f\"{media_alfabetizacion:.2f}\", f\"{covarianza_muestral:.2f}\"] ]  # Mostrar la tabla en la consola con colores print(tabulate(tabla_info, headers=\"firstrow\", tablefmt=\"fancy_grid\", colalign=(\"center\", \"center\", \"center\")))  # Graficar los datos con el color de fondo #D4F8B7 fig, ax = plt.subplots() ax.scatter(ingreso_per_capita, tasa_alfabetizacion, color='#5CCB5F', edgecolor=\"black\") ax.set_xlabel('Ingreso Per C\u00e1pita') ax.set_ylabel('Tasa de Alfabetizaci\u00f3n') ax.axhline(y=media_alfabetizacion, color='red', linestyle='dashed', linewidth=2, label=f'Media Alfabetizaci\u00f3n: {media_alfabetizacion:.2f}') ax.axvline(x=media_ingreso, color='blue', linestyle='dashed', linewidth=2, label=f'Media Ingreso: {media_ingreso:.2f}') ax.legend() ax.set_facecolor('#D4F8B7') fig.patch.set_facecolor('#D4F8B7') plt.suptitle(\"Dispersi\u00f3n entre Ingreso Per C\u00e1pita y Tasa de Alfabetizaci\u00f3n\", fontsize=16, color=\"#5CCB5F\")  plt.show()  <pre>\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502                        \u2502  Media  \u2502  Covarianza Muestral  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502   Ingreso Per C\u00e1pita   \u2502  5600   \u2502                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Tasa de Alfabetizaci\u00f3n \u2502  84.6   \u2502        4800.00        \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\n</pre> <p>Covarianza Poblacional</p> <p>La covarianza poblacional es una medida estad\u00edstica que eval\u00faa la relaci\u00f3n lineal entre dos variables en una poblaci\u00f3n completa. A diferencia de la covarianza muestral, que utiliza datos de una muestra espec\u00edfica, la covarianza poblacional considera todos los individuos en la poblaci\u00f3n. Esta medida proporciona informaci\u00f3n valiosa sobre la direcci\u00f3n y fuerza de la relaci\u00f3n entre dos variables aleatorias.</p> <p>La f\u00f3rmula de covarianza poblacional $$\u03c3_{xy}$$ entre dos variables X e Y en una poblaci\u00f3n se expresa como:</p> <p>$$\u03c3_{xy} = \\frac{\\sum_{i=1}^{N} (x_i - \u03bc_x)(y_i - \u03bc_y)}{N}$$</p> <p>donde:</p> <ul> <li>N es el tama\u00f1o total de la poblaci\u00f3n</li> <li>$$x_i \\text{ y } y_i$$ son los valores individuales de las dos variables de la poblaci\u00f3n</li> <li>$$\u03bc_x \\text{ y } \u03bc_y$$ son las medias poblacionales de las dos variables</li> </ul> <p>La covarianza poblacional toma valores positivos cuando las variables tienden a aumentar o disminuir juntas, valores negativos cuando una variable tiende a aumentar mientras que la otra disminuye, y cerca de cero cuando no hay una clara relaci\u00f3n lineal entre las variables.</p> <p>Es importante tener en cuenta que la covarianza poblacional puede ser utilizada para calcular el coeficiente de correlaci\u00f3n poblacional, que normaliza la covarianza y proporciona una medida estandarizada de la fuerza y direcci\u00f3n de la relaci\u00f3n entre dos variables en toda la poblaci\u00f3n.</p> <p>Ejemplo</p> <p>Supongamos que estamos interesados en estudiar la relaci\u00f3n entre la cantidad de horas de estudio semanal (variable X) y el rendimiento acad\u00e9mico en un examen (variable Y) en una poblaci\u00f3n de estudiantes universitarios. A continuaci\u00f3n, un ejemplo para ilustrar la covarianza poblacional:</p> <p>Horas de estudio semanal (en horas) horas_estudio = [10, 12, 8, 15, 11]</p> <p>Rendimiento acad\u00e9mico en el examen (en porcentaje) rendimiento_examen = [75, 80, 65, 90, 78]</p> <p>Primero, calculamos las medias poblacionales $$\u03bc_x = \\frac{\\sum_{i=1}^{N} (x_i)}{N}$$ $$\u03bc_y = \\frac{\\sum_{i=1}^{N} (y_i)}{N}$$</p> <p>Supongamos que N=5 en este caso.</p> In\u00a0[17]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Datos ficticios\nhoras_estudio = np.array([10, 12, 8, 15, 11])\nrendimiento_examen = np.array([75, 80, 65, 90, 78])\n\n# Calcular las medias poblacionales\nmedia_horas_estudio = np.mean(horas_estudio)\nmedia_rendimiento_examen = np.mean(rendimiento_examen)\n\n# Calcular la covarianza poblacional\ncovarianza_poblacional = np.cov(horas_estudio, rendimiento_examen)[0, 1]\n\n# Crear un scatter plot\nplt.figure(figsize=(8, 6))\nplt.scatter(horas_estudio, rendimiento_examen, color='blue', label='Datos')\n\n# L\u00ednea que indica la direcci\u00f3n de la relaci\u00f3n\nplt.plot([media_horas_estudio, media_horas_estudio], [media_rendimiento_examen, media_rendimiento_examen + covarianza_poblacional], color='red', linestyle='--', linewidth=2, label='Direcci\u00f3n de la relaci\u00f3n')\n\n# Etiquetas y t\u00edtulo\nplt.xlabel('Horas de Estudio Semanal')\nplt.ylabel('Rendimiento en el Examen (%)')\nplt.title(\"Relaci\u00f3n entre Horas de Estudio y Rendimiento en el Examen\", fontsize=16, color=\"#5CCB5F\")\n\n# Establecer el color de fondo\nplt.gca().set_facecolor('#D4F8B7')\n\n# Mostrar la leyenda\nplt.legend()\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  # Datos ficticios horas_estudio = np.array([10, 12, 8, 15, 11]) rendimiento_examen = np.array([75, 80, 65, 90, 78])  # Calcular las medias poblacionales media_horas_estudio = np.mean(horas_estudio) media_rendimiento_examen = np.mean(rendimiento_examen)  # Calcular la covarianza poblacional covarianza_poblacional = np.cov(horas_estudio, rendimiento_examen)[0, 1]  # Crear un scatter plot plt.figure(figsize=(8, 6)) plt.scatter(horas_estudio, rendimiento_examen, color='blue', label='Datos')  # L\u00ednea que indica la direcci\u00f3n de la relaci\u00f3n plt.plot([media_horas_estudio, media_horas_estudio], [media_rendimiento_examen, media_rendimiento_examen + covarianza_poblacional], color='red', linestyle='--', linewidth=2, label='Direcci\u00f3n de la relaci\u00f3n')  # Etiquetas y t\u00edtulo plt.xlabel('Horas de Estudio Semanal') plt.ylabel('Rendimiento en el Examen (%)') plt.title(\"Relaci\u00f3n entre Horas de Estudio y Rendimiento en el Examen\", fontsize=16, color=\"#5CCB5F\")  # Establecer el color de fondo plt.gca().set_facecolor('#D4F8B7')  # Mostrar la leyenda plt.legend()  # Mostrar el gr\u00e1fico plt.show()  <p>Es relativamente frecuente que haya cierta confusi\u00f3n en relaci\u00f3n a lo que estudia un an\u00e1lisis de regresi\u00f3n y un an\u00e1lisis de correlaci\u00f3n. Sin embargo, ambos an\u00e1lisis ofrecen informaci\u00f3n complementaria. El An\u00e1lisis de Regresi\u00f3n estudia la forma en que ambas variables aleatorias est\u00e1n relacionadas, mientras que el An\u00e1lisis de Correlaci\u00f3n investiga la fuerza de dicha relaci\u00f3n. En esta entrada vamos a conocer c\u00f3mo se  calcula el coeficiente de correlaci\u00f3n en R, coeficiente que nos va a medir la fuerza y la direcci\u00f3n de la relaci\u00f3n entre las dos variables.</p> <p>Curiosamente, la abreviatura del coeficiente de correlaci\u00f3n es una r min\u00fascula. De forma predeterminada, R nos va a calcular el coeficiente de correlaci\u00f3n de Pearson. Este tema sobre las regresiones y correlaciones no es nuevo en Viva el Software Libre, como lo atestiguan estes tema sobre intervalos de predicci\u00f3n, este otro sobre intervalos de confianza.</p> <p>Para los datos muestrales, el coeficiente de correlaci\u00f3n del producto-momento de Pearson se define como se indica a continuaci\u00f3n.</p> COEFICIENTE DE CORRELACI\u00d3N DEL PRODUCTO-MOMENTO DE PEARSON: DATOS MUESTRALES                  $$r_{xy} = \\frac{S_{xy}}{S_xS_y}$$              (3.12)         Donde:                           - $r_{xy}$ = coeficiente de correlaci\u00f3n muestral                 - $s_{xy}$ = covarianza muestral                 - $s_x$ = desviaci\u00f3n est\u00e1ndar muestral de x                 - $s_y$ = desviaci\u00f3n est\u00e1ndar muestral de y COEFICIENTE DE CORRELACI\u00d3N DEL PRODUCTO-MOMENTO DE PEARSON: DATOS POBLACIONALES                  $$\\rho_{xy} =\\frac{\\sigma_{xy}}{\\sigma_x \\sigma_y}$$              (3.13)         Donde:                           - $\\rho_{xy}$ = coeficiente de correlaci\u00f3n poblacional                 - $ \\sigma_{xy}$ = covarianza poblacional                 - $ \\sigma_x$ = desviaci\u00f3n est\u00e1ndar poblacional de x                 - $ \\sigma_y$ = desviaci\u00f3n est\u00e1ndar poblacional de y <p>Ejemplo</p> In\u00a0[18]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Datos\nnp.random.seed(42)\nx = np.random.rand(100) * 10  # Variable independiente\ny = 2 * x + 1 + np.random.randn(100) * 2  # Variable dependiente con ruido\n\n# Calcular el coeficiente de correlaci\u00f3n (Pearson)\ncoef_corr = np.corrcoef(x, y)[0, 1]\n\n# Crear un gr\u00e1fico de dispersi\u00f3n\nplt.scatter(x, y, color=\"#5CCB5F\", label=f\"Coeficiente de Correlaci\u00f3n: {coef_corr:.2f}\")\n\n# Configurar el color de fondo\nplt.gcf().patch.set_facecolor('#D4F8B7')\n\n# Configurar etiquetas y t\u00edtulo\nplt.title(\"Gr\u00e1fico de Dispersi\u00f3n con Coeficiente de Correlaci\u00f3n\", fontsize=16, color=\"#5CCB5F\")\nplt.xlabel(\"Variable Independiente\")\nplt.ylabel(\"Variable Dependiente\")\nplt.legend()\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  # Datos np.random.seed(42) x = np.random.rand(100) * 10  # Variable independiente y = 2 * x + 1 + np.random.randn(100) * 2  # Variable dependiente con ruido  # Calcular el coeficiente de correlaci\u00f3n (Pearson) coef_corr = np.corrcoef(x, y)[0, 1]  # Crear un gr\u00e1fico de dispersi\u00f3n plt.scatter(x, y, color=\"#5CCB5F\", label=f\"Coeficiente de Correlaci\u00f3n: {coef_corr:.2f}\")  # Configurar el color de fondo plt.gcf().patch.set_facecolor('#D4F8B7')  # Configurar etiquetas y t\u00edtulo plt.title(\"Gr\u00e1fico de Dispersi\u00f3n con Coeficiente de Correlaci\u00f3n\", fontsize=16, color=\"#5CCB5F\") plt.xlabel(\"Variable Independiente\") plt.ylabel(\"Variable Dependiente\") plt.legend()  # Mostrar el gr\u00e1fico plt.show()  <p>En este ejemplo, existen dos conjuntos de datos relacionados linealmente. El coeficiente de correlaci\u00f3n de Pearson se calcula utilizando np.corrcoef, y luego se visualiza el gr\u00e1fico de dispersi\u00f3n de los datos con el coeficiente de correlaci\u00f3n en la leyenda. Este es un ejemplo positivo de correlaci\u00f3n, ya que el coeficiente deber\u00eda estar cerca de 1 debido a la relaci\u00f3n lineal entre x e y.</p> <p>En la secci\u00f3n 3.1 se present\u00f3 la media como una de las medidas m\u00e1s importantes de ubicaci\u00f3n central. La f\u00f3rmula para la media de una muestra con n observaciones se vuelve a establecer como sigue.</p> MEDIA MUESTRAL                  $$ \\bar{x} = \\frac{\\sum x_i}{n}$$              <p>En esta f\u00f3rmula, cada $x_i$ recibe igual importancia o peso. Aunque esta pr\u00e1ctica es la m\u00e1s com\u00fan, en algunos casos la media se calcula confiriendo a cada observaci\u00f3n un peso que refleje su importancia. Una media calculada de esta manera se conoce como media ponderada.</p> <p>La media ponderada se calcula como sigue.</p> MEDIA PONDERADA                  $$ \\bar{x} = \\frac{\\sum (w_i*x_i)}{\\sum (w_i)}$$              (3.15)         Donde:                           - $x_i$ = valor de observaci\u00f3n $i$                 - $w_i$ = peso de la observaci\u00f3n $i$ <p>Ejemplo</p> <p>Compra de materia prima</p> Compra Costo(Bs) Numero de Libras 1 3.00 1200 2 3.40 500 3 2.80 2750 4 2.90 1000 5 3.25 800 <p>Calcular la media muestral de la venta de las casas usadas y la media muestral de las casas nuevas</p> <p>$$ \\bar{x} =  \\frac{1 200(3.00) + 500(3.40) + 2 750(2.80) + 1 000(2.90) + 800(3.25)}{1 200 + 500 + 2 750 + 1 000 + 800} $$</p> <p>$$ \\bar{x} =  \\frac{18500}{6250} $$</p> <p>$$ \\bar{x} =  2.96 $$</p> <p>Por tanto, el c\u00e1lculo de la media ponderada indica que el costo medio por libra para la materia prima es $2.96(Bs)$.</p> <p>En la mayor\u00eda de los casos, las medidas de posici\u00f3n y variabilidad se calculan con valores de datos individuales. No obstante, los datos en ocasiones est\u00e1n disponibles s\u00f3lo en forma agrupada o en forma de distribuci\u00f3n de frecuencia. En el an\u00e1lisis siguiente se explica c\u00f3mo usar la f\u00f3rmula de la media ponderada para obtener aproximaciones de la media, la varianza y la desviaci\u00f3n est\u00e1ndar para datos agrupados.</p> <p>Gr\u00e1fico</p> In\u00a0[19]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Datos\nintervalos = ['10-20', '20-30', '30-40', '40-50', '50-60']\nfrecuencias = [5, 12, 8, 15, 10]\nmarcas_de_clase = [15, 25, 35, 45, 55]\n\n# Calcular la media muestral\nsuma_fi_mi = sum([f * m for f, m in zip(frecuencias, marcas_de_clase)])\nsuma_fi = sum(frecuencias)\nmedia_muestral = suma_fi_mi / suma_fi\n\n# Configurar colores\ncolor_fondo = '#D4F8B7'\ncolor_barras = '#8CC084'\ncolor_media = 'red'\n\n# Crear el gr\u00e1fico de barras con personalizaciones\nfig, ax = plt.subplots()\nbars = ax.bar(marcas_de_clase, frecuencias, width=8, align='center', alpha=0.7, color=color_barras, label='Frecuencia')\nax.scatter(media_muestral, max(frecuencias), color=color_media, marker='x', s=100, label='Media Muestral')\n\n# Establecer el fondo de color\nfig.patch.set_facecolor(color_fondo)\nax.set_facecolor(color_fondo)\n\n# Etiquetas y t\u00edtulo\nax.set_xlabel('Marca de Clase')\nax.set_ylabel('Frecuencia')\nax.set_title('Histograma con Media Muestral')\nax.legend()\n\n# Mostrar la media muestral en la consola\nprint(f'Media Muestral: {media_muestral}')\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import matplotlib.pyplot as plt  # Datos intervalos = ['10-20', '20-30', '30-40', '40-50', '50-60'] frecuencias = [5, 12, 8, 15, 10] marcas_de_clase = [15, 25, 35, 45, 55]  # Calcular la media muestral suma_fi_mi = sum([f * m for f, m in zip(frecuencias, marcas_de_clase)]) suma_fi = sum(frecuencias) media_muestral = suma_fi_mi / suma_fi  # Configurar colores color_fondo = '#D4F8B7' color_barras = '#8CC084' color_media = 'red'  # Crear el gr\u00e1fico de barras con personalizaciones fig, ax = plt.subplots() bars = ax.bar(marcas_de_clase, frecuencias, width=8, align='center', alpha=0.7, color=color_barras, label='Frecuencia') ax.scatter(media_muestral, max(frecuencias), color=color_media, marker='x', s=100, label='Media Muestral')  # Establecer el fondo de color fig.patch.set_facecolor(color_fondo) ax.set_facecolor(color_fondo)  # Etiquetas y t\u00edtulo ax.set_xlabel('Marca de Clase') ax.set_ylabel('Frecuencia') ax.set_title('Histograma con Media Muestral') ax.legend()  # Mostrar la media muestral en la consola print(f'Media Muestral: {media_muestral}')  # Mostrar el gr\u00e1fico plt.show() <pre>Media Muestral: 37.6\n</pre> In\u00a0[20]: Copied! <pre>from IPython.display import YouTubeVideo\n\nyoutube_video = YouTubeVideo('v8fjSz6PMyk')\n\ndisplay(youtube_video)\n</pre> from IPython.display import YouTubeVideo  youtube_video = YouTubeVideo('v8fjSz6PMyk')  display(youtube_video) MEDIA POBLACIONAL PARA DATOS AGRUPADOS                  $$\\mu = \\frac{\\sum_{i=1}^{k} f_i \\cdot M_i}{N}$$              (3.18)  Donde:  <ul> <li>$\\mu$ representa la media poblacional.</li> <li>$k$ es el n\u00famero de intervalos o clases.</li> <li>$f_i$ es la frecuencia del i-\u00e9simo intervalo.</li> <li>$M_i$ es la marca de clase del i-\u00e9simo intervalo (el punto medio del intervalo).</li> <li>$N$ es el tama\u00f1o total de la poblacion.</li></ul> <p>La media muestral para datos agrupados es una estimaci\u00f3n de la media poblacional basada en una muestra de la poblaci\u00f3n. Tanto la media poblacional como la media muestral para datos agrupados buscan representar la tendencia central de los datos cuando se presentan en intervalos. La diferencia principal radica en que la media poblacional considera la poblaci\u00f3n completa, mientras que la media muestral se basa en una muestra de la poblaci\u00f3n. Ambas son herramientas importantes en estad\u00edstica descriptiva y son \u00fatiles para entender la distribuci\u00f3n de datos agrupados.</p> VARIANZA POBLACIONAL PARA DATOS AGRUPADOS                      $$\u03c3^2 = \\frac{\\sum_{i=1}^{k} f_i \\cdot (M_i - \\mu)^2}{N}$$                  (3.19)  Donde:  <ul> <li>$k$ es el n\u00famero de intervalos o clases.</li> <li>$f_i$ es la frecuencia del i-\u00e9simo intervalo.</li> <li>$M_i$ es la marca de clase del i-\u00e9simo intervalo (el punto medio del intervalo).</li> <li>$\\mu$ es la media poblacional.</li> <li>$N$ es el tama\u00f1o total de la muestra.</li></ul> <p>La varianza muestral para datos agrupados es una estimaci\u00f3n de la varianza poblacional basada en una muestra de la poblaci\u00f3n. Utiliza una f\u00f3rmula similar, pero con las frecuencias relativas de la muestra. La varianza poblacional para datos agrupados mide la dispersi\u00f3n en una poblaci\u00f3n completa, mientras que la varianza muestral para datos agrupados estima esta dispersi\u00f3n bas\u00e1ndose en una muestra. Ambas proporcionan informaci\u00f3n sobre la variabilidad de una caracter\u00edstica en datos agrupados.</p>"},{"location":"capitulo3/","title":"\u00b6","text":"CAPITULO 3  Estad\u00edstica descriptiva:medidas num\u00e9ricas Contenido del capitulo <p>3.1 MEDIDAS DE POSICI\u00d3N O LOCALIZACI\u00d3N</p> <ul> <li>Media</li> <li>Mediana</li> <li>Moda</li> <li>Percentiles</li> <li>Cuartiles</li> </ul> <p>3.2 MEDIDAS DE VARIABILIDAD</p> <ul> <li>Rango</li> <li>Rango intercuart\u00edlico</li> <li>Varianza</li> <li>Desviaci\u00f3n est\u00e1ndar </li> <li>Coeficiente de variaci\u00f3n</li> </ul> <p>3.3 MEDIDAS DE LA FORMA DE LA DISTRIBUCI\u00d3N, POSICI\u00d3N RELATIVA Y DETECCI\u00d3N DE OBSERVACIONES AT\u00cdPICAS</p> <ul> <li>Forma de la distribuci\u00f3n</li> <li>Valor z</li> <li>Teorema de Chebyshev </li> <li>Regla emp\u00edrica</li> <li>Detecci\u00f3n de observaciones at\u00edpicas</li> </ul> <p>3.4 AN\u00c1LISIS EXPLORATORIO DE DATOS</p> <ul> <li>Resumen de cinco n\u00fameros</li> <li>Diagrama de caja</li> </ul> <p>3.5 MEDIDAS DE ASOCIACI\u00d3N ENTRE DOS VARIABLES</p> <ul> <li>Covarianza</li> <li>Interpretaci\u00f3n de la covarianza</li> <li>Coeficiente de correlaci\u00f3n</li> <li>Interpretaci\u00f3n del coeficiente de correlaci\u00f3n</li> </ul> <p>3.6 MEDIA PONDERADA Y TRABAJO CON DATOS AGRUPADOS</p> <ul> <li>Media ponderada</li> <li>Datos agrupados</li> </ul>"},{"location":"capitulo3/#31-medidas-de-posicion-o-localizacion","title":"3.1 Medidas de posici\u00f3n o localizaci\u00f3n\u00b6","text":""},{"location":"capitulo3/#media","title":"Media\u00b6","text":"<p>La media, o valor medio, es quiz\u00e1 la medida de ubicaci\u00f3n m\u00e1s importante para una variable, pues proporciona una medida de la ubicaci\u00f3n central de los datos. Si los datos son para una muestra, la media se denota por $ \\bar{x} $; si son para una poblaci\u00f3n, se denota por la letra griega $ \\mu $. En las f\u00f3rmulas estad\u00edsticas se acostumbra denotar el valor de la primera observaci\u00f3n de la variable $x$ mediante $x_1$, el valor de la segunda observaci\u00f3n de la variable $x$ por medio de $x_2$, y as\u00ed sucesivamente hasta $x_i$. Si se tiene una muestra con $n$ observaciones, la f\u00f3rmula para la media muestral es la siguiente.</p>"},{"location":"capitulo3/#mediana","title":"Mediana\u00b6","text":"<p>La mediana es otra medida de ubicaci\u00f3n central; es el valor de en medio cuando los datos est\u00e1n acomodados en orden ascendente (del valor menor al valor mayor). Con un n\u00famero impar de observaciones, la mediana es el valor de en medio. Con un n\u00famero par, no hay valor de en medio. En este caso se sigue la convenci\u00f3n y la mediana se define como el promedio de los valores de las dos observaciones de en medio. Por conveniencia, la definici\u00f3n de la mediana se replantea como sigue.</p>"},{"location":"capitulo3/#moda","title":"Moda\u00b6","text":"<p>Una tercera medida de posici\u00f3n es la moda. Se define de la manera siguiente.</p>"},{"location":"capitulo3/#percentiles","title":"Percentiles\u00b6","text":"<p>Un percentil proporciona informaci\u00f3n sobre c\u00f3mo se distribuyen los datos en el intervalo del valor menor al valor mayor. Para datos que no contienen muchos valores repetidos, el percentil p-\u00e9simo los divide en dos partes. Alrededor de p por ciento de las observaciones tiene valores menores que el percentil p-\u00e9simo y cerca de (100 - p) por ciento de las observaciones tiene valores mayores que el percentil p-\u00e9simo. \u00c9ste se define formalmente del modo siguiente.</p>"},{"location":"capitulo3/#cuartiles","title":"Cuartiles\u00b6","text":"<p>A menudo es recomendable dividir los datos en cuatro partes, cada una de las cuales contiene aproximadamente un cuarto, o 25% de las observaciones. Los puntos de divisi\u00f3n se conocen como cuartiles y son definidos como:</p>"},{"location":"capitulo3/#32-medidas-de-variabilidad","title":"3.2 Medidas de variabilidad\u00b6","text":"<p>Adem\u00e1s de las medidas de posici\u00f3n, con frecuencia es conveniente considerar las medidas de variabilidad o dispersi\u00f3n.</p>"},{"location":"capitulo3/#rango","title":"Rango\u00b6","text":"<p>La medida de variabilidad m\u00e1s sencilla es el rango.</p>"},{"location":"capitulo3/#ejercicios","title":"Ejercicios\u00b6","text":""},{"location":"capitulo3/#rango-intercuartilico","title":"Rango intercuart\u00edlico\u00b6","text":""},{"location":"capitulo3/#ejercicios","title":"Ejercicios\u00b6","text":""},{"location":"capitulo3/#varianza","title":"Varianza\u00b6","text":""},{"location":"capitulo3/#varianza-poblacional","title":"Varianza Poblacional\u00b6","text":""},{"location":"capitulo3/#varianza-muestral","title":"Varianza Muestral\u00b6","text":""},{"location":"capitulo3/#desviacion-estandar","title":"Desviaci\u00f3n est\u00e1ndar\u00b6","text":""},{"location":"capitulo3/#coeficiente-de-variacion","title":"Coeficiente de variaci\u00f3n\u00b6","text":""},{"location":"capitulo3/#33-medidas-de-la-forma-de-la-distribucion-posicion-relativa-y-deteccion-de-observaciones-atipicas","title":"3.3 Medidas de la forma de la distribuci\u00f3n, posici\u00f3n relativa y detecci\u00f3n de observaciones at\u00edpicas\u00b6","text":""},{"location":"capitulo3/#forma-de-la-distribucion","title":"Forma de la distribuci\u00f3n\u00b6","text":"<p>Histogramas que muestran el sesgo de cuatro distribuciones</p>"},{"location":"capitulo3/#valor-z","title":"Valor z\u00b6","text":""},{"location":"capitulo3/#teorema-de-chebyshev","title":"Teorema de Chebyshev\u00b6","text":""},{"location":"capitulo3/#regla-empirica","title":"Regla emp\u00edrica\u00b6","text":""},{"location":"capitulo3/#deteccion-de-observaciones-atipicas","title":"Detecci\u00f3n de observaciones at\u00edpicas\u00b6","text":""},{"location":"capitulo3/#34-analisis-exploratorio-de-datos","title":"3.4 An\u00e1lisis exploratorio de datos\u00b6","text":""},{"location":"capitulo3/#resumen-de-cinco-numeros","title":"Resumen de cinco n\u00fameros\u00b6","text":""},{"location":"capitulo3/#diagrama-de-caja","title":"Diagrama de caja\u00b6","text":""},{"location":"capitulo3/#35-medidas-de-asociacion-entre-dos-variables","title":"3.5 Medidas de asociaci\u00f3n entre dos variables\u00b6","text":""},{"location":"capitulo3/#covarianza","title":"Covarianza\u00b6","text":""},{"location":"capitulo3/#coeficiente-de-correlacion","title":"Coeficiente de correlaci\u00f3n\u00b6","text":""},{"location":"capitulo3/#36-media-ponderada-y-trabajo-con-datos-agrupados","title":"3.6 Media ponderada y trabajo con datos agrupados\u00b6","text":""},{"location":"capitulo3/#media-ponderada","title":"Media ponderada\u00b6","text":""},{"location":"capitulo3/#datos-agrupados","title":"Datos agrupados\u00b6","text":""},{"location":"capitulo3/#media-muestral-para-datos-agrupados","title":"Media Muestral para Datos Agrupados\u00b6","text":"<p>La media muestral para datos agrupados es una medida estad\u00edstica que proporciona una estimaci\u00f3n de la tendencia central de un conjunto de datos que ha sido organizado en intervalos o clases. Esta medida se denota com\u00fanmente por $\\bar{x}$ y se calcula teniendo en cuenta la frecuencia de cada intervalo.</p> <p>La f\u00f3rmula general para calcular la media muestral para datos agrupados es:</p> <p>$$ \\bar{x} = \\frac{\\sum_{i=1}^{k} f_i \\cdot m_i}{N} $$</p> <p>Donde:</p> <ul> <li>$\\bar{x}$ representa la media muestral.</li> <li>$k$ es el n\u00famero de intervalos o clases.</li> <li>$f_i$ es la frecuencia del i-\u00e9simo intervalo.</li> <li>$m_i$ es la marca de clase del i-\u00e9simo intervalo (el punto medio del intervalo).</li> <li>$N$ es el tama\u00f1o total de la muestra (la suma de todas las frecuencias).</li> </ul> <p>El c\u00e1lculo implica multiplicar cada marca de clase por su frecuencia correspondiente, sumar estos productos y luego dividir por el tama\u00f1o total de la muestra. Esta f\u00f3rmula proporciona una estimaci\u00f3n de la media de la poblaci\u00f3n basada en la informaci\u00f3n agrupada en intervalos.</p> <p>Es esencial tener en cuenta que, al trabajar con datos agrupados, la media muestral proporciona una medida de la tendencia central del conjunto de datos, pero pierde detalle sobre las observaciones individuales dentro de cada intervalo. Es una herramienta \u00fatil para resumir datos agrupados de manera m\u00e1s compacta.</p> <p>Ejercicios</p> <p>Tenemos los siguientes datos agrupados en intervalos para el n\u00famero de ventas mensuales en la tienda de MANACO de las ventas de cada empleado:</p> Intervalo de Ventas Frecuencia 10 - 20 5 20 - 30 12 30 - 40 8 40 - 50 15 50 - 60 10 <p>Paso 1: Calcular la Marca de Clase $m_i$</p> <p>La marca de clase $m_i$ se encuentra tomando el punto medio de cada intervalo. Para el primer intervalo, por ejemplo, ser\u00eda  (10 + 20) / 2 = 15. Haces esto para cada intervalo.</p> <p>Paso 2: Calcular $f_i \\cdot m_i$ para cada intervalo:</p> <p>Multiplicas la frecuencia $f_i$ por la marca de clase $m_i$ para cada intervalo.</p> <p>Paso 3: Sumar $f_i \\cdot m_i$ para todos los intervalos:</p> <p>Sumas los productos obtenidos en el paso anterior.</p> Intervalo de Ventas Frecuencia Marca de Clase fi fi * mi 10 - 20 5 15 75 20 - 30 12 25 300 30 - 40 8 35 280 40 - 50 15 45 675 50 - 60 10 55 550 <p>Paso 4: Calcular la Media Muestral $\\bar{x}$:</p> <p>Utilizas la f\u00f3rmula de la media muestral:</p> <p>$$ \\bar{x} = \\frac{\\sum_{i=1}^{k} f_i \\cdot m_i}{N} $$</p> <p>Paso 5: Suma de $f_i \\cdot m_i$:</p> <p>$75 + 300 + 280 + 675 + 550 = 1880$</p> <p>Paso 6: N\u00famero total de observaciones $N$:</p> <p>$5 + 12 + 8 + 15 + 10 = 50$</p> <p>Paso 7: Media Muestral $\\bar{x}$:</p> <p>$\\frac{1880}{50} = 37.6$</p>"},{"location":"capitulo3/#varianza-muestral-para-datos-agrupados","title":"Varianza Muestral para Datos Agrupados\u00b6","text":"<p>La varianza muestral para datos agrupados es una medida estad\u00edstica que proporciona una estimaci\u00f3n de la variabilidad o dispersi\u00f3n de un conjunto de datos agrupados alrededor de la media muestral. La f\u00f3rmula para calcular la varianza muestral en el caso de datos agrupados se deriva teniendo en cuenta la estructura de intervalos o clases en los que se agrupan los datos.</p> <p>La f\u00f3rmula general para la varianza muestral de datos agrupados es:</p> <p>$s^2 = \\frac{\\sum_{i=1}^{k} f_i \\cdot (m_i - \\bar{x})^2}{N - 1}$</p> <p>Donde:</p> <ul> <li>$k$ es el n\u00famero de intervalos o clases.</li> <li>$f_i$ es la frecuencia del i-\u00e9simo intervalo.</li> <li>$m_i$ es la marca de clase del i-\u00e9simo intervalo (el punto medio del intervalo).</li> <li>$\\bar{x}$ es la media muestral.</li> <li>$N$ es el tama\u00f1o total de la muestra (la suma de todas las frecuencias).</li> </ul> <p>Ejercicios</p> <p>Supongamos que ahora estamos analizando la cantidad de gasto mensual en alimentaci\u00f3n de familias en diferentes ciudades de Bolivia. Hemos recopilado los siguientes datos agrupados en intervalos de 200 bolivianos:</p> Intervalo de Gasto Mensual (en bolivianos) Frecuencia 0-200 10 200-400 15 400-600 20 600-800 12 800-1000 8 <p>Supongamos que la media muestral del gasto mensual ($\\bar{x}$) es de 500 bolivianos.</p> <p>Paso 1: Calcular la clase  $m_i$:</p> <p>La marca de clase se calcula como el punto medio de cada intervalo. Por ejemplo, para el primer intervalo (0-200):</p> <p>$ m_1 = \\frac{0 + 200}{2} = 100 $</p> <p>Realizamos este c\u00e1lculo para todos los intervalos.</p> <p>Paso 2: Calcular  $\\bar{x}$:</p> <p>Dado que ya se proporciona la media muestral: $\\bar{x} = 500$</p> <p>Paso 3: Calcular $ (m_i - \\bar{x})^2 $ para cada intervalo:</p> <p>$(m_1 - \\bar{x})^2 = (100 - 500)^2 = 400^2 = 160000 $</p> <p>Paso 4: Multiplicar $ (m_i - \\bar{x})^2 $ por la frecuencia $f_i$ para cada intervalo :</p> <p>$ f_1 \\cdot (m_1 - \\bar{x})^2 = 10 \\cdot 160000 = 1600000 $</p> Intervalo Frecuencia Marca de Clase (\\(m_i\\)) \\((m_i - \\bar{x})^2\\) \\(f_i \\cdot (m_i - \\bar{x})^2\\) 0-200 10 100 86553.71 865537.1 200-400 15 300 7949.97 119249.55 400-600 20 500 12184.67 243693.4 600-800 12 700 102352.51 1228230.12 800-1000 8 900 160546.81 1284374.48 <p>Paso 5: Sumar $(m_i - \\bar{x})^2$ * $f_i$ para todos los intervalos donde $k$ es igual a 5:</p> <p>$\\sum_{i=1}^{k} f_i \\cdot (m_i - \\bar{x})^2 = \\sum_{i=1}^{5} f_i \\cdot (m_i - \\bar{x})^2$</p> <p>$ \\sum_{i=1}^{5} f_i \\cdot (m_i - \\bar{x})^2 \\approx 865537.1 + 119249.55 + 243693.4 + 1228230.12 + 1284374.48 \\approx 3030084.65 $</p> <p>Paso 6: Calcular la varianza muestral:</p> <p>$ s^2 = \\frac{\\sum_{i=1}^{5} f_i \\cdot (m_i - \\bar{x})^2}{N - 1} = \\frac{3030084.65}{65 - 1} \\approx \\frac{3030084.65}{64} \\approx 47376.64 $</p> <p>La conclusi\u00f3n sobre la varianza muestral obtenida de los datos agrupados en intervalos de gasto mensual en alimentaci\u00f3n para familias en diferentes ciudades de Bolivia es que existe una variabilidad considerable en los gastos mensuales entre las familias. La varianza, que mide la dispersi\u00f3n de los datos respecto a la media muestral, es de aproximadamente 47376.64 47376.64 bolivianos al cuadrado.</p> <p>Este valor indica cu\u00e1nto se alejan, en promedio, los gastos mensuales de cada intervalo del gasto medio muestral. Cuanto mayor sea la varianza, mayor ser\u00e1 la dispersi\u00f3n de los datos. En este caso, la varianza sugiere que hay una variabilidad considerable en los gastos mensuales entre las familias de las diferentes ciudades.</p>"},{"location":"capitulo3/#media-poblacional-para-datos-agrupados","title":"Media Poblacional para datos agrupados\u00b6","text":"<p>La media poblacional para datos agrupados es una medida estad\u00edstica que representa el valor t\u00edpico o promedio de una caracter\u00edstica en una poblaci\u00f3n cuando los datos se presentan en forma de intervalos o clases. Se calcula utilizando la f\u00f3rmula:</p>"},{"location":"capitulo3/#varianza-poblacional-para-datos-agrupados","title":"Varianza Poblacional para datos agrupados\u00b6","text":"<p>La varianza poblacional para datos agrupados es una medida estad\u00edstica que cuantifica la dispersi\u00f3n o variabilidad de una caracter\u00edstica en una poblaci\u00f3n cuando los datos est\u00e1n agrupados en intervalos o clases. Se calcula utilizando la f\u00f3rmula:</p>"},{"location":"capitulo4/","title":"Capitulo 4","text":"Experimento Resultado del experimento Lanzamiento de moneda Cara, Cruz Lanzamiento de dado 1,2,3,4,5,6 Seleccionar una parte inspeccionarla Defectuosa, sin defectos Seleccionar una carta de una baraja 1, 2, 3, ..., 50 <p>Cuando se especifican todos los resultados posibles del experimento, el espacio muestral (conjunto de todos los resultados posibles del experimento) de \u00e9ste se queda definido.</p> In\u00a0[\u00a0]: Copied! <pre>import math\n\n#Introducir n y r (recordar que n debe ser mayor a r)\nn = 10 \nr = 5 \n\n#Sacar factoriales\nfactorial_n = math.factorial(n)\nfactorial_nr = math.factorial(n-r)\n\n#Calcular permutaci\u00f3n (queremos n\u00fameros enteros por eso usamos la divisi\u00f3n entera)\npermutacion = factorial_n//factorial_nr\nprint('La cantidad de permutaciones son:',permutacion)\n</pre> import math  #Introducir n y r (recordar que n debe ser mayor a r) n = 10  r = 5   #Sacar factoriales factorial_n = math.factorial(n) factorial_nr = math.factorial(n-r)  #Calcular permutaci\u00f3n (queremos n\u00fameros enteros por eso usamos la divisi\u00f3n entera) permutacion = factorial_n//factorial_nr print('La cantidad de permutaciones son:',permutacion) In\u00a0[\u00a0]: Copied! <pre>import math\n\n#Total de elementos\nn = 10         #Total\nvar = [3,2,5]  #Aqu\u00ed se puede poner cuantos elementos diferentes tenga\n\n#Calcular los factoriales\nfactorial = math.factorial(n)\nfactorial_var = 1\nfor elem in var:\n        factorial_var *= math.factorial(elem)\n\n#Calcular la permutaci\u00f3n con repetici\u00f3n\npermutacion_rep = factorial//factorial_var\nprint(\"Permutaciones con repetici\u00f3n:\",permutacion_rep)\n</pre> import math  #Total de elementos n = 10         #Total var = [3,2,5]  #Aqu\u00ed se puede poner cuantos elementos diferentes tenga  #Calcular los factoriales factorial = math.factorial(n) factorial_var = 1 for elem in var:         factorial_var *= math.factorial(elem)  #Calcular la permutaci\u00f3n con repetici\u00f3n permutacion_rep = factorial//factorial_var print(\"Permutaciones con repetici\u00f3n:\",permutacion_rep) <pre>Permutaciones con repetici\u00f3n: 2520\n</pre> In\u00a0[\u00a0]: Copied! <pre>import math\n\n#Total de elementos\nn = 10\nk = 2  \n\n#Calcular los factoriales\nfactorial = math.factorial(n)\nfactorial_nk = math.factorial(n-k)\nfactorial_k = math.factorial(k)\n\n#Calcular la permutaci\u00f3n con repetici\u00f3n\ncombinacion = factorial//(factorial_nk*factorial_k)\nprint(\"Combinaciones resultantes:\",combinacion)\n</pre> import math  #Total de elementos n = 10 k = 2    #Calcular los factoriales factorial = math.factorial(n) factorial_nk = math.factorial(n-k) factorial_k = math.factorial(k)  #Calcular la permutaci\u00f3n con repetici\u00f3n combinacion = factorial//(factorial_nk*factorial_k) print(\"Combinaciones resultantes:\",combinacion) <pre>Combinaciones resultantes: 45\n</pre> In\u00a0[\u00a0]: Copied! <pre># Definimos los resultados\nresultados = ['E1', 'E2', 'E3', 'E4']\n\n# a) \u00bfCu\u00e1l es la probabilidad de que E2 ocurra?\nprob_E2 = 1 / len(resultados)\n\n# b) \u00bfCu\u00e1l es la probabilidad de que cualesquiera de los dos resultados ocurran (por ejemplo, E1 o E3)?\nprob_E1_o_E3 = 2 / len(resultados)\n\n# c) \u00bfCu\u00e1l es la probabilidad de que cualesquiera de los tres resultados ocurran (por ejemplo, E1 o E2 o E4)?\nprob_E1_o_E2_o_E4 = 3 / len(resultados)\n\nprint(f\"a) La probabilidad de que E2 ocurra es: {prob_E2}\")\nprint(f\"b) La probabilidad de que E1 o E3 ocurran es: {prob_E1_o_E3}\")\nprint(f\"c) La probabilidad de que E1, E2 o E4 ocurran es: {prob_E1_o_E2_o_E4}\")\n</pre> # Definimos los resultados resultados = ['E1', 'E2', 'E3', 'E4']  # a) \u00bfCu\u00e1l es la probabilidad de que E2 ocurra? prob_E2 = 1 / len(resultados)  # b) \u00bfCu\u00e1l es la probabilidad de que cualesquiera de los dos resultados ocurran (por ejemplo, E1 o E3)? prob_E1_o_E3 = 2 / len(resultados)  # c) \u00bfCu\u00e1l es la probabilidad de que cualesquiera de los tres resultados ocurran (por ejemplo, E1 o E2 o E4)? prob_E1_o_E2_o_E4 = 3 / len(resultados)  print(f\"a) La probabilidad de que E2 ocurra es: {prob_E2}\") print(f\"b) La probabilidad de que E1 o E3 ocurran es: {prob_E1_o_E3}\") print(f\"c) La probabilidad de que E1, E2 o E4 ocurran es: {prob_E1_o_E2_o_E4}\") <pre>a) La probabilidad de que E2 ocurra es: 0.25\nb) La probabilidad de que E1 o E3 ocurran es: 0.5\nc) La probabilidad de que E1, E2 o E4 ocurran es: 0.75\n</pre> <ol> <li>Considere el experimento de seleccionar una carta de una baraja de 52 cartas. Cada carta corresponde a un punto muestral con una probabilidad de 1/52.</li> </ol> <p></p> <p>a) Elabore una lista de los puntos de la muestra en el evento de seleccionar un as. b) Liste los puntos de la muestra en el evento de elegir una carta de bastos. c) Elabore una lista de los puntos de la muestra en el evento de seleccionar una figura (jota, reina o rey). d) Calcule las probabilidades asociadas con cada uno de los eventos de los incisos a), b) y c).</p> In\u00a0[\u00a0]: Copied! <pre># Definimos las cartas\ncartas = ['A', '2', '3', '4', '5', '6', '7', '8', '9', '10', 'J', 'Q', 'K']\npalos = ['corazones', 'diamantes', 'tr\u00e9boles', 'picas'] \n\n# Creamos la baraja\nbaraja = [(carta, palo) for carta in cartas for palo in palos]\n\n# a) Puntos de muestra al seleccionar un as\nas_cartas = [(carta, palo) for carta, palo in baraja if carta == 'A']\nprob_as = len(as_cartas) / len(baraja)\n\n#b) Puntos de muestra al seleccionar una carta de bastos\n# Nota: Reemplaza 'picas' con el palo correspondiente a \"bastos\"\nbastos_cartas = [(carta, palo) for carta, palo in baraja if palo == 'picas']\nprob_bastos = len(bastos_cartas) / len(baraja)\n\n#c) Puntos de muestra al seleccionar una figura (jota, reina o rey)\nfigura_cartas = [(carta, palo) for carta, palo in baraja if carta in ['J', 'Q', 'K']]\nprob_figura = len(figura_cartas) / len(baraja)\nprint(f\"inciso a) \")\nprint(f\"a) Puntos de muestra al seleccionar un as: {as_cartas}, Probabilidad: {prob_as}\")\nprint(f\"inciso b) \")\nprint(f\"b) Puntos de muestra al seleccionar una carta de bastos: {bastos_cartas}, Probabilidad: {prob_bastos}\")\nprint(f\"inciso c) \")\nprint(f\"c) Puntos de muestra al seleccionar una figura: {figura_cartas}, Probabilidad: {prob_figura}\")\n\n#d) Calculamos las probabilidades asociadas con cada uno de los eventos de los incisos a), b) y c)\nprint(f\"inciso d) \")\nprint(f\"a) Probabilidad de seleccionar un as: {prob_as}\")\nprint(f\"b) Probabilidad de seleccionar una carta de bastos: {prob_bastos}\")\nprint(f\"c) Probabilidad de seleccionar una figura: {prob_figura}\")\n</pre> # Definimos las cartas cartas = ['A', '2', '3', '4', '5', '6', '7', '8', '9', '10', 'J', 'Q', 'K'] palos = ['corazones', 'diamantes', 'tr\u00e9boles', 'picas']   # Creamos la baraja baraja = [(carta, palo) for carta in cartas for palo in palos]  # a) Puntos de muestra al seleccionar un as as_cartas = [(carta, palo) for carta, palo in baraja if carta == 'A'] prob_as = len(as_cartas) / len(baraja)  #b) Puntos de muestra al seleccionar una carta de bastos # Nota: Reemplaza 'picas' con el palo correspondiente a \"bastos\" bastos_cartas = [(carta, palo) for carta, palo in baraja if palo == 'picas'] prob_bastos = len(bastos_cartas) / len(baraja)  #c) Puntos de muestra al seleccionar una figura (jota, reina o rey) figura_cartas = [(carta, palo) for carta, palo in baraja if carta in ['J', 'Q', 'K']] prob_figura = len(figura_cartas) / len(baraja) print(f\"inciso a) \") print(f\"a) Puntos de muestra al seleccionar un as: {as_cartas}, Probabilidad: {prob_as}\") print(f\"inciso b) \") print(f\"b) Puntos de muestra al seleccionar una carta de bastos: {bastos_cartas}, Probabilidad: {prob_bastos}\") print(f\"inciso c) \") print(f\"c) Puntos de muestra al seleccionar una figura: {figura_cartas}, Probabilidad: {prob_figura}\")  #d) Calculamos las probabilidades asociadas con cada uno de los eventos de los incisos a), b) y c) print(f\"inciso d) \") print(f\"a) Probabilidad de seleccionar un as: {prob_as}\") print(f\"b) Probabilidad de seleccionar una carta de bastos: {prob_bastos}\") print(f\"c) Probabilidad de seleccionar una figura: {prob_figura}\") <pre>inciso a) \na) Puntos de muestra al seleccionar un as: [('A', 'corazones'), ('A', 'diamantes'), ('A', 'tr\u00e9boles'), ('A', 'picas')], Probabilidad: 0.07692307692307693\ninciso b) \nb) Puntos de muestra al seleccionar una carta de bastos: [('A', 'picas'), ('2', 'picas'), ('3', 'picas'), ('4', 'picas'), ('5', 'picas'), ('6', 'picas'), ('7', 'picas'), ('8', 'picas'), ('9', 'picas'), ('10', 'picas'), ('J', 'picas'), ('Q', 'picas'), ('K', 'picas')], Probabilidad: 0.25\ninciso c) \nc) Puntos de muestra al seleccionar una figura: [('J', 'corazones'), ('J', 'diamantes'), ('J', 'tr\u00e9boles'), ('J', 'picas'), ('Q', 'corazones'), ('Q', 'diamantes'), ('Q', 'tr\u00e9boles'), ('Q', 'picas'), ('K', 'corazones'), ('K', 'diamantes'), ('K', 'tr\u00e9boles'), ('K', 'picas')], Probabilidad: 0.23076923076923078\ninciso d) \na) Probabilidad de seleccionar un as: 0.07692307692307693\nb) Probabilidad de seleccionar una carta de bastos: 0.25\nc) Probabilidad de seleccionar una figura: 0.23076923076923078\n</pre> <ol> <li>Considere el experimento de arrojar un par de dados. Suponga que le interesa la suma de los valores de las caras mostradas en el dado.  a) \u00bfCu\u00e1ntos puntos de la muestra son posibles? (Sugerencia: utilice la regla de conteo para los experimentos de pasos m\u00faltiples.) b) Elabore una lista de los puntos de la muestra. c) \u00bfCu\u00e1l es la probabilidad de obtener un valor de 7? d) \u00bfCu\u00e1l es la probabilidad de obtener un valor de 9 o mayor? e) Debido a que cada tiro tiene seis valores pares de eventos posibles (2, 4, 6, 8, 10 y 12) y s\u00f3lo cinco valores impares posibles (3, 5, 7, 9 y 11), el dado debe mostrar m\u00e1s a menudo valores pares que impares. \u00bfEst\u00e1 usted de acuerdo con este enunciado? Explique. f) \u00bfQu\u00e9 m\u00e9todo utiliz\u00f3 para asignar las probabilidades requeridas?</li> </ol> In\u00a0[\u00a0]: Copied! <pre># Definimos los valores de los dados\ndados = list(range(1, 7))\n\n# Creamos los puntos de la muestra\npuntos_muestra = [(dado1, dado2) for dado1 in dados for dado2 in dados]\n\n# a) \u00bfCu\u00e1ntos puntos de la muestra son posibles?\nnum_puntos_muestra = len(puntos_muestra)\n\n# b) Elaboramos una lista de los puntos de la muestra\nlista_puntos_muestra = puntos_muestra\n\n# c) \u00bfCu\u00e1l es la probabilidad de obtener un valor de 7?\neventos_7 = [(dado1, dado2) for dado1, dado2 in puntos_muestra if dado1 + dado2 == 7]\nprob_7 = len(eventos_7) / num_puntos_muestra\n\n# d) \u00bfCu\u00e1l es la probabilidad de obtener un valor de 9 o mayor?\neventos_9_o_mas = [(dado1, dado2) for dado1, dado2 in puntos_muestra if dado1 + dado2 &gt;= 9]\nprob_9_o_mas = len(eventos_9_o_mas) / num_puntos_muestra\n\n# e) Debido a que cada tiro tiene seis valores pares de eventos posibles (2, 4, 6, 8, 10 y 12) y\n# s\u00f3lo cinco valores impares posibles (3, 5, 7, 9 y 11), el dado debe mostrar m\u00e1s a menudo\n# valores pares que impares. \u00bfEst\u00e1 usted de acuerdo con este enunciado? Explique.\neventos_pares = [(dado1, dado2) for dado1, dado2 in puntos_muestra if (dado1 + dado2) % 2 == 0]\neventos_impares = [(dado1, dado2) for dado1, dado2 in puntos_muestra if (dado1 + dado2) % 2 != 0]\nmas_pares_que_impares = len(eventos_pares) &gt; len(eventos_impares)\n\n# f) \u00bfQu\u00e9 m\u00e9todo utiliz\u00f3 para asignar las probabilidades requeridas?\n# Utilic\u00e9 la definici\u00f3n cl\u00e1sica de probabilidad, que es el n\u00famero de eventos favorables dividido por el n\u00famero de eventos posibles.\n\nprint(f\"a) N\u00famero de puntos de la muestra posibles: {num_puntos_muestra}\")\nprint(f\"b) Lista de puntos de la muestra: {lista_puntos_muestra}\")\nprint(f\"c) Probabilidad de obtener un valor de 7: {prob_7}\")\nprint(f\"d) Probabilidad de obtener un valor de 9 o mayor: {prob_9_o_mas}\")\nprint(f\"e) \u00bfEl dado muestra m\u00e1s a menudo valores pares que impares?: {'S\u00ed' if mas_pares_que_impares else 'No'}\")\nprint(f\"f) \u00bfQu\u00e9 m\u00e9todo utiliz\u00f3 para asignar las probabilidades requeridas?  Utilic\u00e9 la definici\u00f3n cl\u00e1sica de probabilidad, que es el    n\u00famero de eventos favorables dividido por el n\u00famero de eventos posibles.\")\n</pre> # Definimos los valores de los dados dados = list(range(1, 7))  # Creamos los puntos de la muestra puntos_muestra = [(dado1, dado2) for dado1 in dados for dado2 in dados]  # a) \u00bfCu\u00e1ntos puntos de la muestra son posibles? num_puntos_muestra = len(puntos_muestra)  # b) Elaboramos una lista de los puntos de la muestra lista_puntos_muestra = puntos_muestra  # c) \u00bfCu\u00e1l es la probabilidad de obtener un valor de 7? eventos_7 = [(dado1, dado2) for dado1, dado2 in puntos_muestra if dado1 + dado2 == 7] prob_7 = len(eventos_7) / num_puntos_muestra  # d) \u00bfCu\u00e1l es la probabilidad de obtener un valor de 9 o mayor? eventos_9_o_mas = [(dado1, dado2) for dado1, dado2 in puntos_muestra if dado1 + dado2 &gt;= 9] prob_9_o_mas = len(eventos_9_o_mas) / num_puntos_muestra  # e) Debido a que cada tiro tiene seis valores pares de eventos posibles (2, 4, 6, 8, 10 y 12) y # s\u00f3lo cinco valores impares posibles (3, 5, 7, 9 y 11), el dado debe mostrar m\u00e1s a menudo # valores pares que impares. \u00bfEst\u00e1 usted de acuerdo con este enunciado? Explique. eventos_pares = [(dado1, dado2) for dado1, dado2 in puntos_muestra if (dado1 + dado2) % 2 == 0] eventos_impares = [(dado1, dado2) for dado1, dado2 in puntos_muestra if (dado1 + dado2) % 2 != 0] mas_pares_que_impares = len(eventos_pares) &gt; len(eventos_impares)  # f) \u00bfQu\u00e9 m\u00e9todo utiliz\u00f3 para asignar las probabilidades requeridas? # Utilic\u00e9 la definici\u00f3n cl\u00e1sica de probabilidad, que es el n\u00famero de eventos favorables dividido por el n\u00famero de eventos posibles.  print(f\"a) N\u00famero de puntos de la muestra posibles: {num_puntos_muestra}\") print(f\"b) Lista de puntos de la muestra: {lista_puntos_muestra}\") print(f\"c) Probabilidad de obtener un valor de 7: {prob_7}\") print(f\"d) Probabilidad de obtener un valor de 9 o mayor: {prob_9_o_mas}\") print(f\"e) \u00bfEl dado muestra m\u00e1s a menudo valores pares que impares?: {'S\u00ed' if mas_pares_que_impares else 'No'}\") print(f\"f) \u00bfQu\u00e9 m\u00e9todo utiliz\u00f3 para asignar las probabilidades requeridas?  Utilic\u00e9 la definici\u00f3n cl\u00e1sica de probabilidad, que es el    n\u00famero de eventos favorables dividido por el n\u00famero de eventos posibles.\") <pre>a) N\u00famero de puntos de la muestra posibles: 36\nb) Lista de puntos de la muestra: [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6), (3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6), (4, 1), (4, 2), (4, 3), (4, 4), (4, 5), (4, 6), (5, 1), (5, 2), (5, 3), (5, 4), (5, 5), (5, 6), (6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6)]\nc) Probabilidad de obtener un valor de 7: 0.16666666666666666\nd) Probabilidad de obtener un valor de 9 o mayor: 0.2777777777777778\ne) \u00bfEl dado muestra m\u00e1s a menudo valores pares que impares?: No\nf) \u00bfQu\u00e9 m\u00e9todo utiliz\u00f3 para asignar las probabilidades requeridas?  Utilic\u00e9 la definici\u00f3n cl\u00e1sica de probabilidad, que es el    n\u00famero de eventos favorables dividido por el n\u00famero de eventos posibles.\n</pre> <p>Al calcular $P(A)$, se obtiene el resultado siguiente.</p> C\u00e1lculo de la Probabilidad utilizando el complemento                  $$P(A) = 1 - P(A^c)$$              (4.5)  La ecuaci\u00f3n anterior muestra la probabilidad de que un evento A se calcule f\u00e1cilmente si se conoce la probabilidad de su complemento, $P(A^c)$. Como ejemplo, considere el caso de un gerente de ventas quien, despu\u00e9s de revisar los informes de ventas, establece que 80% de los contactos de clientes nuevos no generan ninguna venta. Al hacer que A denote el evento de que se realiza una venta y Ac denote el evento de que no se realice, el gerente establece que $P(A^c)$ = 0.80. Utilizando la ecuaci\u00f3n anterior, vemos que  <p>$$P(A) = 1 - P(A^c) = 1 - 0.80 = 0.20$$</p> In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nfrom matplotlib_venn import venn2\n# Datos de ejemplo\nA = {1,2,3,4,5}\nB = {4,5,6,7,8}\nunion = A.union(B)\ncolor = 'lightgreen'\nvenn_diagram = venn2([A,B], set_labels=('A', 'B'), set_colors=(color, color))\nvenn_diagram.get_label_by_id('10').set_text('')\nvenn_diagram.get_label_by_id('01').set_text('')\nvenn_diagram.get_label_by_id('11').set_text('AUB')\nplt.show()\n</pre> import matplotlib.pyplot as plt from matplotlib_venn import venn2 # Datos de ejemplo A = {1,2,3,4,5} B = {4,5,6,7,8} union = A.union(B) color = 'lightgreen' venn_diagram = venn2([A,B], set_labels=('A', 'B'), set_colors=(color, color)) venn_diagram.get_label_by_id('10').set_text('') venn_diagram.get_label_by_id('01').set_text('') venn_diagram.get_label_by_id('11').set_text('AUB') plt.show() Intersecci\u00f3n de dos Eventos             Dados dos eventos $A$ y $B$, la intersecci\u00f3n de $A$ y $B$ es el evento que contiene los puntos de la muestra que pertenecen a tanto a $A$ como a $B$. La intersecci\u00f3n se denota por medio de $A \u2229 B$.          <p>El diagrama de Venn que representa la intersecci\u00f3n de los eventos A y B se muestra en la figura 4.6. El \u00e1rea donde los dos c\u00edrculos se traslapan es la intersecci\u00f3n; contiene los puntos de la muestra que est\u00e1n tanto en A como en B. Ahora se estudiar\u00e1 la ley de la adici\u00f3n. La ley de la adici\u00f3n proporciona una manera de calcular la probabilidad de que ocurra el evento A o el evento B o ambos. En otras palabras, la ley de la adici\u00f3n se utiliza para calcular la probabilidad de la uni\u00f3n de dos eventos. La ley de la adici\u00f3n se escribe como sigue.</p> Ley de la Adici\u00f3n                  $$P(A \u222a B) = P(A) + P(B) - P(A \u2229 B)$$              (4.6) <p>Figura 4.2 Intersecci\u00f3n de los eventos A y B</p> In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nfrom matplotlib_venn import venn2\n# Datos de ejemplo\nA = {1,2,3,4,5}\nB = {4,5,6,7,8}\nintersection = A.intersection(B)\ncolor = 'lightgreen'\nvenn_diagram = venn2([A,B], set_labels=('A', 'B'), set_colors=(color, color))\nvenn_diagram.get_label_by_id('10').set_text('')\nvenn_diagram.get_label_by_id('01').set_text('')\nvenn_diagram.get_label_by_id('11').set_text('A\u2229B')\nplt.show()\n</pre> import matplotlib.pyplot as plt from matplotlib_venn import venn2 # Datos de ejemplo A = {1,2,3,4,5} B = {4,5,6,7,8} intersection = A.intersection(B) color = 'lightgreen' venn_diagram = venn2([A,B], set_labels=('A', 'B'), set_colors=(color, color)) venn_diagram.get_label_by_id('10').set_text('') venn_diagram.get_label_by_id('01').set_text('') venn_diagram.get_label_by_id('11').set_text('A\u2229B') plt.show() <p>Para entender de manera intuitiva la ley de la adici\u00f3n, considere que los dos primeros t\u00e9rminos de la ley, $P(A) + P(B)$, representan todos los puntos de la muestra en $A \u222a B$. Sin embargo, debido a que los puntos de la muestra en la intersecci\u00f3n $A \u2229 B$ est\u00e1n en $A$ y en $B$, cuando se calcula $P(A) + P(B)$, en realidad se est\u00e1n contando dos veces cada uno de los puntos de la muestra en $A \u2229 B$. Este conteo excesivo se corrige al restar $P(A \u2229 B)$.</p> In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nfrom matplotlib_venn import venn2\n# Datos de ejemplo\nA = {7, 8, 9, 10}\nB = {11, 12, 13, 14}\nfig, ax = plt.subplots(figsize=(5, 5))\ncolor_a = 'lightgreen'\ncolor_b = 'lightgreen'\nvenn_diagram = venn2([A,B], set_labels=('A', 'B'), set_colors=(color_a, color_b))\nvenn_diagram.get_label_by_id('10').set_text('')\nvenn_diagram.get_label_by_id('01').set_text('')\nplt.show()\n</pre> import matplotlib.pyplot as plt from matplotlib_venn import venn2 # Datos de ejemplo A = {7, 8, 9, 10} B = {11, 12, 13, 14} fig, ax = plt.subplots(figsize=(5, 5)) color_a = 'lightgreen' color_b = 'lightgreen' venn_diagram = venn2([A,B], set_labels=('A', 'B'), set_colors=(color_a, color_b)) venn_diagram.get_label_by_id('10').set_text('') venn_diagram.get_label_by_id('01').set_text('') plt.show() In\u00a0[\u00a0]: Copied! <pre># Datos proporcionados\nP_M = 0.56\nP_F = 0.42\nP_M_interseccion_F = 0.24\n\n# Probabilidad de que un hombre joven viva en casa de sus padres\nP_M_solo = P_M - P_M_interseccion_F\n\n# Probabilidad de que una mujer joven viva en casa de sus padres\nP_F_solo = P_F - P_M_interseccion_F\n\n# Probabilidad de que al menos uno de los dos adultos j\u00f3venes viva en casa de sus padres\nP_al_menos_uno = P_M_solo + P_F_solo\n\n# Imprimir los resultados\nprint(f\"Probabilidad de que un hombre joven viva en casa de sus padres: {P_M_solo:.2f}\")\nprint(f\"Probabilidad de que una mujer joven viva en casa de sus padres: {P_F_solo:.2f}\")\nprint(f\"Probabilidad de que al menos uno de los dos adultos j\u00f3venes viva en casa de sus padres: {P_al_menos_uno:.2f}\")\n</pre> # Datos proporcionados P_M = 0.56 P_F = 0.42 P_M_interseccion_F = 0.24  # Probabilidad de que un hombre joven viva en casa de sus padres P_M_solo = P_M - P_M_interseccion_F  # Probabilidad de que una mujer joven viva en casa de sus padres P_F_solo = P_F - P_M_interseccion_F  # Probabilidad de que al menos uno de los dos adultos j\u00f3venes viva en casa de sus padres P_al_menos_uno = P_M_solo + P_F_solo  # Imprimir los resultados print(f\"Probabilidad de que un hombre joven viva en casa de sus padres: {P_M_solo:.2f}\") print(f\"Probabilidad de que una mujer joven viva en casa de sus padres: {P_F_solo:.2f}\") print(f\"Probabilidad de que al menos uno de los dos adultos j\u00f3venes viva en casa de sus padres: {P_al_menos_uno:.2f}\") <p>Solucion inciso b) </p> In\u00a0[\u00a0]: Copied! <pre># Datos proporcionados\nP_M = 0.56\nP_F = 0.42\nP_M_interseccion_F = 0.24\n\n# Probabilidad de que ambos adultos j\u00f3venes vivan en casa de sus padres\nP_Ambos = P_M_interseccion_F\n\n# Imprimir el resultado\nprint(f\"Probabilidad de que ambos adultos j\u00f3venes vivan en casa de sus padres: {P_Ambos:.2%}\")\n</pre> # Datos proporcionados P_M = 0.56 P_F = 0.42 P_M_interseccion_F = 0.24  # Probabilidad de que ambos adultos j\u00f3venes vivan en casa de sus padres P_Ambos = P_M_interseccion_F  # Imprimir el resultado print(f\"Probabilidad de que ambos adultos j\u00f3venes vivan en casa de sus padres: {P_Ambos:.2%}\") <pre>Probabilidad de que ambos adultos j\u00f3venes vivan en casa de sus padres: 24.00%\n</pre> <p>Aunque tambi\u00e9n podemos calcular las probabilidades marginales:</p> <p>$P(I) =  \\frac{4120}{7700} = 0,54 $ , probabilidad de que el estudiante sea var\u00f3n y estudie inform\u00e1tica</p> <p>$P(I^C) = \\frac{3580}{7700} = 0,46 $ , probabilidad de que el estudiante sea var\u00f3n y no estudie inform\u00e1tica</p> <p>$P(V) = \\frac{4980}{7700} = 0,65 $ , probabilidad de que el estudiante sea mujer y estudie inform\u00e1tica</p> <p>$P(M) = \\frac{2720}{7700} = 0,35 $ , probabilidad de que el estudiante sea mujer y  no estudie inform\u00e1tica</p> <p>Con un an\u00e1lisis de la probabilidad condicional: Dado un evento $A$ con $P(A)$ y un evento $B$ ya ocurrido, conociendo la probabilidad del evento $A$ conjunto $B$ o $P(A\\cap B)$,podemos calcular la probabilidad de un evento $A$ dado $B$:</p> Probabilidad Condicional                  $$ P(A|B)=\\frac{P(A\\cap B)}{P(B)} $$              (4.7) o en el caso de, la probabilidad de $B$ dado $A$:                  $$ P(B|A)=\\frac{P(A\\cap B)}{P(A)} $$              (4.8) <p>Con el siguiente diagrama de Venn podemos tener una percepcion mas intuitiva sobre la conjuncion de eventos y la probabilidad de los mismos, y su c\u00e1lculo:</p> <p> Figura 4.8 Probabilidad Condicional P(A | B) = P(A $\\cap$ B)/ P(B)</p> In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nfrom matplotlib_venn import venn2\n# Datos de ejemplo\nA = {1,2,3,4,5}\nB = {4,5,6,7,8}\nintersection = A.intersection(B)\ncolor_a = 'lightgreen'\ncolor_b = 'lightgreen'\nvenn_diagram = venn2([A,B], set_labels=('Evento A', 'Evento B'), set_colors=(color_a, color_b))\n\nvenn_diagram.get_label_by_id('10').set_text('P ( A )')\nvenn_diagram.get_label_by_id('01').set_text('P ( B )')\nvenn_diagram.get_label_by_id('11').set_text('P ( A\u2229B )')\n\nplt.show()\n</pre> import matplotlib.pyplot as plt from matplotlib_venn import venn2 # Datos de ejemplo A = {1,2,3,4,5} B = {4,5,6,7,8} intersection = A.intersection(B) color_a = 'lightgreen' color_b = 'lightgreen' venn_diagram = venn2([A,B], set_labels=('Evento A', 'Evento B'), set_colors=(color_a, color_b))  venn_diagram.get_label_by_id('10').set_text('P ( A )') venn_diagram.get_label_by_id('01').set_text('P ( B )') venn_diagram.get_label_by_id('11').set_text('P ( A\u2229B )')  plt.show() <p>Ejemplo: Si seguimos tomando en cuenta la situacion planteada gracias a la tabla 4.5 y con ayuda de la f\u00f3rmulas 4.7 y 4.8 podemos calcular algunas de las probabilidades condicionales:</p> <p>$P(I|V) =\\frac{\\frac{3100}{7700}}{\\frac{4980}{7700}} = \\frac{3100}{4980} = 0,62 $ , probabilidad de que un estudiante var\u00f3n estudie inform\u00e1tica</p> <p>$P(I|M) =\\frac{\\frac{1020}{7700}}{\\frac{2720}{7700}} = \\frac{1020}{2720} = 0,38 $ , probabilidad de que un estudiante mujer estudie inform\u00e1tica</p> <p>$P(I^C|V) =\\frac{\\frac{1880}{7700}}{\\frac{4980}{7700}} = \\frac{1880}{4980} = 0,38 $ , probabilidad de que un estudiante var\u00f3n no estudie inform\u00e1tica</p> <p>$P(I^C|M) =\\frac{\\frac{1700}{7700}}{\\frac{2720}{7700}} = \\frac{1700}{2720} = 0,62 $ , probabilidad de que un estudiante mujer no estudie inform\u00e1tica</p> <p>$P(V|I) =\\frac{\\frac{3100}{7700}}{\\frac{4120}{7700}} = \\frac{3100}{4120} = 0,75 $ , probabilidad de que un estudiante de inform\u00e1tica sea varon</p> <p>$P(M|I) =\\frac{\\frac{1020}{7700}}{\\frac{4120}{7700}} = \\frac{1020}{4120} = 0,25 $ , probabilidad de que un estudiante de inform\u00e1tica sea mujer</p> <p>$P(V|I^C) =\\frac{\\frac{1880}{7700}}{\\frac{3580}{7700}} =\\frac{1880}{3580}  = 0,53 $ , probabilidad de que un estudiante que no es de inform\u00e1tica sea varon</p> <p>$P(M|I^C) =\\frac{\\frac{1700}{7700}}{\\frac{3580}{7700}} = \\frac{1700}{3580} = 0,47 $ , probabilidad de que un estudiante que no es de inform\u00e1tica sea mujer</p> <p>Cabe recalcar equellas diferencias entre la preposicion verbal de las probabilidades respecto a las otras , es decir , no es lo mismo expresar \"la probabilidad de que un estudiante var\u00f3n estudie inform\u00e1tica\" y \"la probabilidad de que un estudiante sea varon y estudie inform\u00e1tica\"</p> EVENTOS INDEPENDIENTES Dos eventos A Y B son independientes si:                  $$ P(A|B)=P(A) $$              (4.9) o                  $$ P(B|A)=P(B) $$              (4.10 ) <p>caso contrario, los eventos son dependientes.</p> <p>EJEMPLO: Si volvmos a tomar en cuenta  la situacion planteada por la tabla 4.5 y usando las f\u00f3rmulas 4.11 y 4.12 podemos calcular la probabilidades conjuntas:</p> <p>$P(V\\cap I) =  {\\frac{4120}{7700}}\\cdot{\\frac{3100}{4120}} = \\frac{3100}{7700}= 0,40 $</p> <p>$P(V\\cap I) =  {\\frac{4980}{7700}}\\cdot{\\frac{3100}{4980}} = \\frac{3100}{7700}= 0,40 $</p> <p>$P(M\\cap I) =  {\\frac{4120}{7700}}\\cdot{\\frac{1020}{4120}} = \\frac{1020}{7700}= 0,13 $</p> <p>$P(M\\cap I) =  {\\frac{2720}{7700}}\\cdot{\\frac{1020}{2720}} = \\frac{1020}{7700}= 0,13 $</p> <p>$P(V\\cap I^C) =  {\\frac{3580}{7700}}\\cdot{\\frac{1880}{3580}} = \\frac{1880}{7700}= 0,25 $</p> <p>$P(V\\cap I^C) =  {\\frac{4980}{7700}}\\cdot{\\frac{1880}{4980}} = \\frac{1880}{7700}= 0,25 $</p> <p>$P(M\\cap I^C) =  {\\frac{3580}{7700}}\\cdot{\\frac{1700}{3580}} = \\frac{1700}{7700}=0,22 $</p> <p>$P(M\\cap I^C) =  {\\frac{2720}{7700}}\\cdot{\\frac{1700}{2720}} = \\frac{1700}{7700}=0,22 $</p> <p>Y comprobando los resultados nos damos cuentaque los calculos son correctos, aunque es de esperarse debido a que la ley de la multiplicaci\u00f3n es una ecuacion despejada sobre la ecuacion de la probabilidad condicional.</p> <p>Tambi\u00e9n es importante indicar un caso especial sobre la ley de la multiplicaci\u00f3n, que consiste en la indepedencia de los eventos involucrados entre s\u00ed, lo que indicaria que las probabilidades condicionales tendrian el valor de su probabilidad marginal, es decir $P(A|B) = P(A)$ o $P(B|A) = P(B)$, por lo tanto la ley de la multiplicaci\u00f3n en este caso tendr\u00eda el siguiente cambio.</p> LEY DE LA MULTIPLICACI\u00d3N PARA EVENTOS INDEPENDIENTES                  $$ P(A\\cap B)=P(A)\\cdot P(B) $$              (4.13) In\u00a0[\u00a0]: Copied! <pre>from IPython.display import YouTubeVideo\nprint('Teorema de Bayes - Probabilidades - Ejercicios Resueltos')\nruta_video = YouTubeVideo('CP4ToX5Tyvw')\ndisplay(ruta_video)\n</pre> from IPython.display import YouTubeVideo print('Teorema de Bayes - Probabilidades - Ejercicios Resueltos') ruta_video = YouTubeVideo('CP4ToX5Tyvw') display(ruta_video) <pre>Teorema de Bayes - Probabilidades - Ejercicios Resueltos\n</pre> In\u00a0[\u00a0]: Copied! <pre>from IPython.display import YouTubeVideo\nprint('Introducci\u00f3n a la teor\u00eda de Bayes')\nruta_video = YouTubeVideo('bDfCURXoKkU')\ndisplay(ruta_video)\n</pre> from IPython.display import YouTubeVideo print('Introducci\u00f3n a la teor\u00eda de Bayes') ruta_video = YouTubeVideo('bDfCURXoKkU') display(ruta_video) <pre>Introducci\u00f3n a la teor\u00eda de Bayes\n</pre> <p>Ejercicio 1.  Considere una tienda de barrio que recibe gaseosas de dos distribuidoras diferentes. Sea A1 el evento de que un paquete proviene de la distribuidora 1, y A2 el evento de que un paquete proiene de la distribuidora 2. En la actualidad, 65% de las partes adquiridas por la tienda de barrio son de la distribuidora 1 y el 35% restante son de la distribuidora 2. De ah\u00ed que si un paquete es seleccionado al azar, se le asignar\u00edan las probabilidades previas $P(A1)=0.65$ y $P(A2)=0.35$</p> <p>Tabla 3.15  Titulo de la Tabla</p> Refacciones en buen estado (porcentaje) Refacciones en mal estado (porcentaje) Distribuidora 1 98 2 Distribuidora 2 95 5 <p>Si $G$ denota el evento de que una refacci\u00f3n est\u00e1 en buen estado y $B$ denota el evento de que una refacci\u00f3n est\u00e1 en mal estado, la informaci\u00f3n de la tabla anterior proporciona los valores de probabilidad condicional siguientes.</p> <p>$$P(G|A_1)=0.98 P(B|A_1)=0.02$$ $$P(G|A_2)=0.95 P(B|A_2)=0.05$$</p> <p>Partiendo de que $B$ denota el evento de que la refaccion se encuentra en mal estado, se buscan las probabilidades posteriores $P(A_1|B)$ y $P(A_2|B)$. A partir de la let de la probabilidad condicional sabemos que:</p>                  $$P(A_1|B)=\\frac{P(A_1 \\cap B)}{P(B)}(\\star)$$              (4.14) <p>Si nos remitimos al arbol de probabilidades, obtenemos: $$P(A_1 \\cap B)=P(A_1)P(B|A_1) (\\alpha)$$ La probabilidad del resultado es: $$P(A_1 \\cap G)=P(A_1)P(G|A_1)=0.6370$$ $$P(A_1 \\cap B)=P(A_1)P(B|A_1)=0.0130$$ $$P(A_2 \\cap G)=P(A_2)P(G|A_2)=0.3325$$ $$P(A_2 \\cap B)=P(A_2)P(B|A_2)=0.0175$$ Para obtener $P(B)$ notemos que el evento $B$ puede ocurrir de dos maneras diferentes: $A_1\\cap B$ $A_2$. Por lo tanto: $$P(B)=P(A_1\\cap B)+P(A_2\\cap B)$$ $$P(B)=P(A_1)P(B|A_1)+P(A_2)P(B|A_2) (\\gamma)$$</p> <p>Reemplazando $(\\alpha)$ y $(\\gamma)$ en $(\\star)$ obtenemos: $$P(A_i|B)=\\frac{P(A_i)P(B|A_i)}{P(A_1)P(B|A_1)+P(A_2)P(B|A_2)+...+P(A_n)P(B|A_n)}$$ Utilizando la formula anterior hallaremos los valores requeridos: $$P(A_1|B)=\\frac{P(A_1)P(B|A_1)}{P(A_1)P(B|A_1)+P(A_2)P(B|A_2)}=0.4262$$</p> <p>$$P(A_2|B)=\\frac{P(A_2)P(B|A_2)}{P(A_1)P(B|A_1)+P(A_2)P(B|A_2)}=0.5738$$</p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport scipy.stats as st\n\ndef AiIB(pai, pai2, b, b2):\n    return (pai * b) / ((pai * b) + (pai2 * b2))\n\n# Datos del ejercicio\npa1, pa2 = 0.65, 0.35\npg1, pg2 = 0.98, 0.95\npb1, pb2 = 0.02, 0.05\n\n# Crear un DataFrame con los datos del ejercicio\ndf = pd.DataFrame({\n    'pa': [pa1, pa2],\n    'pg': [pg1, pg2],\n    'pb': [pb1, pb2]\n}, index=['A1', 'A2'])\n\n# Calculamos las probabilidades de Ai \u2229 Gi usando la regla del producto\np_ag = df['pa'] * df['pg']\n\n# Calculamos las probabilidades de Ai \u2229 Bi usando la regla del producto\np_ab = df['pa'] * df['pb']\n\n# Calculamos las probabilidades de Ai | Bi usando la funci\u00f3n AiIB\np_a_b = np.array([round(AiIB(pa1, pa2, pb1, pb2), 4), round(AiIB(pa2, pa1, pb2, pb1), 4)])\n\n# Creamos una figura con tres subgr\u00e1ficos\nfig, ax = plt.subplots(1, 3, figsize=(12, 4))\n\n# Agregamos los datos obtenidos a nuestro DataFrame\ndf['p_ag'] = p_ag\ndf['p_ab'] = p_ab\ndf['p_a_b'] = p_a_b\n\n# Graficamos las probabilidades de Ai \u2229 Gi como un gr\u00e1fico de barras con bordes negros\nax[0].bar(['A1 \u2229 G', 'A2 \u2229 G'], p_ag, color=['#5CCB5f', '#5CCB5f'], edgecolor='black')\nax[0].set_ylabel('Probabilidad')\nax[0].set_title('Probabilidades de Ai \u2229 Gi')\n\n# Graficamos las probabilidades de Ai \u2229 Bi como un gr\u00e1fico de barras con bordes negros\nax[1].bar(['A1 \u2229 B', 'A2 \u2229 B'], p_ab, color=['#5CCB5f', '#5CCB5f'], edgecolor='black')\nax[1].set_ylabel('Probabilidad')\nax[1].set_title('Probabilidades de Ai \u2229 Bi')\n\n# Graficamos las probabilidades de Ai | Bi como un gr\u00e1fico de pastel con bordes negros\nax[2].pie(p_a_b, labels=['A1 | B', 'A2 | B'], colors=['#5ccb5f', '#98f84a'], autopct='%1.2f%%', wedgeprops=dict(edgecolor='black'))\nax[2].set_title('Probabilidades de Ai | Bi')\n\n# Mostrar la figura\nprint('\\nDatos que el ejercicio nos brinda y hallados:')\ndisplay(df)\nplt.tight_layout(pad=2)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt import pandas as pd import scipy.stats as st  def AiIB(pai, pai2, b, b2):     return (pai * b) / ((pai * b) + (pai2 * b2))  # Datos del ejercicio pa1, pa2 = 0.65, 0.35 pg1, pg2 = 0.98, 0.95 pb1, pb2 = 0.02, 0.05  # Crear un DataFrame con los datos del ejercicio df = pd.DataFrame({     'pa': [pa1, pa2],     'pg': [pg1, pg2],     'pb': [pb1, pb2] }, index=['A1', 'A2'])  # Calculamos las probabilidades de Ai \u2229 Gi usando la regla del producto p_ag = df['pa'] * df['pg']  # Calculamos las probabilidades de Ai \u2229 Bi usando la regla del producto p_ab = df['pa'] * df['pb']  # Calculamos las probabilidades de Ai | Bi usando la funci\u00f3n AiIB p_a_b = np.array([round(AiIB(pa1, pa2, pb1, pb2), 4), round(AiIB(pa2, pa1, pb2, pb1), 4)])  # Creamos una figura con tres subgr\u00e1ficos fig, ax = plt.subplots(1, 3, figsize=(12, 4))  # Agregamos los datos obtenidos a nuestro DataFrame df['p_ag'] = p_ag df['p_ab'] = p_ab df['p_a_b'] = p_a_b  # Graficamos las probabilidades de Ai \u2229 Gi como un gr\u00e1fico de barras con bordes negros ax[0].bar(['A1 \u2229 G', 'A2 \u2229 G'], p_ag, color=['#5CCB5f', '#5CCB5f'], edgecolor='black') ax[0].set_ylabel('Probabilidad') ax[0].set_title('Probabilidades de Ai \u2229 Gi')  # Graficamos las probabilidades de Ai \u2229 Bi como un gr\u00e1fico de barras con bordes negros ax[1].bar(['A1 \u2229 B', 'A2 \u2229 B'], p_ab, color=['#5CCB5f', '#5CCB5f'], edgecolor='black') ax[1].set_ylabel('Probabilidad') ax[1].set_title('Probabilidades de Ai \u2229 Bi')  # Graficamos las probabilidades de Ai | Bi como un gr\u00e1fico de pastel con bordes negros ax[2].pie(p_a_b, labels=['A1 | B', 'A2 | B'], colors=['#5ccb5f', '#98f84a'], autopct='%1.2f%%', wedgeprops=dict(edgecolor='black')) ax[2].set_title('Probabilidades de Ai | Bi')  # Mostrar la figura print('\\nDatos que el ejercicio nos brinda y hallados:') display(df) plt.tight_layout(pad=2) plt.show()  <pre>\nDatos que el ejercicio nos brinda y hallados:\n</pre> pa pg pb p_ag p_ab p_a_b A1 0.65 0.98 0.02 0.6370 0.0130 0.4262 A2 0.35 0.95 0.05 0.3325 0.0175 0.5738 <p>Ejercicio 1. Considere una libreria que recibe libros de tres editoriales diferentes. Sea A1 el evento de que un libro proviene de la editorial 1, A2 el evento de que un libro proviene de la editorial 2 y A3 el evento de que un libro proviene de la editorial 3. En la actualidad, 50% de los libros adquiridos por la libreria son de la editorial 1, 30% son de la editorial 2 y 20% son de la editorial 3. De ah\u00ed que si un libro es seleccionado al azar, se le asignar\u00edan las probabilidades previas $P(A1)=0.5$, $P(A2)=0.3$ y $P(A3)=0.2$.</p> <p>Tabla 3.15  Titulo de la Tabla</p> Libros con graficos (porcentaje) Libros sin graficos (porcentaje) Editorial 1 99 1 Editorial 2 96 4 Editorial 3 92 8 <p>Si $G$ denota el evento de que un libro tiene graficos y $F$ denota el evento de que un libro no tiene graficos, la informaci\u00f3n de la tabla anterior proporciona los valores de probabilidad condicional siguientes.</p> <p>$$P(G|A_1)=0.99 P(F|A_1)=0.01$$ $$P(G|A_2)=0.96 P(F|A_2)=0.04$$ $$P(G|A_3)=0.92 P(F|A_3)=0.08$$</p> <p>Partiendo de que $F$ denota el evento de que el paquete se encuentra en mal estado, se buscan las probabilidades posteriores $P(A_1|F)$, $P(A_2|F)$ y $P(A_3|F)$.</p> <p>La probabilidad del resultado es: $$P(A_1 \\cap G)=P(A_1)P(G|A_1)=0.495$$ $$P(A_1 \\cap F)=P(A_1)P(F|A_1)=0.005$$ $$P(A_2 \\cap G)=P(A_2)P(G|A_2)=0.288$$ $$P(A_2 \\cap F)=P(A_2)P(F|A_2)=0.012$$ $$P(A_3 \\cap G)=P(A_3)P(G|A_3)=0.184$$ $$P(A_3 \\cap F)=P(A_3)P(F|A_3)=0.016$$ Para obtener $P(F)$ notemos que el evento $F$ puede ocurrir de dos maneras diferentes: $A_1\\cap F$ $A_2$. Por lo tanto: $$P(F)=P(A_1\\cap F)+P(A_2\\cap F)+P(A_3\\cap F)$$ $$P(F)=P(A_1)P(F|A_1)+P(A_2)P(F|A_2) +P(A_3)P(F|A_3)(\\gamma)$$</p> <p>Utilizando la formula necesaria hallaremos los valores requeridos: $$P(A_1|F)=\\frac{P(A_1)P(F|A_1)}{P(A_1)P(F|A_1)+P(A_2)P(F|A_2)+P(A_3)P(F|A_3)}=0.1515$$</p> <p>$$P(A_2|F)=\\frac{P(A_2)P(F|A_2)}{P(A_1)P(F|A_1)+P(A_2)P(F|A_2)+P(A_3)P(F|A_3)}=0.3636$$</p> <p>$$P(A_3|F)=\\frac{P(A_3)P(F|A_3)}{P(A_1)P(F|A_1)+P(A_2)P(F|A_2)+P(A_3)P(F|A_3)}=0.4848$$</p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport scipy.stats as st\nimport matplotlib.pyplot as plt\nimport pandas as pd # Importar pandas\n\ndef AiIB(pai, pai2, pai3, b, b2, b3):\n    return ((pai * b) + (pai2 * b2) + (pai3 * b3)) / ((pai * b) + (pai2 * b2) + (pai3 * b3) + (1 - pai - pai2 - pai3) * 0.1)\n\n# Datos del ejercicio\npa = np.array([0.5, 0.3, 0.2]) # Estas son las probabilidades de elegir un paquete al azar de A1, A2 y A3\npg = np.array([0.99, 0.96, 0.92]) # Estas son las probabilidades de que el libro tenga graficos de A1, A2 y A3\npb = np.array([0.01, 0.04, 0.08]) # Estas son las probabilidades de que el libro no tenga graficos de A1, A2 y A3\n\n# Definir pa3\npa3 = 1 - pa.sum()\n\n# Crear un DataFrame con los datos del ejercicio\ndf = pd.DataFrame({'pa': pa, 'pg': pg, 'pb': pb}, index=['A1', 'A2', 'A3'])\n\n# Calculamos las probabilidades de Ai \u2229 Gi usando la regla del producto\np_ag = df['pa'] * df['pg']\n\n# Calculamos las probabilidades de Ai \u2229 Bi usando la regla del producto\np_ab = df['pa'] * df['pb']\n\n# Calculamos las probabilidades de Ai | Bi usando la regla de Bayes\np_a_b = np.array([round(AiIB(pa[0], pa[1], pa[2], pb[0], pb[1], pb[2]), 4),\n                  round(AiIB(pa[1], pa[0], pa[2], pb[1], pb[0], pb[2]), 4),\n                  round(AiIB(pa[2], pa[0], pa[1], pb[2], pb[0], pb[1]), 4)])\n\n# Creamos una figura con tres subgr\u00e1ficos\nfig, ax = plt.subplots(1, 3, figsize=(12, 4))\n\n# Agregamos los datos obtenidos a nuestro DataFrame\ndf['p_ag'] = p_ag\ndf['p_ab'] = p_ab\ndf['p_a_b'] = p_a_b\n\n# Graficamos las probabilidades de Ai \u2229 Gi como un gr\u00e1fico de barras con bordes negros\nax[0].bar(['A1 \u2229 G', 'A2 \u2229 G', 'A3 \u2229 G'], p_ag, color=['#5ccb5f', '#5ccb5f', '#5ccb5f'], edgecolor='black')\nax[0].set_ylabel('Probabilidad')\nax[0].set_title('Probabilidades de Ai \u2229 Gi')\n\n# Graficamos las probabilidades de Ai \u2229 Bi como un gr\u00e1fico de barras con bordes negros\nax[1].bar(['A1 \u2229 B', 'A2 \u2229 B', 'A3 \u2229 B'], p_ab, color=['#5ccb5f', '#5ccb5f', '#5ccb5f'], edgecolor='black')\nax[1].set_ylabel('Probabilidad')\nax[1].set_title('Probabilidades de Ai \u2229 Bi')\n\n# Graficamos las probabilidades de Ai | Bi como un gr\u00e1fico de pastel\nax[2].pie(p_a_b, labels=['A1 | B', 'A2 | B', 'A3 | B'], colors=['#5ccb5f', '#98f84a', '#e1ffaf'], autopct='%1.2f%%', wedgeprops=dict(edgecolor='black'))\nax[2].set_title('Probabilidades de Ai | Bi')\n\n# Mostrar la figura\nprint('\\nDatos que el ejercicio nos brinda y hallados:')\ndisplay(df)\nprint()\nplt.tight_layout(pad=2) \nplt.show()\n</pre> import numpy as np import scipy.stats as st import matplotlib.pyplot as plt import pandas as pd # Importar pandas  def AiIB(pai, pai2, pai3, b, b2, b3):     return ((pai * b) + (pai2 * b2) + (pai3 * b3)) / ((pai * b) + (pai2 * b2) + (pai3 * b3) + (1 - pai - pai2 - pai3) * 0.1)  # Datos del ejercicio pa = np.array([0.5, 0.3, 0.2]) # Estas son las probabilidades de elegir un paquete al azar de A1, A2 y A3 pg = np.array([0.99, 0.96, 0.92]) # Estas son las probabilidades de que el libro tenga graficos de A1, A2 y A3 pb = np.array([0.01, 0.04, 0.08]) # Estas son las probabilidades de que el libro no tenga graficos de A1, A2 y A3  # Definir pa3 pa3 = 1 - pa.sum()  # Crear un DataFrame con los datos del ejercicio df = pd.DataFrame({'pa': pa, 'pg': pg, 'pb': pb}, index=['A1', 'A2', 'A3'])  # Calculamos las probabilidades de Ai \u2229 Gi usando la regla del producto p_ag = df['pa'] * df['pg']  # Calculamos las probabilidades de Ai \u2229 Bi usando la regla del producto p_ab = df['pa'] * df['pb']  # Calculamos las probabilidades de Ai | Bi usando la regla de Bayes p_a_b = np.array([round(AiIB(pa[0], pa[1], pa[2], pb[0], pb[1], pb[2]), 4),                   round(AiIB(pa[1], pa[0], pa[2], pb[1], pb[0], pb[2]), 4),                   round(AiIB(pa[2], pa[0], pa[1], pb[2], pb[0], pb[1]), 4)])  # Creamos una figura con tres subgr\u00e1ficos fig, ax = plt.subplots(1, 3, figsize=(12, 4))  # Agregamos los datos obtenidos a nuestro DataFrame df['p_ag'] = p_ag df['p_ab'] = p_ab df['p_a_b'] = p_a_b  # Graficamos las probabilidades de Ai \u2229 Gi como un gr\u00e1fico de barras con bordes negros ax[0].bar(['A1 \u2229 G', 'A2 \u2229 G', 'A3 \u2229 G'], p_ag, color=['#5ccb5f', '#5ccb5f', '#5ccb5f'], edgecolor='black') ax[0].set_ylabel('Probabilidad') ax[0].set_title('Probabilidades de Ai \u2229 Gi')  # Graficamos las probabilidades de Ai \u2229 Bi como un gr\u00e1fico de barras con bordes negros ax[1].bar(['A1 \u2229 B', 'A2 \u2229 B', 'A3 \u2229 B'], p_ab, color=['#5ccb5f', '#5ccb5f', '#5ccb5f'], edgecolor='black') ax[1].set_ylabel('Probabilidad') ax[1].set_title('Probabilidades de Ai \u2229 Bi')  # Graficamos las probabilidades de Ai | Bi como un gr\u00e1fico de pastel ax[2].pie(p_a_b, labels=['A1 | B', 'A2 | B', 'A3 | B'], colors=['#5ccb5f', '#98f84a', '#e1ffaf'], autopct='%1.2f%%', wedgeprops=dict(edgecolor='black')) ax[2].set_title('Probabilidades de Ai | Bi')  # Mostrar la figura print('\\nDatos que el ejercicio nos brinda y hallados:') display(df) print() plt.tight_layout(pad=2)  plt.show() <pre>\nDatos que el ejercicio nos brinda y hallados:\n</pre> pa pg pb p_ag p_ab p_a_b A1 0.5 0.99 0.01 0.495 0.005 1.0 A2 0.3 0.96 0.04 0.288 0.012 1.0 A3 0.2 0.92 0.08 0.184 0.016 1.0 <pre>\n</pre> <p>Resolviendo por el metodo tabular:</p> <p>Tabla 3.15  Titulo de la Tabla</p> Eventos Probabilidades Previas Probabilidades Condicionales Probabilidades Conjuntas Probabilidades Posteriores Editorial 1 0,5 0,01 0,005 0,1515 Editorial 2 0,3 0,04 0,012 0,3636 Editorial 3 0,2 0,08 0,016 0,4848 1,00 P(B)=0,033 1,0000 aprox."},{"location":"capitulo4/","title":"\u00b6","text":"CAPITULO 4  introducci\u00f3n a la probabilidad Contenido del Capitulo <p>4.1 Experimento, Reglas de conteo y asignaci\u00f3n de probabilidad</p> <ul> <li>Experimento</li> <li>T\u00e9cnicas de conteo</li> <li>Asignaci\u00f3n de probabilidad</li> </ul> <p>4.2 Eventos y sus probabilidades</p> <ul><li></li></ul> <p>4.3 Algunas relaciones b\u00e1sicas de probabilidad</p> <ul> <li>Complemento de un evento</li> <li>Ley de adici\u00f3n</li> </ul> <p>4.4 Probabilidad Condicional</p> <ul> <li>Eventos independientes</li> <li>Ley de multiplicaci\u00f3n</li> </ul> <p>4.5 Teorema de Bayes</p> <ul> <li>M\u00e9todo tabular</li> </ul>"},{"location":"capitulo4/#41-experimento-reglas-de-conteo-y-asignacion-de-probabilidad","title":"4.1 Experimento, Reglas de conteo y asignaci\u00f3n de probabilidad\u00b6","text":"<p>La probabilidad es una medida num\u00e9rica de la posibilidad de que un evento ocurra, siendo utilizada como una medida del grado de incertidumbre. Si las probabilidades est\u00e1n disponibles, se puede determinar la posibilidad de ocurrencia de cada evento. Los valores de probabilidad siempre se asignan en una escala de 0 a 1, si esta es cercana a 0 indica que es poco probable que ocurra el evento y una probabilidad cercana a 1 indica que es casi seguro que un evento se produzca y otras probabilidades entre 0 y 1 representan grados de posibilidad de que un evento ocurra.</p>"},{"location":"capitulo4/#experimento","title":"Experimento\u00b6","text":"<p>El experimento aleatorio es un proceso o evento cuyo resultado no puede predecirse con certeza, teniendo multiples resultados posibles. En cada repetici\u00f3n ocurre un uno y s\u00f3lo uno de los resultados posibles del experimento. En seguida se listan varios ejemplos de experimentos y sus resultados correspondientes.</p>"},{"location":"capitulo4/#tecnicas-de-conteo","title":"T\u00e9cnicas de conteo\u00b6","text":"<p>Las t\u00e9cnicas de conteo son estrategias matem\u00e1ticas que permiten determinar el n\u00famero total de resultados que pueden haber a partir de sus combinaciones dentro de un conjunto o conjuntos de objetos. Este tipo de t\u00e9cnicas se utilizan cuando es pr\u00e1cticamente imposible o demasiado pesado hacer de forma manual combinaciones de diferentes elementos y saber cu\u00e1ntas de ellas son posibles.</p> <p>Las principales t\u00e9cnicas de conteo son las siguientes cinco, aunque no las \u00fanicas, cada una con unas particularidades propias y utilizadas en funci\u00f3n de los requisitos para saber cu\u00e1ntas combinaciones de conjuntos de objetos son posibles.</p>"},{"location":"capitulo4/#1-principio-multiplicativo","title":"1. Principio Multiplicativo\u00b6","text":"<p>Este tipo de t\u00e9cnica de conteo permite comprender f\u00e1cilmente y de forma pr\u00e1ctica c\u00f3mo funcionan estos m\u00e9todos matem\u00e1ticos. Se da el caso que un evento llamado $A$ ocurre de varias formas y otro evento llamado $B$ ocurre de otras formas. Entonces los eventos conjuntamente pueden ocurrir de $AxB$ formas. Tambi\u00e9n se puede dar para varios eventos, no es exclusivo para dos evento, es para $N$ eventos.</p> <p>Ejemplo: En un restaurante, el men\u00fa consiste en un plato principal, un segundo y postre. De platos principales tenemos 4, de segundos hay 5 y de postres hay 3.</p> <p>Entonces, $E_1 = 4$, $E_2 = 5$ y $E_3 = 3$</p> <p>As\u00ed pues, las combinaciones que ofrece este men\u00fa ser\u00edan $4 * 5 * 3 = 60 $.</p>"},{"location":"capitulo4/#2-principio-aditivo","title":"2. Principio aditivo\u00b6","text":"<p>En este caso, en vez de multiplicarse las alternativas para cada evento, lo que sucede es que se suman las varias formas en las que pueden ocurrir.Esto quiere decir que si la primera actividad puede ocurrir de $A$ formas, la segunda de $B$ y la tercera $C$, entonces ser\u00eda $A+B+C$.</p> <p>Por ejemplo:</p> <p>Queremos comprar chocolate, habiendo tres marcas en el supermercado: $A$, $B$ y $C$.</p> <ul> <li><p>El chocolate $A$ se vende de tres sabores: negro, con leche y blanco, adem\u00e1s de haber la opci\u00f3n sin o con az\u00facar para cada uno de ellos.</p> </li> <li><p>El chocolate $B$ se vende de tres sabores, negro, con leche o blanco, con la opci\u00f3n de tener o no avellanas y con o sin az\u00facar.</p> </li> <li><p>El chocolate $C$ se vende de tres sabores, negro, con leche y blanco, con opci\u00f3n de tener o no avellanas, cacahuete, caramelo o almendras, pero todos con az\u00facar.</p> </li> </ul> <p>En base a esto, la pregunta que se pretende responder es: \u00bfcuantas variedades distintas de chocolate se pueden comprar?</p> <p>$$A = 3 * 2 = 6$$ $$B = 3 * 2 * 2 = 12$$ $$C = 3 * 5 = 15$$ $$A + B + C = 6 + 12 + 15 = 33$$</p> <p>Nota: Para saber si se debe utilizar el principio multiplicativo o el aditivo, la pista principal es si la actividad en cuesti\u00f3n tiene una serie de pasos a realizarse, como era el caso del men\u00fa, o existen varias opciones, como es el caso del chocolate.</p>"},{"location":"capitulo4/#3-permutaciones","title":"3. Permutaciones\u00b6","text":"<p>Una permutaci\u00f3n es un arreglo de varios elementos en la que es importante tener en cuenta su orden o posici\u00f3n.En la cual hay $n$ cantidad de elementos distintos y se selecciona una cantidad de ellos, que ser\u00eda $r$. Siendo su formula:</p> Formula de permutaciones                  $$P_k^n=\\frac{n!}{(n-k)!}$$              (4.1) <p>Ejemplo:</p> <p>Hay un grupo de 10 personas y un asiento en el que pueden caber 5. De cu\u00e1ntas formas se pueden sentar? Recordemos que $n=10$ y $r=5$</p>"},{"location":"capitulo4/#4-permutaciones-con-repeticion","title":"4. Permutaciones con repetici\u00f3n\u00b6","text":"<p>Cuando se quiere saber el n\u00famero de permutaciones en un conjunto de objetos, algunos de los cuales son iguales, teni\u00e9ndose en cuenta que $n$ son los elementos disponibles, algunos de ellos repetidos. Se seleccionan todos los elementos $n$ y su f\u00f3rmula es:</p> F\u00f3rmula de permutaci\u00f3n sin repetici\u00f3n                  $$P = \\frac{n!}{n_1!*n_2!*...n_k!}$$              (4.2) <p>Por ejemplo:</p> <p>En un barco se pueden izar $3$ banderas rojas, $2$ amarillas y $5$ verdes. Cu\u00e1ntas se\u00f1ales diferentes se podr\u00edan hacer izando las $10$ banderas que se tienen?</p>"},{"location":"capitulo4/#5-combinaciones","title":"5. Combinaciones\u00b6","text":"<p>Una combinaci\u00f3n es un arreglo de varios elementos en la que no importa el orden o posici\u00f3n.En la cual hay $n$ cantidad de elementos distintos y se selecciona una cantidad de ellos, que ser\u00eda $k$. Siendo su formula:</p> F\u00f3rmula de combinaciones                  $$C_k^n=\\frac{n!}{(n-k)!k!}$$              (4.3)  Ejemplo: Un grupo de 10 personas quieren hacer limpieza en el barrio y se preparan para formar grupos de 2 miembros cada uno, \u00bfcu\u00e1ntos grupos son posibles?"},{"location":"capitulo4/#asignacion-de-probabilidad","title":"Asignaci\u00f3n de probabilidad\u00b6","text":"<p>Para la asignaci\u00f3n de probabilidad se debe cumplir dos requisitos b\u00e1sicos para la asignaci\u00f3n de probabilidades.</p> <p>REQUISITOS B\u00c1SICOS PARA LA ASIGNACI\u00d3N DE PROBABILIDADES</p> <ol> <li><p>La probabilidad asignada a cada resultado experimental debe estar entre $0$ y $1$. Si $E_i$ denota el i-\u00e9simo resultado del experimento y $P(E_i)$ su probabilidad, entonces este requisito se escribe como $0 \\le P(E_i) \\le 1$ para toda $i$</p> </li> <li><p>La suma de las probabilidades para todos los resultados del experimento debe ser igual a $1$. Para $n$ resultados, este requisito se escribe como $P(E_1) + P(E_2) + . . . + P(E_n) = 1$</p> </li> </ol>"},{"location":"capitulo4/#probabilidad-clasica","title":"Probabilidad cl\u00e1sica\u00b6","text":"<p>Es una medida estad\u00edstica que indica la probabilidad de que suceda un evento siendo apropiado cuando todos los resultados del experimento son igualmente posibles. Siendo igual al n\u00famero de casos favorables de dicho evento dividido entre el n\u00famero total de casos posibles. Tambi\u00e9n se conoce como probabilidad te\u00f3rica o probabilidad a priori.</p> <p>Es un n\u00famero entre 0 y 1. Cuanto m\u00e1s probable de que ocurra un evento, mayor ser\u00e1 la probabilidad cl\u00e1sica, por contra, cuanto menos probable sea de que suceda un evento, menor ser\u00e1 el valor de la probabilidad. No hace falta hacer ning\u00fan experimento para hallar la probabilidad cl\u00e1sica de un evento, sino que se trata de un c\u00e1lculo te\u00f3rico. Con f\u00f3rmula:</p> Regla de Laplace                  $$P(A)=\\frac{n\u00famero \\space de \\space casos \\space favorables \\space al \\space evento \\space A}{n\u00famero \\space total \\space de \\space casos}$$              (4.4) <p>Conocida como regla de Laplace (o ley de Laplace), pues fue el prestigioso matem\u00e1tico franc\u00e9s quien la propuso por primera vez en 1812 en su publicaci\u00f3n de la Teor\u00eda anal\u00edtica de las probabilidades.</p> <p>Ejemplo:</p> <ul> <li><p>Se lanza una moneda, el cual da dos resultados, es decir, cara y cruz, son igualmente probables. la probabilidad de observar una cara es $\\frac12$ o $0.50$, tambi\u00e9n como $50\\%$ de probabilidad de que sea cara.</p> </li> <li><p>Se arroja un dado. como es posible que cualquiera de los $6$ resultados es posible, a cada resultado se le asigna una probabilidad de $\\frac16$. Si $P(1)$ denota la probabilidad de que un punto aparezca en la cara superior del dado, entonces $P(1) = 1/6$ y de misma manera hasta P(6). Observe que estas probabilidades satisfacen los dos requisitos b\u00e1sicos de las ecuaciones, ya que cada una es mayor o igual que cero y suman 1.</p> </li> </ul>"},{"location":"capitulo4/#probabilidad-frecuencial","title":"Probabilidad frecuencial\u00b6","text":"<p>Siendo esta apropiada cuando los datos est\u00e1n disponibles para estimar la proporci\u00f3n del tiempo en que ocurrir\u00e1 el resultado si el experimento se repite un gran n\u00famero de veces. En esta probabilidad se primero se hace un experimento y a partir de los resultados se calcula la probabilidad de ocurrencia.</p> <p>Ejemplo: Un estudio de los tiempos de espera en el departamento de rayos x para un hospital local. Un empleado registr\u00f3 el n\u00famero de pacientes que esperan el servicio a las 9:00 a.m. durante 20 d\u00edas sucesivos y obtuvo los resultados siguientes.</p> N\u00famero de pacientes que esperan N\u00famero de d\u00edas que el resultado ocurri\u00f3 0 2 1 5 2 6 3 4 4 3 Total 20 <p>Seg\u00fan los estudios se puede ver que:</p> <ul> <li>En 2 de los 20 d\u00edas, 0 pacientes esperaban por el servicio ($\\frac 2{20}$)</li> <li>En 5 de los 20 d\u00edas, 1 paciente esperaba por el servicio ($\\frac 5{20}$)</li> <li>En 6 de los 20 d\u00edas, 2 paciente esperaba por el servicio ($\\frac 6{20}$) Y as\u00ed sucesivamente se ir\u00e1 asignando.</li> </ul>"},{"location":"capitulo4/#42-eventos-y-sus-probabilidades","title":"4.2 Eventos y sus probabilidades\u00b6NOTAS Y COMENTARIOS","text":"<p>En la introducci\u00f3n de este cap\u00edtulo se us\u00f3 el t\u00e9rmino evento de manera muy parecida a como se utiliza en el lenguaje cotidiano. Luego, en la secci\u00f3n 4.1 se present\u00f3 el concepto de experimento y los resultados del experimento o puntos de la muestra correspondientes. Los puntos de la muestra y los eventos proporcionan la base del estudio de la probabilidad. Por consiguiente, ahora un evento. se define de manera formal en relaci\u00f3n con los puntos de la muestra. Esta definici\u00f3n es la base para determinar la probabilidad de un evento.</p> Evento                  Un evento es una colecci\u00f3n de puntos de la muestra.              <p>Como ejemplo, retome el proyecto de KP&amp;L y suponga que el gerente est\u00e1 interesado en el evento de que el proyecto completo se termine en 10 meses o menos. Al observar la tabla 4.3 se ve que seis puntos de la muestra \u2014(2, 6), (2, 7), (2, 8), (3, 6), (3, 7) y (4, 6) \u2014 proporcionan una duraci\u00f3n de 10 meses o menos. C denota el evento de que el proyecto dure 10 meses o menos; escribimos</p> <p>$$ \\begin{align*} C = \\{(2,2), (2,7), (2,8), (3,3), (3,7), (4,6)\\} \\end{align*} $$</p> <p>Se dice que el evento C ocurre si cualquiera de estos seis puntos de la muestra aparece como el resultado experimental.</p> <p>Con ayuda de la informaci\u00f3n de la tabla 4.3, vemos que estos eventos constan de los puntos de la muestra siguientes: $$ \\begin{align*} L = \\{(2, 6), (2, 7), (3, 6)\\} \\end{align*} $$ $$ \\begin{align*} M = \\{(3, 8), (4, 7), (4, 8)\\} \\end{align*} $$ Una variedad de eventos adicionales puede definirse para el proyecto de KP&amp;L, pero en cada caso el evento debe identificarse como una colecci\u00f3n de puntos de la muestra para el experimento.</p> <p>Dadas las probabilidades de los puntos de la muestra mostrados en la tabla 4.3, podemos utilizar la definici\u00f3n siguiente para calcular la probabilidad de cualquier evento que la gerencia de KP&amp;L podr\u00eda desear considerar.</p> PROBABILIDAD DE UN EVENTO <p>                     La probabilidad de cualquier evento es igual a la suma de las probabilidades de los puntos de la muestra del evento.                 <p></p> </p> <p>$$ \\begin{align*} P(C)= \\ P(2, 6) + P(2, 7) + P(2, 8) + P(3, 6) + P(3, 7) + P(4, 6)\\ \\end{align*} $$ Revisando las probabilidades de los puntos de la muestra de la tabla 4.3 tenemos $$ \\begin{align*} P(C) = \\ 0.15 + 0.15 + 0.05 + 0.10 + 0.20 + 0.05 = 0.70\\ \\end{align*} $$ De modo parecido, debido a que el evento de que el proyecto se complete en menos de 10 meses est\u00e1 dado por L = {(2, 6), (2, 7), (3, 6)}, la probabilidad de este evento est\u00e1 determinada por $$ \\begin{align*} P(L) =  P(2, 6) + P(2, 7) + P(3, 6)  \\end{align*} $$ $$ \\begin{align*}      = 0.15 + 0.15 + 0.10  0.40  \\end{align*} $$ Por \u00faltimo, para el evento de que el proyecto se termine en m\u00e1s de 10 meses, tenemos M = {(3, 8), (4, 7), (4, 8)}, y por tanto $$ \\begin{align*} P(M) = P(3, 8) + P(4, 7) + P(4, 8)  \\end{align*} $$ $$ \\begin{align*}      = 0.05 + 0.10 + 0.15 = 0.30   \\end{align*} $$</p> <p>Al utilizar estos resultados de la probabilidad, ahora es posible decir a la gerencia de KP&amp;L que hay una probabilidad de 0.70 de que el proyecto se complete en 10 meses o menos, una probabilidad de 0.40 de que se complete en menos de 10 meses y una probabilidad de 0.30 de que concluya en m\u00e1s de 10 meses. Este procedimiento de c\u00e1lculo de las probabilidades del evento puede repetirse para cualquier evento de inter\u00e9s para la gerencia de KP&amp;L. </p> <p>En cualquier momento se pueden identificar todos los puntos de la muestra de un experimento y asignar probabilidades a cada uno, y podemos calcular la probabilidad de un evento utilizando la definici\u00f3n. No obstante, en muchos experimentos un n\u00famero grande de puntos de la muestra hace muy engorrosa, si no es que imposible, la identificaci\u00f3n de estos puntos, as\u00ed como la determinaci\u00f3n de sus probabilidades asociadas. En las secciones restantes de este cap\u00edtulo se presentan algunas relaciones de probabilidad b\u00e1sicas que se usan para calcular la probabilidad de un evento sin conocimiento de todas las probabilidades de los puntos de la muestra</p>  1. El espacio muestral, S, es un evento. Debido a que contiene todos los resultados del experimento, tiene una probabilidad de 1; es decir, P(S)=1.    2. Cuando se utiliza el m\u00e9todo cl\u00e1sico para asignar probabilidades, el supuesto es que los resultados   del experimento son igualmente probables. En estos casos, la probabilidad de un evento se calcula contando el n\u00famero de resultados del experimento en el evento y dividiendo el resultado entre el n\u00famero total de resultados del experimento.  Ejercicios M\u00e9todos <ol> <li>Un experimento tiene cuatro resultados igualmente probables: $E_{1}, E_{2}, E_{3}, E_{4}$</li> </ol> <p>a) \u00bfCu\u00e1l es la probabilidad de que $E_2O$ ocurra? b) \u00bfCu\u00e1l es la probabilidad de que cualesquiera de los dos resultados ocurran (por ejemplo, $E_1$ o $E_3$)? c) \u00bfCu\u00e1l es la probabilidad de que cualesquiera de los tres resultados ocurran (por ejemplo, $E_1$ o $E_2$ o $E_4$)?</p>"},{"location":"capitulo4/#43-algunas-relaciones-basicas-de-probabilidad","title":"4.3 Algunas relaciones b\u00e1sicas de probabilidad\u00b6","text":""},{"location":"capitulo4/#complemento-de-un-evento","title":"Complemento de un evento\u00b6","text":"<p>Dado un evento  A, el  complemento de  A  se define como el evento que consta de todos los puntos de la muestra que  no  est\u00e1n en  A. El complemento de  A  se denota por medio de  Ac. La figura 4.4 es un diagrama, conocido como diagrama de Venn, el cual ilustra el concepto de complemento. El \u00e1rea rectangular representa el espacio muestral para el experimento y como tal contiene todos los puntos de la muestra posibles. El c\u00edrculo representa el evento  A  y contiene s\u00f3lo los puntos de la muestra que pertenecen a  A. La regi\u00f3n sombreada del rect\u00e1ngulo contiene todos los puntos de la muestra que no est\u00e1n en el evento  A  y es por definici\u00f3n el complemento de  A. En cualquier probabilidad de aplicaci\u00f3n debe ocurrir cualquier evento  A  o su complemento $A^c$. Por consiguiente, tenemos $$     P(A) = P(A ^ c) = 1 $$</p>"},{"location":"capitulo4/#ley-de-la-adicion","title":"Ley de la adici\u00f3n\u00b6","text":"<p>La ley de la adici\u00f3n es \u00fatil cuando interesa conocer la probabilidad de que ocurra por lo menos uno de dos eventos. Es decir, con los eventos A y B nos interesa conocer la probabilidad de que ocurra el evento $A$ o el evento $B$, o ambos. Antes de presentar la ley de la adici\u00f3n, debemos estudiar dos conceptos relacionados con la combinaci\u00f3n de eventos: la uni\u00f3n de eventos y la intersecci\u00f3n de eventos. Dados dos eventos $A$ y $B$, la uni\u00f3n de $A$ y $B$ se define como sigue.</p> Uni\u00f3n de dos Eventos  La uni\u00f3n de $A$ y $B$ es el evento que contiene todos los puntos de la muestra que pertenecen a $A$ o $B$ o ambos. La uni\u00f3n se denota mediante $A \u222a B$.          <p>Figura 4.1 Uni\u00f3n de los eventos A y B</p>"},{"location":"capitulo4/#ejemplo-1-ley-de-la-adicion","title":"Ejemplo 1: Ley de la Adici\u00f3n\u00b6","text":"<p>Considere el caso de una peque\u00f1a planta de ensamble con 50 empleados. Se espera que cada trabajador complete las asignaciones de trabajo a tiempo y de tal manera que el producto ensamblado apruebe la inspecci\u00f3n final. De vez en cuando, algunos trabajadores no cumplen con los est\u00e1ndares de desempe\u00f1o, ya que terminan la tarea con atraso o ensamblan un producto defectuoso. Al final del periodo de evaluaci\u00f3n del desempe\u00f1o, el gerente de producci\u00f3n encontr\u00f3 que 5 de los 50 trabajadores terminaron el trabajo con atraso, 6 de los 50 ensamblaron un producto defectuoso y 2 de los 50 terminaron con atraso y ensamblaron un producto defectuoso.</p> <p>Sean:</p>      $L$ = evento de que el trabajo se termine con atraso       $D$ = evento de que el producto ensamblado est\u00e9 defectuoso  <p></p> La informaci\u00f3n de la frecuencia relativa conduce a las probabilidades siguientes. $$P(L) = \\frac{5}{50} =0.10$$ $$P(D) = \\frac{6}{50} = 0.12$$ $$P(L \u2229 D) =\\frac{2}{50} = 0.04$$ Al finalizar de revisar los datos de desempe\u00f1o, el gerente de producci\u00f3n decidi\u00f3 asignar una calificaci\u00f3n baja a cualquier empleado cuyo trabajo estuviera atrasado o defectuoso, por lo que el evento de inter\u00e9s es $L \u222a D$. \u00bfCu\u00e1l es la probabilidad de que el gerente asigne una calificaci\u00f3n de bajo desempe\u00f1o a un empleado? Note que la pregunta de probabilidad trata de la uni\u00f3n de dos eventos. En concreto, se desea conocer $P(L \u222a D)$. $$P(L \u222a D) = P(L) + P(D) - P(L \u2229 D)$$ Como conocemos los valores de las tres probabilidades en el lado derecho de esta expresi\u00f3n, se puede escribir: $$P(L \u222a D) = 0.10 + 0.12 - 0.04 = 0.18$$ Asi se indica que hay una probabilidad de $0.18$ de que un empleado seleccionado al azar reciba una calificaci\u00f3n de bajo desempe\u00f1o."},{"location":"capitulo4/#ejemplo-2-ley-de-la-adicion","title":"Ejemplo 2: Ley de la Adici\u00f3n\u00b6","text":"<p>Considere un estudio reciente realizado por el jefe de personal de una importante firma desistemase. El estudio revel\u00f3 que 30% de los empleados que dejaron la empresa en un plazo de dos a\u00f1os lo hiz  principalmente porque se sent\u00ed insatisfecho con su sueldo, 20% se fue porque no estaba satisfecho c n el trabajo que se  e asign\u00f3 y 12% indic\u00f3 insatisfacci\u00f3n tanto con su sueldo como con el trab jo asignado. \u00bfC \u00e1l es la probabilidad de que un empleado que deja la empresa en un plazo de dos a\u00f1os lo  debido a su insatisfacci\u00f3n con el sueldo, a su insatisfacci\u00f3n con el trabajo asignado o a ambas cosas?<p>Sean:</p></p>      $X$ =  evento de que el empleado deje la empresa debido al sueldo       $Y$ =  evento de que el empleado deje la empresa debido al trabajo asignado  Se tiene $P(X)= 0.30 $; $ P(Y)=0.20$, y $ P(X \u2229 Y)=0.12 $ $$P(X \u222a Y) = P(X) + P(Y) - P(X \u2229 Y) = 0.30 + 0.20 - 0.12 = 0 .38$$ Se obtuvo una probabilidad de 0.38 de que un empleado abandone la empresa por las razones del sueldo o el trabajo asignado.   Eventos mutuamente Excluyentes             Se dice que dos eventos son mutuamente excluyentes si no tienen puntos de la muestra en com\u00fan           Los eventos $A$ y $B$ son mutuamente excluyentes si, cuando ocurre un evento, el otro no puede ocurrir. Por tanto, un requisito para que $A$ y $B$ sean mutuamente excluyentes consiste en que su intersecci\u00f3n no debe contener puntos de la muestra. El diagrama de Venn que representa dos eventos mutuamente excluyentes $A$ y $B$. En este caso $P(A \u2229 B) = 0$, y la ley de la adici\u00f3n puede escribirse de la siguiente forma.   Ley de la adici\u00f3n para eventos mutuamente excluyentes                  $$P(A \u222a B) = P(A) + P(B)$$              <p>Figura 4.3 Eventos mutuamente excluyentes</p>"},{"location":"capitulo4/#aplicaciones","title":"Aplicaciones\u00b6","text":"<p>Ejercicio 1.  La Oficina del Censo de Bolivia proporciona datos sobre el n\u00famero de adultos j\u00f3venes, entre 18 y 24 a\u00f1os, que viven en la casa de sus padres. Sean:</p>  $M=$ el evento de que un hombre adulto joven viva en casa de sus padres   $F=$ el evento de que una mujer adulta joven viva en casa de sus padres  Si se seleccionan al azar un hombre adulto joven y una mujer adulta joven, los datos de la Oficina del Censo permiten concluir $P(M)= 0.56$ y $P(F) = 0.42$. La probabilidad de que ambos est\u00e9n viviendo en la casa de sus padres es 0.24. <p> a) \u00bfCu\u00e1l es la probabilidad de que por lo menos uno de los dos adultos j\u00f3venes seleccionados viva en casa de sus padres? </p> <p> b) \u00bfCu\u00e1l es la probabilidad de que ambos adultos j\u00f3venes vivan solos (ninguno vive en casa de sus padres)? </p> <p>Solucion inciso a) </p>"},{"location":"capitulo4/#44-probabilidad-condicional","title":"4.4 Probabilidad Condicional\u00b6","text":"<p>Se conoce como probabilidad condicional, a la probabilidad de un evento que es influenciado por el acontecimiento de otro evento relacionado. Dado un evento $A$ con su probabilidad independiente $P(A)$, un evento $B$ efectuado y relacionado a $A$. Podemos denotar a la nueva probabilidad o probabilidad condicional como $P(A|B)$. La denotaci\u00f3n indica que se esta considetando la probabilidad del evento $A$ dada la condicion de que $B$ ha ocurrido. Que puede ser leido como: \"la probailidad A dado B\".</p> <p>La probabilidad conjunta se define como la probabilidad de la intersecci\u00f3n de dos eventos, es decir, la probabilidad de que dos eventos ocurran a la par.</p> La Probabilidad de un evento $A$ en conjunto al evento $B$                  $$ P(A\\cap B) \\space o \\space P(B\\cap A)$$              (0.0) <p>La probabilidad marginal se rerfiere a las probabilidades de un evento independiente de otros eventos con los que tengan relaci\u00f3n. Adem\u00e1s de que la suma de todas la probablidades conjuntas respecto a un evnto dado nos da como resultado la probabilidad marginal del evento dado.</p> <p>Ejercicio 1. Para entender mejor los distintos conceptos de probabilidad, podemos plantearnos la siguiente situaci\u00f3n:</p> <p>Imaginemos que en la facultad de Ciencias Puras Y Naturales de la UMSA, se tenga un registro sobre los nuevos estudiantes registrados en las diferentes carreras de la facultad. La carrera de Inform\u00e1tica es una carrera que cuenta con una cantidad considerable de estudiantes nuevos por a\u00f1o, a comparaci\u00f3n de otras carreras de la facultad. En el a\u00f1o x se registro que ingresaron 4120 nuevos estudiantes en la carrera de inform\u00e1tica, donde 3100 estudiantes eran varones y 1020 mujeres. Pero en las otras carreras se registraron 3580 nuevos estudiantes donde 1880 estudiantes eran varones y 1700 eran mujeres.</p> <p>Consideremos los eventos: $ I =$ El evento en el que el estudiante estudiar\u00e1 la carrea de Inform\u00e1tica</p> <p>$ I^C = $El evento en el que el estudiante no estudiar\u00e1 la carrea de Inform\u00e1tica</p> <p>$ V =$ El evento en el que el estudiante es var\u00f3n</p> <p>$M =$ El evento en el que el estudiante es mujer</p> <p>Tabla 4.5  Tabla de Probabilidad Conjunta sobre estudiantes nuevos</p> Eventos Var\u00f3n (V) Mujer (M) Total Estudiar\u00e1n Inform\u00e1tica $(I)$ 3100 1020 4120 No Estudiar\u00e1n Inform\u00e1tica $(I^C)$ 1880 1700 3580 Total 4980 2720 7700 <p>Donde con ayuda de la tabla 4.5 obtenemos las diferentes probabildades conjuntas sobre un estudiante nuevo:</p> <p>$P(V \\cap I) = \\frac{3100}{7700} = 0,40 $ , probabilidad de que el estudiante sea var\u00f3n y estudie inform\u00e1tica</p> <p>$P(V \\cap I^C) = \\frac{1880}{7700} = 0,25 $ , probabilidad de que el estudiante sea var\u00f3n y no estudie inform\u00e1tica</p> <p>$P(M \\cap I) = \\frac{1020}{7700} = 0,13 $ , probabilidad de que el estudiante sea mujer y estudie inform\u00e1tica</p> <p>$P(M \\cap I^C) = \\frac{1700}{7700} = 0,22 $ , probabilidad de que el estudiante sea mujer y  no estudie inform\u00e1tica</p>"},{"location":"capitulo4/#eventos-independientes","title":"Eventos independientes\u00b6","text":"<p>Al momento de calcular la probabilidad condicional de un evento $A$ dado $B$, hay casos donde la probabilidad marginal de $A$ o $P(A)$ se ve alterada o influenciada por el suceso del evento $B$, por lo que $P(A)\\neq P(A\\cap B)$, en este caso podemos decir que los eventos $A$ y $B$ son eventos dependientes. Pero en caso de la probabilidad de $A$ no se vea influenciado por $B$, podemos decir que los eventos $A$ y $B$ son eventos independientes.</p>"},{"location":"capitulo4/#ley-de-la-multiplicacion","title":"Ley de la multiplicaci\u00f3n\u00b6","text":"<p>Es utilizada para calcular la probabilidad de la intersecci\u00f3n de dos eventos. Esta ley se apoya con el concepto de la probabilidad condicional.</p> LEY DE LA MULTPLICACI\u00d3N                  $$ P(A\\cap B)=P(B)\\cdot P(A|B) $$              (4.11) o                  $$ P(A\\cap B)=P(A)\\cdot P(B|A) $$              (4.12)"},{"location":"capitulo4/#45-teorema-de-bayes","title":"4.5 Teorema de bayes\u00b6","text":""},{"location":"capitulo4/#definicion","title":"Definici\u00f3n\u00b6","text":"<p>El teorema de Bayes es una f\u00f3rmula matem\u00e1tica que describe c\u00f3mo se actualizan las probabilidades de una hip\u00f3tesis en funci\u00f3n de nueva evidencia.</p> <p>En t\u00e9rminos simples, el teorema de Bayes establece c\u00f3mo se deben ajustar las probabilidades de eventos o hip\u00f3tesis a la luz de una nueva . La forma general del teorema de Bayes se expresa como:</p> F\u00f3rmula general del teorema de Bayes                  $$P(A|B) = \\frac{P(B|A)*P(A)}{P(B)}$$              (0.0)      Donde:         1. $P(A|B)$ es la probabilidad de la hip\u00f3tesis A dado que ha ocurrido el evento B.         2. $P(B|A)$ es la probabilidad del evento B dado que la hip\u00f3tesis A es verdadera.         3. $P(A)$ es la probabilidad a priori de la hip\u00f3tesis A, es decir, la probabilidad de A antes de tener en cuenta la evidencia B.     4. $P(B)$ es la probabilidad marginal del evento B, es decir, la probabilidad de que ocurra B.  El teorema de Bayes se aplica en una amplia variedad de campos, desde la inteligencia artificial y la estad\u00edstica hasta la toma de decisiones y la medicina."},{"location":"capitulo4/#metodo-tabular","title":"M\u00e9todo Tabular\u00b6","text":"<p>Este metodo es util para realizar calculos del teorema de Bayes. Para realizar la utilizacion de este metodo, debemos seguir una serie de pasos:</p> <ol> <li>Crear 3 columnas, la primera para los eventos, la segunda para las probabilidades previas, la tercera para las probabilidades condicionales.</li> <li>en la cuarta columna colocamos las probabilidades conjuntas y mostrar P(B)</li> <li>Sumamos los valores de la columna 4, cada una debe estar dividida entre P(B)</li> </ol> <p>Utilizando este metodo en el ejercicio anterior obtenemos:</p> <p>Tabla 4.7  M\u00e9todo tabular de los c\u00e1lculos del teorema de Bayes para el problema de los dos proveedores</p> Eventos Probabilidades previas Probabilidades condicionales Probabilidades Conjuntas Probabilidades Posteriores Distribuidora 1 0.65 0.02 0.0130 0.4262 Distribuidora 2 0.35 0.05 0.0175 0.5738 1.00 P(B)=0.0305 1.000"},{"location":"capitulo5/","title":"Capitulo 5","text":"En el cap\u00edtulo 4 se define el concepto de experimento y los resultados experimentales correspondientes. Una variable aleatoria proporciona un medio para describir estos resultados con valores num\u00e9ricos. Las variables aleatorias deben asumir valores num\u00e9ricos. VARIABLE ALEATORIA                  Una variable aleatoria es una descripci\u00f3n num\u00e9rica de los resultados de un experimento.              En efecto, una variable aleatoria asocia un valor num\u00e9rico con cada resultado experimental posible. El valor num\u00e9rico particular de la variable aleatoria depende del resultado del experimento. \u00c9sta se clasifica como discreta o continua en funci\u00f3n de los valores num\u00e9ricos que asume. <p>Variables aleatorias discretas</p> <p>Una variable aleatoria que puede asumir cualquier n\u00famero fi nito de valores o una sucesi\u00f3n infi nita de valores como 0, 1, 2, . . . se conoce como variable aleatoria discreta. Por ejemplo, considere el experimento de un sujeto que presenta el examen de certifi caci\u00f3n de contador p\u00fablico, el cual consta de cuatro partes. Una variable aleatoria se defi ne como x = el n\u00famero de partes del examen aprobadas. Se trata de una variable aleatoria discreta, ya que puede asumir un n\u00famero fi nito de valores 0, 1, 2, 3 o 4. En otro ejemplo, considere el experimento de los autom\u00f3viles que llegan a una caseta de cobro. La variable aleatoria de inter\u00e9s es x = el n\u00famero de veh\u00edculos que llegan durante un periodo de un d\u00eda. Los valores posibles para x provienen de la secuencia de n\u00fameros enteros 0, 1, 2, etc. Por consiguiente, x es una variable aleatoria discreta que asume uno de los valores de esta secuencia infi nita. Aunque los resultados de muchos experimentos se describen de manera natural por medio de valores num\u00e9ricos, otros no pueden describirse as\u00ed. Por ejemplo, en una encuesta se podr\u00eda preguntar a una persona si recuerda el mensaje de un comercial de televisi\u00f3n reciente. Este experimento tendr\u00eda dos resultados posibles: la persona no recuerda el mensaje y la persona recuerda el mensaje. Tambi\u00e9n es posible describir num\u00e9ricamente estos resultados experimentales mediante la defi nici\u00f3n de la variable aleatoria discreta x como sigue: sea x = 0 si la persona no recuerda el mensaje y x = 1 si la persona recuerda el mensaje. Los valores num\u00e9ricos de esta variable son arbitrarios (se podr\u00eda usar 5 y 10), pero son aceptables con base en la defi nici\u00f3n de una variable, es decir, x es una variable aleatoria, ya que proporciona una descripci\u00f3n num\u00e9rica de los resultados del experimento. La tabla 5.1 muestra algunos ejemplos de variables aleatorias discretas. Tenga en cuenta que en cada ejemplo la variable asume un n\u00famero fi nito de valores o una secuencia infi nita de valores como 0, 1, 2, . . . Estos tipos de variables se estudian con detalle en este cap\u00edtulo.</p> <p>TABLA 5.1  Ejemplos de variables aleatorias discretas</p> Experimento Variable aleatoria (x) Valores posibles de la variable aleatoria Llamar a cinco clientes N\u00famero de clientes que hacen un pedido 0, 1, 2, 3, 4, 5 Inspeccionar un embarque de 50 radios N\u00famero de radios defectuosos 0, 1, 2, . . . , 49, 50 Encargarse de un restaurante por un d\u00eda N\u00famero de clientes 0, 1, 2, 3, . . . Vender un autom\u00f3vil G\u00e9nero del cliente 0 si es hombre, 1 si es mujer <p>Variables aleatorias continuas</p> <p>Una variable aleatoria que asume cualquier valor num\u00e9rico en un intervalo o conjunto de intervalos se llama variable aleatoria continua. Los resultados experimentales basados en escalas de medici\u00f3n como el tiempo, el peso, la distancia y la temperatura se describen por medio de este tipo de variable. Por ejemplo, considere un experimento en el que se monitorean las llamadas telef\u00f3nicas que llegan a la ofi cina de reclamaciones de una compa\u00f1\u00eda de seguros importante. Suponga que la variable aleatoria de inter\u00e9s es x = tiempo entre las llamadas entrantes consecutivas en minutos. Esta variable puede asumir cualquier valor en el intervalo x \u2265 0. En realidad, x puede asumir un n\u00famero infi nito de valores, incluidos algunos como 1.26 minutos, 2.751 minutos, 4.3333 minutos, etc. Otro ejemplo es un tramo de 90 millas de la carretera interestatal I-75 al norte de Atlanta, Georgia. Para un servicio de ambulancias de emergencia ubicado en Atlanta, la variable aleatoria podr\u00eda defi nirse como x = n\u00famero de millas al lugar del siguiente accidente de tr\u00e1nsito a lo largo del tramo de la carretera I-75. En este caso, x ser\u00eda una variable aleatoria continua que asume cualquier valor en el intervalo 0 \u2264 x \u2264 90. La tabla 5.2 presenta otros ejemplos de variables aleatorias continuas. Observe que cada ejemplo describe una variable que asume cualquier valor en un intervalo de valores. Las variables aleatorias continuas y sus distribuciones de probabilidad ser\u00e1n el tema del cap\u00edtulo 6.</p> <p>TABLA 5.2  Ejemplos de variables aleatorias continuas</p> Experimento Variable aleatoria (x) Valores posibles de la variable aleatoria Operar un banco Tiempo entre las llegadas de los clientes, en minutos x \u2265 0 Llenar una lata de refresco (m\u00e1x. = 12.1 onzas) Cantidad de onzas 0 \u2264 x \u2264 12.1 Construir una biblioteca Porcentaje del proyecto completado despu\u00e9s de seis meses 0 \u2264 x \u2264 100 Probar un proceso qu\u00edmico nuevo Temperatura a la que ocurre la reacci\u00f3n (m\u00edn. 150 \u00b0F; m\u00e1x. 212 \u00b0F) 150 \u2264 x \u2264 212 CONDICIONES REQUERIDAS PARA UNA FUNCI\u00d3N DE PROBABILIDAD DISCRETA                  f(x) \u2265 0              (5.1)                   \u2211 f(x)= 1              (5.2)  La tabla 5.3 muestra que las probabilidades de la variable aleatoria x satisfacen la ecuaci\u00f3n (5.1); f(x) es mayor o igual que 0 para todos los valores de x. Adem\u00e1s, como estas probabilidades suman 1, la ecuaci\u00f3n (5.2) tambi\u00e9n se satisface. Por tanto, la funci\u00f3n de probabilidad de DiCarlo Motors es una funci\u00f3n de probabilidad discreta v\u00e1lida. Tambi\u00e9n se presentan las distribuciones de probabilidad de manera gr\u00e1fi ca. En la figura 5.1 los valores de la variable aleatoria x para DiCarlo Motors aparecen en el eje horizontal y la probabilidad asociada con estos valores se muestra en el eje vertical. Adem\u00e1s de tablas y gr\u00e1fi cas para describir las distribuciones de probabilidad, con frecuencia se utiliza una f\u00f3rmula que proporciona la funci\u00f3n de probabilidad, f(x), para cada valor de  <p>TABLA 5.3 Distribuci\u00f3n de probabilidad para el n\u00famero de autom\u00f3viles vendidos durante un d\u00eda en Dicarlo Motors</p> x f(x) 0 0.18 1 0.39 2 0.24 3 0.14 4 0.04 5 0.01 Total  1.00 <p>FIGURA 5.1 Representaci\u00f3n gr\u00e1fica de la distribuci\u00f3n de probabilidad para el n\u00famero de autom\u00f3viles vendidos durante un d\u00eda en Dicarlo Motors</p> In\u00a0[73]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Datos de ejemplo\ncategorias = ['0', '1', '2', '3', '4', '5']\nvalores = [0.18, 0.39, 0.24, 0.14, 0.04, 0.01]\n\n# Define color de las barras\ncolor_hex = '#009929'\n\n# Crear el gr\u00e1fico de barras con espacio reducido entre categor\u00edas\nfig, ax = plt.subplots()\nbars = ax.bar(categorias, valores, color=color_hex, width=0.05)\n\n# Ajustar el espacio entre las categor\u00edas y quitar las l\u00edneas de arriba y a la derecha\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.xaxis.set_tick_params(width=0)  # Ocultar las l\u00edneas del eje x\nax.yaxis.set_tick_params(width=0)  # Ocultar las l\u00edneas del eje y\n\n# Ajustar el color de fondo dentro de la gr\u00e1fica a verde claro\nax.set_facecolor('#d4f8b7')  # C\u00f3digo hexadecimal para verde claro\n\n# Ajustar el color de fondo de la figura a verde\nfig.set_facecolor('#d4f8b7')  # C\u00f3digo hexadecimal para verde\n\n# A\u00f1adir l\u00edneas superior e inferior\nlinea_superior = plt.Line2D((0, 1), (1, 1), color='green', linewidth=5, transform=fig.transFigure)\nlinea_inferior = plt.Line2D((0, 1), (0, 0), color='green', linewidth=5, transform=fig.transFigure)\nfig.lines.extend([linea_superior, linea_inferior])\n\n# Ajustar el espacio entre las categor\u00edas y quitar las l\u00edneas de arriba y a la derecha\nubicaciones_y = [0.00, 0.10, 0.20, 0.30, 0.40, 0.50]\netiquetas_y = ['0.00', '0.10', '0.20', '0.30', '0.40', \"f(X)\"]\n\nax.set_yticks(ubicaciones_y)\nax.set_yticklabels(etiquetas_y)\n\n# Agregar etiquetas y t\u00edtulo\nplt.xlabel('N\u00famero de automoviles vendidos en un dia')\nplt.ylabel('Probabilidad')\n# plt.title('Gr\u00e1fico de Barras sin L\u00edneas en la Parte Superior y Derecha')\n\n# Mostrar el gr\u00e1fico\nplt.tight_layout()  # Ajustar el dise\u00f1o para evitar cortar las etiquetas\nplt.show()\n</pre> import matplotlib.pyplot as plt  # Datos de ejemplo categorias = ['0', '1', '2', '3', '4', '5'] valores = [0.18, 0.39, 0.24, 0.14, 0.04, 0.01]  # Define color de las barras color_hex = '#009929'  # Crear el gr\u00e1fico de barras con espacio reducido entre categor\u00edas fig, ax = plt.subplots() bars = ax.bar(categorias, valores, color=color_hex, width=0.05)  # Ajustar el espacio entre las categor\u00edas y quitar las l\u00edneas de arriba y a la derecha ax.spines['top'].set_visible(False) ax.spines['right'].set_visible(False) ax.xaxis.set_tick_params(width=0)  # Ocultar las l\u00edneas del eje x ax.yaxis.set_tick_params(width=0)  # Ocultar las l\u00edneas del eje y  # Ajustar el color de fondo dentro de la gr\u00e1fica a verde claro ax.set_facecolor('#d4f8b7')  # C\u00f3digo hexadecimal para verde claro  # Ajustar el color de fondo de la figura a verde fig.set_facecolor('#d4f8b7')  # C\u00f3digo hexadecimal para verde  # A\u00f1adir l\u00edneas superior e inferior linea_superior = plt.Line2D((0, 1), (1, 1), color='green', linewidth=5, transform=fig.transFigure) linea_inferior = plt.Line2D((0, 1), (0, 0), color='green', linewidth=5, transform=fig.transFigure) fig.lines.extend([linea_superior, linea_inferior])  # Ajustar el espacio entre las categor\u00edas y quitar las l\u00edneas de arriba y a la derecha ubicaciones_y = [0.00, 0.10, 0.20, 0.30, 0.40, 0.50] etiquetas_y = ['0.00', '0.10', '0.20', '0.30', '0.40', \"f(X)\"]  ax.set_yticks(ubicaciones_y) ax.set_yticklabels(etiquetas_y)  # Agregar etiquetas y t\u00edtulo plt.xlabel('N\u00famero de automoviles vendidos en un dia') plt.ylabel('Probabilidad') # plt.title('Gr\u00e1fico de Barras sin L\u00edneas en la Parte Superior y Derecha')  # Mostrar el gr\u00e1fico plt.tight_layout()  # Ajustar el dise\u00f1o para evitar cortar las etiquetas plt.show()  x. El ejemplo m\u00e1s sencillo de una distribuci\u00f3n de probabilidad discreta dada una f\u00f3rmula, es la distribuci\u00f3n de probabilidad uniforme discreta. Su funci\u00f3n de probabilidad se defi ne por medio de la ecuaci\u00f3n (5.3). FUNCI\u00d3N DE PROBABILIDAD UNIFORME DISCRETA                  f(x) = 1/n              (5.3)          donde:  <p>$$\\scriptsize n = \\text{n\u00famero de valores que la variable aleatoria puede asumir.}$$</p>  Por ejemplo, suponga que para el experimento de lanzar un dado la variable aleatoria x se defi ne como el n\u00famero de puntos en la cara que queda hacia arriba. Para este experimento, n = 6 valores son posibles para la variable aleatoria; x = 1, 2, 3, 4, 5, 6. Por tanto, la funci\u00f3n de probabilidad para esta variable aleatoria uniforme discreta es  <p>$$ f (x) = 1/6\\quad x = 1, 2, 3, 4, 5, 6 $$</p> <p>Los valores posibles de la variable aleatoria y las probabilidades asociadas se muestran en seguida.</p> x f(x) 1 1/6 2 1/6 3 1/6 4 1/6 5 1/6 6 1/6  Como otro ejemplo, considere la variable aleatoria x con la distribuci\u00f3n de probabilidad siguiente. x f(x) 1 1/10 2 2/10 3 3/10 4 4/10  Esta distribuci\u00f3n de probabilidad se defi ne por medio de la f\u00f3rmula  <p>$$ f(x) = \\frac{x}{10} \\quad para \\,\\, x = 1, 2, 3\\, o \\,\\,4 $$</p> <p>La evaluaci\u00f3n de $f (x)$ para un valor dado de la variable aleatoria proporciona la probabilidad asociada. Por ejemplo, usando la funci\u00f3n de probabilidad anterior, vemos que $f (2)$ = 2/10 proporciona la probabilidad de que la variable aleatoria asuma el valor 2.</p> <p>Las distribuciones de probabilidad discretas de uso m\u00e1s com\u00fan por lo general se especifican por medio de f\u00f3rmulas. Tres casos importantes son las distribuciones binomial, de Poisson e hipergeom\u00e9trica, las cuales se estudian posteriormente en este cap\u00edtulo.</p> VALOR ESPERADO DE UNA VARIABLE ALEATORIA DISCRETA                  E(x) = \u03bc = \u2211x f(x)              (5.4)  Ambas notaciones, E(x) y \u03bc se usan para denotar el valor esperado de una variable aleatoria. La ecuaci\u00f3n (5.4) muestra que para calcular el valor esperado de una variable aleatoria discreta se debe multiplicar cada valor de la variable por su probabilidad correspondiente f (x), y despu\u00e9s se suman los productos que resultan. Utilizando el ejemplo de la venta de autom\u00f3viles de DiCarlo Motors de la secci\u00f3n 5.2, en la tabla 5.4 se muestra el c\u00e1lculo del valor esperado para el n\u00famero de veh\u00edculos vendidos durante un d\u00eda. La suma de las entradas de la columna xf (x) muestra que el valor esperado es 1.50 unidades por d\u00eda. Por consiguiente, aunque se sabe que en un d\u00eda cualquiera las ventas pueden ser de 0, 1, 2, 3, 4 o 5 autom\u00f3viles, DiCarlo anticipa que con el tiempo se vender\u00e1 un promedio diario de 1.50. Suponiendo que un mes tiene 30 d\u00edas de operaci\u00f3n, se usa el valor esperado de 1.50 para pronosticar el promedio de ventas mensuales de 30(1.50) = 45 veh\u00edculos.  <p>Varianza</p> Aun cuando el valor esperado proporciona el valor medio de la variable aleatoria, a menudo necesitamos una medida de variabilidad o dispersi\u00f3n. As\u00ed como la varianza se us\u00f3 en el cap\u00edtulo 3 para resumir la variabilidad en los datos, ahora la varianza se usa para resumir la variabilidad en los valores de una variable aleatoria. A continuaci\u00f3n se presenta la f\u00f3rmula para la varianza de una variable aleatoria discreta.  VARIANZA DE UNA VARIABLE ALEATORIA DISCRETA                  Var(x) = \u03c3\u00b2 = \u2211(x - \u03bc)\u00b2 f(x)              (5.5) Como muestra la ecuaci\u00f3n (5.5), una parte esencial de la f\u00f3rmula de la varianza es la desviaci\u00f3n, x - \u03bc, la cual mide a qu\u00e9 distancia est\u00e1 el valor esperado, o la media, \u03bc, de un valor particular de la variable aleatoria. Para calcular la varianza de una variable aleatoria, las desviaciones se elevan al cuadrado y luego se ponderan por el valor correspondiente de la funci\u00f3n de probabilidad. La suma de estas desviaciones al cuadrado ponderadas para todos los valores de la variable aleatoria se conocen como la varianza. Las notaciones Var (x) y \u03c32 se usan para denotar la varianza de una variable aleatoria.  <p>TABLA 5.4 C\u00e1lculo del valor esperado para el n\u00famero de autom\u00f3viles que se venden en un d\u00eda en Dicarlo Motors</p> x f (x) xf (x) 0 0.18 0(0.18) = 0.00 1 0.39 1(0.39) = 0.39 2 0.24 2(0.24) = 0.48 3 0.14 3(0.14) = 0.42 4 0.04 4(0.04) = 0.16 5 0.01 5(0.01) = 0.05 1.50 <p>TABLA 5.5  C\u00e1lculo de la varianza para el n\u00famero de autom\u00f3viles que se venden en un d\u00eda en Dicarlo Motors</p> $x$ $x - \u03bc$ $(x - \u03bc)^2$ $f(x)$ $(x-\u03bc)^2 f(x)$ $0$ $0 - 1.50 = -1.50$ $2.25$ $0.18$ $0.4050$ $1$ $1 - 1.50 = -0.50$ $0.25$ $0.39$ $0.0975$ $2$ $2 - 1.50 = 0.50$ $0.25$ $0.24$ $0.0600$ $3$ $3 - 1.50 = 1.50$ $2.25$ $0.14$ $0.3150$ $4$ $4 - 1.50 = 2.50$ $6.25$ $0.04$ $0.2500$ $5$ $5 - 1.50 = 3.50$ $12.25$ $0.01$ $0.1225$ $Total$ $1.2500$ <p>El c\u00e1lculo de la varianza para la distribuci\u00f3n de probabilidad del n\u00famero de autom\u00f3viles vendidos durante un d\u00eda en DiCarlo Motors se resume en la tabla 5.5. Vemos que la varianza es 1.25. tiempo La desviaci\u00f3n est\u00e1ndar, \u03c3, se defi ne como la ra\u00edz cuadrada positiva de la varianza. Por tanto, la desviaci\u00f3n est\u00e1ndar para el n\u00famero de autom\u00f3viles vendidos durante un d\u00eda es</p> <p>$$ \\sigma = \\sqrt{1.25} = 1.118 $$</p> <p>La desviaci\u00f3n est\u00e1ndar se mide en las mismas unidades que la variable aleatoria ($\\sigma = 1.118$ autom\u00f3viles) y por tanto a menudo se prefi ere para describir la variabilidad de una variable aleatoria. La varianza $\\sigma^2$ se mide en unidades cuadradas y, por tanto, es m\u00e1s dif\u00edcil de interpretar.</p> La distribuci\u00f3n de probabilidad binomial es una distribuci\u00f3n de probabilidad discreta que proporciona muchas aplicaciones. Se asocia con un experimento de m\u00faltiples pasos que se llama *experimento binomial*. <p>Un experimento binomial. </p> <p>Un  experimento binomial tiene las cuatro propiedades siguientes.</p> PROPIEDADES DE UN EXPERIMENTO BINOMIAL <ol> <li>El experimento consiste de una secuencia de $n$ ensayos id\u00e9nticos.</li> <li>En cada ensayo hay dos resultados posibles. A uno de ellos se le llama \u00e9xito y al otro, fracaso.</li> <li>La probabilidad de \u00e9xito, denotada por p, no cambia de un ensayo a otro. Por consiguiente, la probabilidad de fracaso, denotada por $1 - p$, tampoco cambia de un ensayo a otro.</li> <li>Los ensayos son independientes.</li></ol> Si est\u00e1n presentes las propiedades 2, 3 y 4, se dice que los ensayos son generados por un proceso de Bernoulli. Si, adem\u00e1s, la propiedad 1 est\u00e1 presente, se dice que tenemos un experimento binomial. La fi gura 5.2 representa una secuencia posible de \u00e9xitos y fracasos para un experimento binomial que consta de ocho ensayos.  <p>En un experimento binomial, lo que interesa es el n\u00famero de \u00e9xitos que ocurren en los n ensayos. Si x denota el n\u00famero de \u00e9xitos que ocurren en n ensayos, vemos que x puede asumir los valores 0, 1, 2, 3..., n. Debido a que el n\u00famero de valores es fi nito, x es una variable aleatoria discreta. La distribuci\u00f3n de probabilidad asociada con esta variable se llama Un distribuci\u00f3n de probabilidad binomial. Por ejemplo, considere el experimento de lanzar una moneda cinco veces y en cada lanzamiento observe si la moneda cae con cara o cruz en el lado superior. Suponga que queremos contar el n\u00famero de caras que aparecen durante los cinco lanzamientos. \u00bfEste ejemplo muestra las propiedades de un experimento binomial? \u00bfCu\u00e1l es la variable aleatoria de inter\u00e9s? Observe que:</p> <ol> <li>El experimento consta de cinco ensayos id\u00e9nticos; cada uno consiste en el lanzamiento de una moneda.</li> <li>En cada ensayo hay dos resultados posibles: cara o cruz. Se puede designar cara como un \u00e9xito y cruz como un fracaso.</li> <li>La probabilidad de obtener cara y la probabilidad de obtener cruz son iguales para cada ensayo, con $p = 0.5$ y $1 - p = 0.5$.</li> <li>Los ensayos o lanzamientos son independientes debido a que el resultado de cualquier ensayo no se ve afectado por lo que ocurre con otros ensayos o lanzamientos.</li> </ol> <p> Propiedad 1 El experimento consta de n = 8 ensayos id\u00e9nticos.</p> <p> Propiedad 2 Cada ensayo da como resultado un \u00e9xito ($S$) o un fracaso ($F$). </p> ensayos Resultados 1 S 2 F 3 F 4 S 5 S 6 F 7 S 8 S Por tanto, las propiedades de un experimento binomial se satisfacen. La variable aleatoria que interesa es x = n\u00famero de caras que ocurren en cinco ensayos. En este caso, x puede tomar los valores 0, 1, 2, 3, 4 o 5.  <p>En otro ejemplo, considere a una vendedora de seguros que visita a 10 familias seleccionadas al azar. El resultado asociado con cada visita se clasifi ca como un \u00e9xito si la familia compra un seguro y un fracaso si no lo compra. A partir de su experiencia, la vendedora sabe que la probabilidad de que una familia seleccionada al azar compre un seguro es de 0.10. Al revisar las propiedades de un experimento binomial se observa que:</p> <ol> <li>El experimento consta de 10 ensayos id\u00e9nticos; cada uno consiste en visitar a una familia.</li> <li>En cada ensayo hay dos resultados posibles: la familia compra el seguro (\u00e9xito) o no lo compra (fracaso)</li> <li>Se asume que las probabilidades de que haya una compra o no la haya son iguales para cada visita, con $p = 0.10$ y $1 - p = 0.90$.</li> <li>Los ensayos son independientes, porque las familias se eligen al azar.</li></ol> Como estos cuatro supuestos se cumplen, este ejemplo es un experimento binomial. La variable aleatoria de inter\u00e9s es el n\u00famero de ventas obtenidas al hacer contacto con las 10 familias. En este caso, x puede asumir los valores 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 y 10.  <p>La propiedad 3 del experimento binomial se llama supuesto de estacionariedad y a veces se confunde con la propiedad 4, la independencia de los ensayos. Para ver c\u00f3mo difi eren, considere de nuevo el caso de la vendedora que visita a las familias para ofrecer seguros. Si, a medida que el d\u00eda avanza, la empleada se cansa y pierde entusiasmo, la probabilidad de \u00e9xito (vender un seguro) para el d\u00e9cimo contacto podr\u00eda disminuir a 0.05, por ejemplo. En este caso, la propiedad 3 (estacionariedad) no se cumplir\u00eda y el experimento no ser\u00eda binomial. Incluso si la propiedad 4 se cumple, es decir, que las decisiones de compra de cada familia se realizaran en forma independiente, el experimento no ser\u00eda binomial si la propiedad 3 no se satisface.</p> <p>En las aplicaciones con experimentos binomiales se usa una f\u00f3rmula matem\u00e1tica especial, llamada funci\u00f3n de probabilidad binomial, para calcular la probabilidad de x \u00e9xitos en n ensayos. Enseguida se mostrar\u00e1 c\u00f3mo se desarrolla la f\u00f3rmula, en el contexto de un problema ilustrativo, usando los conceptos de probabilidad presentados en el cap\u00edtulo 4.</p> <p>El problema de Big Sur </p> Considere las decisiones de compra de los tres clientes siguientes que entran en la tienda de ropa Big Sur. Con base en su experiencia, el gerente de la tienda estima que la probabilidad de que un cliente cualquiera haga una compra es de 0.30. \u00bfCu\u00e1l es la probabilidad de que dos de los tres clientes siguientes realicen una compra?  <p>El experimento de observar a tres clientes que toman una decisi\u00f3n de compra, cada uno tiene ocho resultados posibles. Si S denota \u00e9xito (una compra) y F denota fracaso (no hay compra), se tiene inter\u00e9s en los resultados experimentales que consisten en dos \u00e9xitos en los tres ensayos (decisiones de compra). A continuaci\u00f3n se verificar\u00e1 que el experimento con una secuencia de tres decisiones de compra puede verse como binomial. Al revisar los cuatro requerimientos para un experimento binomial observamos que:</p> <ol> <li>El experimento se describe como una secuencia de tres ensayos id\u00e9nticos, uno para cada uno de los tres clientes que entran en la tienda.</li> <li>Para cada ensayo hay dos resultados posibles: el cliente efect\u00faa una compra (\u00e9xito) o el cliente no efect\u00faa una compra (fracaso).</li> <li>Se asume que la probabilidad de que el cliente realice una compra (0.30) o no la realice (0.70) es la misma para todos los clientes.</li> <li>La decisi\u00f3n de compra de cada sujeto es independiente de las decisiones que tomen los otros clientes.</li> </ol> <p>Por consiguiente, est\u00e1n presentes las propiedades de un experimento binomial. El n\u00famero de resultados experimentales que producen exactamente x \u00e9xitos en n ensayo se calcula usando la f\u00f3rmula siguiente.</p> N\u00daMERO DE RESULTADOS EXPERIMENTALES QUE PROPORCIONAN EXACTAMENTE $x$ \u00c9XITOS EN $n$ ENSAYOS                  \\binom{n}{x} =  \\frac{n!}{x!(n-x)!}               (5.6)          Donde:                           n! = n \\cdot (n - 1) \\cdot (n - 2) \\cdot \\ldots \\cdot (2) \\cdot (1)  $$                      y por definicion,                           0! = 1              Ahora regresemos al experimento de Big Sur que consiste en las decisiones de compra de tres clientes. La ecuaci\u00f3n (5.6) permite determinar el n\u00famero de resultados que involucran dos compras; es decir, el n\u00famero de maneras de obtener $x = 2$ \u00e9xitos en $n = 3$ ensayos.  A partir de la ecuaci\u00f3n (5.6) tenemos <p>$$ \\binom{n}{x} = \\binom{3}{2} = \\frac{3!}{2!(3-2)!} = \\frac{3!}{2!\\cdot1!} = \\frac{3\\cdot2\\cdot1}{2\\cdot1\\cdot1} = \\frac{6}{2} = 3 $$</p> <p>La ecuaci\u00f3n $(5.6)$ muestra que tres de los resultados experimentales produjeron dos \u00e9xitos.</p> <p>A partir de la figura $5.3$, vemos que estos tres resultados se denotan por $(S, S, F)$, $(S, F, S)$ y $(F, S, S)$.</p> <p>Usando la ecuaci\u00f3n $(5.6)$ para determinar cu\u00e1ntos resultados experimentales tienen tres \u00e9xitos (compras) en los tres ensayos, obtenemos</p> <p>$$ \\binom{n}{x} = \\binom{3}{3} = \\frac{3!}{3!(3-3)!} = \\frac{3!}{3!\\cdot0!} = \\frac{3\\cdot2\\cdot1}{3\\cdot2\\cdot1\\cdot1} = \\frac{6}{6} = 1 $$</p> <p>A partir de la figura $5.3$ observamos que el resultado experimental con tres \u00e9xitos se identifica por $(S, S, S)$.</p> <p>Se sabe que la ecuaci\u00f3n $(5.6)$ se utiliza para determinar el n\u00famero de resultados experimentales que dan lugar a $x$ \u00e9xitos. Si se determinar\u00e1 la probabilidad de x \u00e9xitos en n ensayos, no obstante, tambi\u00e9n debemos conocer la probabilidad asociada con cada uno de estos resultados. Como los ensayos de un experimento binomial son independientes, sencillamente es posible multiplicar las probabilidades asociadas con el resultado de cada ensayo para encontrar la probabilidad de una secuencia particular de \u00e9xitos y fracasos.</p> <p>La probabilidad de que los dos primeros clientes compren y que el tercero no compre, denotada por $(S, S, F)$, est\u00e1 dada por:</p> <p>$$ pp(1-p) $$</p> <p>Con una probabilidad de $0.30$ de una compra en cualquier ensayo, la probabilidad de una compra en los primeros dos ensayos y ninguna compra en el tercero est\u00e1 dada por:</p> <p>$$(0.30)(0.30)(0.70) = (0.30)^2(0.70) = 0.063$$</p> <p>Otros dos resultados experimentales tambi\u00e9n dan lugar a dos \u00e9xitos y un fracaso. Las probabilidades de tres resultados que tienen dos \u00e9xitos se presentan a continuaci\u00f3n.</p> <p>RESULTADOS DE LOS ENSAYOS</p> Primer cliente Segundo cliente Tercer cliente Resultado experimental Probabilidad de resultado experimental Compra Compra No compra (S, S, F) pp(1-p)=p^2(1-p)=(0.30)^2(0.70)=0.063 Compra Compra No compra (S, S, F) pp(1-p)=p^2(1-p)=(0.30)^2(0.70)=0.063 Compra No compra Compra (S, F, S) p(1-p)p=p^2(1-p)=(0.30)^2(0.70)=0.063 No compra Compra Compra (S, S, F) (1-p)pp=p^2(1-p)=(0.30)^2(0.70)=0.063 <p>Observe que los tres resultados experimentales con dos \u00e9xitos tienen exactamente la misma probabilidad. Esta observaci\u00f3n es v\u00e1lida en general. En cualquier experimento binomial, todas las secuencias de resultados de ensayos que producen $x$ \u00e9xitos en $n$ ensayos tienen la misma probabilidad de ocurrencia. La probabilidad de cada secuencia de ensayos que producen $x$ \u00e9xitos en $n$ ensayos se presenta a continuaci\u00f3n.</p> <p>$$\\begin{align*} \\text{Probabilidad de una secuencia}\\\\ \\text{particular de resultados de} =p^x(1-p)^{(n-x)}\\\\ \\text{con x \u00e9xitos en n ensayos} \\end{align*}$$</p> <p>En el caso de la tienda Martin Clothing Store, esta f\u00f3rmula indica que cualquier resultado experimental con dos \u00e9xitos tiene una probabilidad de $p^2(1 - p)^{(3-2)} = p^2(1 - p)^1 = (0.30)^2(0.70)^1 = 0.063$.</p> <p>Como la ecuaci\u00f3n $(5.6)$ muestra el n\u00famero de resultados de un experimento binomial con $x$ \u00e9xitos y la ecuaci\u00f3n $(5.7)$ proporciona la probabilidad de cada secuencia con $x$ \u00e9xitos, las ecuaciones $(5.6)$ y $(5.7)$ se combinan para obtener la funci\u00f3n de probabilidad binomial siguiente.</p> FUNCI\u00d3N DE PROBABILIDAD BINOMIAL                   f(x)=\\binom{n}{x}p^x(1-p)^{(n-x)}               (5.8)          donde:  <p>$$\\scriptsize x=\\text{n\u00famero de \u00e9xitos}$$ $$\\scriptsize p=\\text{probabilidad de un \u00e9xito en un ensayo}$$ $$\\scriptsize n=\\text{n\u00famero de ensayos}$$ $$\\scriptsize f(x)=\\text{probabilidad de}\\; x \\;\\text{\u00e9xitos en}\\; n\\; \\text{ensayos}$$ $$\\scriptsize \\binom{n}{x}=\\frac{n!}{x!(n-x)!}$$</p> <p>Para la distribuci\u00f3n de probabilidad binomial, x es una variable aleatoria discreta con la funci\u00f3n de probabilidad $f(x)$ aplicable para los valores de $x = 0, 1, 2,..., n$.</p> <p>En el ejemplo de Martin Clothing Store, se usa la ecuaci\u00f3n $(5.8)$ para calcular la probabilidad de que ning\u00fan cliente realice una compra; exactamente un cliente haga una compra; exactamente dos clientes efect\u00faen una compra, y los tres clientes compren. Los c\u00e1lculos se resumen en la tabla $5.6$, que proporciona la distribuci\u00f3n de probabilidad del n\u00famero de sujetos que realizan una compra. La figura $5.4$ es una gr\u00e1fica de esta distribuci\u00f3n de probabilidad.</p> <p>La funci\u00f3n de probabilidad binomial se aplica a cualquier experimento binomial. Si una situaci\u00f3n demuestra las propiedades de un experimento binomial y se conocen los valores de $n$ y $p$, se puede usar la ecuaci\u00f3n $(5.8)$ para calcular la probabilidad de $x$ \u00e9xitos en $n$ ensayos.</p> <p>TABLA 5.6 Distribuci\u00f3n de probabilidad para el n\u00famero de clientes que efect\u00faan una compra</p> x f(x) 0 \\frac{3!}{0!3!}(0.30)^0(0.70)^3=0.343 1 \\frac{3!}{1!2!}(0.30)^1(0.70)^2=0.441 2 \\frac{3!}{2!1!}(0.30)^2(0.70)^1=0.189 3 \\frac{3!}{3!0!}(0.30)^3(0.70)^0=\\dfrac{0.027}{1.000} <p>FIGURA 5.4 Representaci\u00f3n gr\u00e1fica de la distribuci\u00f3n de probabilidad para el n\u00famero de clientes que efect\u00faan una compra</p> In\u00a0[74]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Datos de ejemplo\ncategorias = ['0', '1', '2', '3']\nvalores = [0.343, 0.441, 0.189, 0.027]\n\n# Define color de las barras\ncolor_hex = '#009929'\n\n# Crear el gr\u00e1fico de barras con espacio reducido entre categor\u00edas\nfig, ax = plt.subplots()\nbars = ax.bar(categorias, valores, color=color_hex, width=0.03)\n\n# Ajustar el espacio entre las categor\u00edas y quitar las l\u00edneas de arriba y a la derecha\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.xaxis.set_tick_params(width=0)  # Ocultar las l\u00edneas del eje x\nax.yaxis.set_tick_params(width=0)  # Ocultar las l\u00edneas del eje y\n\n# Ajustar el color de fondo dentro de la gr\u00e1fica a verde claro\nax.set_facecolor('#d4f8b7')  # C\u00f3digo hexadecimal para verde claro\n\n# Ajustar el color de fondo de la figura a verde\nfig.set_facecolor('#d4f8b7')  # C\u00f3digo hexadecimal para verde\n\n# A\u00f1adir l\u00edneas superior e inferior\nlinea_superior = plt.Line2D((0, 1), (1, 1), color='green', linewidth=5, transform=fig.transFigure)\nlinea_inferior = plt.Line2D((0, 1), (0, 0), color='green', linewidth=5, transform=fig.transFigure)\nfig.lines.extend([linea_superior, linea_inferior])\n\n# Ajustar el espacio entre las categor\u00edas y quitar las l\u00edneas de arriba y a la derecha\nubicaciones_y = [0.00, 0.10, 0.20, 0.30, 0.40, 0.50]\netiquetas_y = ['0.00', '0.10', '0.20', '0.30', '0.40', '0.50']\nax.set_yticks(ubicaciones_y)\nax.set_yticklabels(etiquetas_y)\n\n# Agregar etiquetas y t\u00edtulo\nplt.xlabel('N\u00famero de clientes que efect\u00faan una compra   x')\nplt.ylabel('Probabilidad   f(x)')\n# plt.title('Gr\u00e1fico de Barras sin L\u00edneas en la Parte Superior y Derecha')\n\n# Mostrar el gr\u00e1fico\nplt.tight_layout()  # Ajustar el dise\u00f1o para evitar cortar las etiquetas\nplt.show()\n</pre> import matplotlib.pyplot as plt  # Datos de ejemplo categorias = ['0', '1', '2', '3'] valores = [0.343, 0.441, 0.189, 0.027]  # Define color de las barras color_hex = '#009929'  # Crear el gr\u00e1fico de barras con espacio reducido entre categor\u00edas fig, ax = plt.subplots() bars = ax.bar(categorias, valores, color=color_hex, width=0.03)  # Ajustar el espacio entre las categor\u00edas y quitar las l\u00edneas de arriba y a la derecha ax.spines['top'].set_visible(False) ax.spines['right'].set_visible(False) ax.xaxis.set_tick_params(width=0)  # Ocultar las l\u00edneas del eje x ax.yaxis.set_tick_params(width=0)  # Ocultar las l\u00edneas del eje y  # Ajustar el color de fondo dentro de la gr\u00e1fica a verde claro ax.set_facecolor('#d4f8b7')  # C\u00f3digo hexadecimal para verde claro  # Ajustar el color de fondo de la figura a verde fig.set_facecolor('#d4f8b7')  # C\u00f3digo hexadecimal para verde  # A\u00f1adir l\u00edneas superior e inferior linea_superior = plt.Line2D((0, 1), (1, 1), color='green', linewidth=5, transform=fig.transFigure) linea_inferior = plt.Line2D((0, 1), (0, 0), color='green', linewidth=5, transform=fig.transFigure) fig.lines.extend([linea_superior, linea_inferior])  # Ajustar el espacio entre las categor\u00edas y quitar las l\u00edneas de arriba y a la derecha ubicaciones_y = [0.00, 0.10, 0.20, 0.30, 0.40, 0.50] etiquetas_y = ['0.00', '0.10', '0.20', '0.30', '0.40', '0.50'] ax.set_yticks(ubicaciones_y) ax.set_yticklabels(etiquetas_y)  # Agregar etiquetas y t\u00edtulo plt.xlabel('N\u00famero de clientes que efect\u00faan una compra   x') plt.ylabel('Probabilidad   f(x)') # plt.title('Gr\u00e1fico de Barras sin L\u00edneas en la Parte Superior y Derecha')  # Mostrar el gr\u00e1fico plt.tight_layout()  # Ajustar el dise\u00f1o para evitar cortar las etiquetas plt.show() <p>Si se consideran variaciones del experimento de Big Sur, por ejemplo que 10 clientes en vez de tres entren en la tienda, la funci\u00f3n de probabilidad binomial dada la ecuaci\u00f3n $(5.8)$ sigue siendo v\u00e1lida. Suponga que se tiene un experimento binomial con $n=10, x=4\\;y\\;p=0.30$. La probabilidad de que exactamente cuatro de los 10 clientes que entran en la tienda realicen una compra es:</p> <p>$$f(4)=\\dfrac{10!}{4!6!}(0.30)^4(0.70)^6=0.2001$$</p> <p>TABLA 5.7 Valores seleccionados del ejemplo de la tabla de probabilidad binomial: $n=10;\\;x=3;\\;p=0.040;\\;f(3)=0.2150$</p> p n x 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 9 0 0.6302 0.3874 0.2316 0.1342 0.0751 0.0404 0.0207 0.0101 0.0046 0.0020 1 0.2985 0.3874 0.3679 0.3020 0.2253 0.1556 0.1004 0.0605 0.0339 0.0176 2 0.0629 0.1722 0.2597 0.3020 0.3003 0.2668 0.2162 0.1612 0.1110 0.0703 3 0.0077 0.0446 0.1069 0.1762 0.2336 0.2668 0.2716 0.2508 0.2119 0.1641 4 0.0006 0.0074 0.0283 0.0661 0.1168 0.1715 0.2194 0.2508 0.2600 0.2461 5 0.0000 0.0008 0.0050 0.0165 0.0389 0.0735 0.1181 0.1672 0.2128 0.2461 6 0.0000 0.0001 0.0006 0.0028 0.0087 0.0210 0.0424 0.0743 0.1160 0.1641 7 0.0000 0.0000 0.0000 0.0003 0.0012 0.0039 0.0098 0.0212 0.0407 0.0703 8 0.0000 0.0000 0.0000 0.0000 0.0001 0.0004 0.0013 0.0035 0.0083 0.0176 9 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0001 0.0003 0.0008 0.0020 10 0 0.5987 0.3487 0.1969 0.1074 0.0563 0.0282 0.0135 0.0060 0.0025 0.0010 1 0.3151 0.3874 0.3474 0.2684 0.1877 0.1211 0.0725 0.0403 0.0207 0.0098 2 0.0746 0.1937 0.2759 0.3020 0.2816 0.2335 0.1757 0.1209 0.0763 0.0439 3 0.0105 0.0574 0.1298 0.2013 0.2503 0.2668 0.2522 0.2150 0.1665 0.1172 4 0.0010 0.0112 0.0401 0.0881 0.1460 0.2001 0.2377 0.2508 0.2384 0.2051 5 0.0001 0.0015 0.0085 0.0264 0.0584 0.1029 0.1536 0.2007 0.2340 0.22461 6 0.0000 0.0001 0.0012 0.0055 0.0162 0.0368 0.0689 0.1115 0.1596 0.2051 7 0.0000 0.0000 0.0001 0.0008 0.0031 0.0090 0.0212 0.0425 0.0746 0.1172 8 0.0000 0.0000 0.0000 0.0001 0.0004 0.0014 0.0043 0.0106 0.0229 0.0439 9 0.0000 0.0000 0.0000 0.0000 0.0000 0.0001 0.0005 0.0016 0.0042 0.0098 10 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0001 0.0003 0.0010 <p>Valor esperado y varianza de la distribuci\u00f3n binomial</p> <p>En la secci\u00f3n 5.3 se proporcionaron las f\u00f3rmulas para calcular el valor esperado y la varianza de una variable aleatoria discreta. En el caso especial en que la variable tiene una distribuci\u00f3n binomial con un n\u00famero conocido de ensayos n y una probabilidad conocida de \u00e9xitos p, las f\u00f3rmulas generales para el valor esperado y la varianza se simplifican. Los resultados se muestran a continuaci\u00f3n.</p> VALOR ESPERADO Y VARIANZA DE LA DISTRIBUCION BINOMIAL                  E(x)= \u03bc=np              (5.9)                  Var(x)=\u03c3^2=np(1-p)              (5.10) <p>FIGURA 5.5 Resultado que muestra las probabilidades binomiales para el problema</p> x P(X=x) 0.00 0.0282 1.00 0.1211 2.00 0.2335 3.00 0.2668 4.00 0.2001 5.00 0.1029 6.00 0.0368 7.00 0.0090 8.00 0.0014 9.00 0.0001 10.00 0.0000 <p>En el caso del problema de Martin Clothing Store con tres clientes, se usa la ecuaci\u00f3n $(5.9)$ para calcular el n\u00famero esperado de clientes que realizar\u00e1n una compra.</p> <p>$$E(x)=np=3(0.30)=0.9$$</p> <p>Suponga que para el mes siguiente Martin Clothing Store pronostica que 1000 clientes entrar\u00e1n en la tienda. \u00bfCu\u00e1l es el n\u00famero esperado de personas que realizar\u00e1n una compra? La respuesta es $\u03bc=np=(1000)(0.3)=300$. Por tanto, para aumentar el n\u00famero esperado de compras, la empresa debe lograr que m\u00e1s clientes entren en el establecimiento y/o aumentar de alguna manera la probabilidad de que un cliente realice una compra cuando est\u00e9 adentro. En este problema con tres clientes, vemos que la varianza y la desviaci\u00f3n est\u00e1ndar del n\u00famero de ellos que har\u00e1n una compra es:</p> <p>$$\u03c3^2=np(1-p)=3(0.3)(0.7)=0.63$$ $$\u03c3=\\sqrt{0.63}=0.79$$</p> <p>Para los pr\u00f3ximos 1000 clientes que entren en la tienda, la varianza y la desviaci\u00f3n est\u00e1ndar del n\u00famero de personas que har\u00e1n una compra son:</p> <p>$$\u03c3^2=np(1-p)=1000(0.3)(0.7)=210$$ $$\u03c3=\\sqrt{210}=14.49$$</p> PROPIEDADES DE UN EXPERIMENTO DE POISSON                  1. La probabilidad de ocurrencia es la misma para cualesquiera dos intervalos de igual longitud.                 2. La ocurrencia o no ocurrencia en cualquier intervalo es independiente de la ocurrencia o no ocurrencia en cualquier otro intervalo.              La funci\u00f3n de probabilidad de Poisson se defi ne por medio de la ecuaci\u00f3n (5.11).  FUNCI\u00d3N DE PROBABILIDAD BINOMIAL                   f(x) = \\frac{(\u03bc^x) * e^(-\u03bc)}{x!}              (5.11)          donde:  <p>$$\\scriptsize f (x) =\\text{probabilidad de x ocurrencias en un intervalo}$$ $$\\scriptsize \u03bc = \\text{valor esperado o n\u00famero medio de ocurrencias en un intervalo}$$ $$\\scriptsize e = \\text{2.71828}$$</p> Para la distribuci\u00f3n de probabilidad de Poisson, x es una variable aleatoria discreta que indica el n\u00famero de ocurrencias en el intervalo. Como no hay un l\u00edmite superior establecido para el n\u00famero de ocurrencias, la funci\u00f3n de probabilidad f (x) es aplicable para los valores x = 0, 1, 2, . . . sin l\u00edmite. En las aplicaciones pr\u00e1cticas, x a la larga se volver\u00e1 lo sufi cientemente grande para que f (x) sea aproximadamente cero y la probabilidad de cualquier valor mayor que x se vuelva insignifi cante.  <p>Un ejemplo con intervalos de tiempo</p>  Suponga que le interesa conocer el n\u00famero de llegadas al autocajero de un banco en las ma\u00f1anas de lunes a viernes durante un periodo de 15 minutos. Si se asume que la probabilidad de un autom\u00f3vil que llega es la misma para cualquiera de dos periodos de igual duraci\u00f3n y que la llegada o no llegada de un veh\u00edculo en cualquier periodo es independiente del arribo o no en cualquier otro periodo, la funci\u00f3n de probabilidad de Poisson es aplicable. Suponga que estos supuestos se cumplen y que un an\u00e1lisis de los datos hist\u00f3ricos muestra que el n\u00famero medio de autom\u00f3viles que llega en un periodo de 15 minutos es 10; en este caso, se aplica la funci\u00f3n de probabilidad siguiente.  <p>$$ f(x)= \\frac{10^x*e^{-10}}{x!} $$</p> <p>La variable aleatoria aqu\u00ed es x = n\u00famero de autom\u00f3viles que llega en un periodo de 15 minutos. Si la gerencia quisiera conocer la probabilidad de exactamente cinco llegadas en 15 minutos, se establecer\u00eda que x = 5 y por tanto obtendr\u00edamos</p> <p>Probabilidad de exactamente cinco llegadas en 15 minutos</p> <p>$$ f(5)= \\frac{10^5*e^{-10}}{5!} $$</p> <p>Aunque esta probabilidad se determin\u00f3 al evaluar la funci\u00f3n de probabilidad con \u03bc = 10 y x = 5, a menudo es m\u00e1s f\u00e1cil remitirse a una tabla para la distribuci\u00f3n de Poisson, la cual proporciona probabilidades para valores espec\u00edfi cos de x y \u03bc. Se incluy\u00f3 una similar a la tabla 7 del ap\u00e9ndice B. Por conveniencia, reproducimos una parte de \u00e9sta en la tabla 5.8. Observe que para usar la tabla de probabilidades de Poisson necesitamos conocer s\u00f3lo los valores de x y \u03bc. A partir de la tabla 5.8 vemos que la probabilidad de cinco llegadas en un periodo de 15 minutos se encuentra ubicando el valor en la fi la de la tabla que corresponde a x = 5 y la columna que corresponde a \u03bc = 10. Por consiguiente, obtenemos f (5) = 0.0378. En el ejemplo anterior, la media de la distribuci\u00f3n de Poisson es \u03bc = 10 llegadas por un periodo de 15 minutos. Una propiedad de la distribuci\u00f3n de Poisson consiste en que la media de la distribuci\u00f3n y la varianza de la distribuci\u00f3n son iguales. Por tanto, la varianza para el n\u00famero de llegadas durante un periodo de 15 minutos es $\u03c3^2 = 10$. La desviaci\u00f3n est\u00e1ndar es $\u03c3 = \\sqrt(10) =$ 3.16. El ejemplo involucra un periodo de 15 minutos, pero se pueden usar otros. Suponga que se quiere calcular la probabilidad de una llegada en un periodo de 3 minutos. Dado que 10 es el n\u00famero esperado de llegadas en 15 minutos, vemos que 10/15 = 2/3 es el n\u00famero esperado de llegadas en 1 minuto y que (2/3)(3 minutos) = 2 es el n\u00famero esperado de arribos en 3 minutos. Por tanto, la probabilidad de x llegadas en un periodo de 3 minutos con \u03bc = 2 est\u00e1 dada por la funci\u00f3n de probabilidad de Poisson siguiente.</p> <p>$$ f(x)= \\frac{2^x*e^{-2}}{x!} $$</p> <p>TABLA 5.8 de las tablas de probabilidad de Poisson: $\u03bc=10;\\;x=5;\\;f(5)=0.0378$</p> \u03bc x 9.1 9.2 9.3 9.4 9.5 9.6 9.7 9.8 9.9 10 0 0.0001 0.0001 0.0001 0.0001 0.0001 0.0001 0.0001 0.0001 0.0001 0.0000 1 0.0010 0.0009 0.0009 0.0008 0.0007 0.0007 0.0006 0.0005 0.0005 0.0005 2 0.0046 0.0043 0.0040 0.0037 0.0034 0.0031 0.0029 0.0027 0.0025 0.0023 3 0.0140 0.0131 0.0123 0.0115 0.0107 0.0100 0.0093 0.0087 0.0081 0.0076 4 0.0319 0.0302 0.0285 0.0269 0.0254 0.0240 0.0226 0.0213 0.0201 0.0189 5 0.0581 0.0555 0.0530 0.0506 0.0483 0.0460 0.0439 0.0418 0.0398 0.0378 6 0.0881 0.0851 0.0822 0.0793 0.0764 0.0736 0.0709 0.0682 0.0656 0.0631 7 0.1145 0.1118 0.1091 0.1064 0.1037 0.1010 0.0982 0.0955 0.0928 0.0901 8 0.1302 0.1286 0.1269 0.1251 0.1232 0.1212 0.1191 0.1170 0.1148 0.1126 9 0.1317 0.1315 0.1311 0.1306 0.1300 0.1293 0.1284 0.1274 0.1263 0.1251 10 0.1198 0.1210 0.1219 0.1228 0.1235 0.1241 0.1245 0.1249 0.1250 0.1251 11 0.0991 0.1012 0.1031 0.1049 0.1067 0.1083 0.1098 0.1112 0.1125 0.1137 12 0.0752 0.0776 0.0799 0.0822 0.0844 0.0866 0.0888 0.0908 0.0928 0.0948 13 0.0526 0.0549 0.0572 0.0594 0.0617 0.0640 0.0662 0.0685 0.0707 0.0729 14 0.0342 0.0361 0.0380 0.0399 0.0419 0.0439 0.0459 0.0479 0.0500 0.0521 15 0.0208 0.0221 0.0235 0.0250 0.0265 0.0281 0.0297 0.0313 0.0330 0.0347 16 0.0118 0.0127 0.0137 0.0147 0.0157 0.0168 0.0180 0.0192 0.0204 0.0217 17 0.0063 0.0069 0.0075 0.0081 0.0088 0.0095 0.0103 0.0111 0.0119 0.0128 18 0.0032 0.0035 0.0039 0.0042 0.0046 0.0051 0.0055 0.0060 0.0065 0.0071 19 0.0015 0.0017 0.0019 0.0021 0.0023 0.0026 0.0028 0.0031 0.0034 0.0037 20 0.0007 0.0008 0.0009 0.0010 0.0011 0.0012 0.0014 0.0015 0.0017 0.0019 21 0.0003 0.0003 0.0004 0.0004 0.0005 0.0006 0.0006 0.0007 0.0008 0.0009 22 0.0001 0.0001 0.0002 0.0002 0.0002 0.0002 0.0003 0.0003 0.0004 0.0004 23 0.0000 0.0001 0.0001 0.0001 0.0001 0.0001 0.0001 0.0001 0.0002 0.0002 24 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0001 0.0001 0.0001  La probabilidad de una llegada en un periodo de 3 minutos se calcula como sigue:  <p>Probabilidad de exactamente 1 llegada en 3 minutos</p> <p>$$ f(1)= \\frac{2^1*e^{-2}}{1!} $$</p> <p>Previamente se calcul\u00f3 la probabilidad de cinco llegadas en un periodo de 15 minutos; fue 0.0378. Observe que la probabilidad de un arribo en 3 minutos (0.2707) no es la misma. Cuando se estima una probabilidad de Poisson para un intervalo de tiempo distinto, primero se debe convertir la tasa media de llegadas al periodo de inter\u00e9s y luego calcular la probabilidad.</p> <p>Un ejemplo con intervalos de longitud o de distancia</p>  Se demostrar\u00e1 una aplicaci\u00f3n que no tiene intervalos de tiempo en la que es \u00fatil la distribuci\u00f3n de Poisson. Suponga que le interesa saber cu\u00e1l es la ocurrencia de defectos importantes en una autopista un mes despu\u00e9s de repavimentarla. Considere que la probabilidad de un defecto es la misma en cualquiera de dos intervalos de igual longitud de la autopista, y que la ocurrencia o no ocurrencia de defectos en cualquier intervalo es independiente de su ocurrencia o no en cualquier otro intervalo. Por ende, la distribuci\u00f3n de Poisson puede aplicarse. Suponga que se enter\u00f3 de que los principales defectos despu\u00e9s de un mes de repavimentar ocurren a una tasa media de 2 por milla. En seguida se determinar\u00e1 la probabilidad de que no hay defectos importantes en un tramo particular de 3 millas de la autopista. Como nos interesa un intervalo con esta longitud, \u03bc = (2 defectos/milla)(3 millas) = 6 representa el n\u00famero esperado de anomal\u00edas importantes en este tramo de la autopista. Mediante la ecuaci\u00f3n (5.11), la probabilidad de que no haya alguna aver\u00eda importante es $ f (0) = 0.0025. Por tanto, es poco probable que ning\u00fan defecto importante se presente en la secci\u00f3n de las 3 millas. De hecho, este ejemplo indica que 1 - 0.0025 = 0.9975 es la probabilidad de por lo menos un defecto importante en la secci\u00f3n de 3 millas de la autopista.  <p>Metodos </p> <p>Ejercicio </p> Considere el experimento de lanzar una moneda dos veces. a) Elabore una lista de los resultados experimentales. b) Defina una variable aleatoria que represente el n\u00famero de caras que caen en los dos lanzamientos. c) Muestre el valor que la variable aleatoria asumir\u00eda en cada uno de los resultados experimentales. d) \u00bfEsta variable aleatoria es discreta o continua?  a) El espacio muestral del experimento de lanzar una moneda dos veces es el conjunto de pares ordenados de resultados, donde cada resultado es una combinaci\u00f3n de cara (c) o sello (s). In\u00a0[\u00a0]: Copied! <pre>espacio_muestral = {\n    ('c', 'c'),\n    ('c', 's'),\n    ('s', 'c'),\n    ('s', 's'),\n}\n</pre> espacio_muestral = {     ('c', 'c'),     ('c', 's'),     ('s', 'c'),     ('s', 's'), } b) La variable aleatoria que representa el n\u00famero de caras que caen en los dos lanzamientos se puede definir como: In\u00a0[\u00a0]: Copied! <pre>def numero_caras(resultado):\n    caras = resultado[0] == 'c' or resultado[1] == 'c'\n    return int(caras)\n</pre> def numero_caras(resultado):     caras = resultado[0] == 'c' or resultado[1] == 'c'     return int(caras)  b) El valor que la variable aleatoria asumir\u00eda en cada uno de los resultados experimentales es el siguiente: In\u00a0[4]: Copied! <pre># Espacio muestral\nespacio_muestral = {\n    ('c', 'c'),\n    ('c', 's'),\n    ('s', 'c'),\n    ('s', 's'),\n}\n\n# Variable aleatoria\ndef numero_caras(resultado):\n    caras = resultado[0] == 'c' or resultado[1] == 'c'\n    return int(caras)\n\n# Valor de la variable aleatoria\nfor resultado in espacio_muestral:\n    print(resultado, numero_caras(resultado))\n</pre> # Espacio muestral espacio_muestral = {     ('c', 'c'),     ('c', 's'),     ('s', 'c'),     ('s', 's'), }  # Variable aleatoria def numero_caras(resultado):     caras = resultado[0] == 'c' or resultado[1] == 'c'     return int(caras)  # Valor de la variable aleatoria for resultado in espacio_muestral:     print(resultado, numero_caras(resultado))  <pre>('s', 'c') 1\n('c', 's') 1\n('c', 'c') 1\n('s', 's') 0\n</pre> <p>Ejercicio </p> Considere el experimento de un trabajador que ensambla un producto. a) Defina una variable aleatoria que represente el tiempo en minutos requerido para ensamblar el producto. b) \u00bfQu\u00e9 valores puede asumir la variable aleatoria? c) \u00bfLa variable es discreta o continua?  a) La variable aleatoria que representa el tiempo en minutos requerido para ensamblar el producto se puede definir como: In\u00a0[\u00a0]: Copied! <pre>def tiempo_ensamblaje(minutos):\n    return minutos\n</pre> def tiempo_ensamblaje(minutos):     return minutos  b) La variable aleatoria puede asumir cualquier valor real positivo, ya que el tiempo de ensamblaje puede ser cualquier n\u00famero de minutos mayor que cero. c) La variable es continua, ya que puede asumir cualquier valor real en el intervalo (0, infinito).  In\u00a0[8]: Copied! <pre># Variable aleatoria\ndef tiempo_ensamblaje(minutos):\n  return minutos\n\n# Valores posibles\ndatos = list(tiempo_ensamblaje(minutos) for minutos in range(1, 100))\n\nfor i in range(0, len(datos), 10):\n  print(datos[i:i+10])\n  print()\n</pre> # Variable aleatoria def tiempo_ensamblaje(minutos):   return minutos  # Valores posibles datos = list(tiempo_ensamblaje(minutos) for minutos in range(1, 100))  for i in range(0, len(datos), 10):   print(datos[i:i+10])   print()  <pre>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n[11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n\n[21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n\n[31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n\n[41, 42, 43, 44, 45, 46, 47, 48, 49, 50]\n\n[51, 52, 53, 54, 55, 56, 57, 58, 59, 60]\n\n[61, 62, 63, 64, 65, 66, 67, 68, 69, 70]\n\n[71, 72, 73, 74, 75, 76, 77, 78, 79, 80]\n\n[81, 82, 83, 84, 85, 86, 87, 88, 89, 90]\n\n[91, 92, 93, 94, 95, 96, 97, 98, 99]\n\n</pre> <p>Ejercicio. La tabla siguiente proporciona una distribuci\u00f3n de probabilidad para la variable aleatoria $x$.</p> $x$ $f(x)$ 3 0.25 6 0.50 9 0.25 <p>a) Calcule $E(x)$, el valor esperado de $x$.</p> <p>El valor esperado se calcula utilizando la f\u00f3rmula: $$ E(x) = \\sum_{i} x_i \\cdot P(x_i) $$</p> <p>Donde:</p> <ul> <li>$(x_i)$ son los valores de la variable aleatoria,</li> <li>$P(x_i)$ son las probabilidades correspondientes.</li> </ul> <p>Para la distribuci\u00f3n dada:</p> <p>$ E(x) = 3 \\cdot 0.25 + 6 \\cdot 0.50 + 9 \\cdot 0.25 = 6 $</p> <p>Por lo tanto, el valor esperado $E(x)$ es 6.</p> <p>b) Estime $\u03c3^2$, la varianza de $x$.</p> <p>La varianza se calcula utilizando la f\u00f3rmula:</p> <p>$$ \\sigma^2 = \\sum_{i} (x_i - E(x))^2 \\cdot P(x_i)  $$</p> <p>Para la distribuci\u00f3n dada:</p> <p>$ \\sigma^2 = (3-6)^2 \\cdot 0.25 + (6-6)^2 \\cdot 0.50 + (9-6)^2 \\cdot 0.25 = 4.5 $</p> <p>Por lo tanto, la varianza $\\sigma^2$ es 4.5.</p> <p>c) Calcule $\u03c3$, la desviaci\u00f3n est\u00e1ndar de $x$.</p> <p>La desviaci\u00f3n est\u00e1ndar se obtiene tomando la ra\u00edz cuadrada de la varianza:</p> <p>$ \\sigma = \\sqrt{\\sigma^2} = \\sqrt{4.5} \\approx 2.12 $ Por lo tanto, la desviaci\u00f3n est\u00e1ndar $\\sigma$ es aproximadamente 2.12.</p> In\u00a0[75]: Copied! <pre>import math\n\n# Datos de la distribuci\u00f3n de probabilidad\nvalores_x = [3, 6, 9]\nprobabilidades = [0.25, 0.50, 0.25]\n\n# a) Valor esperado (E(x))\nesperanza = sum(x * p for x, p in zip(valores_x, probabilidades))\nprint(f\"Valor esperado (E(x)): {esperanza}\")\n\n# b) Varianza (\u03c3^2)\nvarianza = sum((x - esperanza) ** 2 * p for x, p in zip(valores_x, probabilidades))\nprint(f\"Varianza (\u03c3^2): {varianza}\")\n\n# c) Desviaci\u00f3n est\u00e1ndar (\u03c3)\ndesviacion_estandar = math.sqrt(varianza)\nprint(f\"Desviaci\u00f3n est\u00e1ndar (\u03c3): {desviacion_estandar}\")\n</pre> import math  # Datos de la distribuci\u00f3n de probabilidad valores_x = [3, 6, 9] probabilidades = [0.25, 0.50, 0.25]  # a) Valor esperado (E(x)) esperanza = sum(x * p for x, p in zip(valores_x, probabilidades)) print(f\"Valor esperado (E(x)): {esperanza}\")  # b) Varianza (\u03c3^2) varianza = sum((x - esperanza) ** 2 * p for x, p in zip(valores_x, probabilidades)) print(f\"Varianza (\u03c3^2): {varianza}\")  # c) Desviaci\u00f3n est\u00e1ndar (\u03c3) desviacion_estandar = math.sqrt(varianza) print(f\"Desviaci\u00f3n est\u00e1ndar (\u03c3): {desviacion_estandar}\") <pre>Valor esperado (E(x)): 6.0\nVarianza (\u03c3^2): 4.5\nDesviaci\u00f3n est\u00e1ndar (\u03c3): 2.1213203435596424\n</pre> <p>Ejercicio. La tabla siguiente proporciona una distribuci\u00f3n de probabilidad para la variable aleatoria $y$.</p> $y$ $f(y)$ 2 0.20 4 0.30 7 0.40 8 0.10 <p>a) Calcule $E(y)$.</p> <p>La esperanza matem\u00e1tica se calcula sumando el producto de cada valor de la variable y su probabilidad correspondiente:</p> <p>$$ E(y) = \\sum_{i} y_i \\cdot f(y_i)  $$</p> <p>En este caso:</p> <p>$ E(y) = 2 \\cdot 0.20 + 4 \\cdot 0.30 + 7 \\cdot 0.40 + 8 \\cdot 0.10 $</p> <p>$ E(y) = 0.40 + 1.20 + 2.80 + 0.80 $</p> <p>$ E(y) = 5.20 $</p> <p>Por lo tanto, $ E(y) = 5.20 $</p> <p>b) Calcule $Var (y)$ y $\u03c3$. La varianza se calcula sumando los cuadrados de las diferencias entre cada valor de la variable y la media, ponderado por sus probabilidades:</p> <p>$ Var(y) = \\sum_{i} (y_i - E(y))^2 \\cdot f(y_i) $</p> <p>En este caso:</p> <p>$ Var(y) = (2 - 5.20)^2 \\cdot 0.20 + (4 - 5.20)^2 \\cdot 0.30 + (7 - 5.20)^2 \\cdot 0.40 + (8 - 5.20)^2 \\cdot 0.10 $</p> <p>$Var(y) = 3.20^2 \\cdot 0.20 + 1.20^2 \\cdot 0.30 + 1.80^2 \\cdot 0.40 + 2.80^2 \\cdot 0.10 $</p> <p>$ Var(y) = 10.24 \\cdot 0.20 + 1.44 \\cdot 0.30 + 3.24 \\cdot 0.40 + 7.84 \\cdot 0.10 $</p> <p>$ Var(y) = 2.048 + 0.432 + 1.296 + 0.784 $</p> <p>$ Var(y) = 4.560 $</p> <p>La desviaci\u00f3n est\u00e1ndar $\\sigma$ es la ra\u00edz cuadrada de la varianza:</p> <p>$ \\sigma = \\sqrt{Var(y)} $</p> <p>$ \\sigma = \\sqrt{4.560} $</p> <p>$ \\sigma \\approx 2.136 $</p> <p>Por lo tanto, $ Var(y) \\approx 4.560 $ y $ \\sigma \\approx 2.136 $.</p> In\u00a0[76]: Copied! <pre># Datos de la distribuci\u00f3n de probabilidad\nvalores_y = [2, 4, 7, 8]\nprobabilidades = [0.20, 0.30, 0.40, 0.10]\n\n# Calculando E(y)\nesperanza_y = sum(y * f_y for y, f_y in zip(valores_y, probabilidades))\nprint(f'E(y) = {esperanza_y:.2f}')\n\n# Calculando Var(y)\nvarianza_y = sum((y - esperanza_y)**2 * f_y for y, f_y in zip(valores_y, probabilidades))\nprint(f'Var(y) = {varianza_y:.3f}')\n\n# Calculando la desviaci\u00f3n est\u00e1ndar (\u03c3)\ndesviacion_estandar = varianza_y**0.5\nprint(f'\u03c3 = {desviacion_estandar:.3f}')\n</pre> # Datos de la distribuci\u00f3n de probabilidad valores_y = [2, 4, 7, 8] probabilidades = [0.20, 0.30, 0.40, 0.10]  # Calculando E(y) esperanza_y = sum(y * f_y for y, f_y in zip(valores_y, probabilidades)) print(f'E(y) = {esperanza_y:.2f}')  # Calculando Var(y) varianza_y = sum((y - esperanza_y)**2 * f_y for y, f_y in zip(valores_y, probabilidades)) print(f'Var(y) = {varianza_y:.3f}')  # Calculando la desviaci\u00f3n est\u00e1ndar (\u03c3) desviacion_estandar = varianza_y**0.5 print(f'\u03c3 = {desviacion_estandar:.3f}') <pre>E(y) = 5.20\nVar(y) = 4.560\n\u03c3 = 2.135\n</pre> <p>Aplicaciones </p> <p>Ejercicio </p> Tres estudiantes programaron entrevistas para un empleo de verano. En cada caso el resultado de la entrevista ser\u00e1 una oferta de empleo o ninguna oferta. Los resultados experimentales se definen en funci\u00f3n de los resultados de las tres entrevistas. a) Prepare una lista de los resultados experimentales. b) Defina una variable aleatoria que representa el n\u00famero de ofertas de empleo formuladas. \u00bfLa variable aleatoria es continua? c) Muestre el valor de la variable aleatoria para cada uno de los resultados experimentales.  a) La variable aleatoria que representa el tiempo en minutos requerido para ensamblar el producto se puede definir como: In\u00a0[\u00a0]: Copied! <pre>espacio_muestral = {\n    (0, 0, 0),\n    (0, 0, 1),\n    (0, 1, 0),\n    (0, 1, 1),\n    (1, 0, 0),\n    (1, 0, 1),\n    (1, 1, 0),\n    (1, 1, 1),\n}\n</pre> espacio_muestral = {     (0, 0, 0),     (0, 0, 1),     (0, 1, 0),     (0, 1, 1),     (1, 0, 0),     (1, 0, 1),     (1, 1, 0),     (1, 1, 1), }  b) La variable aleatoria que representa el n\u00famero de ofertas de empleo formuladas se puede definir como: In\u00a0[9]: Copied! <pre>def numero_ofertas(resultado):\n    ofertas = 0\n    for i in resultado:\n        if i == 1:\n            ofertas += 1\n    return ofertas\n</pre> def numero_ofertas(resultado):     ofertas = 0     for i in resultado:         if i == 1:             ofertas += 1     return ofertas  c) El valor que la variable aleatoria asumir\u00eda en cada uno de los resultados experimentales es el siguiente: In\u00a0[11]: Copied! <pre>espacio_muestral = {\n    (0, 0, 0),\n    (0, 0, 1),\n    (0, 1, 0),\n    (0, 1, 1),\n    (1, 0, 0),\n    (1, 0, 1),\n    (1, 1, 0),\n    (1, 1, 1),\n}\ndef numero_ofertas(resultado):\n    ofertas = 0\n    for i in resultado:\n        if i == 1:\n            ofertas += 1\n    return ofertas\n\nfor resultado in espacio_muestral:\n    print(resultado, numero_ofertas(resultado))\n</pre> espacio_muestral = {     (0, 0, 0),     (0, 0, 1),     (0, 1, 0),     (0, 1, 1),     (1, 0, 0),     (1, 0, 1),     (1, 1, 0),     (1, 1, 1), } def numero_ofertas(resultado):     ofertas = 0     for i in resultado:         if i == 1:             ofertas += 1     return ofertas  for resultado in espacio_muestral:     print(resultado, numero_ofertas(resultado))  <pre>(1, 0, 1) 2\n(1, 1, 0) 2\n(0, 1, 0) 1\n(0, 0, 0) 0\n(1, 0, 0) 1\n(0, 0, 1) 1\n(1, 1, 1) 3\n(0, 1, 1) 2\n</pre> <p>Ejercicio. La distribuci\u00f3n de probabilidad para la variable aleatoria x se presenta enseguida</p> x f(x) 20 0.20 25 0.15 30 0.25 35 0.40 a) \u00bfEs v\u00e1lida esta distribuci\u00f3n de probabilidad? Explique por qu\u00e9. b) \u00bfCu\u00e1l es la probabilidad de que x = 30? c) \u00bfQu\u00e9 probabilidad existe de que x sea menor o igual que 25? d) \u00bfCu\u00e1l es la probabilidad de que x sea mayor que 30? a) Para que una distribuci\u00f3n de probabilidad sea v\u00e1lida, debe cumplir con las siguientes condiciones:  <p>La suma de todas las probabilidades debe ser igual a 1. Cada probabilidad debe ser mayor o igual que 0. En el caso de la distribuci\u00f3n de probabilidad dada, la suma de las probabilidades es:</p> <p>0.20 + 0.15 + 0.25 + 0.40 = 1.00</p> b) La probabilidad de que x = 30 es la suma de las probabilidades de que x sea igual a 20 o 25. En este caso, la probabilidad es:  <p>0.20 + 0.15 = 0.35</p> c) La probabilidad de que x sea menor o igual que 25 es la suma de las probabilidades de que x sea igual a 20, 25 o 30. En este caso, la probabilidad es:  <p>0.20 + 0.15 + 0.25 = 0.60</p> <p>d) La probabilidad de que x sea mayor que 30 es la probabilidad de que x sea igual a 35. En este caso, la probabilidad es:</p> <p>0.40</p> <p>Ejercicio.  8. Los datos siguientes se obtuvieron por conteo del n\u00famero de salas de operaciones en uso en el Hospital General Tampa durante un periodo de 20 d\u00edas: en tres de estos d\u00edas s\u00f3lo se us\u00f3 una sala de cirug\u00eda; en cinco de estos d\u00edas se usaron dos; en ocho d\u00edas se utilizaron tres, y en cuatro d\u00edas se usaron las cuatro salas de operaciones del hospital. a) Use el m\u00e9todo de frecuencia relativa a efecto de construir una distribuci\u00f3n de probabilidad para el n\u00famero de salas de operaci\u00f3n en uso en cualquier d\u00eda dado. b) Muestre que su distribuci\u00f3n de probabilidad satisface las condiciones requeridas para una distribuci\u00f3n de probabilidad discreta v\u00e1lida.</p> a) La distribuci\u00f3n de probabilidad para el n\u00famero de salas de operaciones en uso en cualquier d\u00eda dado se puede construir utilizando el m\u00e9todo de frecuencia relativa como se muestra a continuaci\u00f3n:  x f(x) 3/20 0.15 5/20 0.25 8/20 0.40 4/20 0.20 b) Las condiciones requeridas para una distribuci\u00f3n de probabilidad discreta v\u00e1lida son las siguientes:  <p>La suma de todas las probabilidades debe ser igual a 1. En este caso, la suma de las probabilidades es: 0.15 + 0.25 + 0.40 + 0.20 = 1.00</p> <p>Ejercicio. El n\u00famero de estudiantes que presentan la prueba de aptitudes escolares SAT ha aumentado a una cifra sin precedente de 1.5 millones (Consejo del Colegio, 26 de agosto de 2008). Se permit que los estudiantes repitan la prueba con la esperanza de que mejoren la calificaci\u00f3n q e se env\u00eda a las oficinas de admisi\u00f3n de los colegios y universidades. El n\u00famero de veces que la SAT fue presentada y el n\u00famero de estudiantes son los siguientes.</p> N\u00famero de veces N\u00famero de estudiantes 1 721 769 2 601 325 3 166 736 4 22 299 5 6 730 <p>a) Sea x una variable aleatoria que indica el n\u00famero de veces que un estudiante presenta el SAT. Muestre la distribuci\u00f3n de probabilidad para esta variable aleatoria.87 $</p> <p>$ P(X=1) : \\frac{721,769}{1,500,000} = 0.481179 $</p> <p>$ P(X=2) : \\frac{601,325}{1,500,000} = 0.400883 $</p> <p>$ P(X=3) : \\frac{166,736}{1,500,000} = 0.111157 $</p> <p>$ P(X=4) : \\frac{22,299}{1,500,000} = 0.014866 $</p> <p>$ P(X=5) : \\frac{6,730}{1,500,000} = 0.004487 $</p> <p>b) \u00bfCu\u00e1l es la probabilidad de que un estudiante presente el SAT m\u00e1s de una vez?</p> <p>$ P(X &gt; 1) = 0.400883 + 0.111157 + 0.014866 + 0.004487 = 0.531393 $</p> <p>c) \u00bfCu\u00e1l es la probabilidad de que un estudiante lo presente tres o m\u00e1s veces?</p> <p>$ P(X \\geq 3) = 0.111157 + 0.014866 + 0.004487 = 0.13051 $</p> <p>d) \u00bfCu\u00e1l es el valor esperado del n\u00famero de veces que se presenta el SAT? \u00bfCu\u00e1l es su interpretaci\u00f3n del valor esperado?</p> <p>$ \\mu = 1 \\cdot 0.481179 + 2 \\cdot 0.400883 + 3 \\cdot 0.111157 + 4 \\cdot 0.014866 + 5 \\cdot 0.004487 $</p> <p>$ \\mu = 0.481179 + 0.801766 + 0.333471 + 0.059464 + 0.022435 $</p> <p>$ \\mu = 1.698315 $</p> <p>e) \u00bfCu\u00e1les son la varianza y la desviaci\u00f3n est\u00e1ndar para el n\u00famero de veces que se presenta el SAT?</p> <p>$ \\sigma^2 = (1 - \\mu)^2 \\cdot 0.481179 + (2 - \\mu)^2 \\cdot 0.400883 + (3 - \\mu)^2 \\cdot 0.111157 + (4 - \\mu)^2 \\cdot 0.014866 + (5 - \\mu)^2 \\cdot 0.004487 $</p> <p>Calculando:</p> <p>$ \\sigma^2 \\approx 0.5871 $</p> <p>$ \\sigma \\approx \\sqrt{0.5871} \\approx 0.7663 $</p> In\u00a0[77]: Copied! <pre>import numpy as np\n\n# Datos proporcionados\nnum_estudiantes = 1500000\nnum_veces = np.array([1, 2, 3, 4, 5])\nnum_estudiantes_por_veces = np.array([721769, 601325, 166736, 22299, 6730])\n\n# Distribuci\u00f3n de probabilidad\nprobabilidad = num_estudiantes_por_veces / num_estudiantes\n\n# b) Probabilidad de presentar el SAT m\u00e1s de una vez\nprob_mas_de_una_vez = np.sum(probabilidad[1:])\n\n# c) Probabilidad de presentar el SAT tres o m\u00e1s veces\nprob_tres_o_mas = np.sum(probabilidad[2:])\n\n# d) Valor esperado\nvalor_esperado = np.sum(num_veces * probabilidad)\n\n# e) Varianza y desviaci\u00f3n est\u00e1ndar\nvarianza = np.sum((num_veces - valor_esperado)**2 * probabilidad)\ndesviacion_estandar = np.sqrt(varianza)\n\n# Resultados\nprint(f'Distribuci\u00f3n de probabilidad: {dict(zip(num_veces, probabilidad))}')\nprint(f'Probabilidad de presentar el SAT m\u00e1s de una vez: {prob_mas_de_una_vez:.4f}')\nprint(f'Probabilidad de presentar el SAT tres o m\u00e1s veces: {prob_tres_o_mas:.4f}')\nprint(f'Valor esperado: {valor_esperado:.4f}')\nprint(f'Varianza: {varianza:.4f}')\nprint(f'Desviaci\u00f3n est\u00e1ndar: {desviacion_estandar:.4f}')\n</pre> import numpy as np  # Datos proporcionados num_estudiantes = 1500000 num_veces = np.array([1, 2, 3, 4, 5]) num_estudiantes_por_veces = np.array([721769, 601325, 166736, 22299, 6730])  # Distribuci\u00f3n de probabilidad probabilidad = num_estudiantes_por_veces / num_estudiantes  # b) Probabilidad de presentar el SAT m\u00e1s de una vez prob_mas_de_una_vez = np.sum(probabilidad[1:])  # c) Probabilidad de presentar el SAT tres o m\u00e1s veces prob_tres_o_mas = np.sum(probabilidad[2:])  # d) Valor esperado valor_esperado = np.sum(num_veces * probabilidad)  # e) Varianza y desviaci\u00f3n est\u00e1ndar varianza = np.sum((num_veces - valor_esperado)**2 * probabilidad) desviacion_estandar = np.sqrt(varianza)  # Resultados print(f'Distribuci\u00f3n de probabilidad: {dict(zip(num_veces, probabilidad))}') print(f'Probabilidad de presentar el SAT m\u00e1s de una vez: {prob_mas_de_una_vez:.4f}') print(f'Probabilidad de presentar el SAT tres o m\u00e1s veces: {prob_tres_o_mas:.4f}') print(f'Valor esperado: {valor_esperado:.4f}') print(f'Varianza: {varianza:.4f}') print(f'Desviaci\u00f3n est\u00e1ndar: {desviacion_estandar:.4f}') <pre>Distribuci\u00f3n de probabilidad: {1: 0.48117933333333335, 2: 0.4008833333333333, 3: 0.11115733333333333, 4: 0.014866, 5: 0.004486666666666667}\nProbabilidad de presentar el SAT m\u00e1s de una vez: 0.5314\nProbabilidad de presentar el SAT tres o m\u00e1s veces: 0.1305\nValor esperado: 1.6983\nVarianza: 0.5871\nDesviaci\u00f3n est\u00e1ndar: 0.7663\n</pre> <p>Ejercicio. El estudio American Housing Survey report\u00f3 los datos siguientes sobre el n\u00famero de rec\u00e1maras ocupadas en casas propias y rentadas en las ciudades centrales (sitio web de la Oficina del Censo de Estados Unidos, 31 de marzo de 2003).</p> <p>Numero de casas(miles) </p> Recamaras Rentadas Propias $0$ 547 23 $1$ 5 012 541 $2$ 6 100 3 832 $3$ 2 644 8 690 4 o mas 557 3 783 <p>a) Defina una variable aleatoria x = n\u00famero de rec\u00e1maras en las casas rentadas y elabore una distribuci\u00f3n de probabilidad para la variable aleatoria (x = 4 representa 4 o m\u00e1s rec\u00e1maras.)</p> <p>b) Calcule el valor esperado y la varianza del n\u00famero de rec\u00e1maras en las casas rentadas.</p> $x$ $f(x)$ $xf(x)$ $x - \\mu$ $(x - \\mu)^2$ $(x - \\mu)^2f(x)$ $0$ $0.04$ $0.00$ $-1.84$ $3.39$ $0.12$ $1$ $0.34$ $0.34$ $-0.84$ $0.71$ $0.24$ $2$ $0.41$ $0.82$ $0.16$ $0.02$ $0.01$ $3$ $0.18$ $0.53$ $1.16$ $1.34$ $0.24$ $4$ $0.04$ $0.15$ $2.16$ $4.66$ $0.17$ $Total$ $1.00$ $1.84$ $0.79$ $E(x)$ $Var(x)$ <p>c) Defina una variable aleatoria y = n\u00famero de rec\u00e1maras en las casas propias, y elabore una distribuci\u00f3n de probabilidad para la variable aleatoria (y = 4 representa 4 o m\u00e1s rec\u00e1maras.)</p> <p>d) Calcule el valor esperado y la varianza para el n\u00famero de rec\u00e1maras en las casas propias.</p> $y$ $f(y)$ $yf(y)$ $y - \\mu$ $(y - \\mu)^2$ $(y - \\mu)^2f(y)$ $0$ $0.00$ $0.00$ $-2.93$ $8.58$ $0.01$ $1$ $0.03$ $0.03$ $-1.93$ $3.72$ $0.12$ $2$ $0.23$ $0.45$ $-0.93$ $0.86$ $0.20$ $3$ $0.52$ $1.55$ $0.07$ $0.01$ $0.00$ $4$ $0.22$ $0.90$ $1.07$ $1.15$ $0.26$ $Total$ $1.00$ $2.93$ $0.59$ $E(x)$ $Var(x)$ <p>e) \u00bfQu\u00e9 observaciones puede hacer de la comparaci\u00f3n del n\u00famero de rec\u00e1maras en casas rentadas en comparaci\u00f3n con las casas propias?</p> <p>R. El n\u00famero de recamaras en casas ocupadas de propietarios es mayor a las rentadas y la variabilidad de casas propias es menor a las rentadas</p> In\u00a0[78]: Copied! <pre># Datos proporcionados\nrecamaras_rentadas = [0, 1, 2, 3, 4]\ncasas_rentadas = [547, 5012, 6100, 2644, 557]\n\nrecamaras_propias = [0, 1, 2, 3, 4]\ncasas_propias = [23, 541, 3832, 8690, 3783]\n\n# Funci\u00f3n para calcular el valor esperado y la varianza\ndef calcular_esperanza_varianza(valores, probabilidades):\n    esperanza = sum(valores[i] * probabilidades[i] for i in range(len(valores)))\n    varianza = sum((valores[i] - esperanza) ** 2 * probabilidades[i] for i in range(len(valores)))\n    return esperanza, varianza\n\n# Calcula el valor esperado y la varianza para casas rentadas\nesperanza_rentadas, varianza_rentadas = calcular_esperanza_varianza(recamaras_rentadas, [i/sum(casas_rentadas) for i in casas_rentadas])\n\n# Calcula el valor esperado y la varianza para casas propias\nesperanza_propias, varianza_propias = calcular_esperanza_varianza(recamaras_propias, [i/sum(casas_propias) for i in casas_propias])\n\n# Imprime los resultados\nprint(\"Casas Rentadas:\")\nprint(\"Valor Esperado:\", esperanza_rentadas)\nprint(\"Varianza:\", varianza_rentadas)\n\nprint(\"\\nCasas Propias:\")\nprint(\"Valor Esperado:\", esperanza_propias)\nprint(\"Varianza:\", varianza_propias)\n</pre> # Datos proporcionados recamaras_rentadas = [0, 1, 2, 3, 4] casas_rentadas = [547, 5012, 6100, 2644, 557]  recamaras_propias = [0, 1, 2, 3, 4] casas_propias = [23, 541, 3832, 8690, 3783]  # Funci\u00f3n para calcular el valor esperado y la varianza def calcular_esperanza_varianza(valores, probabilidades):     esperanza = sum(valores[i] * probabilidades[i] for i in range(len(valores)))     varianza = sum((valores[i] - esperanza) ** 2 * probabilidades[i] for i in range(len(valores)))     return esperanza, varianza  # Calcula el valor esperado y la varianza para casas rentadas esperanza_rentadas, varianza_rentadas = calcular_esperanza_varianza(recamaras_rentadas, [i/sum(casas_rentadas) for i in casas_rentadas])  # Calcula el valor esperado y la varianza para casas propias esperanza_propias, varianza_propias = calcular_esperanza_varianza(recamaras_propias, [i/sum(casas_propias) for i in casas_propias])  # Imprime los resultados print(\"Casas Rentadas:\") print(\"Valor Esperado:\", esperanza_rentadas) print(\"Varianza:\", varianza_rentadas)  print(\"\\nCasas Propias:\") print(\"Valor Esperado:\", esperanza_propias) print(\"Varianza:\", varianza_propias) <pre>Casas Rentadas:\nValor Esperado: 1.8419919246298788\nVarianza: 0.7874156823035636\n\nCasas Propias:\nValor Esperado: 2.9288635959452254\nVarianza: 0.5869130544273087\n</pre> <p>Ejercicio. La LNB (Liga Nacional de Basquet) lleva un registro de una variedad de estad\u00edsticas para cada equipo. Dos de \u00e9stas registran el porcentaje de tiros de campo y el porcentaje de tiros de tres puntos efectuados por equipo. Los registros de tiros de los 29 equipos de la LNB para una parte de la temporada 2004 mostraban que la probabilidad de anotar dos puntos en un tiro de campo era de 0.44, y la probabilidad de anotar tres puntos al hacer un tiro de tres puntos era de 0.34.</p> <p>a) \u00bfCu\u00e1l es el valor esperado de un tiro de dos puntos para estos equipos?</p> <p>$ \\text{Valor Esperado} = (\\text{Probabilidad de anotar dos puntos}) \\times (\\text{Puntuaci\u00f3n por tiro de dos puntos}) $</p> <p>$ \\text{Valor Esperado} = 0.44 \\times 2 = 0.88 $</p> <p>b) \u00bfCu\u00e1l es el valor esperado de un tiro de tres puntos para estos equipos?</p> <p>$ \\text{Valor Esperado} = (\\text{Probabilidad de anotar tres puntos}) \\times (\\text{Puntuaci\u00f3n por tiro de tres puntos}) $</p> <p>$ \\text{Valor Esperado} = 0.34 \\times 3 = 1.02 $</p> <p>c) Si la probabilidad de hacer un tiro de dos puntos es mayor que la de hacer un tiro de tres puntos, \u00bfpor qu\u00e9 los entrenadores permiten que algunos jugadores lancen tiros de tres puntos si tienen la oportunidad? Use el valor esperado para explicar su respuesta.</p> <p>R. Los entrenadores permiten y fomentan los tiros de tres puntos porque, en t\u00e9rminos de valor esperado, son m\u00e1s beneficiosos para el equipo en comparaci\u00f3n con los tiros de dos puntos.</p> In\u00a0[79]: Copied! <pre># Datos proporcionados\nprobabilidad_dos_puntos = 0.44\nprobabilidad_tres_puntos = 0.34\npuntuacion_dos_puntos = 2\npuntuacion_tres_puntos = 3\n\n# C\u00e1lculo del valor esperado\nvalor_esperado_dos_puntos = probabilidad_dos_puntos * puntuacion_dos_puntos\nvalor_esperado_tres_puntos = probabilidad_tres_puntos * puntuacion_tres_puntos\n\n# Resultados\nprint(\"a) Valor Esperado de un Tiro de Dos Puntos:\", valor_esperado_dos_puntos)\nprint(\"b) Valor Esperado de un Tiro de Tres Puntos:\", valor_esperado_tres_puntos)\n</pre> # Datos proporcionados probabilidad_dos_puntos = 0.44 probabilidad_tres_puntos = 0.34 puntuacion_dos_puntos = 2 puntuacion_tres_puntos = 3  # C\u00e1lculo del valor esperado valor_esperado_dos_puntos = probabilidad_dos_puntos * puntuacion_dos_puntos valor_esperado_tres_puntos = probabilidad_tres_puntos * puntuacion_tres_puntos  # Resultados print(\"a) Valor Esperado de un Tiro de Dos Puntos:\", valor_esperado_dos_puntos) print(\"b) Valor Esperado de un Tiro de Tres Puntos:\", valor_esperado_tres_puntos) <pre>a) Valor Esperado de un Tiro de Dos Puntos: 0.88\nb) Valor Esperado de un Tiro de Tres Puntos: 1.02\n</pre> <p>Ejercicio. La distribuci\u00f3n de probabilidad de las reclamaciones por da\u00f1os que pag\u00f3 Newton Automobile Insurance Company por seguro contra choques es la siguiente.</p> Pago($) Probabilidad 0 0.85 500 0.04 1 000 0.04 3 000 0.03 5 000 0.02 8 000 0.01 10 000 0.01 <p>a) Use el pago de choque esperado para determinar la prima del seguro contra colisiones que permitir\u00eda a la empresa no ganar ni perder.</p> <p>El pago de choque esperado se calcula sumando el producto de cada pago posible y su probabilidad asociada.</p> <p>$ \\text{Pago esperado} = \\sum_{i=1}^{n} (\\text{Pago}_i \\times \\text{Probabilidad}_i) $</p> <p>Sustituyendo los valores dados:</p> <p>$ \\text{Pago esperado} = (0 \\times 0.85) + (500 \\times 0.04) + (1,000 \\times 0.04) + (3,000 \\times 0.03) + (5,000 \\times 0.02) + (8,000 \\times 0.01) + (10,000 \\times 0.01) $</p> <p>Calculando:</p> <p>$ \\text{Pago esperado} = 0 + 20 + 40 + 90 + 100 + 80 + 100 = 430 $</p> <p>Por lo tanto, el pago de choque esperado es de $430.</p> <p>b) La compa\u00f1\u00eda de seguros cobra una tarifa anual de $520 por la cobertura de choques. \u00bfCu\u00e1l es el valor esperado del seguro contra choques para un asegurado? (Pista: son los pagos esperados de la empresa menos el costo de cobertura.) \u00bfPor qu\u00e9 el cliente compra un seguro contra colisiones con este valor esperado?</p> <p>El valor esperado del seguro se obtiene restando el costo de la cobertura del pago esperado de choques.</p> <p>$ \\text{Valor esperado del seguro} = \\text{Pago esperado} - \\text{Costo de cobertura} $</p> <p>Sustituyendo los valores dados:</p> <p>$ \\text{Valor esperado del seguro} = 430 - 520 = -90 $</p> <p>-90, Porque busca protegerse a toda costa contra el gasto de una gran perdida.</p> In\u00a0[80]: Copied! <pre># Definir los pagos y sus probabilidades\npagos = [0, 500, 1000, 3000, 5000, 8000, 10000]\nprobabilidades = [0.85, 0.04, 0.04, 0.03, 0.02, 0.01, 0.01]\n\n# Calcular el pago de choque esperado\npago_esperado = sum(p * prob for p, prob in zip(pagos, probabilidades))\nprint(\"Pago de choque esperado:\", pago_esperado)\n\n# Costo de cobertura anual\ncosto_cobertura = 520\n\n# Calcular el valor esperado del seguro\nvalor_esperado_seguro = pago_esperado - costo_cobertura\nprint(\"Valor esperado del seguro:\", valor_esperado_seguro)\n</pre> # Definir los pagos y sus probabilidades pagos = [0, 500, 1000, 3000, 5000, 8000, 10000] probabilidades = [0.85, 0.04, 0.04, 0.03, 0.02, 0.01, 0.01]  # Calcular el pago de choque esperado pago_esperado = sum(p * prob for p, prob in zip(pagos, probabilidades)) print(\"Pago de choque esperado:\", pago_esperado)  # Costo de cobertura anual costo_cobertura = 520  # Calcular el valor esperado del seguro valor_esperado_seguro = pago_esperado - costo_cobertura print(\"Valor esperado del seguro:\", valor_esperado_seguro) <pre>Pago de choque esperado: 430.0\nValor esperado del seguro: -90.0\n</pre> Se muestra c\u00f3digo en Python para elaborar una gr\u00e1fica de barras de estadistica con color de fondo y modificando el ancho de las barras importando la libreria de python mayplotlib.pyplot."},{"location":"capitulo5/","title":"\u00b6","text":"CAPITULO 5  DISTRIBUCIONES DE PROBABILIDAD DISCRETA Contenido <p>5.1 VARIABLES ALEATORIAS</p> <ul> <li>Variables aleatorias discretas</li> <li>Variables aleatorias continuas</li> </ul> <p>5.2 DISTRIBUCIONES DE PROBABILIDAD DISCRETA</p> <p>5.3 VALOR ESPERADO Y VARIANZA</p> <ul> <li>Valor esperado</li> <li>Varianza</li> </ul> <p>5.4 DISTRIBUCI\u00d3N DE PROBABILIDAD BINOMIAL</p> <ul> <li>Un experimento binomial</li> <li>El problema de Big Sur</li> <li>Uso de tablas de probabilidades binomiales</li> <li>Valor esperado y varianza de la distribuci\u00f3n binomial</li> </ul> <p>5.5 DISTRIBUCI\u00d3N DE PROBABILIDAD DE POISSON</p> <ul> <li>Un ejemplo con intervalos de tiempo</li> <li>Un ejemplo con intervalos de longitud o de distancia</li> </ul> <p>5.6 DISTRIBUCI\u00d3N DE PROBABILIDAD HIPERGEOM\u00c9TRICA</p>"},{"location":"capitulo5/#51-variables-aleatorias","title":"5.1 Variables aleatorias\u00b6","text":""},{"location":"capitulo5/#notas-y-comentarios","title":"NOTAS Y COMENTARIOS\u00b6","text":"<p> Una forma de determinar si una variable aleatoria es discreta o continua es pensar en sus valores como puntos en un segmento de recta. Elija dos puntos que representen valores de la variable aleatoria. Si todo el segmento de recta entre los dos puntos representa tambi\u00e9n los valores posibles de la variable aleatoria, entonces \u00e9sta es continua.</p>"},{"location":"capitulo5/#52-distribuciones-de-probabilidad-discreta","title":"5.2 Distribuciones de probabilidad discreta\u00b6","text":"La distribuci\u00f3n de probabilidad de una variable aleatoria describe c\u00f3mo se distribuyen las probabilidades entre los valores de la misma. Para una variable aleatoria discreta x, la distribuci\u00f3n de probabilidad se define por medio de una funci\u00f3n de probabilidad, denotada por f (x). La funci\u00f3n de probabilidad proporciona la probabilidad para cada valor que puede asumir la variable aleatoria. Como ejemplo de una variable aleatoria discreta y su distribuci\u00f3n de probabilidad, considere las ventas de autom\u00f3viles en DiCarlo Motors, con sede en Saratoga, Nueva York. Durante los \u00faltimos 300 d\u00edas de operaci\u00f3n, los datos de ventas mostraron que en 54 d\u00edas no se vendi\u00f3 ning\u00fan autom\u00f3vil, en 117 d\u00edas se vendi\u00f3 1 autom\u00f3vil, en 72 d\u00edas se vendieron 2, en 42 d\u00edas se vendieron 3, en 12 d\u00edas se vendieron 4 y en 3 d\u00edas se vendieron 5. Suponga que se considera el experimento de seleccionar un d\u00eda de operaci\u00f3n en DiCarlo Motors y se defi ne la variable aleatoria de inter\u00e9s como x = n\u00famero de autom\u00f3viles vendidos en un d\u00eda. A partir de los datos hist\u00f3ricos, sabemos que x es una variable aleatoria discreta que puede asumir los valores 0, 1, 2, 3, 4 o 5. En la notaci\u00f3n de la funci\u00f3n de probabilidad, f (0) es la probabilidad de vender 0 unidades, f(1) es la probabilidad de vender 1 autom\u00f3vil, y as\u00ed sucesivamente. Dado que los datos hist\u00f3ricos muestran que en 54 de los 300 d\u00edas se vendieron 0 unidades, se asigna el valor 54/300 = 0.18 a f(0), lo que indica que la probabilidad de que se vendan 0 autom\u00f3viles en un d\u00eda es de 0.18. Asimismo, como en 117 de los 300 d\u00edas se vendi\u00f3 un veh\u00edculo, se asigna el valor 117/300 = 0.39 a f (1), indicando que la probabilidad de que se venda exactamente 1 autom\u00f3vil en un d\u00eda es de 0.39. Si se contin\u00faa de esta manera para los otros valores de la variable aleatoria, obtenemos los valores de f (2), f (3), f (4) y f (5) como muestra la tabla 5.3, que es la distribuci\u00f3n de probabilidad para el n\u00famero de veh\u00edculos vendidos durante un d\u00eda en DiCarlo Motors. Una de las principales ventajas de defi nir una variable aleatoria y su distribuci\u00f3n de probabilidad es que, una vez que se conoce esta \u00faltima, es relativamente f\u00e1cil determinar la probabilidad de una variedad de eventos que pueden ser \u00fatiles para quien toma decisiones. Por ejemplo, utilizando la distribuci\u00f3n de probabilidad para DiCarlo Motors que aparece en la tabla 5.3, vemos que el n\u00famero de autom\u00f3viles que es m\u00e1s probable vender en un d\u00eda es 1, con una probabilidad de f(1) = 0.39. Adem\u00e1s, hay una probabilidad de f(3) + f(4) + f(5) = 0.14 + 0.04 + 0.01 = 0.19 de vender 3 o m\u00e1s unidades durante un d\u00eda. Estas probabilidades, adem\u00e1s de otras que quien toma decisiones puede solicitar, proporcionan informaci\u00f3n que le ayudan a entender el proceso de la venta de autom\u00f3viles en DiCarlo Motors. Cuando se desarrolla una funci\u00f3n de probabilidad para una variable aleatoria discreta, se deben satisfacer las dos condiciones siguientes."},{"location":"capitulo5/#53-valor-esperado-y-varianza","title":"5.3 Valor esperado y varianza\u00b6","text":"<p>Valor esperado</p> El valor esperado , o media, de una variable aleatoria es una medida de su posici\u00f3n central. La f\u00f3rmula para el valor esperado de una variable aleatoria discreta x se indica enseguida."},{"location":"capitulo5/#54-distribucion-de-probabilidad-binomial","title":"5.4 Distribuci\u00f3n de probabilidad binomial\u00b6","text":""},{"location":"capitulo5/#notas-y-comentarios","title":"NOTAS Y COMENTARIOS\u00b6","text":"<p> 1. La tabla binomial del ap\u00e9ndice B muestra valores de p hasta p = 0.95, inclusive. Algunas fuentes de la tabla binomial s\u00f3lo muestran valores de p hasta p = 0.50.Parecer\u00eda que una tabla como \u00e9sta no puede usarse cuando la probabilidad de \u00e9xito rebasa p = 0.50. No obstante, puede utilizarse si se considera que la probabilidad de n - x fracasos es tambi\u00e9n la probabilidad de x \u00e9xitos. Por tanto, cuando la probabilidad de \u00e9xito es mayor que p = 0.50, se calcula la probabilidad de n - x fracasos en vez de la probabilidad de \u00e9xitos. La probabilidad de fracasos, 1 - p, es menor que 0.50 cuando p &gt; 0.50.  2. Algunas fuentes presentan las tablas binomiales en forma acumulada. Al usarlas para encontrar exactamente x \u00e9xitos en n ensayos, se deben restar las entradas de la tabla correspondiente. Por ejemplo, f (2) = P(x \u2264 2) - P(x  \u2264 1). La tabla binomial del ap\u00e9ndice B proporciona f (2) directamente. Para calcular las probabilidades acumuladas usando las tablas binomiales del ap\u00e9ndice B, se suman las entradas de la tabla correspondiente. Por ejemplo, para determinar la probabilidadacumulada P(x  \u2264 2),  calcule la suma f (0) + f (1) + f (2). </p>"},{"location":"capitulo5/#55-distribucion-de-probabilidad-de-poisson","title":"5.5 Distribuci\u00f3n de probabilidad de Poisson\u00b6","text":"En esta secci\u00f3n consideramos una variable aleatoria discreta que a menudo es \u00fatil para estimar el n\u00famero de ocurrencias en un intervalo espec\u00edfi co de tiempo o espacio. Por ejemplo, la variable aleatoria de inter\u00e9s podr\u00eda ser el n\u00famero de llegadas a un centro de lavado automotriz en una hora, el n\u00famero de reparaciones necesarias en 10 millas de una autopista o el n\u00famero de fugas en 100 millas de tuber\u00eda. Si las dos propiedades siguientes se satisfacen, el n\u00famero de ocurrencias es una variable aleatoria descrita por la distribuci\u00f3n de probabilidad de Poisson."},{"location":"capitulo5/#ejercicios","title":"Ejercicios\u00b6","text":""},{"location":"capitulo5/#anexos","title":"ANEXOS\u00b6","text":""},{"location":"capitulo6/","title":"Capitulo 6","text":"<p>La funci\u00f3n gaussiana lleva el nombre de Carl Friedrich Gauss, un matem\u00e1tico, astr\u00f3nomo y f\u00edsico alem\u00e1n que vivi\u00f3 en el siglo XVIII y principios del siglo XIX (1777-1855). Es utilizada en muchos campos, incluyendo el an\u00e1lisis de datos, el procesamiento de se\u00f1ales, la inteligencia artificial y otros \u00e1mbitos cient\u00edficos y t\u00e9cnicos.</p> <p>Considere la variable aleatoria $x$ = tiempo de vuelo de un avi\u00f3n que viaja de La Paz a Santa Cruz. Suponga que este tiempo puede ser cualquier valor en el intervalo de 60 a 80 minutos. Dado que $x$ puede asumir cualquier valor en ese intervalo, esta es una variable aleatoria continua. Suponiendo que cada intervalo de 1 minuto es igualmente probable, se dice que la variable aleatoria $x$ tiene una probabilidad de distribuci\u00f3n uniforme. La funci\u00f3n de densidad de probabilidad es:</p> <p>\\begin{align*} f(x) =\\begin{cases}             \\frac{1}{20} \\quad \\text{para} \\quad 60\\leq x \\leq 80 \\\\             0  \\quad\\quad \\text{en cualquier otro caso}     \\end{cases} \\end{align*}</p> <p>La figura 6.1 es una gr\u00e1fica de esta funci\u00f3n de densidad de probabilidad. En general, la funci\u00f3n de densidad de probabilidad uniforme para una variable aleatoria $x$ se define por medio de la f\u00f3rmula siguiente:</p> FUNCI\u00d3N DE DENSIDAD DE PROBABILIDAD UNIFORME                  $$ f(x) =                      \\begin{cases}                         \\frac{1}{b-a} \\quad \\text{para} \\quad a\\leq x \\leq b \\\\\\\\                         0  \\quad\\quad \\text{en cualquier otro caso}                     \\end{cases}$$              (6.1) <p>Para la variable aleatoria del tiempo de vuelo, a= 80 y b =60.</p> <p> Figura 6.1 Distribuci\u00f3n de probabilidad uniforme para el tiempo de vuelo</p> In\u00a0[41]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\n# Funci\u00f3n de densidad de probabilidad uniforme\ndef pdf(x):\n    if 60 &lt;= x &lt;= 80:\n        return 1/20  # Intervalo [60, 80], probabilidad uniforme\n    else:\n        return 0\n\n# Crear un conjunto de valores x para la gr\u00e1fica\nx_values = np.linspace(55, 85, 1000)  # Rango de x de 50 a 90\n\n# Calcular los valores y correspondientes a la funci\u00f3n de densidad de probabilidad\ny_values = [pdf(x) for x in x_values]\n\n# Crear la gr\u00e1fica con un color de fondo personalizado\nfig, ax = plt.subplots(figsize=(7, 2))\nax.plot(x_values, y_values, color='black')\nax.set_xlabel('Tiempo de vuelo en minutos')\nax.set_ylabel('1/20')\nfig.patch.set_facecolor('#D4F8B7')  # Color de fondo personalizado\nax.set_facecolor('#D4F8B7')\nax.fill_between(x_values, 0, y_values, color='#5CCB5F')\nax.set_yticks([])\nax.set_yticklabels([])\n# Quitar los bordes superior y derecho\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\n# Agregar texto\ninfo_desviacion = '$f(x)$'\nax.text(-0.03, 1.1, info_desviacion, transform=ax.transAxes, fontsize=12, color='#000')\ninfo_desviacion = 'x'\nax.text(1.03, 0, info_desviacion, transform=ax.transAxes, fontsize=12, color='#000')\n\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  # Funci\u00f3n de densidad de probabilidad uniforme def pdf(x):     if 60 &lt;= x &lt;= 80:         return 1/20  # Intervalo [60, 80], probabilidad uniforme     else:         return 0  # Crear un conjunto de valores x para la gr\u00e1fica x_values = np.linspace(55, 85, 1000)  # Rango de x de 50 a 90  # Calcular los valores y correspondientes a la funci\u00f3n de densidad de probabilidad y_values = [pdf(x) for x in x_values]  # Crear la gr\u00e1fica con un color de fondo personalizado fig, ax = plt.subplots(figsize=(7, 2)) ax.plot(x_values, y_values, color='black') ax.set_xlabel('Tiempo de vuelo en minutos') ax.set_ylabel('1/20') fig.patch.set_facecolor('#D4F8B7')  # Color de fondo personalizado ax.set_facecolor('#D4F8B7') ax.fill_between(x_values, 0, y_values, color='#5CCB5F') ax.set_yticks([]) ax.set_yticklabels([]) # Quitar los bordes superior y derecho ax.spines['top'].set_visible(False) ax.spines['right'].set_visible(False)  # Agregar texto info_desviacion = '$f(x)$' ax.text(-0.03, 1.1, info_desviacion, transform=ax.transAxes, fontsize=12, color='#000') info_desviacion = 'x' ax.text(1.03, 0, info_desviacion, transform=ax.transAxes, fontsize=12, color='#000')  plt.show()   <p>La probabilidad s\u00f3lo se considera en t\u00e9rminos de la posibilidad de que la variable aleatoria tome un valor dentro de un intervalo determinado.</p> <p>Ejemplo</p> <p>\u00bfcu\u00e1l es la probabilidad de que el tiempo de vuelo se encuentre entre 60 y 70 minutos? $P$(60 $\\leq  x \\leq$ 70) Debido a que la probabilidad se describe como uniforme a lo largo de este intervalo, es factible decir que $P$(60 $\\leq x \\leq$ 130) = 0.50. En la subsecci\u00f3n siguiente se muestra que esta probabilidad se calcula como el \u00e1rea bajo la gr\u00e1fica f(x) de 60 a 70.</p> In\u00a0[77]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.stats import norm\n\n# Funci\u00f3n de densidad de probabilidad uniforme\ndef pdf(x):\n    if 60 &lt;= x &lt;= 80:\n        return 1/20  # Intervalo [60, 80], probabilidad uniforme\n    else:\n        return 0\n\n# Crear un conjunto de valores x para la gr\u00e1fica\nx_values = np.linspace(55, 85, 1000)  # Rango de x de 50 a 90\n\n# Calcular los valores y correspondientes a la funci\u00f3n de densidad de probabilidad\ny_values = [pdf(x) for x in x_values]\n\n# Crear la gr\u00e1fica con un color de fondo personalizado\nfig, ax = plt.subplots(figsize=(7, 2))\nax.plot(x_values, y_values, color='black')\nax.set_xlabel('Tiempo de vuelo en minutos')\nax.set_ylabel('1/20')\nfig.patch.set_facecolor('#D4F8B7')  # Color de fondo personalizado\nax.set_facecolor('#D4F8B7')\nax.fill_between(x_values, 0, y_values, where=(x_values &lt;= 70), color='#5CCB5F')\nax.set_yticks([])\nax.set_yticklabels([])\n# Quitar los bordes superior y derecho\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\nax.axvline(x=70, color='black', linestyle='-', linewidth=2)  # Agregar l\u00ednea vertical en x=70\n\n# Agregar flecha con texto\narrow_text = '$P(60 \\leq x \\leq 70) = \u00e1rea = 1/20(10) = 10/20 = 0.50$'\nax.annotate(arrow_text, xy=(65, 0.01), xytext=(55, 0.055),\n            arrowprops=dict(facecolor='black', arrowstyle='-&gt;'),\n            fontsize=10)\n\n# Agregar texto\ninfo1 = '$f(x)$'\nax.text(-0.03, 1.1, info1, transform=ax.transAxes, fontsize=8, color='#000')\ninfo2 = 'x'\nax.text(1.03, 0, info2, transform=ax.transAxes, fontsize=8, color='#000')\n\n\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np from scipy.stats import norm  # Funci\u00f3n de densidad de probabilidad uniforme def pdf(x):     if 60 &lt;= x &lt;= 80:         return 1/20  # Intervalo [60, 80], probabilidad uniforme     else:         return 0  # Crear un conjunto de valores x para la gr\u00e1fica x_values = np.linspace(55, 85, 1000)  # Rango de x de 50 a 90  # Calcular los valores y correspondientes a la funci\u00f3n de densidad de probabilidad y_values = [pdf(x) for x in x_values]  # Crear la gr\u00e1fica con un color de fondo personalizado fig, ax = plt.subplots(figsize=(7, 2)) ax.plot(x_values, y_values, color='black') ax.set_xlabel('Tiempo de vuelo en minutos') ax.set_ylabel('1/20') fig.patch.set_facecolor('#D4F8B7')  # Color de fondo personalizado ax.set_facecolor('#D4F8B7') ax.fill_between(x_values, 0, y_values, where=(x_values &lt;= 70), color='#5CCB5F') ax.set_yticks([]) ax.set_yticklabels([]) # Quitar los bordes superior y derecho ax.spines['top'].set_visible(False) ax.spines['right'].set_visible(False)  ax.axvline(x=70, color='black', linestyle='-', linewidth=2)  # Agregar l\u00ednea vertical en x=70  # Agregar flecha con texto arrow_text = '$P(60 \\leq x \\leq 70) = \u00e1rea = 1/20(10) = 10/20 = 0.50$' ax.annotate(arrow_text, xy=(65, 0.01), xytext=(55, 0.055),             arrowprops=dict(facecolor='black', arrowstyle='-&gt;'),             fontsize=10)  # Agregar texto info1 = '$f(x)$' ax.text(-0.03, 1.1, info1, transform=ax.transAxes, fontsize=8, color='#000') info2 = 'x' ax.text(1.03, 0, info2, transform=ax.transAxes, fontsize=8, color='#000')   plt.show() <p>Como podemos observar son id\u00e9nticas. De hecho, esta observaci\u00f3n es v\u00e1lida para todas las variables aleatorias continuas.</p> <p>Ejemplo</p> <p>\u00bfCu\u00e1l es la probabilidad de un tiempo de vuelo entre 68 y 76 minutos? El ancho del intervalo es 76 - 68 = 8.</p> <p>$$P(68 \\leq x \\leq 76) = 8(1/20) = 0.40.$$</p> <p>Observe que $P$(120$ \\leq x \\leq$ 140) = 20(1/20) = 1; es decir, el \u00e1rea total bajo la gr\u00e1fica f(x) es igual a 1.</p> <p>Hay dos diferencias importantes entre el tratamiento de la variable aleatoria continua y el tratamiento de sus hom\u00f3logas discretas.</p> <p>1.  La probabilidad de que una variable aleatoria ya no asume valor particular, sino un valor dentro de cierto intervalo.</p> <p>2.  La probabilidad de que una variable aleatoria continua asuma cualquier valor particular es exactamente cero; tambi\u00e9n signifi ca que la probabilidad de que asuma un valor en cualquier intervalo es la misma.</p> F\u00d3RMULAS PARA EL VALOR ESPERADO Y LA VARIANZA                  \\begin{align*}                     E(x)&amp;= \\frac{a+b}{2}\\\\                     Var(x)&amp;=\\frac{(b-a)^2}{12}                 \\end{align*}              <p>En estas f\u00f3rmulas, a es el valor menor y b es el valor mayor que la variable aleatoria puede asumir.</p> <p>Aplicamos las formulas al ejemplo para obtener $E(x)$ y su respectiva $Var(x)$.</p> <p>\\begin{align*} E(x)&amp;=\\frac{60+80}{2}=70\\\\\\\\ Var(x)&amp;= \\frac{(80-60)^2}{12}=33.3 \\end{align*}</p> <p>La desviaci\u00f3n est\u00e1ndar se obtiene al calcular la ra\u00edz cuadrada de la varianza. Por tanto, $\\sigma$= 5.77 minutos.</p> <p>Ejemplo 1</p> <p>El precio medio del litro de gasolina durante el pr\u00f3ximo a\u00f1o se estima que puede oscilar entre 2,50 y 3,00 d\u00f3lares, podr\u00eda ser por lo tanto 2,55 a 2,90 d\u00f3lares.</p> <p>1) Calcular la funci\u00f3n de densidad uniforme.</p> <p>2) Cual es la probabilidad que se encuentre el precio de la gasolina entre 2,55 a **2,90 **.</p> <p>Soluci\u00f3n </p> <p>Datos: $$a = 2.50  \\quad \\quad  b = 3.00$$</p> <p>1) </p> <p>$ f(x) = \\begin{cases} \\frac{1}{b-a} &amp; \\text{si } a \\le x &lt; b, \\\\ 0 &amp; \\text{en cualquier otro caso}. \\end{cases}\\\\ f(x) = \\begin{cases} \\frac{1}{3.00-2.50} &amp; \\text{si } 2.50 \\le x &lt; 3.00, \\\\ 0 &amp; \\text{en cualquier otro caso}. \\end{cases}\\\\ f(x) = \\begin{cases} \\frac{1}{0.5} &amp; \\text{si } 2.50 \\le x &lt; 3.00, \\\\ 0 &amp; \\text{en cualquier otro caso}. \\end{cases} $</p> <p>1) </p> <p>\\begin{align*} P[2.55\\le x\\le2.90] &amp;= \\int_{2.55}^{2.90} \\frac{1}{0.5} \\, dx \\\\ &amp;= \\frac{1}{0.5}(2.90-2.55) &amp;= 0.7\\\\ &amp;= 70\\% \\end{align*}</p> <p>Ejemplo 2</p> <p>Una distribuci\u00f3n uniforme se define en el intervalo de 6 a 10</p> <p>a) Cu\u00e1l es la media de esta distribuci\u00f3n uniforme?</p> <p>b) Cu\u00e1l es la desviaci\u00f3n estandar?</p> <p>c) Demuestre que el \u00e1rea total es de 1.</p> <p>d) Calcule la probabilidad de un valor entre 7 y 9.</p> <p>Soluci\u00f3n </p> <p>a) $$\\mu=\\frac{a+b}{2}=\\frac{6+10}{2}=8$$</p> <p>b)  \\begin{align*} \\sigma^2 &amp;=\\frac{(b-a)^2}{12}=\\frac{(10-6)^2}{12}=\\frac{4}{3}\\\\\\\\ \\sigma &amp;=\\sqrt{\\frac{4}{3}}=\\frac{2}{\\sqrt{3}} \\end{align*}</p> <p>c)  $$ f(x) = \\begin{cases} \\frac{1}{4} &amp; \\text{si } 6 \\le x &lt; 10, \\\\ 0 &amp; \\text{en cualquier otro caso}. \\end{cases} $$ $$ A=\\int_{6}^{10}\\frac{1}{4}dx=\\frac{1}{4}\\cdot x\\Big|_{6}^{10}=\\frac{1}{4}\\cdot(4)=1 $$</p> <p>d)  $$P[7 &lt; x &lt; 9]=\\frac{1}{4}\\cdot (9-7)=\\frac{2}{4}=0.5=50\\%$$</p> <p>Es la mas importante para describir una variable aleatoria continua, asi tambien en la inferencia estadistica. Nos ofrece la probabilidad de los resultados de un muestreo.</p> In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Par\u00e1metros de la distribuci\u00f3n normal\nmedia = 0\ndesviacion_estandar = 1\n\n# Generar datos de la distribuci\u00f3n normal\nx = np.linspace(media - 3 * desviacion_estandar, media + 3 * desviacion_estandar, 1000)\ny = norm.pdf(x, media, desviacion_estandar)\n\n# Crear la gr\u00e1fica\nfig, ax = plt.subplots()\nax.plot(x, y, color='black')\n# Establecer el color de fondo\nax.set_facecolor('#d4f8b7') \nax.fill_between(x, y, color='#5CCB5F', alpha=1) \nfig.patch.set_facecolor('#D4F8B7')\n\n#Configuraci\u00f3n de los ejes\nax.set_xlabel('Media', fontsize=12)\nax.set_ylabel('Densidad de Probabilidad', fontsize=12)\nax.set_xticks([0],['$\\mu$'])\nax.set_yticks([])\n\n# Agregar texto\ninfo_desviacion = 'Desviaci\u00f3n'\nax.text(0.6, 0.85, info_desviacion, transform=ax.transAxes, fontsize=12, color='#000')\ninfo_desviacion = 'estandar $\\sigma$'\nax.text(0.7, 0.8, info_desviacion, transform=ax.transAxes, fontsize=12, color='#000')\n\n#Mostrar grafico\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm  # Par\u00e1metros de la distribuci\u00f3n normal media = 0 desviacion_estandar = 1  # Generar datos de la distribuci\u00f3n normal x = np.linspace(media - 3 * desviacion_estandar, media + 3 * desviacion_estandar, 1000) y = norm.pdf(x, media, desviacion_estandar)  # Crear la gr\u00e1fica fig, ax = plt.subplots() ax.plot(x, y, color='black') # Establecer el color de fondo ax.set_facecolor('#d4f8b7')  ax.fill_between(x, y, color='#5CCB5F', alpha=1)  fig.patch.set_facecolor('#D4F8B7')  #Configuraci\u00f3n de los ejes ax.set_xlabel('Media', fontsize=12) ax.set_ylabel('Densidad de Probabilidad', fontsize=12) ax.set_xticks([0],['$\\mu$']) ax.set_yticks([])  # Agregar texto info_desviacion = 'Desviaci\u00f3n' ax.text(0.6, 0.85, info_desviacion, transform=ax.transAxes, fontsize=12, color='#000') info_desviacion = 'estandar $\\sigma$' ax.text(0.7, 0.8, info_desviacion, transform=ax.transAxes, fontsize=12, color='#000')  #Mostrar grafico plt.show() FUNCI\u00d3N DE DENSIDAD DE PROBABILIDAD NORMAL                  $$ f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}} $$              (6.2) \"$f$ de $x$ es igual a uno dividido por el producto de la desviaci\u00f3n ($\\sigma$) multiplicada por la ra\u00edz cuadrada de dos veces pi, multiplicado por la exponencial ($e$) de la expresi\u00f3n negativa de la diferencia entre $x$ y la media ($\\mu$) al cuadrado, dividido por dos veces la desviaci\u00f3n al cuadrado.\"         Donde:  <ul> <li>$\\mu$ = media</li> <li>$\\sigma$ = desviaci\u00f3n est\u00e1ndar</li> <li>$\\pi$ = 3.14159</li> <li>$e$ = 2.71828</li></ul> <p>Se formulan varias observaciones acerca de sus caracter\u00edsticas.</p> <ol> <li>Se diferencia por medio de dos par\u00e1metros: la media \u03bc y la desviaci\u00f3n est\u00e1ndar \u03c3.</li> <li>El punto m\u00e1s alto de una campana de gauss se encuentra sobre la media, el cual coincide con la mediana.</li> <li>La media de una distribuci\u00f3n normal puede tener cualquier valor num\u00e9rico: negativo, cero o positivo.</li> </ol> <p>En el siguiente grafico se muestra tres distribuciones normales con diferentes medias.</p> In\u00a0[2]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Funci\u00f3n para la densidad de probabilidad de la distribuci\u00f3n normal\ndef normal_distribution(x, mean, std_dev):\n    return (1 / (std_dev * np.sqrt(2 * np.pi))) * np.exp(-((x - mean)**2) / (2 * std_dev**2))\n\n# Datos de las curvas normales\nparams = [(0, 5), (-7, 5), (14, 5)]\n\n# Generar datos x para el gr\u00e1fico\nx = np.linspace(-30, 30, 1000)\n\n# Crear el gr\u00e1fico\nfig, ax = plt.subplots()\n\nfor mean, std_dev in params:\n    y = normal_distribution(x, mean, std_dev)\n    ax.plot(x, y, color='black', label=f'Media {mean}, Desviaci\u00f3n {std_dev}')\n    ax.fill_between(x, y, color='#5CCB5F', alpha=1)\n\n# Configurar color de fondo\nfig.patch.set_facecolor('#D4F8B7')\nax.set_facecolor('#d4f8b7') \n\n#Configuraci\u00f3n de los ejes\nax.set_xticks([mean for mean, _ in params])\nax.set_xticklabels([str(mean) for mean, _ in params])\nplt.subplots_adjust(bottom=0.5)\nax.set_yticks([])\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  # Funci\u00f3n para la densidad de probabilidad de la distribuci\u00f3n normal def normal_distribution(x, mean, std_dev):     return (1 / (std_dev * np.sqrt(2 * np.pi))) * np.exp(-((x - mean)**2) / (2 * std_dev**2))  # Datos de las curvas normales params = [(0, 5), (-7, 5), (14, 5)]  # Generar datos x para el gr\u00e1fico x = np.linspace(-30, 30, 1000)  # Crear el gr\u00e1fico fig, ax = plt.subplots()  for mean, std_dev in params:     y = normal_distribution(x, mean, std_dev)     ax.plot(x, y, color='black', label=f'Media {mean}, Desviaci\u00f3n {std_dev}')     ax.fill_between(x, y, color='#5CCB5F', alpha=1)  # Configurar color de fondo fig.patch.set_facecolor('#D4F8B7') ax.set_facecolor('#d4f8b7')   #Configuraci\u00f3n de los ejes ax.set_xticks([mean for mean, _ in params]) ax.set_xticklabels([str(mean) for mean, _ in params]) plt.subplots_adjust(bottom=0.5) ax.set_yticks([])  # Mostrar el gr\u00e1fico plt.show() <ol> <li>La distribuci\u00f3n normal es sim\u00e9trica: la forma de la curva normal a la izquierda de la media es igual a la forma de la curva a la derecha. Los extremos de la curva normal se extienden hacia el infinito en ambas direcciones.</li> <li>El valor de $\\sigma$ (desviacion estandar) determina la forma de la curva normal, a mayor valor, este sera mas ancha y plana.</li> </ol> <p>En el siguiente grafico se observan dos distribuciones nomales con diferentes desviaciones estandar.</p> In\u00a0[5]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Par\u00e1metros de las curvas normales\nparams = [(0, 9, '$\\sigma = 9$', (4, 0.07, 20, 0.08)),\n          (0, 4, '$\\sigma = 4$', (12, 0.02, 20, 0.03))]\n\n# Generar datos para los ejes x\nx = np.linspace(-30, 30, 1000)\n\n# Crear el gr\u00e1fico\nfig, ax = plt.subplots(figsize=(8, 5))\n\nfor mean, std_dev, label, arrow_props in params:\n    y = norm.pdf(x, mean, std_dev)\n    ax.plot(x, y, color='black', label=f'Media=0, Desviaci\u00f3n={std_dev}')\n    ax.fill_between(x, y, color='#5CCB5F', alpha=1)\n\n    # Agregar texto con una flecha\n    ax.annotate(label, xy=arrow_props[:2], xytext=arrow_props[2:], arrowprops=dict(facecolor='black', shrink=0.05, width=0.2, headwidth=5),\n                 fontsize=10, ha='center', va='center')\n\n# Configurar color de fondo de la figura\nfig.set_facecolor('#D4F8B7')\nax.set_facecolor('#d4f8b7')\n\n#Configuraci\u00f3n de los ejes\nax.set_yticks([])\nax.set_xticks([0],['$\\mu$'])\nplt.subplots_adjust(bottom=0.3)\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  # Par\u00e1metros de las curvas normales params = [(0, 9, '$\\sigma = 9$', (4, 0.07, 20, 0.08)),           (0, 4, '$\\sigma = 4$', (12, 0.02, 20, 0.03))]  # Generar datos para los ejes x x = np.linspace(-30, 30, 1000)  # Crear el gr\u00e1fico fig, ax = plt.subplots(figsize=(8, 5))  for mean, std_dev, label, arrow_props in params:     y = norm.pdf(x, mean, std_dev)     ax.plot(x, y, color='black', label=f'Media=0, Desviaci\u00f3n={std_dev}')     ax.fill_between(x, y, color='#5CCB5F', alpha=1)      # Agregar texto con una flecha     ax.annotate(label, xy=arrow_props[:2], xytext=arrow_props[2:], arrowprops=dict(facecolor='black', shrink=0.05, width=0.2, headwidth=5),                  fontsize=10, ha='center', va='center')  # Configurar color de fondo de la figura fig.set_facecolor('#D4F8B7') ax.set_facecolor('#d4f8b7')  #Configuraci\u00f3n de los ejes ax.set_yticks([]) ax.set_xticks([0],['$\\mu$']) plt.subplots_adjust(bottom=0.3)  # Mostrar el gr\u00e1fico plt.show() <ol> <li>Las probabilidades para la variable aleatoria normal est\u00e1n representadas por las \u00e1reas bajo la curva. El \u00e1rea total bajo la curva es 1. Como es sim\u00e9trica, el \u00e1rea bajo la curva a la izquierda como a la derecha es 0.50.</li> <li>Los porcentajes de los valores en algunos intervalos de uso com\u00fan son los siguientes.</li> </ol> <p>$$a.\\quad 68.3%$$ $$b.\\quad 95.4%$$ $$c.\\quad 99.7%$$</p> <p>La figura 6.4 muestra las propiedades a, b y c.</p> NOTAS <p>Para mas accesibilidad, tenemos Pydroid 3, esta te permite ejecutar c\u00f3digo Python en dispositivos Android. Con un entorno de desarrollo completo, incluyendo editor y consola interactiva.</p> <p>Se te ofrece un ejemplo de como se puede ejecutar la funci\u00f3n gaussiana utilizando la aplicaci\u00f3n: haz click aqu\u00ed</p> <p> Figura 6.4 \u00c1reas bajo la curva de cualquier distribuci\u00f3n normal</p> In\u00a0[4]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Par\u00e1metros de la curva normal\nmedia = 0\ndesviacion = 10\nescala_curva = 0.5\n\n# Generar datos para el eje x\nx = np.linspace(media - 4 * desviacion, media + 4 * desviacion, 1000)\n\n# Calcular los valores de la distribuci\u00f3n normal\ny = norm.pdf(x, media, desviacion)\n\n# Calcular los valores de la distribuci\u00f3n normal y ajustar la escala\ny = escala_curva * norm.pdf(x, media, desviacion)\n\n# Crear el gr\u00e1fico y cambiar color de fondo\nfig, ax = plt.subplots(figsize=(8, 5))\nax.plot(x, y,color='black')\nfig.set_facecolor('#D4F8B7')\nax.set_facecolor('#D4F8B7')\nax.fill_between(x, y, color='#5CCB5F', alpha=1)\n\n# A\u00f1adir una l\u00ednea vertical en coordenadas personalizadas\nplt.axvline(x=media-3*desviacion, ymin=0, ymax=0.85, color='black', linestyle='-', linewidth=1)\nplt.axvline(x=media+3*desviacion, ymin=0, ymax=0.85, color='black', linestyle='-', linewidth=1)\n\nplt.axvline(x=media-2*desviacion, ymin=0, ymax=0.75, color='black', linestyle='-', linewidth=1)\nplt.axvline(x=media+2*desviacion, ymin=0, ymax=0.75, color='black', linestyle='-', linewidth=1)\n\nplt.axvline(x=media-1*desviacion, ymin=0, ymax=0.6, color='black', linestyle='-', linewidth=1)\nplt.axvline(x=media+1*desviacion, ymin=0, ymax=0.6, color='black', linestyle='-', linewidth=1)\n\n# Agregar flechas\nax.annotate('',\n            xy=(media-3*desviacion, 0.032),\n            xytext=(media+3*desviacion, 0.032),\n            arrowprops=dict(arrowstyle='&lt;-&gt;', color='black', lw=1),\n            )\n\n# Agregar texto\nax.text(media, 0.033, '99.7%', ha='center', va='center', color='black')\n\nax.annotate('',\n            xy=(media-2*desviacion, 0.028),\n            xytext=(media+2*desviacion, 0.028),\n            arrowprops=dict(arrowstyle='&lt;-&gt;', color='black', lw=1),\n            )\n\n# Agregar texto\nax.text(media, 0.029, '95.4%', ha='center', va='center', color='black')\n\nax.annotate('',\n            xy=(media-1*desviacion, 0.022),\n            xytext=(media+1*desviacion, 0.022),\n            arrowprops=dict(arrowstyle='&lt;-&gt;', color='black', lw=1),\n            )\n\n# Agregar texto\nax.text(media, 0.023, '68.3%', ha='center', va='center', color='black')\n\n# Ajustar las marcas del eje x\nmarcas_x = [media - 3 * desviacion, media - 2 * desviacion, media - desviacion,\n            media, media + desviacion, media + 2 * desviacion, media + 3 * desviacion]\nmarcas_etiquetas = [r'$\\mu - 3\\sigma$', r'$\\mu - 2\\sigma$', r'$\\mu - 1\\sigma$', r'$\\mu$',\n                    r'$\\mu + 1\\sigma$', r'$\\mu + 2\\sigma$', r'$\\mu + 3\\sigma$']\n\n#Configuraci\u00f3n de los ejes\nax.set_xticks(marcas_x)\nax.set_yticks([])\nax.set_xticklabels(marcas_etiquetas)\nplt.ylim(top=0.04)\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  # Par\u00e1metros de la curva normal media = 0 desviacion = 10 escala_curva = 0.5  # Generar datos para el eje x x = np.linspace(media - 4 * desviacion, media + 4 * desviacion, 1000)  # Calcular los valores de la distribuci\u00f3n normal y = norm.pdf(x, media, desviacion)  # Calcular los valores de la distribuci\u00f3n normal y ajustar la escala y = escala_curva * norm.pdf(x, media, desviacion)  # Crear el gr\u00e1fico y cambiar color de fondo fig, ax = plt.subplots(figsize=(8, 5)) ax.plot(x, y,color='black') fig.set_facecolor('#D4F8B7') ax.set_facecolor('#D4F8B7') ax.fill_between(x, y, color='#5CCB5F', alpha=1)  # A\u00f1adir una l\u00ednea vertical en coordenadas personalizadas plt.axvline(x=media-3*desviacion, ymin=0, ymax=0.85, color='black', linestyle='-', linewidth=1) plt.axvline(x=media+3*desviacion, ymin=0, ymax=0.85, color='black', linestyle='-', linewidth=1)  plt.axvline(x=media-2*desviacion, ymin=0, ymax=0.75, color='black', linestyle='-', linewidth=1) plt.axvline(x=media+2*desviacion, ymin=0, ymax=0.75, color='black', linestyle='-', linewidth=1)  plt.axvline(x=media-1*desviacion, ymin=0, ymax=0.6, color='black', linestyle='-', linewidth=1) plt.axvline(x=media+1*desviacion, ymin=0, ymax=0.6, color='black', linestyle='-', linewidth=1)  # Agregar flechas ax.annotate('',             xy=(media-3*desviacion, 0.032),             xytext=(media+3*desviacion, 0.032),             arrowprops=dict(arrowstyle='&lt;-&gt;', color='black', lw=1),             )  # Agregar texto ax.text(media, 0.033, '99.7%', ha='center', va='center', color='black')  ax.annotate('',             xy=(media-2*desviacion, 0.028),             xytext=(media+2*desviacion, 0.028),             arrowprops=dict(arrowstyle='&lt;-&gt;', color='black', lw=1),             )  # Agregar texto ax.text(media, 0.029, '95.4%', ha='center', va='center', color='black')  ax.annotate('',             xy=(media-1*desviacion, 0.022),             xytext=(media+1*desviacion, 0.022),             arrowprops=dict(arrowstyle='&lt;-&gt;', color='black', lw=1),             )  # Agregar texto ax.text(media, 0.023, '68.3%', ha='center', va='center', color='black')  # Ajustar las marcas del eje x marcas_x = [media - 3 * desviacion, media - 2 * desviacion, media - desviacion,             media, media + desviacion, media + 2 * desviacion, media + 3 * desviacion] marcas_etiquetas = [r'$\\mu - 3\\sigma$', r'$\\mu - 2\\sigma$', r'$\\mu - 1\\sigma$', r'$\\mu$',                     r'$\\mu + 1\\sigma$', r'$\\mu + 2\\sigma$', r'$\\mu + 3\\sigma$']  #Configuraci\u00f3n de los ejes ax.set_xticks(marcas_x) ax.set_yticks([]) ax.set_xticklabels(marcas_etiquetas) plt.ylim(top=0.04)  # Mostrar el gr\u00e1fico plt.show() <p> Figura 6.5 Distribuci\u00f3n normal estandar</p> In\u00a0[3]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Par\u00e1metros de la curva normal\nmedia = 0\ndesviacion = 1\n\n# Generar datos para el eje x\nx = np.linspace(media - 4 * desviacion, media + 4 * desviacion, 1000)\n\n# Calcular los valores de la distribuci\u00f3n normal\ny = norm.pdf(x, media, desviacion)\n\n# Crear el gr\u00e1fico y cambiar color de fondo\nfig, ax = plt.subplots(figsize=(8, 5))\nax.plot(x, y, color='black')\nfig.set_facecolor('#D4F8B7')\nax.set_facecolor('#D4F8B7')\nax.fill_between(x, y, color='#5CCB5F', alpha=1)\n\n#Configuraci\u00f3n de los ejes\nax.text(1.3, 0.23, '$\\sigma = 1$')\nax.set_xticks([media])\nax.set_yticks([])\nax.set_xticklabels(['0'])\nplt.subplots_adjust(bottom=0.3)\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  # Par\u00e1metros de la curva normal media = 0 desviacion = 1  # Generar datos para el eje x x = np.linspace(media - 4 * desviacion, media + 4 * desviacion, 1000)  # Calcular los valores de la distribuci\u00f3n normal y = norm.pdf(x, media, desviacion)  # Crear el gr\u00e1fico y cambiar color de fondo fig, ax = plt.subplots(figsize=(8, 5)) ax.plot(x, y, color='black') fig.set_facecolor('#D4F8B7') ax.set_facecolor('#D4F8B7') ax.fill_between(x, y, color='#5CCB5F', alpha=1)  #Configuraci\u00f3n de los ejes ax.text(1.3, 0.23, '$\\sigma = 1$') ax.set_xticks([media]) ax.set_yticks([]) ax.set_xticklabels(['0']) plt.subplots_adjust(bottom=0.3)  # Mostrar el gr\u00e1fico plt.show() <p>como $\u03bc=0$ y $\\sigma=1$, la f\u00f3rmula para la funci\u00f3n de densidad de probabilidad normal est\u00e1ndar es la siguiente.</p> FUNCION DE DENSIDAD NORMAL ESTANDAR                  $$ f(z) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{z^2}{2}} $$              <p>Para encontrar la probabilidad de que una variable aleatoria normal, debe calcularse el \u00e1rea bajo la curva normal del intervalo obtenido.</p> <p>Para la distribuci\u00f3n normal est\u00e1ndar, las \u00e1reas bajo la curva normal ya se han estimado y est\u00e1n disponibles en tablas que se utilizan para el c\u00e1lculo de probabilidades.</p> <p>Los tres tipos de probabilidades que se necesita calcular incluyen la probabilidad de que: ($z \\leq x$), ($x_1\\leq z \\leq x_2$) o ($x\\leq z$).</p> <p>Para saber como hacer uso de la tabla de probabilidad acumulada de la distribucion normal se emplea el siguiente ejemplo:</p> <p>Primero se mostrar\u00e1 c\u00f3mo calcular la probabilidad de que $z$ sea menor o igual que 0.70, esta situada en el \u00e1rea bajo la curva normal a la izquierda de $z$ = 0.70 en la gr\u00e1fica siguiente.</p> In\u00a0[2]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Par\u00e1metros de la curva normal\nmedia = 0\ndesviacion = 1\n\n# Generar datos para el eje x\nx = np.linspace(media - 4 * desviacion, media + 4 * desviacion, 1000)\n\n# Calcular los valores de la distribuci\u00f3n normal\ny = norm.pdf(x, media, desviacion)\n\n# Crear el gr\u00e1fico y cambiar color de fondo\nfig, ax = plt.subplots(figsize=(8, 5))\nax.plot(x, y, color='black')\nfig.set_facecolor('#D4F8B7')\nax.set_facecolor('#D4F8B7')\n\n# Dibujar la l\u00ednea vertical\narea_limite = 0.755\nx_limite = norm.ppf(area_limite, media, desviacion)\nax.axvline(x_limite, ymin=0.045, ymax=area_limite, color='black', linestyle='-')\n\n# Configuraci\u00f3n del texto y la flecha\ncoordenadas_texto1 = (-0.5, 0.25)\nax.annotate('$P(z \\leq 0.70)$',\n             xy=coordenadas_texto1,\n             xytext=(-1.8, 0.3),\n             arrowprops=dict(facecolor='#009929', shrink=0.05, width=0.2, headwidth=4),\n             fontsize=10,\n             ha='center',\n             va='center'\n            )\n\n# Configuraci\u00f3n general del gr\u00e1fico\nax.fill_between(x, y, where=(x &gt;= x_limite), color='#98F84A', alpha=0.7)\nax.fill_between(x, y, where=(x &lt;= x_limite), color='#5CCB5F', alpha=1)\n\n#Ejes\nax.set_yticks([])\nax.set_xticks([0, x_limite])\nax.set_xticklabels(['0', '0.7'])\n\n# Mostrar la gr\u00e1fica\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  # Par\u00e1metros de la curva normal media = 0 desviacion = 1  # Generar datos para el eje x x = np.linspace(media - 4 * desviacion, media + 4 * desviacion, 1000)  # Calcular los valores de la distribuci\u00f3n normal y = norm.pdf(x, media, desviacion)  # Crear el gr\u00e1fico y cambiar color de fondo fig, ax = plt.subplots(figsize=(8, 5)) ax.plot(x, y, color='black') fig.set_facecolor('#D4F8B7') ax.set_facecolor('#D4F8B7')  # Dibujar la l\u00ednea vertical area_limite = 0.755 x_limite = norm.ppf(area_limite, media, desviacion) ax.axvline(x_limite, ymin=0.045, ymax=area_limite, color='black', linestyle='-')  # Configuraci\u00f3n del texto y la flecha coordenadas_texto1 = (-0.5, 0.25) ax.annotate('$P(z \\leq 0.70)$',              xy=coordenadas_texto1,              xytext=(-1.8, 0.3),              arrowprops=dict(facecolor='#009929', shrink=0.05, width=0.2, headwidth=4),              fontsize=10,              ha='center',              va='center'             )  # Configuraci\u00f3n general del gr\u00e1fico ax.fill_between(x, y, where=(x &gt;= x_limite), color='#98F84A', alpha=0.7) ax.fill_between(x, y, where=(x &lt;= x_limite), color='#5CCB5F', alpha=1)  #Ejes ax.set_yticks([]) ax.set_xticks([0, x_limite]) ax.set_xticklabels(['0', '0.7'])  # Mostrar la gr\u00e1fica plt.show() <p>La probabilidad que corresponde a ($z \\leq$ 0.70) es el valor ubicado en la intersecci\u00f3n de la fila en la columna izquierda, cuyo encabezado es 0.7 y la columna en la fila superior, cuyo encabezado es 0.00 .</p> <p>Estas se intersecan en el valor 0.7580; por tanto, $P$($z \\leq$ 0.70)= 0.7580.</p> <p>Tabla 6.1  Distribuci\u00f3n de probabilidad normal estandar</p> z 0.00 0.01 0.02 ... 0.6 0.7258 0.7291 0.7324 0.7 0.7580 0.7611 0.7642 0.8 0.7881 0.7910 0.7939 0.9 0.8159 0.8186 0.8212 ... <p>Para ilustrar el segundo tipo de c\u00e1lculo de la probabilidad, suponga que se quiere determina la probabilidad de que $z$ est\u00e9 en el intervalo entre -0.50 y 1.25; es decir, $P$(-0.50 $\\le z \\le$ 1.25). La gr\u00e1fica siguiente muestra esta \u00e1rea, o probabilidad.</p> In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n\nx = np.arange(-2.9, 2.9, 0.001)\n\n#pintar el fondo externo del grafico\nplt.figure(facecolor='#D4F8B7')\n\n#area de sombreado rango\nx_filtered = x[(x &gt;= -0.50) &amp; (x &lt;= 1.25)]\n\n#pintar la linea curva del grafico\nplt.plot(x, norm.pdf(x, 0, 1), linewidth = 2, color = '#000')\n\n#pintar el area sombreada del grafico y graficar\nplt.fill_between(x_filtered, norm.pdf(x_filtered, 0, 1), color='#5CCB5F', alpha=0.5, edgecolor='black')\n\n#a\u00f1adir texto al grafico\nplt.text(-2.8, 0.20, (\"P(z &lt; -0.50)\"))\nplt.text(3, 0, (\"z\"))\n\n#bordes del grafico\nax = plt.gca()\nax.spines['top'].set_color('#009929')\nax.spines['top'].set_linewidth(2)\n#ancho del borde superior\nax.spines['top'].set_bounds(-6, 6)\nax.spines['bottom'].set_color('#009929')\nax.spines['bottom'].set_linewidth(2)\n#ancho del borde inferior\nax.spines['bottom'].set_bounds(-6, 6)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\n\n#pintar el fondo interno del grafico\nax.set_facecolor('#D4F8B7')\n\n#linea inferior del grafico\nplt.plot(x, [0]*len(x), color='black', linewidth=1)\n\n#centrar el grafico\nplt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)\n\n#plt.arrow(0.1, 0.1, 0.2, 0.2, width=0.05, color='black')\n\n#flecha\nplt.annotate(\" \", xytext = (-2, 0.2), xy = (-1, 0.05), arrowprops = dict(facecolor = 'black', width = 0.2, headwidth = 8),\n             horizontalalignment = 'center')\n\n#texto con flecha\nplt.annotate(\"P(-0.50 \\u2264 z \\u2264 1.25)\", xytext = (2.5, 0.25),\n             xy = (0.5, 0.15), arrowprops = dict(facecolor = 'black', width = 0.2, headwidth = 8),\n             horizontalalignment = 'center')\n\n#mostrar ejes x, y\nplt.xticks([-0.50, 0, 1.25])\nplt.yticks([])\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm   x = np.arange(-2.9, 2.9, 0.001)  #pintar el fondo externo del grafico plt.figure(facecolor='#D4F8B7')  #area de sombreado rango x_filtered = x[(x &gt;= -0.50) &amp; (x &lt;= 1.25)]  #pintar la linea curva del grafico plt.plot(x, norm.pdf(x, 0, 1), linewidth = 2, color = '#000')  #pintar el area sombreada del grafico y graficar plt.fill_between(x_filtered, norm.pdf(x_filtered, 0, 1), color='#5CCB5F', alpha=0.5, edgecolor='black')  #a\u00f1adir texto al grafico plt.text(-2.8, 0.20, (\"P(z &lt; -0.50)\")) plt.text(3, 0, (\"z\"))  #bordes del grafico ax = plt.gca() ax.spines['top'].set_color('#009929') ax.spines['top'].set_linewidth(2) #ancho del borde superior ax.spines['top'].set_bounds(-6, 6) ax.spines['bottom'].set_color('#009929') ax.spines['bottom'].set_linewidth(2) #ancho del borde inferior ax.spines['bottom'].set_bounds(-6, 6) ax.spines['right'].set_visible(False) ax.spines['left'].set_visible(False)  #pintar el fondo interno del grafico ax.set_facecolor('#D4F8B7')  #linea inferior del grafico plt.plot(x, [0]*len(x), color='black', linewidth=1)  #centrar el grafico plt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)  #plt.arrow(0.1, 0.1, 0.2, 0.2, width=0.05, color='black')  #flecha plt.annotate(\" \", xytext = (-2, 0.2), xy = (-1, 0.05), arrowprops = dict(facecolor = 'black', width = 0.2, headwidth = 8),              horizontalalignment = 'center')  #texto con flecha plt.annotate(\"P(-0.50 \\u2264 z \\u2264 1.25)\", xytext = (2.5, 0.25),              xy = (0.5, 0.15), arrowprops = dict(facecolor = 'black', width = 0.2, headwidth = 8),              horizontalalignment = 'center')  #mostrar ejes x, y plt.xticks([-0.50, 0, 1.25]) plt.yticks([]) plt.show() <p>Se requieren tres pasos:</p> <ol> <li>Se encuentra el area a la izquierda de z = 1.25.</li> <li>Se obtiene el area bajo la curva izquierda de z = -0.50</li> <li>Se resta el area a la izquierda de z = -0.50, del area a la izquierda de z = 1.25 para obtener P(-0.50 $\\le$ z $\\le$ 1.25).</li> </ol> <p>En el ejemplo, para $z$ = 1.25, se localiza el valor en la fila 1.2 y columna 0.05 de la tabla, resultando en un valor de 0.8944. Esto significa que la probabilidad de que ($z \\le$ 1.25) = 0.8944. De manera similar, para $z$ = -0.50, se encuentra el valor en la fila -0.5 y columna 0.00, siendo 0.3085, lo que indica que la probabilidad de que ($z \\le$ -0.50) = 0.3085. Luego, se calcula la probabilidad de que $z$ est\u00e9 entre (-0.50 $\\le z \\le$ 1.25) restando las dos probabilidades obtenidas, resultando en 0.5859.</p> <p>Ejemplo</p> <p>Suponga que queremos calcular la probabilidad de que la variable aleatoria normal est\u00e1ndar est\u00e9 dentro de una desviaci\u00f3n est\u00e1ndar de la media; es decir, $P$(-1.00 $\\le z \\le$ 1.00). Para ello, primero se obtiene el \u00e1rea bajo la curva entre -1.00 y 1.00.</p> <p>Antes se encontr\u00f3 que P(z $\\le$ 1.00) = 0.8413. Se ve que el \u00e1rea bajo la curva a la izquierda de z = -1.00 es 0.1587; por tanto P(z $\\le$ -1.00) = 0.1587. De ah\u00ed que P(-1.00 $\\le$ z $\\le$ 1.00) = P(z $\\le$ 1.00) - P(z $\\le$ -1.00) = 0.8413 - 0.1587 = 0.6826. Esta probabilidad se muestra gr\u00e1ficamente en la figura siguiente.</p> In\u00a0[8]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\nx = np.arange(-2.9, 2.9, 0.001)\n\n#pintar el fondo externo del grafico\nplt.figure(facecolor='#D4F8B7')\n\n#area de sombreado rango\nx_filtered = x[(x &gt;= -1.00) &amp; (x &lt;= 1.00)]\n\n#pintar la linea curva del grafico\nplt.plot(x, norm.pdf(x, 0, 1), linewidth = 1, color = '#000')\n\n#pintar el area sombreada del grafico y graficar\nplt.fill_between(x_filtered, norm.pdf(x_filtered, 0, 1), color='#5CCB5F', alpha=0.5, edgecolor='black')\n\n#a\u00f1adir texto al grafico\nplt.text(-2.8, 0.20, (\"P(z \\u2264 -0.50) \\n= 0.1587\"))\nplt.text(3, 0, (\"z\"))\n\n#bordes del grafico\nax = plt.gca()\nax.spines['top'].set_color('#009929')\nax.spines['top'].set_linewidth(2)\n#ancho del borde superior\nax.spines['top'].set_bounds(-6, 6)\nax.spines['bottom'].set_color('#009929')\nax.spines['bottom'].set_linewidth(2)\n#ancho del borde inferior\nax.spines['bottom'].set_bounds(-6, 6)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\n\n#pintar el fondo interno del grafico\nax.set_facecolor('#D4F8B7')\n\n#linea inferior del grafico\nplt.plot(x, [0]*len(x), color='black', linewidth=2)\n\n#centrar el grafico\nplt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)\n\n#flecha\nplt.annotate(\" \", xytext = (-2, 0.2), xy = (-1.25, 0.10), arrowprops = dict(facecolor = 'black', width = 0.2, headwidth = 8),\n             horizontalalignment = 'center')\n\n#texto con flecha\nplt.annotate(\"P(-1.00 \\u2264 z \\u2264 1.00) \\n= 0.8413 - 01587 = 0.6826\", xytext = (2.5, 0.25),\n             xy = (0.5, 0.15), arrowprops = dict(facecolor = 'black', width = 0.2, headwidth = 8),\n             horizontalalignment = 'center')\n\n#mostrar ejes x, y\nplt.xticks([-1, 0, 1], ['{:.2f}'.format(i) for i in [-1, 0, 1]])\nplt.yticks([])\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm  x = np.arange(-2.9, 2.9, 0.001)  #pintar el fondo externo del grafico plt.figure(facecolor='#D4F8B7')  #area de sombreado rango x_filtered = x[(x &gt;= -1.00) &amp; (x &lt;= 1.00)]  #pintar la linea curva del grafico plt.plot(x, norm.pdf(x, 0, 1), linewidth = 1, color = '#000')  #pintar el area sombreada del grafico y graficar plt.fill_between(x_filtered, norm.pdf(x_filtered, 0, 1), color='#5CCB5F', alpha=0.5, edgecolor='black')  #a\u00f1adir texto al grafico plt.text(-2.8, 0.20, (\"P(z \\u2264 -0.50) \\n= 0.1587\")) plt.text(3, 0, (\"z\"))  #bordes del grafico ax = plt.gca() ax.spines['top'].set_color('#009929') ax.spines['top'].set_linewidth(2) #ancho del borde superior ax.spines['top'].set_bounds(-6, 6) ax.spines['bottom'].set_color('#009929') ax.spines['bottom'].set_linewidth(2) #ancho del borde inferior ax.spines['bottom'].set_bounds(-6, 6) ax.spines['right'].set_visible(False) ax.spines['left'].set_visible(False)  #pintar el fondo interno del grafico ax.set_facecolor('#D4F8B7')  #linea inferior del grafico plt.plot(x, [0]*len(x), color='black', linewidth=2)  #centrar el grafico plt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)  #flecha plt.annotate(\" \", xytext = (-2, 0.2), xy = (-1.25, 0.10), arrowprops = dict(facecolor = 'black', width = 0.2, headwidth = 8),              horizontalalignment = 'center')  #texto con flecha plt.annotate(\"P(-1.00 \\u2264 z \\u2264 1.00) \\n= 0.8413 - 01587 = 0.6826\", xytext = (2.5, 0.25),              xy = (0.5, 0.15), arrowprops = dict(facecolor = 'black', width = 0.2, headwidth = 8),              horizontalalignment = 'center')  #mostrar ejes x, y plt.xticks([-1, 0, 1], ['{:.2f}'.format(i) for i in [-1, 0, 1]]) plt.yticks([]) plt.show() <p>suponga que se quiere determinar la probabilidad de obtener un valor $z$ por lo menos igual a 1.58; es decir, $P$($z \\ge$ 1.58). El valor en la fila $z$ = 1.5 y la columna 0.08 de la tabla normal acumulada es 0.9429; por tanto, $P$($z &lt;$ 1.58) = 0.9429. Como el \u00e1rea total bajo la curva normal es 1, $P$($z \\ge$ 1.58) = 1 - 0.9429 = 0.0571.</p> In\u00a0[11]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\nx = np.arange(-3.5, 3.5, 0.001)\n\n#pintar el fondo externo del grafico\nplt.figure(facecolor='#D4F8B7')\n\n\n#tama\u00f1o del grafico\n#plt.figure(figsize=(6,4))\n\n\n#area de sombreado rango\nx_filtered = x[(x &gt;= 1.58) &amp; (x &lt;= 3.50)]\n\n#pintar la linea curva del grafico\nplt.plot(x, norm.pdf(x, 0, 1), linewidth = 1, color = '#000')\n\n#pintar el area sombreada del grafico y graficar \nplt.fill_between(x_filtered, norm.pdf(x_filtered, 0, 1), color='#5CCB5F', alpha=0.5, edgecolor='black')\n\n#a\u00f1adir texto al grafico\nplt.text(3, 0.15, (\"P(z \\u2265 1.58) \\n= 1.0000 - 0.9429 = 0.0571\"))\nplt.text(3.9, 0, (\"z\"))\n\n#bordes del grafico\nax = plt.gca()\nax.spines['top'].set_color('#009929')\nax.spines['top'].set_linewidth(2)\n#ancho del borde superior\nax.spines['top'].set_bounds(-6, 6)\nax.spines['bottom'].set_color('#009929')\nax.spines['bottom'].set_linewidth(2)\n#ancho del borde inferior\nax.spines['bottom'].set_bounds(-6, 6)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\n\n#pintar el fondo interno del grafico\nax.set_facecolor('#D4F8B7')\n\n#linea inferior del grafico\nplt.plot(x, [0]*len(x), color='black', linewidth=1)\n\n#centrar el grafico\nplt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)\n\n#plt.arrow(0.1, 0.1, 0.2, 0.2, width=0.05, color='black')\n\n#flecha\nplt.annotate(\" \", xytext = (2.9, 0.15), xy = (1.8, 0.05), arrowprops = dict(facecolor = 'black', width = 0.2, headwidth = 8),\n             horizontalalignment = 'center')\n\n#texto con flecha\nplt.annotate(\"P(z &lt; 1.58) = 09429\", xytext = (2.5, 0.25), \n             xy = (0, 0.20), arrowprops = dict(facecolor = 'black', width = 0.2, headwidth = 8),\n             horizontalalignment = 'center')\n\n#mostrar ejes x, y\nplt.xticks([-2, -1, 0, 1, 2])\nplt.yticks([])\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm  x = np.arange(-3.5, 3.5, 0.001)  #pintar el fondo externo del grafico plt.figure(facecolor='#D4F8B7')   #tama\u00f1o del grafico #plt.figure(figsize=(6,4))   #area de sombreado rango x_filtered = x[(x &gt;= 1.58) &amp; (x &lt;= 3.50)]  #pintar la linea curva del grafico plt.plot(x, norm.pdf(x, 0, 1), linewidth = 1, color = '#000')  #pintar el area sombreada del grafico y graficar  plt.fill_between(x_filtered, norm.pdf(x_filtered, 0, 1), color='#5CCB5F', alpha=0.5, edgecolor='black')  #a\u00f1adir texto al grafico plt.text(3, 0.15, (\"P(z \\u2265 1.58) \\n= 1.0000 - 0.9429 = 0.0571\")) plt.text(3.9, 0, (\"z\"))  #bordes del grafico ax = plt.gca() ax.spines['top'].set_color('#009929') ax.spines['top'].set_linewidth(2) #ancho del borde superior ax.spines['top'].set_bounds(-6, 6) ax.spines['bottom'].set_color('#009929') ax.spines['bottom'].set_linewidth(2) #ancho del borde inferior ax.spines['bottom'].set_bounds(-6, 6) ax.spines['right'].set_visible(False) ax.spines['left'].set_visible(False)  #pintar el fondo interno del grafico ax.set_facecolor('#D4F8B7')  #linea inferior del grafico plt.plot(x, [0]*len(x), color='black', linewidth=1)  #centrar el grafico plt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)  #plt.arrow(0.1, 0.1, 0.2, 0.2, width=0.05, color='black')  #flecha plt.annotate(\" \", xytext = (2.9, 0.15), xy = (1.8, 0.05), arrowprops = dict(facecolor = 'black', width = 0.2, headwidth = 8),              horizontalalignment = 'center')  #texto con flecha plt.annotate(\"P(z &lt; 1.58) = 09429\", xytext = (2.5, 0.25),               xy = (0, 0.20), arrowprops = dict(facecolor = 'black', width = 0.2, headwidth = 8),              horizontalalignment = 'center')  #mostrar ejes x, y plt.xticks([-2, -1, 0, 1, 2]) plt.yticks([]) plt.show() <p>Suponga que quiere determinar un valor de $z$ tal que la probabilidad de obtener un valor de $z$ mayor sea 0.10. La figura siguiente muestra esta situaci\u00f3n de manera gr\u00e1fica.</p> In\u00a0[12]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\nx = np.arange(-3.5, 3.5, 0.001)\n\n#pintar el fondo externo del grafico\nplt.figure(facecolor='#D4F8B7')\n\n\n#tama\u00f1o del grafico\n#plt.figure(figsize=(6,4))\n\n\n#area de sombreado rango\nx_filtered = x[(x &gt;= 1.58) &amp; (x &lt;= 3.50)]\n\n#pintar la linea curva del grafico\nplt.plot(x, norm.pdf(x, 0, 1), linewidth = 1, color = '#000')\n\n#pintar el area sombreada del grafico y graficar \nplt.fill_between(x_filtered, norm.pdf(x_filtered, 0, 1), color='#5CCB5F', alpha=0.5, edgecolor='black')\n\n#a\u00f1adir texto al grafico\nplt.text(-1, 0.10, (\"Probabilidad = 0.10\"))\nplt.text(3.9, 0, (\"z\"))\n\n#bordes del grafico\nax = plt.gca()\nax.spines['top'].set_color('#009929')\nax.spines['top'].set_linewidth(2)\n#ancho del borde superior\nax.spines['top'].set_bounds(-6, 6)\nax.spines['bottom'].set_color('#009929')\nax.spines['bottom'].set_linewidth(2)\n#ancho del borde inferior\nax.spines['bottom'].set_bounds(-6, 6)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\n\n#pintar el fondo interno del grafico\nax.set_facecolor('#D4F8B7')\n\n#linea inferior del grafico\nplt.plot(x, [0]*len(x), color='black', linewidth=1)\n\n#centrar el grafico\nplt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)\n\n#plt.arrow(0.1, 0.1, 0.2, 0.2, width=0.05, color='black')\n\n#flecha\nplt.annotate(\" \", xytext = (1, 0.10), xy = (1.8, 0.05), arrowprops = dict(facecolor = 'black', width = 0.2, headwidth = 8),\n             horizontalalignment = 'center')\n\nplt.annotate(\"\u00bfCual es el valor de z?\", xytext = (3.8, 0.05), xy = (1.58, 0), arrowprops = dict(facecolor = 'black', width = 0.2, headwidth = 8),\n             horizontalalignment = 'center')\n\n#mostrar ejes x, y\nplt.xticks([-2, -1, 0, 1, 2])\nplt.yticks([])\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm  x = np.arange(-3.5, 3.5, 0.001)  #pintar el fondo externo del grafico plt.figure(facecolor='#D4F8B7')   #tama\u00f1o del grafico #plt.figure(figsize=(6,4))   #area de sombreado rango x_filtered = x[(x &gt;= 1.58) &amp; (x &lt;= 3.50)]  #pintar la linea curva del grafico plt.plot(x, norm.pdf(x, 0, 1), linewidth = 1, color = '#000')  #pintar el area sombreada del grafico y graficar  plt.fill_between(x_filtered, norm.pdf(x_filtered, 0, 1), color='#5CCB5F', alpha=0.5, edgecolor='black')  #a\u00f1adir texto al grafico plt.text(-1, 0.10, (\"Probabilidad = 0.10\")) plt.text(3.9, 0, (\"z\"))  #bordes del grafico ax = plt.gca() ax.spines['top'].set_color('#009929') ax.spines['top'].set_linewidth(2) #ancho del borde superior ax.spines['top'].set_bounds(-6, 6) ax.spines['bottom'].set_color('#009929') ax.spines['bottom'].set_linewidth(2) #ancho del borde inferior ax.spines['bottom'].set_bounds(-6, 6) ax.spines['right'].set_visible(False) ax.spines['left'].set_visible(False)  #pintar el fondo interno del grafico ax.set_facecolor('#D4F8B7')  #linea inferior del grafico plt.plot(x, [0]*len(x), color='black', linewidth=1)  #centrar el grafico plt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)  #plt.arrow(0.1, 0.1, 0.2, 0.2, width=0.05, color='black')  #flecha plt.annotate(\" \", xytext = (1, 0.10), xy = (1.8, 0.05), arrowprops = dict(facecolor = 'black', width = 0.2, headwidth = 8),              horizontalalignment = 'center')  plt.annotate(\"\u00bfCual es el valor de z?\", xytext = (3.8, 0.05), xy = (1.58, 0), arrowprops = dict(facecolor = 'black', width = 0.2, headwidth = 8),              horizontalalignment = 'center')  #mostrar ejes x, y plt.xticks([-2, -1, 0, 1, 2]) plt.yticks([]) plt.show()      Dada una probabilidad, se puede usar la tabla normal  est\u00e1ndar en modo inverso para encontrar el valor de z correspondiente.    <p>Este problema es el inverso de las situaciones presentadas en los ejemplos anteriores, en los cuales se especific\u00f3 el valor de $z$ y luego se calcul\u00f3 la probabilidad, o \u00e1rea, correspondiente. En este ejemplo se proporciona la probabilidad, o \u00e1rea, y luego se pide determinar el valor $z$ respectivo. Para hacerlo, se usa la tabla de probabilidad normal est\u00e1ndar de una manera un poco distinta.</p> <p>La tabla proporciona el \u00e1rea bajo la curva a la izquierda de un valor de $z$ espec\u00edfico. Dado que se conoce que el \u00e1rea en el extremo superior de la curva es 0.10, se busca un valor de $z$ tal que el \u00e1rea a la izquierda de este sea igual a 0.9000. Al revisar la tabla, se encuentra que 0.8997 es la probabilidad acumulada m\u00e1s cercana a 0.9000, y se presenta la secci\u00f3n correspondiente de la tabla que muestra este resultado.</p> <p>Tabla 6.2  Distribuci\u00f3n de probabilidad normal estandar z 0.06 0.07 0.08 0.09 ... 1.0 0.8554 0.8577 0.8599 0.8621 1.1 0.8770 0.8790 0.8810 0.8830 1.2 0.8962 0.8980 0.8997 0.9015 1.3 0.9131 0.9147 0.9162 0.9177 1.4 0.9279 0.9292 0.9306 0.9319 ... </p> <p>Al leer el valor de $z$ en la columna del extremo izquierdo y la fila superior de la tabla, encontramos que es 1.28. Por tanto, un \u00e1rea de aproximadamente 0.9000 (en realidad, 0.8997) estar\u00e1 a la izquierda de $z$ = 1.28 Respecto de la pregunta formulada originalmente, hay una probabilidad aproximada de 0.10 de que el valor de $z$ sea mayor que 1.28.</p> <p>Se estudia la distribuci\u00f3n normal est\u00e1ndar de manera detallada porque se utiliza para calcular las probabilidades de todas las distribuciones normales. Cuando se enfrenta a preguntas de probabilidad sobre una distribuci\u00f3n normal con una media ($\\mu$) y una desviaci\u00f3n est\u00e1ndar ($\\sigma$) espec\u00edficas, se resuelven convirtiendo primero la distribuci\u00f3n a la normal est\u00e1ndar. Se emplea la tabla de probabilidad normal est\u00e1ndar y los valores de $z$ correspondientes para obtener las probabilidades deseadas. El p\u00e1rrafo menciona la f\u00f3rmula para convertir cualquier variable aleatoria normal ($x$) con media $\\mu$ y desviaci\u00f3n est\u00e1ndar $\\sigma$ a la variable aleatoria normal est\u00e1ndar ($z$).</p> CONVERSI\u00d3N A LA VARIABLE ALEATORIA NORMAL ESTANDAR                  $$ z = \\frac{x - \\mu}{\\sigma}$$              (6.3) <p>Suponga que LLANTAX<sub>Ltda</sub> Desarrollo un nuevo neumatico radial con cinturon de acero que se vende a traves de una cadena nacional de tiendas de descuento. Tomando en cuenta que el neumatico es un nuevo producto. Los gerentes creen que la garantia de kilometraje sera un factor importante. Los gerentes quieren informacion de probabilidad sobre los x = numero de kilometros que estos duran.</p> <p>El grupo de ingenieria estim\u00f3 que su kilometraje es \u03bc = 42000 kilometros y la desviacion estandar es \u03c3 = 5000. Los datos recabados indican que es una distribucion normal.</p> <p>\u00bfCual es la probabilidad de que el kilometraje de los neumaticos x sepere la cifra de 50000 kilometros?</p> In\u00a0[13]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\nx = np.arange(-3.5, 3.5, 0.001)\n\n#pintar el fondo externo del grafico\nplt.figure(facecolor='#D4F8B7')\n\n#area de sombreado rango\nx_filtered = x[(x &gt;= 1.6) &amp; (x &lt;= 3.50)]\n\n#pintar la linea curva del grafico\nplt.plot(x, norm.pdf(x, 0, 1), linewidth = 1, color = '#000')\n\n#pintar el area sombreada del grafico y graficar \nplt.fill_between(x_filtered, norm.pdf(x_filtered, 0, 1), color='#5CCB5F', alpha=0.5, edgecolor='black')\n\n#a\u00f1adir texto al grafico\nplt.text(2.6, 0.10, (\"P(x \\u2265 50000)\"))\nplt.text(2.6, 0.30, (\"\u03bc = 42000\"))\nplt.text(2.6, 0.28, (\"\u03c3 = 5000\"))\nplt.text(-3, 0.30, (\"P(x &lt; 50000)\"))\nplt.text(3.9, 0, (\"z\"))\n\n#bordes del grafico\nax = plt.gca()\nax.spines['top'].set_color('#009929')\nax.spines['top'].set_linewidth(2)\n#ancho del borde superior\nax.spines['top'].set_bounds(-6, 6)\nax.spines['bottom'].set_color('#009929')\nax.spines['bottom'].set_linewidth(2)\n#ancho del borde inferior\nax.spines['bottom'].set_bounds(-6, 6)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\n\n#pintar el fondo interno del grafico\nax.set_facecolor('#D4F8B7')\n\n#linea inferior del grafico\nplt.plot(x, [0]*len(x), color='black', linewidth=1)\n\n#centrar el grafico\nplt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)\n\n#plt.arrow(0.1, 0.1, 0.2, 0.2, width=0.05, color='black')\n\n#flecha\nplt.annotate(\" \", xytext = (2.9, 0.1), xy = (1.8, 0.03), arrowprops = dict(facecolor = 'black', width = 0.2, headwidth = 8),\n             horizontalalignment = 'center')\n\nplt.annotate(\" \", xytext = (-2, 0.29), xy = (0, 0.15), arrowprops = dict(facecolor = 'black', width = 0.2, headwidth = 8),\n             horizontalalignment = 'center')\n\n#mostrar ejes x, y\nplt.xticks([0, 1.6])\nplt.yticks([])\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm  x = np.arange(-3.5, 3.5, 0.001)  #pintar el fondo externo del grafico plt.figure(facecolor='#D4F8B7')  #area de sombreado rango x_filtered = x[(x &gt;= 1.6) &amp; (x &lt;= 3.50)]  #pintar la linea curva del grafico plt.plot(x, norm.pdf(x, 0, 1), linewidth = 1, color = '#000')  #pintar el area sombreada del grafico y graficar  plt.fill_between(x_filtered, norm.pdf(x_filtered, 0, 1), color='#5CCB5F', alpha=0.5, edgecolor='black')  #a\u00f1adir texto al grafico plt.text(2.6, 0.10, (\"P(x \\u2265 50000)\")) plt.text(2.6, 0.30, (\"\u03bc = 42000\")) plt.text(2.6, 0.28, (\"\u03c3 = 5000\")) plt.text(-3, 0.30, (\"P(x &lt; 50000)\")) plt.text(3.9, 0, (\"z\"))  #bordes del grafico ax = plt.gca() ax.spines['top'].set_color('#009929') ax.spines['top'].set_linewidth(2) #ancho del borde superior ax.spines['top'].set_bounds(-6, 6) ax.spines['bottom'].set_color('#009929') ax.spines['bottom'].set_linewidth(2) #ancho del borde inferior ax.spines['bottom'].set_bounds(-6, 6) ax.spines['right'].set_visible(False) ax.spines['left'].set_visible(False)  #pintar el fondo interno del grafico ax.set_facecolor('#D4F8B7')  #linea inferior del grafico plt.plot(x, [0]*len(x), color='black', linewidth=1)  #centrar el grafico plt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)  #plt.arrow(0.1, 0.1, 0.2, 0.2, width=0.05, color='black')  #flecha plt.annotate(\" \", xytext = (2.9, 0.1), xy = (1.8, 0.03), arrowprops = dict(facecolor = 'black', width = 0.2, headwidth = 8),              horizontalalignment = 'center')  plt.annotate(\" \", xytext = (-2, 0.29), xy = (0, 0.15), arrowprops = dict(facecolor = 'black', width = 0.2, headwidth = 8),              horizontalalignment = 'center')  #mostrar ejes x, y plt.xticks([0, 1.6]) plt.yticks([]) plt.show() <p>En $x$ = 50000 tenemos</p> <p>\\begin{equation*}     z = \\frac{x - \\mu}{\\sigma} = \\frac{50000 - 42000}{5000} = \\frac{8000}{5000} = 1.6 \\end{equation*}</p> <p>Vemos que un valor de $x$ = 50 000 en la distribuci\u00f3n normal de LLANTAX<sub>Ltda</sub> corresponde al valor de $z$ =1.6 en la distribuci\u00f3n normal est\u00e1ndar. Consultando la tabla de probabilidad normal est\u00e1ndar, constatamos que el \u00e1rea bajo la curva normal est\u00e1ndar a la izquierda de $z$ = 1.6 es 0.9452. Por tanto, 1.000 - 0.9452 = 0.0548 es la probabilidad de que $z$ exceda 1.6, y por consiguiente x exceder\u00e1 de 50 000.</p> <p>Podemos concluir que alrededor de 5.48% de los neum\u00e1ticos superar\u00e1 los 50 000 kilometros.</p> <p>La distribuci\u00f3n normal proporciona una aproximaci\u00f3n f\u00e1cil de usar de las probabilidades binomiales.</p> <p>Cuando se usa la aproximaci\u00f3n normal a la binomial, se establece</p> <p>$$\\mu = np \\quad y\\quad \\sigma = np(1 -p)$$</p> <p>en la definici\u00f3n de la curva normal.</p> <p>Si x es una variable aleatoria binomial con media $\\mu = np$ y varianza $\\sigma^2 = npq$  entonces la forma limitante de la distribuci\u00f3n de</p> <p>\\begin{align*} z=\\frac{x-np}{\\sqrt{npq}} \\end{align*}</p> <p>conforme $n\\rightarrow\\infty$, es la distribucion normal estandar $n(z;0,1).$</p> <p>Resulta que la distribuci\u00f3n normal con $\\mu = np$ y $\\sigma^2 = np(1-p)$ no solo ofrece una aproximaci\u00f3n muy precisa la distribuci\u00f3n binomial cuando $n$ es grande y $p$ no est\u00e1 extremadamente cerca de 0 o de 1, sino que tambi\u00e9n brinda una aproximaci\u00f3n bastante buena a\u00fan cuando $n$ es peque\u00f1a y $p$ est\u00e1 razonablemente cerca de 1/2.</p> <p>Ejemplo 1</p> <p>Un paciente que padece una rara enfermedad de la sangre tiene 0.4 de probabilidad de recuperarse , si se sabe que 100 personas contrajeron esta enfermedad, \u00bfCu\u00e1l es la probabilidad de que sobrevivan menos de 30?</p> <p>Soluci\u00f3n </p> <p>En este caso:</p> <ul> <li>$n$ (tama\u00f1o de la muestra) = 100</li> <li>$p$ (probabilidad de \u00e9xito) = 0.4</li> <li>$\\sigma $(desviaci\u00f3n est\u00e1ndar) = $\\sqrt{100 \\cdot 0.4\\cdot 0.6}= 4.899 $</li> <li>$\\mu$ (media) = $n*p$ = 120</li> </ul> <p>para obtener la probabilidad que se desea, tenemos que calcular</p> <ul> <li>el area a la izquierda de x= 29.5</li> <li>el valor $z$ que corresponde a 29.5</li> </ul> <p>es:</p> <p>\\begin{align*} z=\\frac{29.5 - 40}{4.899} = -2.14 \\end{align*}</p> <p>y la probabilidad de que menos de 30 de los 100 pacientes sobrevivan est\u00e1 dada por la reg\u00edon sombreada de la siguiente figura:</p> <p>$$z=P(X&lt;30)\u2261P(Z&lt;-2.14)=0.0162$$</p> In\u00a0[4]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\nx = np.arange(-2.9, 2.9, 0.001)\n\n#pintar el fondo externo del grafico\nplt.figure(facecolor='#D4F8B7')\n\n#area de sombreado rango\nx_filtered = x[(x &lt;= -2.14)]\n\n#pintar la linea curva del grafico\nplt.plot(x, norm.pdf(x, 0, 1), linewidth = 1, color = '#000')\n\n#pintar el area sombreada del grafico y graficar\nplt.fill_between(x_filtered, norm.pdf(x_filtered, 0, 1), color='#5CCB5F', alpha=0.5, edgecolor='black')\n\n#a\u00f1adir texto al grafico\nplt.text(-5, 0.3, (\"$z= P(X \\u003C 30) \\u2261 P(Z\\u003C-2.14)\\u003D  0.0162$\")) \nplt.text(-3.9, 0.10, (\"P(z \\u2264 -2.14) \\n= 0.0162\"))  \nplt.text(3, 0, (\"z\"))\n\n#bordes del grafico\nax = plt.gca()\nax.spines['top'].set_color('#009929')\nax.spines['top'].set_linewidth(2)\n#ancho del borde superior\nax.spines['top'].set_bounds(-6, 6)\nax.spines['bottom'].set_color('#009929')\nax.spines['bottom'].set_linewidth(2)\n#ancho del borde inferior\nax.spines['bottom'].set_bounds(-6, 6)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\n\n#pintar el fondo interno del grafico\nax.set_facecolor('#D4F8B7')\n\n#linea inferior del grafico\nplt.plot(x, [0]*len(x), color='black', linewidth=2)\n\n#centrar el grafico\nplt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)\n\n#flecha\nplt.annotate(\" \", xytext = (-3.3, 0.1), xy = (-2.5, 0.01), arrowprops = dict(facecolor = 'black', width = 0.2, headwidth = 8),\n             horizontalalignment = 'center')\n\n#mostrar ejes x, y\nplt.xticks([-2.14, -1, 0, 1], ['{:.2f}'.format(i) for i in [-2.14, -1, 0, 1]])\nplt.yticks([])\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm  x = np.arange(-2.9, 2.9, 0.001)  #pintar el fondo externo del grafico plt.figure(facecolor='#D4F8B7')  #area de sombreado rango x_filtered = x[(x &lt;= -2.14)]  #pintar la linea curva del grafico plt.plot(x, norm.pdf(x, 0, 1), linewidth = 1, color = '#000')  #pintar el area sombreada del grafico y graficar plt.fill_between(x_filtered, norm.pdf(x_filtered, 0, 1), color='#5CCB5F', alpha=0.5, edgecolor='black')  #a\u00f1adir texto al grafico plt.text(-5, 0.3, (\"$z= P(X \\u003C 30) \\u2261 P(Z\\u003C-2.14)\\u003D  0.0162$\"))  plt.text(-3.9, 0.10, (\"P(z \\u2264 -2.14) \\n= 0.0162\"))   plt.text(3, 0, (\"z\"))  #bordes del grafico ax = plt.gca() ax.spines['top'].set_color('#009929') ax.spines['top'].set_linewidth(2) #ancho del borde superior ax.spines['top'].set_bounds(-6, 6) ax.spines['bottom'].set_color('#009929') ax.spines['bottom'].set_linewidth(2) #ancho del borde inferior ax.spines['bottom'].set_bounds(-6, 6) ax.spines['right'].set_visible(False) ax.spines['left'].set_visible(False)  #pintar el fondo interno del grafico ax.set_facecolor('#D4F8B7')  #linea inferior del grafico plt.plot(x, [0]*len(x), color='black', linewidth=2)  #centrar el grafico plt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)  #flecha plt.annotate(\" \", xytext = (-3.3, 0.1), xy = (-2.5, 0.01), arrowprops = dict(facecolor = 'black', width = 0.2, headwidth = 8),              horizontalalignment = 'center')  #mostrar ejes x, y plt.xticks([-2.14, -1, 0, 1], ['{:.2f}'.format(i) for i in [-2.14, -1, 0, 1]]) plt.yticks([]) plt.show() <p>Ejemplo 2</p> <p>Un examen de opcion multiple tiene 200 preguntas, cada una con 4 respuestas posibles, de las que solo una es la correcta. \u00bfCual es la probabilidad de que solamente adivinando se obtengan de 25 a 30 respuestas correctas para 80 de los 200 problemas sobre los que el estudiante no tiene conocimientos?</p> <p>Soluci\u00f3n </p> <p>La probabilidad de adivinar una respuesta correcta para cada una de las 80 preguntas es $p$=1/4. Si x representa el numero de respuestas correctas solo por que se adivinaron, entonces</p> <p>\\begin{align*} P(25\\leq X\\leq 30) = \\sum_{x=25}^{30} b(x;80,1/4) \\end{align*}</p> <p>Al usar la aproximacion de la curva normal con</p> <p>\\begin{align*} \\mu = np =(80)\\left(\\frac{1}{4}\\right) = 20 \\end{align*}</p> <p>y</p> <p>\\begin{align*} \\sigma =\\sqrt{npq} = \\sqrt{(80)\\left(\\frac{1}{4}\\right)\\left(\\frac{3}{4}\\right)}= 3.873 \\end{align*}</p> <p>necesitamos el area entre $x_1=24.5$ y $x_2=30.5$.</p> <p>Los valores $z$ correspondientes son</p> <p>\\begin{equation*}     z_1=\\frac{24.5-20}{3.873} = 1.16 \\quad y \\quad z_2=\\frac{30.5-20}{3.873} = 2.71 \\end{equation*}</p> <p>La probabilidad de adivinar correctamente de 25 a 30 preguntas es dada por la region sombreada de la siguiente figura, encontramos que:</p> <p>\\begin{align*} P(25 \\leq X \\leq 30) &amp;= P(1.16 &lt; X &lt; 2.71)\\\\ &amp;=P[(Z&lt;2.71) - (Z&lt; 1.16)]\\\\ &amp;= 0.9966-0.8770 = 0.1196 \\end{align*}</p> In\u00a0[6]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\nx = np.arange(-2.9, 2.9, 0.001)\n\n#pintar el fondo externo del grafico\nplt.figure(facecolor='#D4F8B7')\n\n#area de sombreado rango\nx_filtered = x[(x &gt;= 1.16) &amp; (x&lt;=2.71)]\n\n#pintar la linea curva del grafico\nplt.plot(x, norm.pdf(x, 0, 1), linewidth = 1, color = '#000')\n\n#pintar el area sombreada del grafico y graficar\nplt.fill_between(x_filtered, norm.pdf(x_filtered, 0, 1), color='#5CCB5F', alpha=0.5, edgecolor='black')\n\n#a\u00f1adir texto al grafico\nplt.text(2.9, 0.10, (\"$P(1.16 \\u003C Z \\u003C 2.71) \\u003D 0.1196$\")) \n\nplt.text(3, 0, (\"z\"))\n\n#bordes del grafico\nax = plt.gca()\nax.spines['top'].set_color('#009929')\nax.spines['top'].set_linewidth(2)\n#ancho del borde superior\nax.spines['top'].set_bounds(-6, 6)\nax.spines['bottom'].set_color('#009929')\nax.spines['bottom'].set_linewidth(2)\n#ancho del borde inferior\nax.spines['bottom'].set_bounds(-6, 6)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\n\n#pintar el fondo interno del grafico\nax.set_facecolor('#D4F8B7')\n\n#linea inferior del grafico\nplt.plot(x, [0]*len(x), color='black', linewidth=2)\n\n#centrar el grafico\nplt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)\n\n#flecha\nplt.annotate(\" \", xytext = (2.9, 0.1), xy = (1.8, 0.09), arrowprops = dict(facecolor = 'black', width = 0.2, headwidth = 8),\n             horizontalalignment = 'center')\n\n#mostrar ejes x, y\nplt.xticks([-3,-2,-1, 0 ,1.16,2,2.71], ['{:.2f}'.format(i) for i in [-3,-2,-1, 0, 1.16,2, 2.71]])\n\nplt.yticks([])\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm  x = np.arange(-2.9, 2.9, 0.001)  #pintar el fondo externo del grafico plt.figure(facecolor='#D4F8B7')  #area de sombreado rango x_filtered = x[(x &gt;= 1.16) &amp; (x&lt;=2.71)]  #pintar la linea curva del grafico plt.plot(x, norm.pdf(x, 0, 1), linewidth = 1, color = '#000')  #pintar el area sombreada del grafico y graficar plt.fill_between(x_filtered, norm.pdf(x_filtered, 0, 1), color='#5CCB5F', alpha=0.5, edgecolor='black')  #a\u00f1adir texto al grafico plt.text(2.9, 0.10, (\"$P(1.16 \\u003C Z \\u003C 2.71) \\u003D 0.1196$\"))   plt.text(3, 0, (\"z\"))  #bordes del grafico ax = plt.gca() ax.spines['top'].set_color('#009929') ax.spines['top'].set_linewidth(2) #ancho del borde superior ax.spines['top'].set_bounds(-6, 6) ax.spines['bottom'].set_color('#009929') ax.spines['bottom'].set_linewidth(2) #ancho del borde inferior ax.spines['bottom'].set_bounds(-6, 6) ax.spines['right'].set_visible(False) ax.spines['left'].set_visible(False)  #pintar el fondo interno del grafico ax.set_facecolor('#D4F8B7')  #linea inferior del grafico plt.plot(x, [0]*len(x), color='black', linewidth=2)  #centrar el grafico plt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)  #flecha plt.annotate(\" \", xytext = (2.9, 0.1), xy = (1.8, 0.09), arrowprops = dict(facecolor = 'black', width = 0.2, headwidth = 8),              horizontalalignment = 'center')  #mostrar ejes x, y plt.xticks([-3,-2,-1, 0 ,1.16,2,2.71], ['{:.2f}'.format(i) for i in [-3,-2,-1, 0, 1.16,2, 2.71]])  plt.yticks([]) plt.show() <p>La distribuci\u00f3n de probabilidad exponencial es una distribuci\u00f3n continua que esta ligada al tiempo, se utiliza para modelar tiempos de espera para la ocurrencia de un cierto evento se puede usarse para variables aleatorias como el tiempo entre la llegada de un autom\u00f3vil a un autolavado, el tiempo requerido para cargar un cami\u00f3n, el tiempo de espera para ser atendidos los pacientes en una cl\u00ednica, tiempo de espera en un banco, etc.</p> <p>La funci\u00f3n de densidad de probabilidad exponencial se presenta a continuaci\u00f3n.</p> FFUNCI\u00d3N DE DENSIDAD DE PROBABILIDAD EXPONENCIAL                  $$  f(x) = \\frac{1}{\\mu} e^{-\\frac{x}{\\mu}}$$              (6.4)          Donde:  <ul> <li>$\\mu$ = valor esperado o media</li></ul> <p>Como ejemplo de la distribuci\u00f3n exponencial, suponga que $x$ representa el tiempo de carga para un cami\u00f3n en el muelle Schips y sigue dicha distribuci\u00f3n. Si la media, o promedio, del tiempo de carga es 15 minutos ($\\mu$ = 15), la funci\u00f3n de densidad de probabilidad apropiada para $x$ es:</p> <p>\\begin{equation*}     f(x) = \\frac{1}{15} e^{-\\frac{x}{15}} \\end{equation*}</p> <p>La figura 6.10 es la gr\u00e1fica de esta funci\u00f3n de densidad de probabilidad</p> <p>Al igual que con la distribuci\u00f3n de probabilidad continua, el \u00e1rea bajo la curva correspondiente a un intervalo proporciona la probabilidad de que la variable aleatoria asuma un valor en ese intervalo.</p> <p>En el muelle M\u00d3NACO, la probabilidad de que la carga de un cami\u00f3n tarde 20 minutos o menos $P(x \\leqslant 10)$ se define como el \u00e1rea bajo la curva en la figura 6.10 de x = 0 a x = 10. De manera similar, la probabilidad de que dicho tiempo sea de 20 minutos o menos $P(x \\leqslant 25)$ es el \u00e1rea bajo la curva de x = 0 a x = 25. Note tambi\u00e9n que la probabilidad de que el tiempo de carga est\u00e9 entre 10 y 25 minutos $P(10 \\leqslant x \\leqslant 25)$ est\u00e1 dado por el \u00e1rea bajo la curva de x = 10 a x = 25. Para calcular probabilidades exponenciales como las que se acaban de describir, se usa la f\u00f3rmula siguiente, la cual proporciona la probabilidad acumulada de obtener un valor para la variable aleatoria exponencial menor o igual que un valor espec\u00edfico denotado por $x_0$.</p> DISTRIBUCI\u00d3N EXPONENCIAL: PROBABILIDADES ACUMULADAS                  $$ P(x \\leq x_0) = 1-e^{-\\frac{x_0}{\\mu}}$$              (6.5) <p> Figura 6.10 Distribuci\u00f3n exponencial para el ejemplo del muelle de carga Schips</p> In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Definir la funci\u00f3n\ndef f(x):\n    return (1/20) * np.exp(-x/20)\n\n# Generar valores x\nx = np.linspace(0, 35, 1000)\n\n# Calcular los valores y correspondientes\ny = f(x)\n\n# Crear la gr\u00e1fica\nplt.figure(figsize=(8, 6))\nplt.plot(x, y, label=r'$f(x) = \\frac{1}{20}e^{-\\frac{x}{20}}$', color='black')\nplt.xlabel('Tiempo de carga')\n\n# Agregar fondo verde\nplt.gca().set_facecolor('#E1FFAF')\nplt.gcf().patch.set_facecolor('#E1FFAF')\n\n# Colorear las regiones entre 0-6 y 18-30\nplt.fill_between(x, y, where=[(val &gt;= 0 and val &lt;= 10) or (val &gt;= 25 and val &lt;= 35) for val in x], color='#98F84A')\nplt.fill_between(x, y, where=[(val &gt;= 10 and val &lt;= 25) for val in x], color='#5ccb5f')\n\n# Establecer los lugares y etiquetas deseadas en el eje x\nplt.xticks([0, 5, 10, 15, 20, 25, 30, 35])\n\n# Establecer las ubicaciones y etiquetas deseadas en el eje y\nplt.yticks([0.01, 0.03, 0.05, 0.07])\n\n# Ajustar l\u00edmites de los ejes\nplt.ylim(0, 0.07)  # Ajusta el l\u00edmite y seg\u00fan tu preferencia\nplt.xlim(0, 30)   # Ajusta el l\u00edmite x seg\u00fan tu preferencia\n\n# Ocultar solo las aristas de la derecha y de arriba\nplt.gca().spines['right'].set_visible(False)\nplt.gca().spines['top'].set_visible(False)\n\n# A\u00f1ade lineas en x = 10 y 25\nplt.vlines(x=10, ymin=0, ymax=0.03031, color='black', linestyle='-', linewidth=1)\nplt.vlines(x=25, ymin=0, ymax=0.01432, color='black', linestyle='-', linewidth=1)\n\n# Ajustar las l\u00edneas en el eje x\nfor point in [0, 5, 10, 15, 20, 25, 30, 35]:\n    plt.vlines(x=point, ymin=0, ymax=0.001, color='black', linestyle='-', linewidth=1)\nplt.text(30.5, 0, r'$x$', ha='left', va='center', color='black')\n\n# Ajustar las l\u00edneas en el eje y\nfor point in [0.01, 0.03, 0.05, 0.07]:\n    plt.hlines(y=point, xmin=0, xmax=0.5, color='black', linestyle='-', linewidth=1)\nplt.text(0, 0.074, r'$f(x)$', ha='left', va='center', color='black')\n\n# A\u00f1ade una flecha que apunte al intervalo entre 0 y 6\nplt.annotate('$P(x \\leqslant 10)$', xy=(3, 0.025), xytext=(5, 0.055),\n             arrowprops=dict(facecolor='black', arrowstyle='-&gt;'))\n\n# A\u00f1ade una flecha que apunte al intervalo entre 6 y 18\nplt.annotate('$P(10 \\leqslant x \\leqslant 25)$', xy=(16, 0.015), xytext=(18, 0.05),\n             arrowprops=dict(facecolor='black', arrowstyle='-&gt;'))\n\n# Mostrar la gr\u00e1fica\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  # Definir la funci\u00f3n def f(x):     return (1/20) * np.exp(-x/20)  # Generar valores x x = np.linspace(0, 35, 1000)  # Calcular los valores y correspondientes y = f(x)  # Crear la gr\u00e1fica plt.figure(figsize=(8, 6)) plt.plot(x, y, label=r'$f(x) = \\frac{1}{20}e^{-\\frac{x}{20}}$', color='black') plt.xlabel('Tiempo de carga')  # Agregar fondo verde plt.gca().set_facecolor('#E1FFAF') plt.gcf().patch.set_facecolor('#E1FFAF')  # Colorear las regiones entre 0-6 y 18-30 plt.fill_between(x, y, where=[(val &gt;= 0 and val &lt;= 10) or (val &gt;= 25 and val &lt;= 35) for val in x], color='#98F84A') plt.fill_between(x, y, where=[(val &gt;= 10 and val &lt;= 25) for val in x], color='#5ccb5f')  # Establecer los lugares y etiquetas deseadas en el eje x plt.xticks([0, 5, 10, 15, 20, 25, 30, 35])  # Establecer las ubicaciones y etiquetas deseadas en el eje y plt.yticks([0.01, 0.03, 0.05, 0.07])  # Ajustar l\u00edmites de los ejes plt.ylim(0, 0.07)  # Ajusta el l\u00edmite y seg\u00fan tu preferencia plt.xlim(0, 30)   # Ajusta el l\u00edmite x seg\u00fan tu preferencia  # Ocultar solo las aristas de la derecha y de arriba plt.gca().spines['right'].set_visible(False) plt.gca().spines['top'].set_visible(False)  # A\u00f1ade lineas en x = 10 y 25 plt.vlines(x=10, ymin=0, ymax=0.03031, color='black', linestyle='-', linewidth=1) plt.vlines(x=25, ymin=0, ymax=0.01432, color='black', linestyle='-', linewidth=1)  # Ajustar las l\u00edneas en el eje x for point in [0, 5, 10, 15, 20, 25, 30, 35]:     plt.vlines(x=point, ymin=0, ymax=0.001, color='black', linestyle='-', linewidth=1) plt.text(30.5, 0, r'$x$', ha='left', va='center', color='black')  # Ajustar las l\u00edneas en el eje y for point in [0.01, 0.03, 0.05, 0.07]:     plt.hlines(y=point, xmin=0, xmax=0.5, color='black', linestyle='-', linewidth=1) plt.text(0, 0.074, r'$f(x)$', ha='left', va='center', color='black')  # A\u00f1ade una flecha que apunte al intervalo entre 0 y 6 plt.annotate('$P(x \\leqslant 10)$', xy=(3, 0.025), xytext=(5, 0.055),              arrowprops=dict(facecolor='black', arrowstyle='-&gt;'))  # A\u00f1ade una flecha que apunte al intervalo entre 6 y 18 plt.annotate('$P(10 \\leqslant x \\leqslant 25)$', xy=(16, 0.015), xytext=(18, 0.05),              arrowprops=dict(facecolor='black', arrowstyle='-&gt;'))  # Mostrar la gr\u00e1fica plt.show()  <p>Para el ejemplo del muelle M\u00d3NACO, x = tiempo de carga en minutos y \u00b5 = 20 minutos.</p> <p>Usando la ecuaci\u00f3n (6.5)</p> <p>\\begin{equation*} P(x \\leqslant x_0) = 1-e^{-\\frac{x_0}{15}} \\end{equation*}</p> <p>Por consiguiente, la probabilidad de que un barco tarde 10 minutos o menos es</p> <p>\\begin{equation*} P(x \\leqslant 6) = 1-e^{-\\frac{10}{20}} = 0.3935 \\end{equation*}</p> <p>Utilizando la ecuaci\u00f3n (6.5), calculamos la probabilidad de cargar un barco en 25 minutos o menos.</p> <p>\\begin{equation*} P(x \\leqslant 18) = 1-e^{-\\frac{25}{20}} = 0.7135 \\end{equation*}</p> <p>Por tanto, la probabilidad de que la carga del barco tarde entre 10 y 25 minutos es igual a 0.6988 - 0.3297 = 0.3691.</p> <p>\\begin{align*} P(10 \\leqslant x \\leqslant 25)&amp;=P(x \\leqslant 25) - P(x \\leqslant 10)\\\\  &amp;= 0.7135 - 0.3935\\\\  &amp;= 0.32 \\end{align*}</p> <p>Las probabilidades para cualquier otro intervalo pueden calcularse de manera similar. En el ejemplo anterior, el tiempo promedio que toma cargar un barco es \u00b5 = 20 minutos. Una propiedad de la distribuci\u00f3n exponencial indica que la media de la distribuci\u00f3n y la desviaci\u00f3n est\u00e1ndar de la distribuci\u00f3n son iguales. Por tanto, la desviaci\u00f3n est\u00e1ndar del tiempo que lleva cargar un barco es \u03c3 = 20 minutos. La varianza es $\u03c3^2 = (20)^2 = 400.$</p> <p>Si la distribuci\u00f3n de Poisson proporciona una descripci\u00f3n apropiada del n\u00famero de ocurrencias por intervalo, la distribuci\u00f3n exponencial provee una descripci\u00f3n de la duraci\u00f3n del intervalo entre ocurrencias.</p> <p>Ejercicio 1. En la ciudad de La Paz se estima que la temperatura m\u00e1xima en el mes de septiembre sigue una distribuci\u00f3n normal, con media 18\u00b0 y desviaci\u00f3n t\u00edpica 4\u00b0.</p> <p>Calcular el numero de dias del mes en los que se espera alcanzar maximas entre 16\u00b0 y 21\u00b0 .</p> <p>Soluci\u00f3n  \\begin{align}     P(16 \\leq x \\leq 21) &amp;= P\\left(\\frac{16 - 18}{4} \\leq z \\leq \\frac{21 - 18}{4}\\right)\\\\     &amp;= P(-0.5 \\leq z \\leq 0.75)\\\\     &amp;= P(z \\leq 0.75) - P(z \\geq -0.5)\\\\     &amp;= P(z \\leq 0.75) - [1 - P(z \\leq 0.5)] \\end{align}</p> <p>Buscamos los valores en la tabla de distribucion normal:</p> <p>\\begin{equation*}     P(z \\leq 0.75) = 0.7733 \\quad y \\quad P(z \\leq 0.5) = 0.6914 \\end{equation*}</p> <p>Por lo tanto</p> <p>\\begin{align}     30 \\cdot P(16 \\leq x \\leq 21) &amp;= 30 \\cdot P\\left(\\frac{16 - 18}{4} \\leq z \\leq \\frac{21 - 18}{4}\\right)\\\\     &amp;= (30)[0.7733-(1-0.6914)]\\\\     &amp;= (30)(0.4647)\\\\     &amp;= 13.941 \\end{align}</p> <p>\u2234 Esto quiere decir, que en todo el mes, solo 14 dias alcanzaran temperatura entre 16 y 21 grados</p> <p>Ejercicio 2. La media de los pesos de 600 estudiantes de un colegio es 70 kg y la desviacion tipica 4 kg.</p> <p>Suponiendo que los pesos se distribuyen normalmente, hallar cuantos estudiantes pesan:</p> <p>1)  Entre 60 kg y 75 kg.</p> <p>2)  Mas de 90 kg.</p> <p>3)  Menos de 64 kg</p> <p>Soluci\u00f3n </p> <p>1 Entre 60 kg y 75 kg. </p> <p>\\begin{align}     P(60 &lt; x \\leq 75) &amp;= P\\left(\\frac{60 - 70}{4} \\leq z \\leq \\frac{75 - 70}{4}\\right)\\\\     &amp;= P(-2.5 \\leq z \\leq 1.25)\\\\     &amp;= P(z \\leq 1.25) - P(z \\geq -2.5)\\\\     &amp;= P(z \\leq 1.25) - [1 - P(z \\leq 2.5)] \\end{align}</p> <p>Buscamos los valores en la tabla de distribucion normal:</p> <p>\\begin{equation*}     P(z \\leq 1.25) = 0.8943 \\quad y \\quad P(z \\leq 2.5) = 0.9937 \\end{equation*}</p> <p>Por lo tanto</p> <p>\\begin{align}     600 \\cdot P(60 &lt; x \\leq 75) &amp;= 600 \\cdot P\\left(\\frac{60 - 70}{4} \\leq z \\leq \\frac{75 - 70}{4}\\right)\\\\     &amp;= (600)[0.8943-(1-0.9937)]\\\\     &amp;= 533 \\end{align}</p> <p>\u2234 De los 600 estudiantes 533 se encuentran entre los 60 y 75 kilogramos de peso</p> <p>2 Mas de 90 kg. </p> <p>\\begin{align}     P(x &gt; 90) &amp;= P\\left(z &gt;\\frac{90 - 70}{4}\\right)\\\\     &amp;= P(z &gt; 5)\\\\     &amp;= 1 - P(z \\leq 5)\\\\     &amp;= 1-1\\\\     &amp;= 0 \\end{align}</p> <p>multiplicando por 600</p> <p>\\begin{equation}     600 \\cdot P (x &gt; 90) = (600)(0) = 0 \\end{equation}</p> <p>\u2234 Es imposible hallar a un solo estudiante por encima de los 90 kilogramos</p> <p>3 Menos de 64 kg. </p> <p>\\begin{align}     P(x &lt; 64) &amp;= P\\left(z &lt; \\frac{64 - 70}{4}\\right)\\\\     &amp;= P(z &lt; -1.5)\\\\     &amp;= 1 - P(z &lt; 1.5)\\\\     &amp;= 1-0.9331\\\\     &amp;= 0.0669 \\end{align}</p> <p>Por lo tanto</p> <p>\\begin{equation}     600 \\cdot P (x &lt; 64) = (600)(0.0669) = 40.14 \\end{equation}</p> <p>\u2234 Hay 40 estudiantes que pesan menos de 64 kilogramos</p> <p>Ejercicio 3. El n\u00famero de minutos requeridos por un estudiante de la carrera de INFORMATICA para terminar un examen se distribuye como una exponencial, con un promedio de 70 minutos. Suponga que el examen inicia a las 8:00am. \u00bfCu\u00e1l es la probabilidad que termine antes de las 8:45am?</p> <p>Soluci\u00f3n </p> <p>\\begin{align*} \u03bc &amp;= 70[min]\\\\ x &amp;= tiempo\\ en\\ minutos\\ para\\ resolver\\ el\\ examen \\end{align*}</p> <p>como el examen empieza a las 8:00am y necesitamos la probabilidad de que termine antes de las 8:45am, aqui el intervalo de tiempo va de 8:00am a 8:45am lo cual nos da un tiempo de 45 minutos</p> <p>\\begin{equation*} x_0 = 45[min] \\end{equation*}</p> <p>lo cual significa que la probabilidad buscada es la siguiente</p> <p>\\begin{equation*} P(x \\leq 45) \\end{equation*}</p> <p>usando la ecuaci\u00f3n (6.5)</p> <p>\\begin{equation*} P(x &lt; 45) \\end{equation*}</p> <p>usando la probabilidad obtenida y la ecuacion (6.5)</p> <p>\\begin{align} P(x &lt; 45) &amp;= 1-e^{-\\frac{45}{70}}\\\\ &amp;= 0.4742 \\end{align}</p> <p>por lo tanto la probabilidad de que un estudiante de la carrera de INFORMATICA  termine el examen antes de las 8:45am es</p> <p>\\begin{equation} P(x &lt; 45) = 0.4742 \\end{equation}</p> <p>Ejercicio 4. En la ciudad de La Paz el tiempo de arribo de los PumaKataris tiene una distribucion exponencial con media de 10 minutos.</p> <p>a) \u00bfCual es la probabilidad de que una persona tenga que esperar mas de una hora para tomar un PumaKatari?</p> <p>b)  Suponga que la persona ya espero una hora. \u00bfcual es la probabilidad de que llegue uno en los siguientes 10 minutos?</p> <p>Soluci\u00f3n </p> <p>a) </p> <p>Sea la variable aleatoria x la siguiente \\begin{equation*} x = \\text{tiempo que tarda en minutos un Pumakatari para llegar a la parada} \\end{equation*}</p> <p>\\begin{align*} \u03bc &amp;= 10[min]\\\\ x_0 &amp;= 1[h] \\end{align*}</p> <p>convirtiendo las horas a minutos</p> <p>\\begin{equation*} x_0 = 60[min] \\end{equation*}</p> <p>usando la ecuacion (6.5)</p> <p>\\begin{equation} P(x \\leq 60) = 1-e^{-\\frac{60}{10}} \\tag{1} \\end{equation}</p> <p>pero se nos pide $P(x &gt; 60)$</p> <p>Por la regla del complemento y usando la ecuacion (1) obtenida anteriormente</p> <p>\\begin{align} P(x \\leq 60) &amp;= 1 - P(x &gt; 60)\\\\ P(x \\leq 60) &amp;= 1-e^{-\\frac{60}{10}}\\\\ P(x &gt; 60) &amp;= e^{-\\frac{60}{10}}\\\\ &amp;=e^{-\\frac{6}{1}}\\\\ &amp;=0.0025 \\end{align}</p> <p>la probabilidad de que una persona espere mas de una hora un PumaKatari es</p> <p>\\begin{equation} P(x &gt; 60) = 0.0025 \\end{equation}</p> <p>b) </p> <p>la persona ya espero una hora, y se quiere calcular la probabilidad de que llegue uno en los siguientes 10 minutos el intervalo de tiempo empieza despues  de la hora y acaba en los 10 minutos por lo tanto \\begin{align*} \u03bc &amp;= 10[min]\\\\ x_0 &amp;= 10[min] \\end{align*}</p> <p>\\begin{equation*} P(x \\leq 10) \\end{equation*}</p> <p>usando la ecuacion (6.5)</p> <p>\\begin{align} P(x \\leq 10) &amp;= 1-e^{-\\frac{10}{10}}\\\\ &amp;= 0.632 \\end{align}</p> <p>Si la persona ya espero una hora la probabilidad de que llegue un PumaKatari en los siguientes 10 minutos es</p> <p>\\begin{equation} P(x \\leq 10) = 0.632 \\end{equation}</p>"},{"location":"capitulo6/","title":"\u00b6","text":"CAP\u00cdTULO 6  Distribuciones de probabilidad continua CONTENIDO <p>6.1 DiSTRIBUCI\u00d3N DE PROBABILIDAD UNIFORME</p> <ul> <li>El \u00e1rea como medida de la probabilidad</li> </ul> <p>6.2 DiSTRIBUCI\u00d3N DE PROBABILIDAD NORMAL</p> <ul> <li>Curva normal</li> <li>Distribuci\u00f3n de probabilidad normal est\u00e1ndar</li> <li>C\u00e1lculo de probabilidades para cualquier distribuci\u00f3n de probabilidad normal</li> <li>El problema de LLANTAX<sub>Ltda</sub></li> </ul> <p>6.3 APROXIMACI\u00d3N NORMAL DE LAS PROBABILIDADES BINOMIALES</p> <p>6.4 DISTRIBUCI\u00d3N DE PROBABILIDAD EXPONENCIAL</p> <ul> <li>C\u00e1lculo de probabilidades para la distribuci\u00f3n exponencial</li> <li>Relaci\u00f3n entre las distribuciones de Poisson y exponencial</li> </ul>"},{"location":"capitulo6/#61-distribucion-de-probabilidad-uniforme","title":"6.1 Distribuci\u00f3n de probabilidad uniforme\u00b6","text":""},{"location":"capitulo6/#el-area-como-medida-de-la-probabilidad","title":"El \u00e1rea como medida de la probabilidad\u00b6","text":"<p>Como una observaci\u00f3n, el \u00e1rea de un rect\u00e1ngulo (forma geometrica que toma el grafico 6.1) es el ancho multiplicado por la altura. Si se considera ancho = 70 - 60 = 10, y la altura es igual a f(x) = 1/20, se tiene el \u00e1rea = ancho $\\cdot$ altura = 10(1/20) = 0.50.</p> <p> Figura 6.2 El \u00e1rea proporciona la probabilidad de que el tiempo de vuelo est\u00e9 entre 60 y 70 minutos</p>"},{"location":"capitulo6/#62-distribucion-de-probabilidad-normal","title":"6.2 Distribuci\u00f3n de probabilidad normal\u00b6","text":""},{"location":"capitulo6/#curva-normal","title":"Curva normal\u00b6","text":"<p>Tambi\u00e9n conocida como Campana de Gauss, esta se caracteriza por su forma de campana sim\u00e9trica. La forma de la curva est\u00e1 determinada por dos par\u00e1metros: la media y la desviaci\u00f3n est\u00e1ndar como se presenta en la siguiente figura.</p> <p> Figura 6.3 Curva con forma de campana de la distribuci\u00f3n normal</p>"},{"location":"capitulo6/#distribucion-de-probabilidad-normal-estandar","title":"Distribuci\u00f3n de probabilidad normal est\u00e1ndar\u00b6","text":"<p>Se dice que una variable aleatoria con una media de cero y una desviaci\u00f3n est\u00e1ndar de uno tiene una distribuci\u00f3n normal est\u00e1ndar. La letra $z$ se usa com\u00fanmente para designar esta variable aleatoria normal.</p> <p>La figura 6.5 muestra la gr\u00e1fica general de la distribuci\u00f3n normal est\u00e1ndar.</p>"},{"location":"capitulo6/#calculo-de-probabilidades-para-culaquier-distribucion-de-probabilidad-normal","title":"C\u00e1lculo de probabilidades para culaquier distribuci\u00f3n de probabilidad normal\u00b6","text":""},{"location":"capitulo6/#el-problema-de-llantaxltda","title":"El problema de LLANTAX<sub>Ltda</sub>\u00b6","text":""},{"location":"capitulo6/#63-aproximacion-normal-de-las-probabilidades-binomiales","title":"6.3 Aproximaci\u00f3n normal de las probabilidades binomiales\u00b6","text":""},{"location":"capitulo6/#64-distribucion-de-probabilidad-exponencial","title":"6.4 Distribuci\u00f3n de probabilidad exponencial\u00b6","text":""},{"location":"capitulo6/#calculo-de-probabilidades-para-la-distribucion-exponencial","title":"C\u00e1lculo de probabilidades para la distribuci\u00f3n exponencial\u00b6","text":""},{"location":"capitulo6/#relacion-entre-las-distribuciones-de-poisson-y-exponencial","title":"Relaci\u00f3n entre las distribuciones de Poisson y exponencial\u00b6","text":""},{"location":"capitulo6/#ejercicios","title":"Ejercicios\u00b6","text":""},{"location":"capitulo7/","title":"Capitulo 7","text":"CAPITULO 7  Muestreo y distribuciones de muestreo Contenido del capitulo <p>7.1 EL PROBLEMA DE MUESTREO DE ELECTRONICS ASSOCIATES</p> <p>7.2 SELECCI\u00d3N DE UNA MUESTRA</p> <ul> <li>Muestreo de una poblaci\u00f3n finita</li> <li>Muestreo de una poblaci\u00f3n infinita</li> </ul> <p>7.3 ESTIMACI\u00d3N PUNTUAL</p> <ul> <li>Consejo pr\u00e1ctico</li> </ul> <p>7.4 INTRODUCCI\u00d3N A LAS DISTRIBUCIONES MUESTRALES O DE MUESTREO</p> <p>7.5 DISTRIBUCI\u00d3N DEMUESTREO DE LA MEDIA MUESTRAL X</p> <ul> <li>Valor esperado de la media muestral x</li> <li>Desviaci\u00f3n est\u00e1ndar de la media muestral x</li> <li>Forma de la distribuci\u00f3n de muestreo de la media muestral x</li> <li>Distribuci\u00f3n de muestreo de la media muestral x en el problema EAI</li> <li>Valor pr\u00e1ctico de la distribuci\u00f3n de muestreo de la media muestral x</li> <li>Relaci\u00f3n entre el tama\u00f1o dela muestra y la distribuci\u00f3n de muestreo de la media muestral x</li> </ul> <p>7.6 DISTRIBUCI\u00d3N DE MUESTREO DE LA PROPORCION MUESTRAL p</p> <ul> <li>Valor esperado de la proporcion muestral p</li> <li>Desviaci\u00f3n est\u00e1ndar de la proporcion muestral p</li> <li>Forma de la distribuci\u00f3n de muestreo de la proporcion muestral p</li> <li>Valor pr\u00e1ctico de la distribuci\u00f3n de muestreo de la proporcion muestral p</li> </ul> <p>7.7 PROPIEDADES DE LOSESTIMADORES PUNTUALES</p> <ul> <li>Insesgadez</li> <li>Eficiencia</li> <li>Consistencia</li> </ul> <p>7.8 OTROS M\u00c9TODOS DE MUESTREO</p> <ul> <li>Muestreo aleatorio estratificado</li> <li>Muestreo por conglomerados</li> <li>Muestreo sistem\u00e1tico</li> <li>Muestreo de conveniencia</li> <li>MMuestreo subjetivo</li> </ul> <ul> <li> La Papelera - Innovaci\u00f3n en la Producci\u00f3n de Papel <p>La Papelera, una empresa l\u00edder a nivel global en la producci\u00f3n de papel y productos derivados, se destaca en la fabricaci\u00f3n de embalajes, papeles especiales, bienes de consumo y de oficina, as\u00ed como en la elaboraci\u00f3n de sustancias qu\u00edmicas especiales. Con una plantilla de m\u00e1s de 25,000 empleados, La Papelera opera en m\u00e1s de 25 pa\u00edses y brinda sus servicios a clientes en todo el mundo. Su posici\u00f3n destacada en la producci\u00f3n de papel se evidencia en una capacidad anual de 1.5 millones de toneladas.</p> <p>El enfoque estrat\u00e9gico de La Papelera incluye el uso eficiente del muestreo como herramienta fundamental para recopilar informaci\u00f3n diversa y mantener su competitividad. Un ejemplo significativo es la gesti\u00f3n de sus recursos forestales, que sirven como materia prima esencial para gran parte de su l\u00ednea de productos. Los consultores internos aplican el muestreo aleatorio para obtener datos clave sobre la poblaci\u00f3n forestal, tales como el volumen actual de los bosques, su historial de crecimiento y las proyecciones futuras. Estos datos son cruciales para la planificaci\u00f3n a largo plazo y la programaci\u00f3n de actividades como la tala de \u00e1rboles.</p> <p>El proceso de muestreo en La Papelera implica la subdivisi\u00f3n de los bosques en secciones, la identificaci\u00f3n de puntos muestrales aleatorios y la recopilaci\u00f3n de datos en campo mediante equipos especializados, que incluyen expertos forestales. La informaci\u00f3n recopilada se registra en el sistema de inventario forestal continuo (IFC) de la empresa, generando informes detallados con estad\u00edsticas sobre la composici\u00f3n de especies, volumen actual de los bosques, tasas de crecimiento hist\u00f3ricas y proyecciones futuras. Este enfoque estad\u00edstico proporciona la base necesaria para una gesti\u00f3n efectiva y sostenible de los recursos forestales de La Papelera.</p> <p>En este contexto, se examina el muestreo aleatorio simple, el proceso de selecci\u00f3n de muestras, y el uso de estad\u00edsticos como la media muestral y la proporci\u00f3n muestral para estimar caracter\u00edsticas clave de la poblaci\u00f3n forestal de La Papelera.</p> </li> </ul> In\u00a0[\u00a0]: Copied! <pre># Instala la biblioteca IPython para mostrar HTML\n!pip install IPython\n\n# Importa la clase HTML de la biblioteca IPython\nfrom IPython.display import HTML\n\n# Define la funci\u00f3n para mostrar el video de YouTube centrado\ndef display_centered_youtube_video(video_id, width=560, height=315):\n    video_url = f\"https://www.youtube.com/embed/{video_id}\"\n    iframe_code = f'&lt;div style=\"display: flex; justify-content: center; align-items: center; height: 100%;\"&gt;&lt;iframe width=\"{width}\" height=\"{height}\" src=\"{video_url}\" frameborder=\"0\" allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt;'\n    display(HTML(iframe_code))\n\n# Reemplaza \"Y7oKqrV4Bmw\" con el ID de tu video de YouTube\nvideo_id = \"Y7oKqrV4Bmw\"\n\n# Muestra el video de YouTube centrado\ndisplay_centered_youtube_video(video_id)\n</pre> # Instala la biblioteca IPython para mostrar HTML !pip install IPython  # Importa la clase HTML de la biblioteca IPython from IPython.display import HTML  # Define la funci\u00f3n para mostrar el video de YouTube centrado def display_centered_youtube_video(video_id, width=560, height=315):     video_url = f\"https://www.youtube.com/embed/{video_id}\"     iframe_code = f''     display(HTML(iframe_code))  # Reemplaza \"Y7oKqrV4Bmw\" con el ID de tu video de YouTube video_id = \"Y7oKqrV4Bmw\"  # Muestra el video de YouTube centrado display_centered_youtube_video(video_id)   <pre>Requirement already satisfied: IPython in /usr/local/lib/python3.10/dist-packages (7.34.0)\nRequirement already satisfied: setuptools&gt;=18.5 in /usr/local/lib/python3.10/dist-packages (from IPython) (67.7.2)\nRequirement already satisfied: jedi&gt;=0.16 in /usr/local/lib/python3.10/dist-packages (from IPython) (0.19.1)\nRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from IPython) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from IPython) (0.7.5)\nRequirement already satisfied: traitlets&gt;=4.2 in /usr/local/lib/python3.10/dist-packages (from IPython) (5.7.1)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0 in /usr/local/lib/python3.10/dist-packages (from IPython) (3.0.41)\nRequirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from IPython) (2.16.1)\nRequirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from IPython) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from IPython) (0.1.6)\nRequirement already satisfied: pexpect&gt;4.3 in /usr/local/lib/python3.10/dist-packages (from IPython) (4.9.0)\nRequirement already satisfied: parso&lt;0.9.0,&gt;=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi&gt;=0.16-&gt;IPython) (0.8.3)\nRequirement already satisfied: ptyprocess&gt;=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect&gt;4.3-&gt;IPython) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0-&gt;IPython) (0.2.12)\n</pre> <p>En el cap\u00edtulo 1 se presentaron las siguientes definiciones de los t\u00e9rminos elemento, poblaci\u00f3n y muestra.</p> <ul> <li>Un elemento es la entrada en la que se recolectan los datos.</li> <li>Una poblaci\u00f3n es el conjunto de todos los elementos de inter\u00e9s.</li> <li>Una muestra es un subconjunto de la poblaci\u00f3n. La raz\u00f3n por la que se selecciona una muestra estriba en recabar datos para realizar una inferencia y responder una pregunta de investigaci\u00f3n acerca de una poblaci\u00f3n.</li> </ul> <p>Para empezar, se presentan dos ejemplos en los que se utiliza el muestreo para responder una pregunta de investigaci\u00f3n acerca de una poblaci\u00f3n.</p> <ol> <li>Los miembros de un partido pol\u00edtico en Texas consideraban postular a un determinado candidato para el Senado, y los dirigentes del partido quer\u00edan estimar la proporci\u00f3n de votantes registrados en el estado que pod\u00edan apoyarlo. Por tanto, se seleccion\u00f3 una muestra de 400 votantes registrados en Texas, y 160 de este total indicaron estar a favor del candidato. As\u00ed, una estimaci\u00f3n de la proporci\u00f3n de la poblaci\u00f3n de votantes registrados a favor del candidato es 160/400 = 0.40.</li> <li>Un fabricante de llantas est\u00e1 considerando producir un nuevo modelo que ofrezca mayor duraci\u00f3n que los actuales neum\u00e1ticos de l\u00ednea de la empresa. Para estimar la duraci\u00f3n media, en millas, el fabricante selecciona una muestra de 120 neum\u00e1ticos nuevos para probarlos. De los resultados de esta prueba se obtiene una media muestral de 36,500 millas. Por tanto, una estimaci\u00f3n de la vida \u00fatil media de la poblaci\u00f3n de nuevas llantas es 36,500 millas.</li> </ol> <p>Los resultados muestrales ofrecen solo estimaciones de las caracter\u00edsticas de la poblaci\u00f3n, no exactitudes precisas. Debido a que las muestras representan solo una fracci\u00f3n de la poblaci\u00f3n, se esperan errores de muestreo. Afortunadamente, existen procedimientos estad\u00edsticos para evaluar la calidad de estas estimaciones.</p> <p>Se definen t\u00e9rminos clave, como poblaci\u00f3n muestreada (de donde se extrae la muestra) y marco (la lista de elementos de donde se selecciona la muestra). En ejemplos, la poblaci\u00f3n muestreada puede ser finita, como los votantes registrados en Texas, o conceptualmente infinita, como en el caso de muestras de neum\u00e1ticos obtenidas de un proceso productivo.</p> <p>El cap\u00edtulo se enfoca en c\u00f3mo utilizar el muestreo aleatorio simple para seleccionar muestras de poblaciones finitas e infinitas. Se explora la selecci\u00f3n de muestras aleatorias simples en situaciones espec\u00edficas. Se discute el uso de estas muestras para calcular estimaciones de media, desviaci\u00f3n est\u00e1ndar y proporci\u00f3n poblacional. Se introduce la distribuci\u00f3n de muestreo, crucial para evaluar la precisi\u00f3n de las estimaciones en comparaci\u00f3n con los par\u00e1metros poblacionales. Adem\u00e1s, se presentan alternativas al muestreo aleatorio simple com\u00fanmente utilizadas en la pr\u00e1ctica</p>    Al director de personal de Electronics Associates, Inc. (EAI) se le ha encomendado crear un perfil para los 2,500 gerentes de la empresa, centr\u00e1ndose en su sueldo anual promedio y la proporci\u00f3n que ha completado el programa de capacitaci\u00f3n. Utilizando la poblaci\u00f3n de 2,500 gerentes, se pueden obtener estos datos consultando el archivo EAI, que contiene la informaci\u00f3n necesaria. Con estos datos y las f\u00f3rmulas del cap\u00edtulo 3, se calcula la media y la desviaci\u00f3n est\u00e1ndar poblacional de los sueldos anuales.   <p>Media poblacional $\\mu = 51,800$</p> <p>Desviaci\u00f3n est\u00e1ndar poblacional $\\sigma = 4,000$</p> <p>Los datos muestran que 1,500 de los 2,500 gerentes han completado el programa de capacitaci\u00f3n. Las caracter\u00edsticas num\u00e9ricas de la poblaci\u00f3n, como la media $\\mu = \\$51,800$ y la desviaci\u00f3n est\u00e1ndar $\\sigma = \\$4,000$ de los sueldos anuales, junto con la proporci\u00f3n de gerentes capacitados $\\rho  = 0.60$, son par\u00e1metros poblacionales. La pregunta ahora es c\u00f3mo el director de personal puede obtener estimaciones de estos par\u00e1metros utilizando una muestra de 30 gerentes en lugar de estudiar a toda la poblaci\u00f3n de 2,500 sujetos. El uso de una muestra es m\u00e1s eficiente en t\u00e9rminos de tiempo y costo para elaborar perfiles. Si una muestra de 30 gerentes proporciona informaci\u00f3n adecuada sobre la poblaci\u00f3n completa, se explorar\u00e1 c\u00f3mo determinarla.</p>    En esta secci\u00f3n se describe c\u00f3mo seleccionar una muestra. Primero se estudiar\u00e1 c\u00f3mo seleccionarla de una poblaci\u00f3n \ufb01nita y luego de una poblaci\u00f3n in\ufb01nita.  <p>Muestreo de una poblaci\u00f3n finita</p> <p>Los estad\u00edsticos sugieren el uso de muestras de probabilidad al muestrear de una poblaci\u00f3n finita, ya que facilita inferencias estad\u00edsticas v\u00e1lidas. El muestreo aleatorio simple, donde cada muestra de tama\u00f1o $\\eta$ tiene igual probabilidad de selecci\u00f3n, es el tipo m\u00e1s b\u00e1sico de muestra de probabilidad.</p> <p>Bloc con sangr\u00eda</p> <p>MUESTREO ALEATORIO SIMPLE (POBLACION FINITA) Una muestra aleatoria simple de tama\u00f1o n de una poblaci\u00f3n finita de tama\u00f1o N es una muestra seleccionada de manera que cada posible muestra de tama\u00f1o n tenga la misma probabilidad de ser seleccionada.</p> <p>Para seleccionar una muestra aleatoria simple de una poblaci\u00f3n finita, se eligen los elementos uno a uno, asegurando que cada elemento restante tenga igual probabilidad de ser seleccionado en cada paso. As\u00ed se cumple con la definici\u00f3n de muestra aleatoria simple. Para realizar esto con la poblaci\u00f3n finita de gerentes de EAI, se asigna un n\u00famero a cada sujeto, por ejemplo, del 1 al 2,500 en orden.</p> <p>TABLA 7.1 N\u00fameros aleatorios</p> <p>Tabla 7.2  Sueldo anual y situaci\u00f3n respecto del programa de capacitaci\u00f3n para una muestra aleatoria simple de 30 gerentes de EAI</p> 63 271  59 986 71 744 51 102 15 141 80 714  58 683  93 108  13 554  79 945  88 547 09 896 95 436  79 115  08 303 01 041 20 030 63 754 08 459 28 364 55 957 57 243 83 865  09 911  19 761 66 535 40 102 26 646 60 147 15 702 46 276 87 453 44 790  67 122  45 573 84 358 21 625 16 999 13 385 22 782 55 363 07 449 34 835  15 290  76 616  67 191  12 777  21 861  68 689  03 263  <p> </p> 69 393  92 785 49 902 58 447 42 048 30 378  87 618  26 933  40 640  16 281  13 186 29 431 88 190  04 588  38 733 81 290 89 541  70 290  40 113  08 243 17 726 28 652  56 836  78 351 47 327 18 518 92 222 55 201 27 340 10 493 36 520 64 465 05 550  30 157  82 242 29 520 69 753 72 602 23 756 54 935 81 628 36 100 39 254  56 835  37 636 02 421 98 063 89 641 64 953 99 337 <p>El procedimiento para seleccionar una muestra aleatoria simple de una poblaci\u00f3n finita implica asignar n\u00fameros a cada elemento y utilizar d\u00edgitos aleatorios de una tabla. En el caso de la poblaci\u00f3n de gerentes de EAI, se asignan n\u00fameros del 1 al 2500. Los n\u00fameros aleatorios de cuatro d\u00edgitos se eligen consultando una tabla de d\u00edgitos aleatorios, seleccionando conjuntos de cuatro d\u00edgitos. Se puede empezar en cualquier lugar de la tabla y avanzar sistem\u00e1ticamente. En este caso, se utiliza la primera fila y se avanza de izquierda a derecha.</p> <p>6327 --- 1599 --- 8671 --- 7445 --- 1102 --- 1514 --- 1807</p> <p>Para seleccionar una muestra aleatoria simple de una poblaci\u00f3n finita, se asignan n\u00fameros a cada elemento de la poblaci\u00f3n. En este caso, consideramos la poblaci\u00f3n de gerentes de EAI, a la cual se le asignan n\u00fameros del 1 al 2500. La clave para la aleatoriedad se encuentra en una tabla de d\u00edgitos aleatorios, donde cada d\u00edgito tiene igual probabilidad de aparecer. Estos d\u00edgitos se eligen en conjuntos de cuatro, ya que el n\u00famero m\u00e1s grande en la poblaci\u00f3n de gerentes es 2500.</p> <p>El proceso implica utilizar estos n\u00fameros aleatorios de cuatro d\u00edgitos para dar a cada gerente de la poblaci\u00f3n la misma oportunidad de ser seleccionado en la muestra aleatoria. Algunos n\u00fameros pueden ser mayores que el tama\u00f1o de la poblaci\u00f3n, y en ese caso, se descartan. Por ejemplo, si el primer n\u00famero aleatorio es 6327 y la poblaci\u00f3n solo va hasta el n\u00famero 2500, se descarta. El siguiente n\u00famero, por ejemplo, 1599, est\u00e1 dentro del rango de la poblaci\u00f3n y se selecciona el primer gerente asociado con ese n\u00famero.</p> <p>Este proceso contin\u00faa hasta alcanzar la muestra deseada de, por ejemplo, 30 gerentes de EAI. Es importante destacar que este m\u00e9todo de selecci\u00f3n se conoce como muestreo sin reemplazo, ya que una vez que un gerente ha sido seleccionado, su n\u00famero se ignora para evitar duplicados en la muestra final. Este enfoque garantiza que cada gerente tenga una oportunidad justa y \u00fanica de ser parte de la muestra aleatoria.</p> <p>Cuando se selecciona una muestra en la que se aceptan n\u00fameros aleatorios ya usados y los gerentes correspondientes son incluidos dos o m\u00e1s veces, se realiza un muestreo con remplazo.</p> <p>Muestrear con remplazo es una forma v\u00e1lida de identi\ufb01 car una muestra aleatoria simple; sin embargo, como es el procedimiento de muestreo m\u00e1s usado, cuando se hable de muestreo aleatorio simple se asumir\u00e1 que \u00e9ste es sin reemplazo.</p> <p>Muestreo de una poblaci\u00f3n infinita</p> <p>Algunas veces se quiere seleccionar una muestra de una poblaci\u00f3n, pero \u00e9sta es in\ufb01nitamente grande o sus elementos est\u00e1n siendo generados por un proceso en marcha, por lo cual no hay l\u00edmite para el n\u00famero de elementos que pueden ser generados. Por tanto, no es posible hacer una lista de todos los elementos de la poblaci\u00f3n. Esto se considera el caso de una poblaci\u00f3n in\ufb01nita, con la cual no se puede seleccionar una muestra aleatoria simple debido a que no es factible construir un marco constituido por todos los elementos. En el caso de una poblaci\u00f3n in\ufb01nita, los profesionales de la estad\u00edstica recomiendan seleccionar lo que se llama una muestra aleatoria.</p> <p>MUESTRA ALEATORIA (POBLACI\u00d3N INFINITA) Una muestra aleatoria de tama\u00f1o n de una poblaci\u00f3n infinita es seleccionada de manera tal que se satisfagan las condiciones siguientes.   <ol> <li>Cada elemento elegido proviene de la misma poblaci\u00f3n.</li> <li>Cada elemento es seleccionado de manera independiente.</li> </ol> </p> <p>La implementaci\u00f3n del proceso de selecci\u00f3n de una muestra aleatoria en una poblaci\u00f3n infinita debe realizarse con cuidado. Dos condiciones clave son: 1) que cada elemento seleccionado provenga de la misma poblaci\u00f3n y 2) que cada elemento se elija de manera independiente.</p> <p>En un caso pr\u00e1ctico, como el control de calidad en la producci\u00f3n de cajas de cereal, donde la poblaci\u00f3n conceptual es infinita, se busca asegurar que la muestra refleje la condici\u00f3n 1. Para lograrlo, el inspector elige las cajas aproximadamente al mismo tiempo, evitando as\u00ed sesgos en la selecci\u00f3n debido a posibles malfuncionamientos en el proceso.</p> <p>En otro ejemplo, al seleccionar una muestra aleatoria de clientes en un restaurante de comida r\u00e1pida, donde la poblaci\u00f3n en marcha se considera infinita, se busca obtener un perfil representativo de los consumidores. En este caso, la muestra se elige sin la posibilidad de obtener una lista completa de todos los consumidores, satisfaciendo as\u00ed las condiciones de selecci\u00f3n aleatoria.</p> <p>El dise\u00f1o de un procedimiento de muestreo efectivo implica seleccionar elementos de la muestra de manera independiente y garantizar que todos provengan de la misma poblaci\u00f3n. En el caso de un restaurante de comida r\u00e1pida, seleccionar consumidores de manera independiente puede ser m\u00e1s desafiante, pero es esencial para prevenir sesgos en la muestra.</p> <p>Para cumplir con la primera condici\u00f3n de que los elementos sean de la misma poblaci\u00f3n, el encuestador debe extraer la muestra de personas que realizan consumos en el restaurante. La segunda condici\u00f3n, la selecci\u00f3n independiente, es crucial para evitar sesgos en la elecci\u00f3n de clientes, como preferencias por grupos de edad particulares.</p> <p>Un ejemplo exitoso de muestreo aleatorio simple se dio en McDonald's, donde se utiliz\u00f3 la presentaci\u00f3n aleatoria de cupones de descuento. Cada vez que alguien presentaba un cup\u00f3n, el siguiente cliente se seleccionaba de manera independiente para completar un cuestionario, asegurando as\u00ed la imparcialidad en la selecci\u00f3n.</p> <p>Las poblaciones infinitas, comunes en procesos continuos a lo largo del tiempo, como la producci\u00f3n, experimentos o transacciones, pueden abordarse con un muestreo aleatorio simple si se cumplen ambas condiciones: elementos seleccionados de la misma poblaci\u00f3n e independientemente.</p> NOTAS Y COMENTARIOS <p> <ol> <li>En esta secci\u00f3n se ha tenido sumo cuidado en definir dos tipos de muestras: la muestra aleatoria simple de una poblaci\u00f3n finita y la muestra aleatoria de una poblaci\u00f3n infinita. En el resto de la obra se har\u00e1 referencia a ellas como muestra aleatoria o s\u00f3lo muestra. No se har\u00e1 distinci\u00f3n de que sea una muestra aleatoria \u201csimple\u201d a menos que sea necesario para el ejercicio o el an\u00e1lisis.       </li> <li>Los profesionales de la estad\u00edstica especializados en encuestas por muestreo de poblaciones finitas utilizan m\u00e9todos que proporcionan muestras de probabilidad, con las cuales cada posible muestra tiene una probabilidad conocida de selecci\u00f3n y se utiliza un proceso aleatorio para elegir sus elementos. El muestreo aleatorio simple es uno de esos m\u00e9todos. En la secci\u00f3n 7.8 se describen algunos otros m\u00e9todos de muestreo probabil\u00edstico: muestreo aleatorio estratificado, muestreo por conglomerados y muestreo sistem\u00e1tico. Se utiliza el t\u00e9rmino \u201csimple\u201d en el muestreo aleatorio simple para aclarar que es el m\u00e9todo que asegura que cada muestra de tama\u00f1o $\\eta$ tiene la misma probabilidad de ser seleccionada.       </li> <li>El n\u00famero de muestras aleatorias simples distintas de tama\u00f1o n que pueden seleccionarse de una poblaci\u00f3n finita de tama\u00f1o N es      $$\\frac{\\textit{N!}}{\\textit{n!}\\left ( N-n \\right )\\textit{!}}$$      En esta expresi\u00f3n, $\\textit{N!}$ y $\\textit{n!}$ son las f\u00f3rmulas factoriales estudiadas en el cap\u00edtulo 4. Al utilizar esta expresi\u00f3n con los datos del problema de EAI en el que $\\textit{N!}$ = 2500 y $\\textit{n!}$ = 30, se ve que se pueden obtener aproximadamente $2.75 \\times 10^{69} $  muestras aleatorias simples distintas de 30 gerentes de EAI       </li> <li>Para tomar una muestra aleatoria puede emplearse software. En los ap\u00e9ndices del cap\u00edtulo se explica c\u00f3mo usar Minitab y Excel para seleccionar una muestra aleatoria simple de una poblaci\u00f3n finita.       </li> </ol> </p> EJERCICIOS <p> <ol> <li>Tome una poblaci\u00f3n finita con cinco elementos A, B, C, D y E. Se pueden seleccionar 10 muestras aleatorias simples de tama\u00f1o 2.       a) Liste las 10 muestras empezando con AB, AC y as\u00ed en lo sucesivo. <p>       Respuesta:       <pre>\n      AB -- AC -- AD -- AE -- BC -- BD -- BE -- CD -- CE -- DE\n      </pre> <p>       b) Utilizando el muestreo aleatorio simple, \u00bfcu\u00e1l es la probabilidad para cada muestra de tama\u00f1o 2 de ser seleccionada?       </p> <p>       Respuesta: Dado que estamos utilizando muestreo aleatorio simple y hay 10 muestras posibles, la probabilidad de seleccionar cada muestra es la misma. Hay       </p> </p></li> </ol> </p> <p>$$\\binom{5}{2} = \\frac{5!}{2!\\left ( 5-2 \\right )!} = 10$$</p> <p>formas de seleccionar 2 elementos de una poblaci\u00f3n de 5 sin importar el orden. Por lo tanto, la probabilidad de seleccionar cada muestra es $$\\frac{1}{10} = 0.1$$</p> <p> <ol> <p>       c) Asuma que el n\u00famero aleatorio 1 corresponde a A, el n\u00famero 2 corresponde a B y as\u00ed en lo sucesivo. Liste la muestra aleatoria de tama\u00f1o 2 que ser\u00e1 seleccionada al usar los n\u00fameros aleatorios 8 0 5 7 5 3 2. </p> <p>       Respuesta: Asumiendo que el n\u00famero aleatorio 1 corresponde a A, el n\u00famero 2 corresponde a B, y as\u00ed sucesivamente, la muestra aleatoria de tama\u00f1o 2 seleccionada con los n\u00fameros aleatorios 8, 0, 5, 7, 5, 3, 2 ser\u00eda:       </p> </ol> </p> <ol> <li>C (correspondiente al n\u00famero 5)</li> <li>A (correspondiente al n\u00famero 1)</li> </ol> <ol> <li>Fortune publica datos sobre ventas, valor del activo, valor de mercado y utilidades por acci\u00f3n de las 500 corporaciones industriales m\u00e1s grandes de Estados Unidos (Fortune 500, 2006). Suponga que usted desea seleccionar una muestra aleatoria simple de 10 corporaciones de la lista Fortune 500. Use los tres \u00faltimos d\u00edgitos de la novena columna de la tabla 7.1, empezando con 554. Leyendo hacia abajo por esa columna, identifique los n\u00fameros de las 10 corporaciones que se tomar\u00e1n para la muestra.</li> <p>     Respuesta: Para seleccionar una muestra aleatoria simple de 10 corporaciones de la lista Fortune 500 utilizando los tres \u00faltimos d\u00edgitos de la novena columna, simplemente tomamos los primeros 10 n\u00fameros de esa columna:     </p> <p> 459,147,385,113,340,401,215,2,33,348</p> <p>Por lo tanto, estas son las corporaciones seleccionadas para la muestra aleatoria.     </p> </ol> <p>Por lo tanto, la muestra aleatoria seleccionada ser\u00eda CA</p> <p>Despu\u00e9s de describir c\u00f3mo seleccionar una muestra aleatoria simple, volvemos al problema de EAI. En la Tabla 7.2, se muestra una muestra aleatoria simple de 30 gerentes con sus datos de sueldo anual y participaci\u00f3n en el programa de capacitaci\u00f3n, utilizando la notaci\u00f3n x1, x2, etc., para denotar los sueldos anuales respectivos. La participaci\u00f3n en el programa se indica con un \"S\u00ed\" en la columna correspondiente.</p> <p>Para estimar los par\u00e1metros poblacionales, como la media \u03bc y la desviaci\u00f3n est\u00e1ndar \u03c3 de los sueldos anuales de los gerentes de EAI, se utilizan los datos de la Tabla 7.2. Se calculan los estad\u00edsticos muestrales, como la media muestral y la desviaci\u00f3n est\u00e1ndar muestral (s), empleando las f\u00f3rmulas presentadas en el Cap\u00edtulo 3</p> <p>Tabla 7.2  Sueldo anual y situaci\u00f3n respecto del programa de capacitaci\u00f3n para una muestra aleatoria simple de 30 gerentes de EAI</p> Sueldo anual ($) Programa de capacitaci\u00f3n Sueldo anual ($) Programa de capacitaci\u00f3n x1 = 49094.30 S\u00ed x16 = 51766.00 S\u00ed x2 = 53263.90 S\u00ed x17 = 52541.30 No x3 = 49643.50 S\u00ed x18 =  44980.00 S\u00ed x4 = 49894.90 S\u00ed x19 = 51932.60 S\u00ed x5 = 47621.60 No x20 = 52973.00 S\u00ed x6 = 55924.00 S\u00ed x21 = 45120.90 S\u00ed x7 = 49092.30 S\u00ed x22 = 51753.00 S\u00ed x8 = 51404.40 S\u00ed x23 = 54391.80 No x9 = 50957.70 S\u00ed x24 = 50164.20 No x10 = 55109.70 S\u00ed x25 = 52973.60 No x11 = 45922.60 S\u00ed x26 = 50241.30 No x12 = 57268.40 No x27 = 52793.90 No x13 = 55688.80 S\u00ed x28 = 50979.40 S\u00ed x14 = 51564.70 No x29 = 55860.90 S\u00ed x15 = 56188.20 No x30 = 57309.10 No <p>Con las f\u00f3rmulas para ambas categor\u00edas se obtiene que la media muestral es</p> <p>$$\\bar{x} = \\frac{\\sum x_i}{n} = \\frac{1554420}{30} = \\$51814$$</p> <p>y la desviaci\u00f3n est\u00e1ndar muestral es</p> <p>$$s = \\sqrt{\\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n-1}} = \\sqrt{\\frac{325009260}{29}} = \\$3348$$</p> <p>Para estimar p, la proporci\u00f3n de gerentes en la poblaci\u00f3n que completaron el programa de capacitaci\u00f3n, se usa la proporci\u00f3n muestral correspondiente p\u0304. Sea x que denota el n\u00famero de gerentes en la muestra que completaron el programa de capacitaci\u00f3n. Seg\u00fan la tabla 7.2, x = 19. Por tanto, como el tama\u00f1o de la muestra es n = 30, la proporci\u00f3n muestral es</p> <p>$$\\bar{p} = \\frac{x}{n} = \\frac{19}{30} = 0.63$$</p> <p>Al efectuar los c\u00e1lculos anteriores, se lleva a cabo el proceso estad\u00edstico conocido como estimaci\u00f3n puntual. A la media muestral x\u0304 se le identifica como estimador puntual de la media poblacional \u03bc, a la desviaci\u00f3n est\u00e1ndar muestral s como el estimador puntual de la desviaci\u00f3n est\u00e1ndar poblacional \u03c3 y a la proporci\u00f3n muestral p\u0304 como el estimador puntual de la proporci\u00f3n poblacional p. Al valor num\u00e9rico obtenido de x\u0304, s o p\u0304 se le conoce como estimaci\u00f3n puntual. As\u00ed, en la muestra aleatoria simple de 30 gerentes de EAI que se presenta en la tabla 7.2, \\$51814 es la estimaci\u00f3n puntual de \u03bc, \\$3348 es la estimaci\u00f3n puntual de \u03c3 y 0.63 es la estimaci\u00f3n puntual de p. En la tabla 7.3 se resumen los resultados muestrales y se comparan las estimaciones puntuales con los valores de los par\u00e1metros poblacionales.</p> <p>Como se observa en la tabla 7.3, las estimaciones puntuales difieren un poco de los correspondientes par\u00e1metros poblacionales. Estas diferencias son de esperarse, ya que para elaborar las estimaciones muestrales se usa una muestra, y no un censo de toda la poblaci\u00f3n. En el cap\u00edtulo siguiente se ver\u00e1 c\u00f3mo elaborar un intervalo de estimaci\u00f3n para tener informaci\u00f3n respecto de qu\u00e9 tan cerca est\u00e1 la estimaci\u00f3n muestral del par\u00e1metro poblacional.</p> <p>Tabla 7.3  Resumen de las estimaciones puntuales obtenidas de una muestra aleatoria simple de 30 gerentes de EAI</p> Par\u00e1metro poblacional Valor del par\u00e1metro Estimador puntual Estimaci\u00f3n puntual \u03bc = Media poblacional de los sueldos anuales \\$51800 $\\bar{x}$ = Media muestral de los sueldos anuales \\$51814 \u03c3 = Desviaci\u00f3n est\u00e1ndar poblacional de los sueldos anuales \\$4000 s = Desviaci\u00f3n est\u00e1ndar muestral de los sueldos anuales \\$3348 p = Proporci\u00f3n poblacional que ha completado el programa de capacitaci\u00f3n 0.60 $\\bar{s}$ = Proporci\u00f3n muestral que ha completado el programa de capacitaci\u00f3n 0.63 <p>En la secci\u00f3n anterior se dijo que la media muestral x\u0304 es el estimador puntual de la media poblacional \u03bc, y que la proporci\u00f3n muestral p\u0304 es el estimador puntual de la proporci\u00f3n poblacional p. En la muestra aleatoria simple de los 30 gerentes de EAI que se presenta en la tabla 7.2, la estimaci\u00f3n puntual de \u03bc es x\u0304 = $51814 y la estimaci\u00f3n puntual de p es p\u0304 = 0.63. Suponga que se selecciona otra muestra aleatoria simple de 30 gerentes de EAI y se obtienen las estimaciones puntuales siguientes:</p>  Media muestral: x\u0304 = $52670  <p>Proporci\u00f3n muestral: p\u0304 = 0.70</p> <p>Tabla 7.4  Valores de x\u0304 y de p\u0304 obtenidos en 500 muestras aleatorias simples de 30 gerentes de EAI</p> Muestra n\u00famero Media muestral (x\u0304) Proporci\u00f3n muestral (p\u0304) 1 51814 0.63 2 52670 0.70 3 51780 0.67 4 51588 0.53 ... ... ... 500 51752 0.50 <p>Observe que se obtuvieron valores diferentes de x\u0304 y de p\u0304. En efecto, una segunda muestra aleatoria simple de 30 gerentes de EAI no se puede esperar que proporcione las mismas estimaciones puntuales que la primera.</p> <p>Ahora suponga que el proceso de seleccionar una muestra aleatoria simple de 30 gerentes de EAI se repite una y otra vez, y que en cada ocasi\u00f3n se calculan los valores de x\u0304 y de p\u0304. La tabla 7.4 presenta una parte de los resultados obtenidos en 500 muestras aleatorias simples y la tabla 7.5 registra las distribuciones de frecuencia y de frecuencia relativa de los valores x\u0304 de las 500. En la figura 7.1 se muestra el histograma de las frecuencias de los valores de x\u0304.</p> <p>En el cap\u00edtulo 5 se define una variable aleatoria como una descripci\u00f3n num\u00e9rica del resultado de un experimento. Si el proceso de seleccionar una muestra aleatoria simple se considera un experimento, la media muestral x\u0304 es la descripci\u00f3n num\u00e9rica del resultado de ese experimento. Por tanto, la media muestral x\u0304 es una variable aleatoria. Entonces, como ocurre con otras variables aleatorias, x\u0304 tiene una media o valor esperado, una desviaci\u00f3n est\u00e1ndar y una distribuci\u00f3n de probabilidad. Como los distintos valores que toma x\u0304 son resultado de distintas muestras aleatorias simples, a la distribuci\u00f3n de probabilidad de x\u0304 se le conoce como distribuci\u00f3n de muestreo de x\u0304. Conocer esta distribuci\u00f3n y sus propiedades permitir\u00e1 hacer declaraciones de probabilidad acerca de qu\u00e9 tan cerca est\u00e1 la media muestral x\u0304 de la media poblacional \u03bc.</p> <p>Rem\u00edtase a la figura 7.1. Se necesitar\u00eda enumerar todas las muestras posibles de 30 gerentes y calcular cada una de las medias muestrales para determinar totalmente la distribuci\u00f3n de muestreo de x\u0304. Sin embargo, el histograma de 500 valores de x\u0304 provee una aproximaci\u00f3n a esta distribuci\u00f3n de muestreo. En esta aproximaci\u00f3n se observa la apariencia de una curva de campana de esta distribuci\u00f3n. Note adem\u00e1s que la mayor concentraci\u00f3n de valores de x\u0304 y la</p> <p>Tabla 7.5  Distribuciones de frecuencia y de frecuencia relativa de x\u0304 en 500 muestras aleatorias simples de 30 gerentes de EAI</p> Sueldo anual medio ($) Frecuencia Frecuencia relativa 49500.00-49999.99 2 0.004 50000.00-50499.99 16 0.032 50500.00-50999.99 52 0.104 51000.00-51499.99 101 0.202 51500.00-51999.99 133 266 52000.00-52499.99 110 0.220 52500.00-52999.99 54 0.108 53000.00-53499.99 26 0.052 53500.00-53999.99 6 0.012 Totals 500 1.000 <p> Figura 7.1 Histograma de la frecuencia relativa de los valores de x\u0304 obtenidos en 500 muestras aleatorias simples de tama\u00f1o 30 cada una</p> In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Datos para el gr\u00e1fico de barras\ncategorias = [\"49500-50000\", \"50000-50500\", \"50500-51000\", \"51000-51500\", \"51500-52000\", \"52000-52500\", \"52500-53000\", \"53000-53500\", \"53500-54000\"]\nvalores = [0.004, 0.032, 0.104, 0.202, 0.266, 0.220, 0.108, 0.052, 0.012]\n\n# Crear la figura y los ejes\nfig, ax = plt.subplots()\n\n# Ajustar el color de fondo\nax.set_facecolor(\"#d4f8b7\")\n# Pintar el fondo externo del gr\u00e1fico\nfig.patch.set_facecolor('#D4F8B7')\n\n# Crear el gr\u00e1fico de barras\nplt.bar(categorias, valores, color='#5CCB5f', edgecolor='black', linewidth=1.5, width=0.8)\n\nplt.xticks(fontsize=5)\n\n# A\u00f1adir etiquetas y t\u00edtulo con texto en negrita\nplt.xlabel('Valores de x\\u0305', fontsize=10, fontweight='bold')\nplt.ylabel('Frecuencia Relativa', fontsize=10, fontweight='bold')\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import matplotlib.pyplot as plt  # Datos para el gr\u00e1fico de barras categorias = [\"49500-50000\", \"50000-50500\", \"50500-51000\", \"51000-51500\", \"51500-52000\", \"52000-52500\", \"52500-53000\", \"53000-53500\", \"53500-54000\"] valores = [0.004, 0.032, 0.104, 0.202, 0.266, 0.220, 0.108, 0.052, 0.012]  # Crear la figura y los ejes fig, ax = plt.subplots()  # Ajustar el color de fondo ax.set_facecolor(\"#d4f8b7\") # Pintar el fondo externo del gr\u00e1fico fig.patch.set_facecolor('#D4F8B7')  # Crear el gr\u00e1fico de barras plt.bar(categorias, valores, color='#5CCB5f', edgecolor='black', linewidth=1.5, width=0.8)  plt.xticks(fontsize=5)  # A\u00f1adir etiquetas y t\u00edtulo con texto en negrita plt.xlabel('Valores de x\\u0305', fontsize=10, fontweight='bold') plt.ylabel('Frecuencia Relativa', fontsize=10, fontweight='bold')  # Mostrar el gr\u00e1fico plt.show() <p>media de los 500 valores de x\u0304 se encuentran cerca de la media poblacional \u03bc = \\$51 800. En la secci\u00f3n siguiente se describir\u00e1n m\u00e1s detalladamente las propiedades de la distribuci\u00f3n de muestreo de x\u0304.</p> <p>Los 500 valores de la proporci\u00f3n muestral de p\u0304 se resumen en el histograma de frecuencia relativa de la figura 7.2. Como ocurre con x\u0304, p\u0304 es una variable aleatoria. Si se tomara cada muestra posible de tama\u00f1o 30 y para cada una se calculara el valor de p\u0304, la distribuci\u00f3n de probabilidad que se obtuviera ser\u00eda la distribuci\u00f3n de muestreo de p\u0304. En la figura 7.2, el histograma de frecuencia relativa de los 500 valores muestrales proporciona una idea general de la apariencia de la distribuci\u00f3n de muestreo de p\u0304.</p> <p>En la pr\u00e1ctica s\u00f3lo se selecciona una muestra aleatoria simple de la poblaci\u00f3n. En esta secci\u00f3n el proceso de muestreo se repiti\u00f3 500 veces para ilustrar que es posible tomar muchas muestras diferentes y que distintas muestras dar\u00e1n valores diversos de los estad\u00edsticos muestrales x\u0304 y p\u0304. A la distribuci\u00f3n de muestreo de cualquier estad\u00edstico determinado se le llama distribuci\u00f3n de muestreo del estad\u00edstico. En la secci\u00f3n 7.5 se presentan las caracter\u00edsticas de la distribuci\u00f3n de muestreo de x\u0304. En la secci\u00f3n 7.6 se describen las caracter\u00edsticas de la distribuci\u00f3n de muestreo de p\u0304.</p> <p>En la secci\u00f3n anterior se dijo que la media muestral x\u0304 es una variable aleatoria y que a su distribuci\u00f3n de probabilidad se le llama distribuci\u00f3n de muestreo de x\u0304.</p> In\u00a0[\u00a0]: Copied! <pre>from IPython.display import HTML\n\nhtml_code = '''\n\n&lt;head&gt;\n    &lt;title&gt;Ecuaciones con Markdown&lt;/title&gt;\n    &lt;script src=\"https://polyfill.io/v3/polyfill.min.js?features=es6\"&gt;&lt;/script&gt;\n    &lt;script id=\"MathJax-script\" async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"&gt;&lt;/script&gt;\n&lt;/head&gt;\n&lt;style&gt;\n        .formulas {\n            background-color: #D4F8B7;\n            padding: 10px;\n            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\n        }\n&lt;/style&gt;\n\n&lt;div class=\"formulas\"&gt;\n\nDISTRIBUCI\u00d3N DE MUESTREO DE x&amp;#772;\n&lt;br&gt;&lt;br&gt;\nLa distribuci\u00f3n muestral de x&amp;#772; es la distribuci\u00f3n de probabilidad de todos los posibles valores de la media muestral x&amp;#772;.\n\n&lt;/div&gt;\n\n'''\nHTML(html_code)\n</pre> from IPython.display import HTML  html_code = '''   Ecuaciones con Markdown   DISTRIBUCI\u00d3N DE MUESTREO DE x\u0304  La distribuci\u00f3n muestral de x\u0304 es la distribuci\u00f3n de probabilidad de todos los posibles valores de la media muestral x\u0304.    ''' HTML(html_code) Out[\u00a0]: Ecuaciones con Markdown   DISTRIBUCI\u00d3N DE MUESTREO DE x\u0304  La distribuci\u00f3n muestral de x\u0304 es la distribuci\u00f3n de probabilidad de todos los posibles valores de la media muestral x\u0304.   <p> Figura 7.2 Histograma de la frecuencia relativa de los valores de p\u0304 obtenidos en 500 muestras aleatorias simples de tama\u00f1o 30 cada una</p> In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Datos para el gr\u00e1fico de barras\ncategorias = [\"0.32-0.40\", \"0.40-0.48\", \"0.48-0.56\", \"0.56-0.64\", \"0.64-0.72\", \"0.72-0.80\", \"0.80-0.88\"]\nvalores = [0.03, 0.09, 0.20, 0.4, 0.20, 0.09, 0.02]\n\n# Crear la figura y los ejes\nfig, ax = plt.subplots()\n\n# Ajustar el color de fondo\nax.set_facecolor(\"#d4f8b7\")\n# Pintar el fondo externo del gr\u00e1fico\nfig.patch.set_facecolor('#D4F8B7')\n\n# Crear el gr\u00e1fico de barras\nplt.bar(categorias, valores, color='#5CCB5f', edgecolor='black', linewidth=1.5, width=0.8)\n\nplt.xticks(fontsize=7)\n\n# A\u00f1adir etiquetas y t\u00edtulo con texto en negrita\nplt.xlabel('Valores de p\\u0305', fontsize=10, fontweight='bold')\nplt.ylabel('Frecuencia Relativa', fontsize=10, fontweight='bold')\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import matplotlib.pyplot as plt  # Datos para el gr\u00e1fico de barras categorias = [\"0.32-0.40\", \"0.40-0.48\", \"0.48-0.56\", \"0.56-0.64\", \"0.64-0.72\", \"0.72-0.80\", \"0.80-0.88\"] valores = [0.03, 0.09, 0.20, 0.4, 0.20, 0.09, 0.02]  # Crear la figura y los ejes fig, ax = plt.subplots()  # Ajustar el color de fondo ax.set_facecolor(\"#d4f8b7\") # Pintar el fondo externo del gr\u00e1fico fig.patch.set_facecolor('#D4F8B7')  # Crear el gr\u00e1fico de barras plt.bar(categorias, valores, color='#5CCB5f', edgecolor='black', linewidth=1.5, width=0.8)  plt.xticks(fontsize=7)  # A\u00f1adir etiquetas y t\u00edtulo con texto en negrita plt.xlabel('Valores de p\\u0305', fontsize=10, fontweight='bold') plt.ylabel('Frecuencia Relativa', fontsize=10, fontweight='bold')  # Mostrar el gr\u00e1fico plt.show() <p>En esta secci\u00f3n se describen las propiedades de la distribuci\u00f3n de muestreo de x\u0304. Como ocurre con otras distribuciones de probabilidad estudiadas, la distribuci\u00f3n de muestreo de x\u0304 tiene un valor esperado o media, una desviaci\u00f3n est\u00e1ndar y una forma caracter\u00edstica. Para empezar, se considerar\u00e1 la media de todos los valores posibles de x\u0304, a la que se conoce como valor esperado de x\u0304.</p> <p>Este resultado ense\u00f1a que utilizando el muestreo aleatorio simple, el valor esperado o media de la distribuci\u00f3n de muestreo de x\u0304 es igual a la media de la poblaci\u00f3n. En la secci\u00f3n 7.1 se vio que el sueldo anual medio de los gerentes de EAI es \u03bc = $51800. Por tanto, con base en la ecuaci\u00f3n (7.1), la media de todas las medias muestrales posibles en el estudio de EAI es tambi\u00e9n $51800.</p> <p>Cuando el valor esperado de un estimador puntual es igual al par\u00e1metro poblacional, se dice que el estimador puntual es insesgado. Por tanto, la ecuaci\u00f3n (7.1) indica que x es un estimador insesgado de la media poblacional \u03bc.</p> <p>Al comparar las dos f\u00f3rmulas en (7.2) se ve que el factor $\\sqrt{(N-n)/(N-1)}$ se requiere cuando la poblaci\u00f3n es finita, pero no cuando es infinita. A este factor se le conoce como factor de correcci\u00f3n para una poblaci\u00f3n finita. En muchas situaciones pr\u00e1cticas de muestreo se encuentra que, aunque la poblaci\u00f3n sea fi nita, es \u201cgrande\u201d, mientras que el tama\u00f1o de la muestra es \u201cpeque\u00f1o\u201d. En estos casos el factor de correcci\u00f3n para una poblaci\u00f3n finita $\\sqrt{(N-n)/(N-1)}$  es cercano a 1. Por tanto, la diferencia entre el valor de la desviaci\u00f3n est\u00e1ndar de x para las poblaciones finitas e infinitas se vuelve despreciable. Entonces $\\sigma_x = \\sigma/\\sqrt{n}$ se convierte en una buena aproximaci\u00f3n a la desviaci\u00f3n est\u00e1ndar de x\u0304 aun cuando la poblaci\u00f3n sea finita. Esta observaci\u00f3n lleva al siguiente lineamiento, o regla general, para calcular la desviaci\u00f3n est\u00e1ndar de x\u0304.</p> <p>En los casos en que n/N &gt; 0.05, para calcular \u03c3<sub>x\u0304</sub> debe usarse la versi\u00f3n para poblaciones finitas de la f\u00f3rmula (7.2). En este libro, a menos que se indique otra cosa, se supondr\u00e1 que el tama\u00f1o de la poblaci\u00f3n es \u201cgrande\u201d, n/N $\\leq$ 0.05, y se utilizar\u00e1 la expresi\u00f3n (7.3) para calcular \u03c3<sub>x\u0304</sub>.</p> <p>Para calcular \u03c3<sub>x\u0304</sub> se necesita conocer \u03c3, la desviaci\u00f3n est\u00e1ndar de la poblaci\u00f3n. Para subrayar, a\u00fan m\u00e1s, la diferencia entre \u03c3<sub>x\u0304</sub> y \u03c3, a la desviaci\u00f3n est\u00e1ndar de x\u0304, \u03c3<sub>x\u0304</sub>, se le llama error est\u00e1ndar de la media. En general, el t\u00e9rmino error est\u00e1ndar se refiere a la desviaci\u00f3n est\u00e1ndar de un estimador puntual. M\u00e1s adelante se ver\u00e1 que el valor del error est\u00e1ndar de la media ayuda a determinar qu\u00e9 tan lejos puede estar la media muestral de la media poblacional. Ahora, de nuevo con el ejemplo de EAI, se calcula el error est\u00e1ndar de la media correspondiente a las muestras aleatorias simples de 30 gerentes de EAI.</p> <p>En la secci\u00f3n 7.1 vimos que la desviaci\u00f3n est\u00e1ndar de los sueldos anuales en la poblaci\u00f3n de los 2500 gerentes de EAI era \u03c3 = 4000. En este caso la poblaci\u00f3n es finita, N = 2500. Sin embargo, como el tama\u00f1o de la muestra es 30, se tiene n/N = 30/2500 = 0.012. Dado que el tama\u00f1o de la muestra es menor que 5% del tama\u00f1o de la poblaci\u00f3n, se puede ignorar el factor de correcci\u00f3n para una poblaci\u00f3n finita y usar la ecuaci\u00f3n (7.3) para calcular el error est\u00e1ndar.</p> <p>$$ \\sigma_x = \\frac{\\sigma}{\\sqrt{n}} = \\frac{4000}{\\sqrt{30}} = 730.3$$</p> In\u00a0[\u00a0]: Copied! <pre>from IPython.display import HTML\n\nhtml_code = '''\n\n&lt;head&gt;\n    &lt;script src=\"https://polyfill.io/v3/polyfill.min.js?features=es6\"&gt;&lt;/script&gt;\n    &lt;script id=\"MathJax-script\" async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"&gt;&lt;/script&gt;\n&lt;/head&gt;\n&lt;style&gt;\n        .formulas {\n            background-color: #D4F8B7;\n            padding: 10px;\n            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\n&lt;/style&gt;\n\n&lt;div class=\"formulas\"&gt;\n\nTEOREMA DEL L\u00cdMITE CENTRAL\n&lt;br&gt;&lt;br&gt;\nCuando se seleccionan muestras aleatorias simples de tama\u00f1o n de una poblaci\u00f3n, la distribuci\u00f3n de muestreo de la media muestral x&amp;#772; puede aproximarse mediante una distribuci\u00f3n normal a medida que el tama\u00f1o de la muestra se hace grande.\n\n&lt;/div&gt;\n\n'''\nHTML(html_code)\n</pre> from IPython.display import HTML  html_code = '''     TEOREMA DEL L\u00cdMITE CENTRAL  Cuando se seleccionan muestras aleatorias simples de tama\u00f1o n de una poblaci\u00f3n, la distribuci\u00f3n de muestreo de la media muestral x\u0304 puede aproximarse mediante una distribuci\u00f3n normal a medida que el tama\u00f1o de la muestra se hace grande.    ''' HTML(html_code) Out[\u00a0]:   TEOREMA DEL L\u00cdMITE CENTRAL  Cuando se seleccionan muestras aleatorias simples de tama\u00f1o n de una poblaci\u00f3n, la distribuci\u00f3n de muestreo de la media muestral x\u0304 puede aproximarse mediante una distribuci\u00f3n normal a medida que el tama\u00f1o de la muestra se hace grande.   <p>En la figura 7.3 se ilustra c\u00f3mo funciona el teorema del l\u00edmite central en tres poblaciones diferentes; cada columna se refi ere a una de ellas. En el panel superior de la fi gura se aprecia que ninguna de las tres poblaciones est\u00e1 distribuida normalmente. La poblaci\u00f3n I tiene una distribuci\u00f3n uniforme, y a la II se le conoce como distribuci\u00f3n de orejas de conejo. Esta distribuci\u00f3n es sim\u00e9trica, pero los valores m\u00e1s probables se encuentran en las colas de la distribuci\u00f3n. La forma de la poblaci\u00f3n III se parece a una distribuci\u00f3n exponencial y es sesgada a la derecha.</p> <p>En los tres paneles superiores de la figura 7.3 se presentan las formas de las distribuciones de muestreo de tama\u00f1os n = 2, n = 5 y n = 30. Cuando el tama\u00f1o es 2, se observa que cada distribuci\u00f3n de muestreo tiene una forma diferente a la distribuci\u00f3n poblacional correspondiente.</p> <p> Figura 7.3  Ilustraci\u00f3n del teorema central del l\u00edmite con tres poblaciones</p> <p></p> <p>Con el tama\u00f1o 5 vemos que las formas de las distribuciones de muestreo en los casos de las poblaciones I y II empiezan a parecerse a la forma de una distribuci\u00f3n normal. En el caso de la poblaci\u00f3n III, aun cuando la forma de la distribuci\u00f3n de muestreo comienza a semejarse a una distribuci\u00f3n normal, se observa todav\u00eda cierto sesgo a la derecha. Por \u00faltimo, para el tama\u00f1o 30, la forma de cada una de las tres distribuciones de muestreo es aproximadamente normal.</p> <p>Desde un punto de vista pr\u00e1ctico, con frecuencia se querr\u00e1 saber qu\u00e9 tan grande debe ser el tama\u00f1o de la muestra antes de aplicar el teorema del l\u00edmite central y suponer que la forma de la distribuci\u00f3n de muestreo es aproximadamente normal. En las investigaciones estad\u00edsticas se ha estudiado este problema en distribuciones de muestreo de x\u0304 de diversas poblaciones y tama\u00f1os de muestra. En la pr\u00e1ctica estad\u00edstica general se asume que, en la mayor\u00eda de las aplicaciones, la distribuci\u00f3n de muestreo de x\u0304 se puede aproximar mediante una distribuci\u00f3n normal siempre que la muestra sea de tama\u00f1o 30 o mayor. En los casos en que la poblaci\u00f3n es muy sesgada o existen observaciones at\u00edpicas, pueden necesitarse muestras de tama\u00f1o 50. Por \u00faltimo, si la poblaci\u00f3n es discreta, el tama\u00f1o de muestra necesario para la aproximaci\u00f3n normal suele depender de la proporci\u00f3n poblacional. Se profundizar\u00e1 m\u00e1s en este tema cuando se estudie la distribuci\u00f3n de muestreo de p\u0304 en la secci\u00f3n 7.6.</p> <p> Figura 7.4  Distribuci\u00f3n de muestreo de x\u0304 para el sueldo medio anual de una muestra aleatoria simple de 30 gerentes de EAI</p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Par\u00e1metros de la distribuci\u00f3n normal\nmedia = 51800\ndesviacion_estandar = 730.3\n\n# Generar datos de la distribuci\u00f3n normal\nx = np.linspace(media - 4 * desviacion_estandar, media + 4 * desviacion_estandar, 1000)\ny = norm.pdf(x, media, desviacion_estandar)\n\n# Crear la gr\u00e1fica\nfig, ax = plt.subplots()\nax.plot(x, y, color='#009929')\n\n# Establecer el color de fondo\nax.set_facecolor('#d4f8b7')\n\n# Pintar el fondo externo del gr\u00e1fico\nfig.patch.set_facecolor('#D4F8B7')\n\n#Informacion en los ejes\nax.set_xlabel(f'Media = {media}', fontsize=12)\n#ax.set_ylabel('Densidad de Probabilidad', fontsize=12)\n\n# Agregar informaci\u00f3n flotante sobre la desviaci\u00f3n est\u00e1ndar\ninfo_desviacion = f'\u03c3 = {desviacion_estandar}'\nax.text(0.6, 0.85, info_desviacion, transform=ax.transAxes, fontsize=12, color='#000')\n\nax.grid(False)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm  # Par\u00e1metros de la distribuci\u00f3n normal media = 51800 desviacion_estandar = 730.3  # Generar datos de la distribuci\u00f3n normal x = np.linspace(media - 4 * desviacion_estandar, media + 4 * desviacion_estandar, 1000) y = norm.pdf(x, media, desviacion_estandar)  # Crear la gr\u00e1fica fig, ax = plt.subplots() ax.plot(x, y, color='#009929')  # Establecer el color de fondo ax.set_facecolor('#d4f8b7')  # Pintar el fondo externo del gr\u00e1fico fig.patch.set_facecolor('#D4F8B7')  #Informacion en los ejes ax.set_xlabel(f'Media = {media}', fontsize=12) #ax.set_ylabel('Densidad de Probabilidad', fontsize=12)  # Agregar informaci\u00f3n flotante sobre la desviaci\u00f3n est\u00e1ndar info_desviacion = f'\u03c3 = {desviacion_estandar}' ax.text(0.6, 0.85, info_desviacion, transform=ax.transAxes, fontsize=12, color='#000')  ax.grid(False) plt.show() <p>Como ya se identificaron las propiedades de la distribuci\u00f3n de muestreo de $\\bar{x}$ (figura 7.4), se utilizar\u00e1 esta distribuci\u00f3n para contestar dicha interrogante probabil\u00edstica. Observe la distribuci\u00f3n de muestreo de $\\bar{x}$ que se presenta nuevamente en la figura 7.5. Como la media poblacional es $51 800, el director de personal desea saber cu\u00e1l es la probabilidad de que $\\bar{x}$ est\u00e9 entre $51 300 y $52 300. Esta probabilidad corresponde al \u00e1rea sombreada de la distribuci\u00f3n de muestreo de la figura 7.5. Como la distribuci\u00f3n de muestreo est\u00e1 distribuida normalmente, su media es $51 800 y el error est\u00e1ndar de la media es 730.3, se usa la tabla de probabilidad normal est\u00e1ndar para determinar el \u00e1rea o probabilidad. Primero se calcula el valor de z en el extremo superior de este intervalo (52 300) y se usa la tabla para hallar el \u00e1rea bajo la curva a la izquierda de ese punto (hacia la cola izquierda). Despu\u00e9s se determina el valor de z en el extremo inferior de este intervalo (51 300) y se usa la tabla para hallar el \u00e1rea bajo la curva a la izquierda de este punto (otra \u00e1rea hacia la cola izquierda). Al restar la segunda \u00e1rea de la primera, se obtiene la probabilidad buscada. En $\\bar{x}= 52 300$ tenemos $$z = \\frac{52300-51800}{730.30}=0.68$$ En la tabla de probabilidad normal est\u00e1ndar se encuentra que la probabilidad acumulada (\u00e1rea a la izquierda de $z=0.68$) es 0.7517. En $\\bar{x}= 51 300$ tenemos $$z=\\frac{51300-51800}{730.30}=-0.68$$ El \u00e1rea bajo la curva a la izquierda de $z=0.68$ es 0.2483. Por tanto, $P(51300\\leq \\bar{x} \\leq 52300)=P(z\\leq 0.68)-P(z&lt;-0.68)=0.7517-0.2483=0.5034.$ Estos c\u00e1lculos indican que hay una probabilidad de 0.5034 de que con una muestra aleatoria simple de 30 gerentes de EAI se obtenga una media muestral $\\bar{x}$ que est\u00e9 en un margen de $500 de la media poblacional. Por tanto, la probabilidad de que la diferencia entre $\\bar{x}$ y $\u03bc$  $51 800 sea superior a $500 es $1-0.5034=0.4966$. En otras palabras, una muestra aleatoria simple de 30 gerentes de EAI tiene aproximadamente 50/50 oportunidades de tener una media muestral que no difi era de la media poblacional en m\u00e1s de los aceptables $500. Quiz\u00e1 deba pensarse en \\ FIGURA 7.5 Probabilidad de que una media muestral se encuentre en un margen de $500 de la media poblacional en una muestra aleatoria simple de 30 gerentes de EAI</p> <p> Figura 7.5 Probabilidad de que una media muestral se encuentre en un margen de $500 de la media poblacional en una muestra aleatoria simple de 30 gerentes de EAI </p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Par\u00e1metros de la distribuci\u00f3n normal\nmedia = 51800\ndesviacion_estandar = 730.3\n\n# Generar datos de la distribuci\u00f3n normal\nx = np.linspace(media - 4 * desviacion_estandar, media + 4 * desviacion_estandar, 1000)\ny = norm.pdf(x, media, desviacion_estandar)\n\n# Crear la gr\u00e1fica\nplt.figure(figsize=(12, 8))\nfig, ax = plt.subplots()\nax.fill_between(x, y, where=((x &gt;= 51200) &amp; (x &lt;= 52400)), color='#5ccb5f', alpha=0.3, label='\u00c1rea Especial')\nax.fill_between(x, y, where=((x &gt;= 0) &amp; (x &lt;= 51200)), color='#98F84A', alpha=0.3, label='\u00c1rea Especial')\nax.fill_between(x, y, where=((x &gt;= 52400) &amp; (x &lt;= 100000)), color='#98F84A', alpha=0.3, label='\u00c1rea Especial')\nax.plot(x, y, color='#009929')\n\n# Establecer el color de fondo\nax.set_facecolor('#d4f8b7')\n\n# Pintar el fondo externo del gr\u00e1fico\nfig.patch.set_facecolor('#D4F8B7')\nplt.axvline(x=51200, color='#008000', linestyle='--', label='Media Poblacional - $500')\nplt.axvline(x=52400, color='#008000', linestyle='--', label='Media Poblacional + $500')\n#Informacion en los ejes\n#ax.set_xlabel(f'Media = {media}', fontsize=12)\n#ax.set_ylabel('Densidad de Probabilidad', fontsize=12)\n\nplt.yticks([])  # Oculta las marcas del eje y\n\n\nplt.xticks([media,51200,52400], [f'{media}',f'{media-500}',f'{media+500}'])\n\n#info_desviacion = f'\u03c3= {desviacion_estandar}'\n#ax.text(0.6, 0.85, info_desviacion, transform=ax.transAxes, fontsize=12, color='#000')\nplt.text(0.05, 0.9,r'Distribuci\u00f3n de muestreo', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top')\nplt.text(0.05, 0.8,r'de $\\bar{x}$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top')\nplt.text(0.05, 0.2,r'$P(\\bar{x}&lt;513000)$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top')\nplt.text(0.8, 0.7, r'$\\sigma_{\\bar{x}}=730.30$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='right')\nplt.text(0.99, 0.3, r'$P(51300 \\leq \\bar{x} \\leq 52300)$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='right')\nplt.text(0.75, 0, r'$E(\\bar{p})$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='right')\n\nax.grid(False)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm  # Par\u00e1metros de la distribuci\u00f3n normal media = 51800 desviacion_estandar = 730.3  # Generar datos de la distribuci\u00f3n normal x = np.linspace(media - 4 * desviacion_estandar, media + 4 * desviacion_estandar, 1000) y = norm.pdf(x, media, desviacion_estandar)  # Crear la gr\u00e1fica plt.figure(figsize=(12, 8)) fig, ax = plt.subplots() ax.fill_between(x, y, where=((x &gt;= 51200) &amp; (x &lt;= 52400)), color='#5ccb5f', alpha=0.3, label='\u00c1rea Especial') ax.fill_between(x, y, where=((x &gt;= 0) &amp; (x &lt;= 51200)), color='#98F84A', alpha=0.3, label='\u00c1rea Especial') ax.fill_between(x, y, where=((x &gt;= 52400) &amp; (x &lt;= 100000)), color='#98F84A', alpha=0.3, label='\u00c1rea Especial') ax.plot(x, y, color='#009929')  # Establecer el color de fondo ax.set_facecolor('#d4f8b7')  # Pintar el fondo externo del gr\u00e1fico fig.patch.set_facecolor('#D4F8B7') plt.axvline(x=51200, color='#008000', linestyle='--', label='Media Poblacional - $500') plt.axvline(x=52400, color='#008000', linestyle='--', label='Media Poblacional + $500') #Informacion en los ejes #ax.set_xlabel(f'Media = {media}', fontsize=12) #ax.set_ylabel('Densidad de Probabilidad', fontsize=12)  plt.yticks([])  # Oculta las marcas del eje y   plt.xticks([media,51200,52400], [f'{media}',f'{media-500}',f'{media+500}'])  #info_desviacion = f'\u03c3= {desviacion_estandar}' #ax.text(0.6, 0.85, info_desviacion, transform=ax.transAxes, fontsize=12, color='#000') plt.text(0.05, 0.9,r'Distribuci\u00f3n de muestreo', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top') plt.text(0.05, 0.8,r'de $\\bar{x}$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top') plt.text(0.05, 0.2,r'$P(\\bar{x}&lt;513000)$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top') plt.text(0.8, 0.7, r'$\\sigma_{\\bar{x}}=730.30$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='right') plt.text(0.99, 0.3, r'$P(51300 \\leq \\bar{x} \\leq 52300)$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='right') plt.text(0.75, 0, r'$E(\\bar{p})$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='right')  ax.grid(False) plt.show() <pre>&lt;Figure size 1200x800 with 0 Axes&gt;</pre> <p>una muestra de tama\u00f1o mayor. Se explorar\u00e1 esta posibilidad considerando la relaci\u00f3n entre el tama\u00f1o de la muestra y la distribuci\u00f3n de muestreo de $\\bar{x}$.</p> <p> Figura 7.6 Comparaci\u00f3n entre las distribuciones de muestreo de $\\bar{x}$ con muestras aleatorias simples de tama\u00f1o $n=30$ y $n=100$ gerentes de EAI </p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Par\u00e1metros de la distribuci\u00f3n normal\nmedia = 51800\ndesviacion_estandar = 730.3\nmedia2 = 51800\ndesviacion_estandar2 = 400\n\nx2 = np.linspace(media2 - 4 * desviacion_estandar2, media2 + 4 * desviacion_estandar2, 1000)\ny2 = norm.pdf(x2, media2, desviacion_estandar2)\n# Generar datos de la distribuci\u00f3n normal\nx = np.linspace(media - 4 * desviacion_estandar, media + 4 * desviacion_estandar, 1000)\ny = norm.pdf(x, media, desviacion_estandar)\n\n# Crear la gr\u00e1fica\n\nfig, ax = plt.subplots()\n# Trazar la distribuci\u00f3n normal\nax.plot(x, y, color='Black')\nax.plot(x2, y2, color='#009929')\n# Establecer el color de fondo\nax.set_facecolor('#d4f8b7')\n\n# Pintar el fondo externo del gr\u00e1fico\nfig.patch.set_facecolor('#D4F8B7')\n\n# L\u00edneas verticales y punto de la media poblacional\nplt.axvline(x=51800, color='Black', linestyle='-', label='Media Poblacional - $500')\nplt.scatter([media], [0], color='#FF0000', marker='|', label='Media Poblacional')\n# Desactivar la cuadr\u00edcula\nax.grid(False)\nplt.yticks([])\nplt.xticks([51800],[\"51800\"])\nplt.text(0.05, 0.9,r'_____', transform=plt.gca().transAxes, fontsize=12,color=\"#009929\", verticalalignment='top')\nplt.text(0.05, 0.8,r'con $n=100$,', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top')\nplt.text(0.05, 0.7,r'$\\sigma_{\\bar{x}}=400$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top')\n#plt.text(0.9, 0.7, r'$\\sigma_{\\bar{x}}=400$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='right')\n\nplt.text(0.9, 0.7, r'_____          ', transform=plt.gca().transAxes, fontsize=12,color='Black', verticalalignment='top', horizontalalignment='right')\nplt.text(0.9, 0.6, r'Con $n=30$,', transform=plt.gca().transAxes, fontsize=12, color='Black',verticalalignment='top', horizontalalignment='right')\nplt.text(0.9, 0.5, r'$\\sigma_{\\bar{x}}=730.3$', transform=plt.gca().transAxes, fontsize=12, color='Black',verticalalignment='top', horizontalalignment='right')\n# Mostrar leyenda\n#ax.legend()\n\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm  # Par\u00e1metros de la distribuci\u00f3n normal media = 51800 desviacion_estandar = 730.3 media2 = 51800 desviacion_estandar2 = 400  x2 = np.linspace(media2 - 4 * desviacion_estandar2, media2 + 4 * desviacion_estandar2, 1000) y2 = norm.pdf(x2, media2, desviacion_estandar2) # Generar datos de la distribuci\u00f3n normal x = np.linspace(media - 4 * desviacion_estandar, media + 4 * desviacion_estandar, 1000) y = norm.pdf(x, media, desviacion_estandar)  # Crear la gr\u00e1fica  fig, ax = plt.subplots() # Trazar la distribuci\u00f3n normal ax.plot(x, y, color='Black') ax.plot(x2, y2, color='#009929') # Establecer el color de fondo ax.set_facecolor('#d4f8b7')  # Pintar el fondo externo del gr\u00e1fico fig.patch.set_facecolor('#D4F8B7')  # L\u00edneas verticales y punto de la media poblacional plt.axvline(x=51800, color='Black', linestyle='-', label='Media Poblacional - $500') plt.scatter([media], [0], color='#FF0000', marker='|', label='Media Poblacional') # Desactivar la cuadr\u00edcula ax.grid(False) plt.yticks([]) plt.xticks([51800],[\"51800\"]) plt.text(0.05, 0.9,r'_____', transform=plt.gca().transAxes, fontsize=12,color=\"#009929\", verticalalignment='top') plt.text(0.05, 0.8,r'con $n=100$,', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top') plt.text(0.05, 0.7,r'$\\sigma_{\\bar{x}}=400$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top') #plt.text(0.9, 0.7, r'$\\sigma_{\\bar{x}}=400$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='right')  plt.text(0.9, 0.7, r'_____          ', transform=plt.gca().transAxes, fontsize=12,color='Black', verticalalignment='top', horizontalalignment='right') plt.text(0.9, 0.6, r'Con $n=30$,', transform=plt.gca().transAxes, fontsize=12, color='Black',verticalalignment='top', horizontalalignment='right') plt.text(0.9, 0.5, r'$\\sigma_{\\bar{x}}=730.3$', transform=plt.gca().transAxes, fontsize=12, color='Black',verticalalignment='top', horizontalalignment='right') # Mostrar leyenda #ax.legend()  plt.show() <p> Figura 7.7 Probabilidad de que la media muestral est\u00e9 en un margen de $500 de la media poblacional usando una muestra aleatoria simple de 100 gerentes de EAI </p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Par\u00e1metros de la distribuci\u00f3n normal\nmedia = 51800\ndesviacion_estandar = 400\n\n# Generar datos de la distribuci\u00f3n normal\nx = np.linspace(media - 4 * desviacion_estandar, media + 4 * desviacion_estandar, 1000)\ny = norm.pdf(x, media, desviacion_estandar)\n\n# Crear la gr\u00e1fica\nplt.figure(figsize=(12, 8))\nfig, ax = plt.subplots()\nax.fill_between(x, y, where=((x &gt;= 51200) &amp; (x &lt;= 52400)), color='#5ccb5f', alpha=0.3, label='\u00c1rea Especial')\nax.fill_between(x, y, where=((x &gt;= 0) &amp; (x &lt;= 51200)), color='#98F84A', alpha=0.3, label='\u00c1rea Especial')\nax.plot(x, y, color='#009929')\n\n# Establecer el color de fondo\nax.set_facecolor('#d4f8b7')\n\n# Pintar el fondo externo del gr\u00e1fico\nfig.patch.set_facecolor('#D4F8B7')\nplt.axvline(x=51200, color='#008000', linestyle='--', label='Media Poblacional - $500')\nplt.axvline(x=52400, color='#008000', linestyle='--', label='Media Poblacional + $500')\n\nplt.yticks([])  # Oculta las marcas del eje y\n\n# Configurar los ticks del eje x para mostrar solo la media\nplt.xticks([media,51200,52400], [f'{media}',f'{media-500}',f'{media+500}'])\n#info_desviacion = f'\u03c3= {desviacion_estandar}'\n#ax.text(0.6, 0.85, info_desviacion, transform=ax.transAxes, fontsize=12, color='#000')\nplt.text(0.05, 0.9,r'Distribuci\u00f3n de muestreo', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top')\nplt.text(0.05, 0.8,r'de $\\bar{x}$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top')\nplt.text(0.05, 0.6,r'$P(51300 \\leq \\bar{x} \\leq 52300)$=0.7888', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top')\nplt.text(0.9, 0.7, r'$\\sigma_{\\bar{x}}=400$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='right')\nax.grid(False)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm  # Par\u00e1metros de la distribuci\u00f3n normal media = 51800 desviacion_estandar = 400  # Generar datos de la distribuci\u00f3n normal x = np.linspace(media - 4 * desviacion_estandar, media + 4 * desviacion_estandar, 1000) y = norm.pdf(x, media, desviacion_estandar)  # Crear la gr\u00e1fica plt.figure(figsize=(12, 8)) fig, ax = plt.subplots() ax.fill_between(x, y, where=((x &gt;= 51200) &amp; (x &lt;= 52400)), color='#5ccb5f', alpha=0.3, label='\u00c1rea Especial') ax.fill_between(x, y, where=((x &gt;= 0) &amp; (x &lt;= 51200)), color='#98F84A', alpha=0.3, label='\u00c1rea Especial') ax.plot(x, y, color='#009929')  # Establecer el color de fondo ax.set_facecolor('#d4f8b7')  # Pintar el fondo externo del gr\u00e1fico fig.patch.set_facecolor('#D4F8B7') plt.axvline(x=51200, color='#008000', linestyle='--', label='Media Poblacional - $500') plt.axvline(x=52400, color='#008000', linestyle='--', label='Media Poblacional + $500')  plt.yticks([])  # Oculta las marcas del eje y  # Configurar los ticks del eje x para mostrar solo la media plt.xticks([media,51200,52400], [f'{media}',f'{media-500}',f'{media+500}']) #info_desviacion = f'\u03c3= {desviacion_estandar}' #ax.text(0.6, 0.85, info_desviacion, transform=ax.transAxes, fontsize=12, color='#000') plt.text(0.05, 0.9,r'Distribuci\u00f3n de muestreo', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top') plt.text(0.05, 0.8,r'de $\\bar{x}$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top') plt.text(0.05, 0.6,r'$P(51300 \\leq \\bar{x} \\leq 52300)$=0.7888', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top') plt.text(0.9, 0.7, r'$\\sigma_{\\bar{x}}=400$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='right') ax.grid(False) plt.show() <pre>&lt;Figure size 1200x800 with 0 Axes&gt;</pre> <p>En la tabla de probabilidad normal est\u00e1ndar se encuentra que la probabilidad acumulada correspondiente a $z=1.25$ es 0.8944.</p> <p>Para $\\bar{x}=51300$ tenemos $$z=\\frac{51300-51800}{400}=-1.25$$ La probabilidad acumulada correspondiente a $z=1.25$ es $0.1056$. Por tanto, $P(51 300\\leq \\bar{x} \\leq 52 300)=P(z \\leq 1.25)-P(z \\leq -1.25)= 0.8944- 0.1056=0.7888$. Entonces, al aumentar el tama\u00f1o de la muestra de 30 a 100 gerentes de EAI, la probabilidad de obtener una muestra aleatoria simple que est\u00e9 entre los $500 de la media poblacional aumenta de 0.5034 a 0.7888.</p> <p>El punto importante estriba en que cuando el tama\u00f1o de la muestra aumenta, el error est\u00e1ndar de la media disminuye. Como resultado, una muestra de mayor tama\u00f1o proporciona mayor probabilidad de que la media muestral est\u00e9 dentro de una distancia determinada de la media poblacional.</p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Par\u00e1metros\nmedia_poblacional = 200\ndesviacion_estandar_poblacional = 50\ntamano_muestra = 100\n\n# Simulaci\u00f3n de la distribuci\u00f3n de muestreo de la media muestral\nmedias_muestrales = np.random.normal(media_poblacional, desviacion_estandar_poblacional / np.sqrt(tamano_muestra), 1000)\n\n# Crear gr\u00e1fico de densidad con colores personalizados\nsns.kdeplot(medias_muestrales, color='green', fill=True, palette=sns.color_palette(\"Set2\"))\nplt.title('Distribuci\u00f3n de Muestreo de la Media Muestral')\nplt.xlabel('Media Muestral (\\(\\bar{x}\\))')\nplt.ylabel('Densidad')\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt import seaborn as sns  # Par\u00e1metros media_poblacional = 200 desviacion_estandar_poblacional = 50 tamano_muestra = 100  # Simulaci\u00f3n de la distribuci\u00f3n de muestreo de la media muestral medias_muestrales = np.random.normal(media_poblacional, desviacion_estandar_poblacional / np.sqrt(tamano_muestra), 1000)  # Crear gr\u00e1fico de densidad con colores personalizados sns.kdeplot(medias_muestrales, color='green', fill=True, palette=sns.color_palette(\"Set2\")) plt.title('Distribuci\u00f3n de Muestreo de la Media Muestral') plt.xlabel('Media Muestral (\\(\\bar{x}\\))') plt.ylabel('Densidad') plt.show()  <p>$d)$ Interpretaci\u00f3n de la distribuci\u00f3n de muestreo de la media muestral ($\\bar{x}$):</p> <p>La distribuci\u00f3n de muestreo de la media muestral describe la variabilidad que se esperar\u00eda en las medias muestrales si tomamos m\u00faltiples muestras de la poblaci\u00f3n. En este caso, debido al Teorema del L\u00edmite Central, la distribuci\u00f3n de muestreo de $\\bar{x}$ ser\u00e1 aproximadamente normal, independientemente de la forma de la distribuci\u00f3n original, siempre y cuando el tama\u00f1o de la muestra sea lo suficientemente grande. La desviaci\u00f3n est\u00e1ndar de esta distribuci\u00f3n de muestreo($(\u03c3_{\\bar{x}})$ proporciona una medida de cu\u00e1nto var\u00edan las medias muestrales alrededor de la media poblacional. En este ejemplo, $\u03c3_{\\bar{x}}=5$, lo que indica que esperamos que las medias muestrales tiendan a agruparse alrededor de la media poblacional con una desviaci\u00f3n est\u00e1ndar de 5 unidades.</p> In\u00a0[\u00a0]: Copied! <pre>import scipy.stats as stats\n#Solucion usando phyton\n# Datos dados\nmedia_poblacional = 939\ndesviacion_estandar = 245\n\n# Tama\u00f1os de muestra\ntamanos_muestra = [30, 50, 100, 400]\n\n# Valor de diferencia en medias\ndiferencia_medias = 25\n\n# Calcular las probabilidades para cada tama\u00f1o de muestra\nfor n in tamanos_muestra:\n    # Calcular z\n    z = diferencia_medias / (desviacion_estandar / (n ** 0.5))\n\n    # Calcular la probabilidad usando la distribuci\u00f3n normal est\u00e1ndar\n    probabilidad = stats.norm.cdf(z) - stats.norm.cdf(-z)\n    print(f\"Para n = {n}, la probabilidad es: {probabilidad}\")\n</pre> import scipy.stats as stats #Solucion usando phyton # Datos dados media_poblacional = 939 desviacion_estandar = 245  # Tama\u00f1os de muestra tamanos_muestra = [30, 50, 100, 400]  # Valor de diferencia en medias diferencia_medias = 25  # Calcular las probabilidades para cada tama\u00f1o de muestra for n in tamanos_muestra:     # Calcular z     z = diferencia_medias / (desviacion_estandar / (n ** 0.5))      # Calcular la probabilidad usando la distribuci\u00f3n normal est\u00e1ndar     probabilidad = stats.norm.cdf(z) - stats.norm.cdf(-z)     print(f\"Para n = {n}, la probabilidad es: {probabilidad}\") <p>Ejercicio 28. La puntuaci\u00f3n promedio de golfistas hombres es de 95 y para las golfistas mujeres es de 106 (Golf Digest, abril de 2006). Considere estos valores como medias poblacionales de los hombres y las mujeres y suponga que la desviaci\u00f3n est\u00e1ndar poblacional es \u03c3=14 golpes en ambos casos. Se tomar\u00e1 una muestra aleatoria simple de 30 golfistas hombres y otra muestra aleatoria simple de 45 golfistas mujeres.</p> <p>a) Proporcione la distribuci\u00f3n de muestreo de $\\bar{x}$ correspondiente a los golfistas.</p> <p>b) \u00bfCu\u00e1l es la probabilidad de que la media muestral no difiera en m\u00e1s de 3 golpes de la media poblacional en la muestra de hombres?</p> <p>c) \u00bfCu\u00e1l es la probabilidad de que la media muestral no difiera en m\u00e1s de 3 golpes de la media poblacional en la muestra de golfistas mujeres?</p> <p>d) \u00bfEn cu\u00e1l de los casos, inciso a) o inciso b), es mayor la probabilidad de que la media muestral no difiera en m\u00e1s de 3 golpes de la media poblacional? \u00bfPor qu\u00e9?</p> <p>Solucion: </p> <p>$a)$ La distribuci\u00f3n de muestreo de la media muestral, $\\bar{x}$ , se puede describir como una distribuci\u00f3n normal con una media igual a la media poblacional y una desviaci\u00f3n est\u00e1ndar igual a $\\frac{\u03c3}{\\sqrt{n}}$, donde $n$ es el tama\u00f1o de la muestra. \\ Resolvemos para los golfistas hombre: $$\u03bc_{\\bar{x}_{hombres}}=\u03bc_{hombres}=95$$ $$\u03c3_{\\bar{x}_{hombres}}=\\frac{\u03c3_{hombres}}{\\sqrt{n_{hombres}}}=\\frac{14}{\\sqrt{130}}$$ $$\u03c3_{\\bar{x}}=2.56$$ Resolvemos para los golfistas mujeres: $$\u03bc_{\\bar{x}_{mujeres}}=\u03bc_{mujeres}=106$$ $$\u03c3_{\\bar{x}_{mujeres}}=\\frac{\u03c3_{mujeres}}{\\sqrt{n_{mujeres}}}=\\frac{14}{\\sqrt{45}}$$ $$\u03c3_{\\bar{x}}=2.09$$ $b)$ Probabilidad de que la media muestral de hombres no difiera en m\u00e1s de 3 golpes de la media poblacional usaremos lo siguiente: $$z_{hombres}=\\frac{\\bar{x}-\u03bc_{hombres}}{\u03c3_{\\bar{x}_{hombres}}}$$ Luego, buscaremos la probabilidad a: $$|z_{hombres}|\\leq \\frac{3}{\u03c3_{\\bar{x}_{hombres}}}$$ $$|z_{hombres}|\\leq \\frac{3}{2.56}$$ Probabilidad de que la media muestral de hombres no difiera en m\u00e1s de 3 golpes es de 0.7580.</p> <p>$c)$ Probabilidad de que la media muestral de mujeres no difiera en m\u00e1s de 3 golpes de la media poblacional usaremos lo siguiente: $$z_{mujeres}=\\frac{\\bar{x}-\u03bc_{mujeres}}{\u03c3_{\\bar{x}_{mujeres}}}$$ Luego, buscaremos la probabilidad a: $$|z_{mujeres}|\\leq \\frac{3}{\u03c3_{\\bar{x}_{mujeres}}}$$ $$|z_{mujeres}|\\leq \\frac{3}{2.09}$$ Probabilidad de que la media muestral de mujeres no difiera en m\u00e1s de 3 golpes es de 0.8502.</p> <p>$d)$ Es el inciso c debido a que el tamano de la muestra es mayor.</p> <p>Solucion con phyton: </p> In\u00a0[\u00a0]: Copied! <pre>import scipy.stats as stats\n\n# Datos para hombres\nmedia_hombres = 95\ndesviacion_hombres = 14\ntamanos_muestra_hombres = 30\n\n# Datos para mujeres\nmedia_mujeres = 106\ndesviacion_mujeres = 14\ntamanos_muestra_mujeres = 45\n# SOLUCIO USANDO PYTHON\n# Diferencia m\u00e1xima permitida en golpes\ndiferencia_maxima = 3\n\n# a) Distribuci\u00f3n de muestreo\n# Hombres\nmedia_muestra_hombres = media_hombres\ndesviacion_muestra_hombres = desviacion_hombres / (tamanos_muestra_hombres ** 0.5)\n\n# Mujeres\nmedia_muestra_mujeres = media_mujeres\ndesviacion_muestra_mujeres = desviacion_mujeres / (tamanos_muestra_mujeres ** 0.5)\n\n# b) Probabilidad para hombres\nz_hombres = diferencia_maxima / desviacion_muestra_hombres\nprobabilidad_hombres = stats.norm.cdf(z_hombres) - stats.norm.cdf(-z_hombres)\n\n# c) Probabilidad para mujeres\nz_mujeres = diferencia_maxima / desviacion_muestra_mujeres\nprobabilidad_mujeres = stats.norm.cdf(z_mujeres) - stats.norm.cdf(-z_mujeres)\n\n# d) Comparaci\u00f3n de probabilidades\nif probabilidad_hombres &gt; probabilidad_mujeres:\n    mayor_probabilidad = \"Hombres\"\nelse:\n    mayor_probabilidad = \"Mujeres\"\n\n# Mostrar resultados\nprint(f\"Distribuci\u00f3n de muestreo para hombres: Media = {media_muestra_hombres}, Desviaci\u00f3n = {desviacion_muestra_hombres}\")\nprint(f\"Distribuci\u00f3n de muestreo para mujeres: Media = {media_muestra_mujeres}, Desviaci\u00f3n = {desviacion_muestra_mujeres}\")\nprint(f\"b) Probabilidad de que la media muestral de hombres no difiera en m\u00e1s de 3 golpes: {probabilidad_hombres}\")\nprint(f\"c) Probabilidad de que la media muestral de mujeres no difiera en m\u00e1s de 3 golpes: {probabilidad_mujeres}\")\nprint(f\"d) En {mayor_probabilidad} es mayor la probabilidad de que la media muestral no difiera en m\u00e1s de 3 golpes.\")\n</pre> import scipy.stats as stats  # Datos para hombres media_hombres = 95 desviacion_hombres = 14 tamanos_muestra_hombres = 30  # Datos para mujeres media_mujeres = 106 desviacion_mujeres = 14 tamanos_muestra_mujeres = 45 # SOLUCIO USANDO PYTHON # Diferencia m\u00e1xima permitida en golpes diferencia_maxima = 3  # a) Distribuci\u00f3n de muestreo # Hombres media_muestra_hombres = media_hombres desviacion_muestra_hombres = desviacion_hombres / (tamanos_muestra_hombres ** 0.5)  # Mujeres media_muestra_mujeres = media_mujeres desviacion_muestra_mujeres = desviacion_mujeres / (tamanos_muestra_mujeres ** 0.5)  # b) Probabilidad para hombres z_hombres = diferencia_maxima / desviacion_muestra_hombres probabilidad_hombres = stats.norm.cdf(z_hombres) - stats.norm.cdf(-z_hombres)  # c) Probabilidad para mujeres z_mujeres = diferencia_maxima / desviacion_muestra_mujeres probabilidad_mujeres = stats.norm.cdf(z_mujeres) - stats.norm.cdf(-z_mujeres)  # d) Comparaci\u00f3n de probabilidades if probabilidad_hombres &gt; probabilidad_mujeres:     mayor_probabilidad = \"Hombres\" else:     mayor_probabilidad = \"Mujeres\"  # Mostrar resultados print(f\"Distribuci\u00f3n de muestreo para hombres: Media = {media_muestra_hombres}, Desviaci\u00f3n = {desviacion_muestra_hombres}\") print(f\"Distribuci\u00f3n de muestreo para mujeres: Media = {media_muestra_mujeres}, Desviaci\u00f3n = {desviacion_muestra_mujeres}\") print(f\"b) Probabilidad de que la media muestral de hombres no difiera en m\u00e1s de 3 golpes: {probabilidad_hombres}\") print(f\"c) Probabilidad de que la media muestral de mujeres no difiera en m\u00e1s de 3 golpes: {probabilidad_mujeres}\") print(f\"d) En {mayor_probabilidad} es mayor la probabilidad de que la media muestral no difiera en m\u00e1s de 3 golpes.\") <p>Ejercicio 30. Para estimar la edad media de una poblaci\u00f3n de 4 000 empleados se selecciona una muestra aleatoria simple de 40 sujetos.</p> <p>$a)$ \u00bfUsar\u00eda el factor de correcci\u00f3n para una poblaci\u00f3n finita en el c\u00e1lculo del error est\u00e1ndar de la media? Explique.</p> <p>$b)$ Si la desviaci\u00f3n est\u00e1ndar poblacional es \u03c3=8.2 a\u00f1os, calcule el error est\u00e1ndar con y sin el factor de correcci\u00f3n para una poblaci\u00f3n finita. \u00bfCu\u00e1l es la base para ignorar el factor de correcci\u00f3n para la poblaci\u00f3n finita si $n/N \\leq 0.05$?</p> <p>$c)$ \u00bfCu\u00e1l es la probabilidad de que la media muestral de las edades de los empleados no difiera en m\u00e1s de $\\pm2$ a\u00f1os de la media poblacional de las edades?</p> <p>Solucion: </p> <p>$a)$ El factor de correcci\u00f3n para una poblaci\u00f3n finita se usa cuando la muestra es una fracci\u00f3n significativa de la poblaci\u00f3n total. El factor de correcci\u00f3n ajusta el error est\u00e1ndar de la media $(\u03c3_{\\bar{x}})$ para tener en cuenta el hecho de que se est\u00e1 muestreando sin reemplazo de una poblaci\u00f3n finita. La f\u00f3rmula del error est\u00e1ndar de la media con el factor de correcci\u00f3n es: $$\u03c3_{\\bar{x}}=\\frac{\\sigma}{N}\\times \\sqrt{\\frac{N-n}{N-1}}$$ Donde $\u03c3_{\\bar{x}}$ es el error est\u00e1ndar de la media, $sigma$ es la desciaci\u00f3n est\u00e1ndar poblacional, $N$ es el tama\u00f1o de la poblaci\u00f3n y $n$ es el tama\u00f1o de la muestra. \\ En este caso, la poblaci\u00f3n tiene 4,000 empleados y la muestra es de 40 sujetos. Si $n/N$ es peque\u00f1o (generalmente menor o igual a 0.05), se puede ignorar el factor de correcci\u00f3n.Entonces no usaremos el factor de correci\u00f3n</p> <p>$b)$ Ahora solo reemplazamos en la formula anterior:</p> <p>Con factor de correci\u00f3n: $$\u03c3_{\\bar{x}}=\\frac{8.2}{4000}\\times \\sqrt{\\frac{4000-40}{4000-1}}$$ $$\u03c3_{\\bar{x}}=1.29$$ Sin factor de correcci\u00f3n: $$\u03c3_{\\bar{x}}=\\frac{8.2}{\\sqrt{40}}$$ $$\u03c3_{\\bar{x}}=1.30$$ Entonces hay poca diferencia entre usar el factor de correcci\u00f3n o no.</p> <p>$c)$ Para esto necesitaremos usar la distribuci\u00f3n normal y la puntuaci\u00f3n z. La f\u00f3rmula de la puntuaci\u00f3n z es: $$z=\\frac{\\bar{x}-\u03bc}{\\frac{\u03c3}{\\sqrt{n}}}$$ Donde $\\bar{x}$ es la media muestral, \u03bc es la media poblacional, \u03c3 es la desviaci\u00f3n est\u00e1ndar poblacional, y $n$ es el tama\u00f1o de la muestra. Ahora reemplazamos: $$z=\\frac{-2}{\\frac{8.2}{\\sqrt{40}}}$$ $$z=-1.54$$ Ahora calculamos la probabilidad asociada con $-2\\leq z\\leq2$ usando una tabla de la distribuci\u00f3n normal est\u00e1ndar o una calculadora estad\u00edstica. \\ Dandonos que la probabilidad de que no difiera en m\u00e1s  de $\\pm2$ es de 0.8764.</p> <p>texto del enlace</p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Par\u00e1metros del problema\nproporcion_poblacional = 0.60\nerror_estandar_proporcion = 0.0894\n\n# Valores para la distribuci\u00f3n de muestreo de p\np_vals = np.linspace(0, 1, 1000)\n\n# Calcula la funci\u00f3n de densidad de probabilidad para cada valor de p\npdf_vals = norm.pdf(p_vals, loc=proporcion_poblacional, scale=error_estandar_proporcion)\n\n# Crea el gr\u00e1fico de la distribuci\u00f3n de muestreo de p\n#plt.figure(figsize=(10, 6))\nplt.plot(p_vals, pdf_vals, color='#009929', label='Distribuci\u00f3n de Muestreo de p')\nplt.gca().set_facecolor('#d4f8b7')\n#plt.title('Distribuci\u00f3n de Muestreo de p')\nplt.text(0.05, 0.7,r'Distribuci\u00f3n de muestreo', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top')\nplt.text(0.05, 0.6,r'de $\\bar{p}$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top')\nplt.text(0.95, 0.4, r'$\\sigma_{\\bar{p}}=0.0894$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='right')\nplt.text(0.75, 0, r'$E(\\bar{p})$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='right')\narea_interes = np.logical_and(p_vals &gt;= 0.55, p_vals &lt;= 0.65)\nplt.xticks([0.60],['0.60'])\nplt.yticks([])\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm  # Par\u00e1metros del problema proporcion_poblacional = 0.60 error_estandar_proporcion = 0.0894  # Valores para la distribuci\u00f3n de muestreo de p p_vals = np.linspace(0, 1, 1000)  # Calcula la funci\u00f3n de densidad de probabilidad para cada valor de p pdf_vals = norm.pdf(p_vals, loc=proporcion_poblacional, scale=error_estandar_proporcion)  # Crea el gr\u00e1fico de la distribuci\u00f3n de muestreo de p #plt.figure(figsize=(10, 6)) plt.plot(p_vals, pdf_vals, color='#009929', label='Distribuci\u00f3n de Muestreo de p') plt.gca().set_facecolor('#d4f8b7') #plt.title('Distribuci\u00f3n de Muestreo de p') plt.text(0.05, 0.7,r'Distribuci\u00f3n de muestreo', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top') plt.text(0.05, 0.6,r'de $\\bar{p}$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top') plt.text(0.95, 0.4, r'$\\sigma_{\\bar{p}}=0.0894$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='right') plt.text(0.75, 0, r'$E(\\bar{p})$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='right') area_interes = np.logical_and(p_vals &gt;= 0.55, p_vals &lt;= 0.65) plt.xticks([0.60],['0.60']) plt.yticks([]) plt.show()  <p>Si se aumenta el tama\u00f1o de la muestra a $n=100$, el error est\u00e1ndar de la proporci\u00f3n se convierte en $$\u03c3_{\\bar{p}}=\\sqrt{\\frac{0.60(1-0.60)}{100}}=0.049$$ Con una muestra de 100 gerentes de EAI, se calcula ahora la probabilidad de que la proporci\u00f3n muestral tenga un valor que no difiera en m\u00e1s de 0.05 de la proporci\u00f3n poblacional. Como la distribuci\u00f3n de muestreo es aproximadamente normal, con media 0.60 y desviaci\u00f3n est\u00e1ndar 0.049, se puede usar la tabla de probabilidad normal est\u00e1ndar para determinar el \u00e1rea o probabilidad. Para $\\bar{p}=0.65$, se tiene $z=(0.65 - 0.60)/0.049 =1.02$. La tabla de probabilidad normal est\u00e1ndar indica que la probabilidad acumulada correspondiente a $z=1.02$ es 0.8461. De</p> <p> Figura 7.9 Probabilidad de que $\\bar{p}$ est\u00e9 entre 0.55 y 0.65 </p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Par\u00e1metros del problema\nmedia_poblacional = 0.60\ndesviacion_estandar = 0.049\n\n# Valores para la distribuci\u00f3n de muestreo de p\np_vals = np.linspace(0, 1, 1000)\n\n# Calcula la funci\u00f3n de densidad de probabilidad para cada valor de p\npdf_vals = norm.pdf(p_vals, loc=media_poblacional, scale=desviacion_estandar)\n\n# Crea el gr\u00e1fico de la distribuci\u00f3n de muestreo de p\nplt.figure(figsize=(10, 6))\nplt.plot(p_vals, pdf_vals, color='#009929', label='Distribuci\u00f3n de Muestreo de p')\n\n# A\u00f1adir l\u00edneas verticales para marcar los l\u00edmites de 0.55 y 0.65\nplt.axvline(x=0.55, color='#008000', linestyle='--', label='L\u00edmite Inferior (0.55)')\nplt.axvline(x=0.65, color='#008000', linestyle='--', label='L\u00edmite Superior (0.65)')\n\narea_interes = np.logical_and(p_vals &gt;= 0.55, p_vals &lt;= 0.65)\narea_interes2 = np.logical_and(p_vals &gt;= 0, p_vals &lt;= 0.55)\nplt.gca().set_facecolor('#d4f8b7')\nplt.fill_between(p_vals, pdf_vals, where=area_interes, color='#5ccb5f', alpha=0.3, label='Probabilidad Deseada')\nplt.fill_between(p_vals, pdf_vals, where=area_interes2, color='#98F84A', alpha=0.3, label='Probabilidad Deseada')\nplt.xticks([0.55,0.60,0.65],['0.55','0.60','0.65'])\nplt.yticks([])\nplt.text(0.05, 0.7,r'Distribuci\u00f3n de muestreo', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top')\nplt.text(0.05, 0.6,r'de $\\bar{p}$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top')\nplt.text(0.2, 0.2,r'$P(\\bar{p} \\leq  0.55) =0.2877$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top')\nplt.text(0.8, 0.4, r'$\\sigma_{\\bar{p}}=0.0894$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='right')\nplt.text(0.95, 0.3, r'$P(0.55 \\leq p \\leq 0.65)=0.4246$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='right')\nplt.text(0.95, 0.2, r'$=0.7123- 0.2877$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='right')\nplt.text(0.75, 0, r'$E(\\bar{p})$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='right')\n#plt.legend()\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm  # Par\u00e1metros del problema media_poblacional = 0.60 desviacion_estandar = 0.049  # Valores para la distribuci\u00f3n de muestreo de p p_vals = np.linspace(0, 1, 1000)  # Calcula la funci\u00f3n de densidad de probabilidad para cada valor de p pdf_vals = norm.pdf(p_vals, loc=media_poblacional, scale=desviacion_estandar)  # Crea el gr\u00e1fico de la distribuci\u00f3n de muestreo de p plt.figure(figsize=(10, 6)) plt.plot(p_vals, pdf_vals, color='#009929', label='Distribuci\u00f3n de Muestreo de p')  # A\u00f1adir l\u00edneas verticales para marcar los l\u00edmites de 0.55 y 0.65 plt.axvline(x=0.55, color='#008000', linestyle='--', label='L\u00edmite Inferior (0.55)') plt.axvline(x=0.65, color='#008000', linestyle='--', label='L\u00edmite Superior (0.65)')  area_interes = np.logical_and(p_vals &gt;= 0.55, p_vals &lt;= 0.65) area_interes2 = np.logical_and(p_vals &gt;= 0, p_vals &lt;= 0.55) plt.gca().set_facecolor('#d4f8b7') plt.fill_between(p_vals, pdf_vals, where=area_interes, color='#5ccb5f', alpha=0.3, label='Probabilidad Deseada') plt.fill_between(p_vals, pdf_vals, where=area_interes2, color='#98F84A', alpha=0.3, label='Probabilidad Deseada') plt.xticks([0.55,0.60,0.65],['0.55','0.60','0.65']) plt.yticks([]) plt.text(0.05, 0.7,r'Distribuci\u00f3n de muestreo', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top') plt.text(0.05, 0.6,r'de $\\bar{p}$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top') plt.text(0.2, 0.2,r'$P(\\bar{p} \\leq  0.55) =0.2877$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top') plt.text(0.8, 0.4, r'$\\sigma_{\\bar{p}}=0.0894$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='right') plt.text(0.95, 0.3, r'$P(0.55 \\leq p \\leq 0.65)=0.4246$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='right') plt.text(0.95, 0.2, r'$=0.7123- 0.2877$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='right') plt.text(0.75, 0, r'$E(\\bar{p})$', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='right') #plt.legend() plt.show() <p>manera similar, para $\\bar{p}$ 0.55, se tiene que $z$ $=$(0.55 $\u2013$ 0.60)$/$0.049$=$ $-$ 1.02. Se encuentra que la probabilidad acumulada correspondiente a $z=$ 1.02 es 0.1539. Por tanto, si el tama\u00f1o de la muestra aumenta de 30 a 100, la probabilidad de que la proporci\u00f3n muestral $\\bar{p}$ no difiera en m\u00e1s de 0.05 de la proporci\u00f3n poblacional $p$ aumenta a 0.8461 0.1539 0.6922.</p> <p>En este cap\u00edtulo se ha explicado que los estad\u00edsticos muestrales, como la media muestral x, la desviaci\u00f3n est\u00e1ndar muestral $s$ y la proporci\u00f3n muestral $\\bar{p}$  sirven como estimadores puntuales de sus correspondientes par\u00e1metros poblacionales, $\u03bc$, $\u03c3$ y $p$. Resulta interesante advertir que cada uno de estos estad\u00edsticos muestrales sean los estimadores puntuales de sus correspondientes par\u00e1metros poblacionales. Sin embargo, antes de usar un estad\u00edstico muestral como estimador puntual, se verifi ca si \u00e9ste tiene ciertas propiedades que corresponden a un buen estimador puntual. En esta secci\u00f3n se estudian las propiedades que deben tener los buenos estimadores puntuales: insesgadez, efi ciencia y consistencia. Como hay distintos estad\u00edsticos muestrales que se utilizan como estimadores puntuales de sus diferentes par\u00e1metros poblacionales, en esta secci\u00f3n se usar\u00e1 la notaci\u00f3n general siguiente.</p> $\u03b8 =$ par\u00e1metro poblacional de inter\u00e9s ......................$\\hat{\\theta}=$ estad\u00edstico muestral o estimador puntual de $\u03b8$ In\u00a0[\u00a0]: Copied! <pre>from IPython.display import HTML, display\n\n# C\u00f3digo para colocar el s\u00edmbolo LaTeX en el fondo de texto\nhtml_code = \"\"\"\n&lt;script src=\"https://polyfill.io/v3/polyfill.min.js?features=es6\"&gt;&lt;/script&gt;\n&lt;script id=\"MathJax-script\" async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"&gt;&lt;/script&gt;\n&lt;style&gt;\n  .custom-container {\n    background-color: #D4F8B7; /* Color de fondo */\n    padding: 10px;\n    border: none; /* Eliminar bordes */\n    border-radius: 0; /* Eliminar esquinas redondeadas */\n  }\n  .custom-text {\n    color: #000000; /* Color del texto */\n    font-size: 18px;\n    font-weight: bold;\n    display: flex;\n    justify-content: center;\n    align-items: center;\n  }\n&lt;/style&gt;\n&lt;div class=\"custom-container\"&gt;\n  &lt;p&gt;INSESGADEZ&lt;/p&gt;\n  &lt;p&gt;El estad\u00edstico muestral \\\\(\\hat{\\\\theta}\\\\) es un estimador insesgado del par\u00e1metro poblacional \\\\({\\\\theta}\\\\) si&lt;/p&gt;\n  &lt;br&gt;\n  &lt;p class=\"custom-text\"&gt;\\\\({E}\\\\)\\\\((\\hat{\\\\theta})\\\\)  \\\\(={\\\\theta}\\\\)&lt;/p&gt;\n\n  &lt;p&gt;donde&lt;/p&gt;\n  &lt;p &gt;\\\\({E}\\\\)\\\\((\\hat{\\\\theta})\\\\)  valor esperado del estad\u00edstico muestral \\\\({\\\\theta}\\\\)&lt;/p&gt;\n&lt;/div&gt;\n\"\"\"\n# Mostrar el HTML con el estilo personalizado\ndisplay(HTML(html_code))\n</pre> from IPython.display import HTML, display  # C\u00f3digo para colocar el s\u00edmbolo LaTeX en el fondo de texto html_code = \"\"\"  <p>INSESGADEZ</p> <p>El estad\u00edstico muestral \\\\(\\hat{\\\\theta}\\\\) es un estimador insesgado del par\u00e1metro poblacional \\\\({\\\\theta}\\\\) si</p> <p>\\\\({E}\\\\)\\\\((\\hat{\\\\theta})\\\\)  \\\\(={\\\\theta}\\\\)</p> <p>donde</p> <p>\\\\({E}\\\\)\\\\((\\hat{\\\\theta})\\\\)  valor esperado del estad\u00edstico muestral \\\\({\\\\theta}\\\\)</p>  \"\"\" # Mostrar el HTML con el estilo personalizado display(HTML(html_code)) <p>INSESGADEZ</p> <p>El estad\u00edstico muestral \\(\\hat{\\theta}\\) es un estimador insesgado del par\u00e1metro poblacional \\({\\theta}\\) si</p> <p>\\({E}\\)\\((\\hat{\\theta})\\)  \\(={\\theta}\\)</p> <p>donde</p> <p>\\({E}\\)\\((\\hat{\\theta})\\)  valor esperado del estad\u00edstico muestral \\({\\theta}\\)</p> <p>Por tanto, el valor esperado, o media, de todos los posibles valores de un estad\u00edstico muestral insesgado es igual al par\u00e1metro poblacional que se est\u00e1 estimando.</p> <p>En la figura 7.10 se exponen los casos de los estimadores puntuales sesgado e insesgado. En la gr\u00e1fica que ilustra el estimador insesgado, la media de la distribuci\u00f3n de muestreo es igual al valor del par\u00e1metro poblacional. En este caso los errores de estimaci\u00f3n se equilibran, ya que algunas veces el valor del estimador puntual $\\hat{\\theta}$ puede ser menor que $\u03b8$ y otras veces es mayor que $\u03b8$. En el estimador sesgado, la media de la distribuci\u00f3n de muestreo es menor o mayor que el valor del par\u00e1metro poblacional. En la gr\u00e1fica $B$ de la figura 7.10, $E(\\hat{\\theta})$ es mayor que $\u03b8$ ; as\u00ed, la probabilidad de que los estad\u00edsticos muestrales sobreestimen el valor del par\u00e1metro poblacional es grande. En la fi gura se muestra la amplitud de este sesgo.</p> <p>Al estudiar las distribuciones de muestreo de la media muestral y de la proporci\u00f3n muestral, se vio que $E(\\bar{x})$  $\u03bc$ y que $E(\\bar{p})$  $=p$. Por tanto, $\\bar{x}$ y $\\bar{p}$ son estimadores insesgados de sus correspondientes par\u00e1metros poblacionales $\u03bc$ y $p$.</p> <p>En cuanto a la desviaci\u00f3n est\u00e1ndar muestral $s$ y la varianza muestral $s^{2}$ , se puede demostrar que $E(s^{2})=\u03c3^{2}$. Por consiguiente, se concluye que la varianza muestral $s^{2}$ es un estimador insesgado de la varianza poblacional $\u03c3^{2}$. En efecto, en el cap\u00edtulo 3, cuando se presentaron las</p> <p> Figura 7.10 Ejemplos de estimadores puntuales insesgados y sesgados </p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Par\u00e1metros para las distribuciones\nmedia, desviacion = 0, 1\nmedia_sesgada = media + 0.5  # A\u00f1adir sesgo para la segunda distribuci\u00f3n\n\n# Generar puntos para las distribuciones\nx = np.linspace(media - 3*desviacion, media + 3*desviacion, 100)\nx_sesgada = np.linspace(media_sesgada - 3*desviacion, media_sesgada + 3*desviacion, 100)\n\n# Crear las distribuciones\ndistribucion = norm.pdf(x, media, desviacion)\ndistribucion_sesgada = norm.pdf(x_sesgada, media_sesgada, desviacion)\n\n# Crear la figura y los ejes\nfig, axs = plt.subplots(1, 2, figsize=(10, 5))\n\n# Establecer el color de fondo para la figura completa\nfig.patch.set_facecolor('#d4f8b7')\n\n# Iterar sobre cada eje\nfor ax in axs:\n    ax.set_facecolor('#d4f8b7')\n\n    # Graficar la distribuci\u00f3n insesgada\n    axs[0].plot(x, distribucion, color='#009929')  # Cambiado a color 009929\n    axs[0].axhline(0, color='black', linestyle='-', linewidth=1)  # L\u00ednea en la parte inferior\n    axs[0].set_title('Distribuci\u00f3n de muestreo\\n de $\\hat{\u03b8}$')\n    axs[0].set_xlabel('\\n \\n El par\u00e1metro $\u03b8$ se localiza en la media\\n de la distribuci\u00f3n de muestreo; \\n $E(\\hat{\u03b8})=\u03b8$ \\n Gr\u00e1fica A. Estimador insesgado \\n \\n')\n    axs[0].text(3.5, -0.0, r'$\\hat{\\theta}$', ha='center', va='bottom', color='black', fontsize=14)\n    axs[0].text(3.5, -0.0, r'____________', ha='center', va='bottom', color='#d4f8b7', fontsize=14)\n    axs[0].text(0, -0.0, r'|', ha='center', va='bottom', color='black', fontsize=14)\n    axs[0].text(0, -0.05, r'\u03b8', ha='center', va='bottom', color='black', fontsize=14)\n\n    # Desactivar etiquetas de los ejes en el primer gr\u00e1fico\n    axs[0].tick_params(axis='both', which='both', labelbottom=False, labelleft=False)\n    axs[0].set_xticks([])  # Eliminar las marcas del eje x\n    axs[0].set_yticks([])  # Eliminar las marcas del eje y\n\n    # Configurar el color de fondo de los ejes sin contorno\n    for spine in axs[0].spines.values():\n        spine.set_edgecolor('#d4f8b7')\n\n    # Graficar la distribuci\u00f3n sesgada\n    axs[1].plot(x_sesgada, distribucion_sesgada, color='#009929')  # Cambiado a color 009929\n    axs[1].axhline(0, color='black', linestyle='-', linewidth=1)  # L\u00ednea en la parte inferior\n    axs[1].set_title('Distribuci\u00f3n de muestreo\\n de $\\hat{\u03b8}$')\n    axs[1].set_xlabel('\\n \\n El par\u00e1metro $\u03b8$ no se localiza en la media \\n de la distribuci\u00f3n de muestreo; \\n $E(\\hat{\u03b8})= \u03b8$ \\n Gr\u00e1fica B. Estimador insesgado \\n\\n')\n    axs[1].text(4.0, -0.01, r'$\\hat{\\theta}$', ha='center', va='bottom', color='black', fontsize=14)\n    axs[1].text(0.5, -0.00, r'|', ha='center', va='bottom', color='black', fontsize=14)\n    axs[1].text(-1.6, -0.00, r'|', ha='center', va='bottom', color='black', fontsize=14)\n    axs[1].text(-0.6, 0.03, r'Sesgo', ha='center', va='bottom', color='black', fontsize=14)\n    axs[1].text(-1.4, 0.03, r'&lt;', ha='center', va='bottom', color='black', fontsize=14)\n    axs[1].text(-1.35, 0.03, r'---', ha='center', va='bottom', color='black', fontsize=14)\n    axs[1].text(0.1, 0.03, r'---', ha='center', va='bottom', color='black', fontsize=14)\n    axs[1].text(0.15, 0.03, r'&gt;', ha='center', va='bottom', color='black', fontsize=14)\n    axs[1].text(0.5, -0.05, r'E($\\hat{\u03b8}$)', ha='center', va='bottom', color='black', fontsize=14)\n    axs[1].text(-1.6, -0.05, r'\u03b8', ha='center', va='bottom', color='black', fontsize=14)\n\n    # Desactivar etiquetas de los ejes en el segundo gr\u00e1fico\n    axs[1].tick_params(axis='both', which='both', labelbottom=False, labelleft=False)\n    axs[1].set_xticks([])  # Eliminar las marcas del eje x\n    axs[1].set_yticks([])  # Eliminar las marcas del eje y\n\n    # Configurar el color de fondo de los ejes sin contorno\n    for spine in axs[1].spines.values():\n        spine.set_edgecolor('#d4f8b7')\n\n# Mostrar los gr\u00e1ficos\nplt.tight_layout()\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm  # Par\u00e1metros para las distribuciones media, desviacion = 0, 1 media_sesgada = media + 0.5  # A\u00f1adir sesgo para la segunda distribuci\u00f3n  # Generar puntos para las distribuciones x = np.linspace(media - 3*desviacion, media + 3*desviacion, 100) x_sesgada = np.linspace(media_sesgada - 3*desviacion, media_sesgada + 3*desviacion, 100)  # Crear las distribuciones distribucion = norm.pdf(x, media, desviacion) distribucion_sesgada = norm.pdf(x_sesgada, media_sesgada, desviacion)  # Crear la figura y los ejes fig, axs = plt.subplots(1, 2, figsize=(10, 5))  # Establecer el color de fondo para la figura completa fig.patch.set_facecolor('#d4f8b7')  # Iterar sobre cada eje for ax in axs:     ax.set_facecolor('#d4f8b7')      # Graficar la distribuci\u00f3n insesgada     axs[0].plot(x, distribucion, color='#009929')  # Cambiado a color 009929     axs[0].axhline(0, color='black', linestyle='-', linewidth=1)  # L\u00ednea en la parte inferior     axs[0].set_title('Distribuci\u00f3n de muestreo\\n de $\\hat{\u03b8}$')     axs[0].set_xlabel('\\n \\n El par\u00e1metro $\u03b8$ se localiza en la media\\n de la distribuci\u00f3n de muestreo; \\n $E(\\hat{\u03b8})=\u03b8$ \\n Gr\u00e1fica A. Estimador insesgado \\n \\n')     axs[0].text(3.5, -0.0, r'$\\hat{\\theta}$', ha='center', va='bottom', color='black', fontsize=14)     axs[0].text(3.5, -0.0, r'____________', ha='center', va='bottom', color='#d4f8b7', fontsize=14)     axs[0].text(0, -0.0, r'|', ha='center', va='bottom', color='black', fontsize=14)     axs[0].text(0, -0.05, r'\u03b8', ha='center', va='bottom', color='black', fontsize=14)      # Desactivar etiquetas de los ejes en el primer gr\u00e1fico     axs[0].tick_params(axis='both', which='both', labelbottom=False, labelleft=False)     axs[0].set_xticks([])  # Eliminar las marcas del eje x     axs[0].set_yticks([])  # Eliminar las marcas del eje y      # Configurar el color de fondo de los ejes sin contorno     for spine in axs[0].spines.values():         spine.set_edgecolor('#d4f8b7')      # Graficar la distribuci\u00f3n sesgada     axs[1].plot(x_sesgada, distribucion_sesgada, color='#009929')  # Cambiado a color 009929     axs[1].axhline(0, color='black', linestyle='-', linewidth=1)  # L\u00ednea en la parte inferior     axs[1].set_title('Distribuci\u00f3n de muestreo\\n de $\\hat{\u03b8}$')     axs[1].set_xlabel('\\n \\n El par\u00e1metro $\u03b8$ no se localiza en la media \\n de la distribuci\u00f3n de muestreo; \\n $E(\\hat{\u03b8})= \u03b8$ \\n Gr\u00e1fica B. Estimador insesgado \\n\\n')     axs[1].text(4.0, -0.01, r'$\\hat{\\theta}$', ha='center', va='bottom', color='black', fontsize=14)     axs[1].text(0.5, -0.00, r'|', ha='center', va='bottom', color='black', fontsize=14)     axs[1].text(-1.6, -0.00, r'|', ha='center', va='bottom', color='black', fontsize=14)     axs[1].text(-0.6, 0.03, r'Sesgo', ha='center', va='bottom', color='black', fontsize=14)     axs[1].text(-1.4, 0.03, r'&lt;', ha='center', va='bottom', color='black', fontsize=14)     axs[1].text(-1.35, 0.03, r'---', ha='center', va='bottom', color='black', fontsize=14)     axs[1].text(0.1, 0.03, r'---', ha='center', va='bottom', color='black', fontsize=14)     axs[1].text(0.15, 0.03, r'&gt;', ha='center', va='bottom', color='black', fontsize=14)     axs[1].text(0.5, -0.05, r'E($\\hat{\u03b8}$)', ha='center', va='bottom', color='black', fontsize=14)     axs[1].text(-1.6, -0.05, r'\u03b8', ha='center', va='bottom', color='black', fontsize=14)      # Desactivar etiquetas de los ejes en el segundo gr\u00e1fico     axs[1].tick_params(axis='both', which='both', labelbottom=False, labelleft=False)     axs[1].set_xticks([])  # Eliminar las marcas del eje x     axs[1].set_yticks([])  # Eliminar las marcas del eje y      # Configurar el color de fondo de los ejes sin contorno     for spine in axs[1].spines.values():         spine.set_edgecolor('#d4f8b7')  # Mostrar los gr\u00e1ficos plt.tight_layout() plt.show()   <p>f\u00f3rmulas para la varianza muestral y la desviaci\u00f3n est\u00e1ndar muestral, en el denominador se us\u00f3 $n = 1$ en lugar de n para que la varianza muestral fuera un estimador insesgado de la varianza poblacional.</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>tanto, los valores de  $\\hat{\\theta}$<sub>1</sub> tienen m\u00e1s posibilidades de estar cerca del par\u00e1metro $\\hat{\\theta}$ que los valores de $\\hat{\\theta}$<sub>2</sub>. Como el error est\u00e1ndar del estimador puntual $\\hat{\\theta}$<sub>1</sub> es menor que el del estimador puntual $\\hat{\\theta}$<sub>2</sub>, $\\hat{\\theta}$<sub>1</sub> es relativamente m\u00e1s efi ciente que $\\hat{\\theta}$<sub>2</sub> y se prefi ere como estimador puntual.</p> <p>Se describi\u00f3 el muestreo aleatorio simple como un procedimiento de muestreo de una poblaci\u00f3n fi nita y se estudiaron las propiedades de las distribuciones de muestreo de x y de p cuando se us\u00f3 el muestreo aleatorio simple. Sin embargo, no es el \u00fanico m\u00e9todo de muestreo que existe. Hay otros, como el muestro aleatorio estratifi cado, el muestreo por conglomerados y el muestreo sistem\u00e1tico que, en ciertas situaciones, tienen ventajas sobre el aleatorio simple. En esta secci\u00f3n se presentan brevemente estos tres m\u00e9todos. En el cap\u00edtulo 22, que se encuentra en el sitio web del libro, se estudian con m\u00e1s detalle.</p> <p> Figura 7.12 Diagrama de un muestreo aleatorio estratificado </p> In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nfrom matplotlib.patches import FancyBboxPatch, Rectangle\nfrom matplotlib.lines import Line2D\n\n# Crear una figura con un solo subgr\u00e1fico\nfig, ax = plt.subplots(figsize=(9, 4))\nfig.patch.set_facecolor('#D4F8B7')  # Cambiar el color de fondo de la figura a verde\n\n# Tama\u00f1o de los rect\u00e1ngulos\nrect_width = 0.2\nrect_height = 0.2\n\n# A\u00f1adir rect\u00e1ngulos y l\u00edneas en el diagrama\nrect1 = FancyBboxPatch((0.5, 0.7), rect_width, 0.0, boxstyle=\"round,pad=0.1\", fill=True, color='#5CCB5F', linewidth=0.5, zorder=2)\nrect2 = Rectangle((0.1, 0.3), rect_width, rect_height, fill=True, color='#5CCB5F', linewidth=0.5, zorder=2)\nrect3 = Rectangle((0.4, 0.3), rect_width, rect_height, fill=True, color='#5CCB5F', linewidth=0.5, zorder=2)\n\nrect5 = Rectangle((1.0, 0.3), rect_width, rect_height, fill=True, color='#5CCB5F', linewidth=0.5, zorder=2)\n\nax.add_patch(rect1)\nax.add_patch(rect2)\nax.add_patch(rect3)\nax.add_patch(rect5)\n\nfor rect in [rect1, rect2, rect3, rect5]:\n    rect.set_edgecolor('black')\n\nax.text(0.6, 0.7, 'Poblaci\u00f3n', ha=\"center\", va=\"center\", color='black', fontsize=10, fontweight='light', zorder=3)\nax.text(0.2, 0.4, 'Estrato 1', ha=\"center\", va=\"center\", color='black', fontsize=10, fontweight='light', zorder=3)\nax.text(0.5, 0.4, 'Estrato 2', ha=\"center\", va=\"center\", color='black', fontsize=10, fontweight='light', zorder=3)\nax.text(0.8, 0.4, '.  .  . ', ha=\"center\", va=\"center\", color='black', fontsize=10, fontweight='light', zorder=3)\nax.text(1.1, 0.4, 'Estrato H', ha=\"center\", va=\"center\", color='black', fontsize=10, fontweight='light', zorder=3)\n\nax.add_line(Line2D([1.1, 0.2], [0.55, 0.55], linewidth=0.5, color='black', zorder=1))\nax.add_line(Line2D([0.5, 0.5], [0.5, 0.55], linewidth=0.5, color='black', zorder=1))\nax.add_line(Line2D([0.2, 0.2], [0.5, 0.55], linewidth=0.5, color='black', zorder=1))\n\nax.add_line(Line2D([0.6, 0.6], [0.6, 0.55], linewidth=0.5, color='black', zorder=1))\nax.add_line(Line2D([1.1, 1.1], [0.5, 0.55], linewidth=0.5, color='black', zorder=1))\n\nax.set_xlim(0, 1.5)\nax.set_ylim(0, 1)\nax.axis('off')\n\n# Mostrar la figura con el \u00fanico diagrama\nplt.show()\n</pre> import matplotlib.pyplot as plt from matplotlib.patches import FancyBboxPatch, Rectangle from matplotlib.lines import Line2D  # Crear una figura con un solo subgr\u00e1fico fig, ax = plt.subplots(figsize=(9, 4)) fig.patch.set_facecolor('#D4F8B7')  # Cambiar el color de fondo de la figura a verde  # Tama\u00f1o de los rect\u00e1ngulos rect_width = 0.2 rect_height = 0.2  # A\u00f1adir rect\u00e1ngulos y l\u00edneas en el diagrama rect1 = FancyBboxPatch((0.5, 0.7), rect_width, 0.0, boxstyle=\"round,pad=0.1\", fill=True, color='#5CCB5F', linewidth=0.5, zorder=2) rect2 = Rectangle((0.1, 0.3), rect_width, rect_height, fill=True, color='#5CCB5F', linewidth=0.5, zorder=2) rect3 = Rectangle((0.4, 0.3), rect_width, rect_height, fill=True, color='#5CCB5F', linewidth=0.5, zorder=2)  rect5 = Rectangle((1.0, 0.3), rect_width, rect_height, fill=True, color='#5CCB5F', linewidth=0.5, zorder=2)  ax.add_patch(rect1) ax.add_patch(rect2) ax.add_patch(rect3) ax.add_patch(rect5)  for rect in [rect1, rect2, rect3, rect5]:     rect.set_edgecolor('black')  ax.text(0.6, 0.7, 'Poblaci\u00f3n', ha=\"center\", va=\"center\", color='black', fontsize=10, fontweight='light', zorder=3) ax.text(0.2, 0.4, 'Estrato 1', ha=\"center\", va=\"center\", color='black', fontsize=10, fontweight='light', zorder=3) ax.text(0.5, 0.4, 'Estrato 2', ha=\"center\", va=\"center\", color='black', fontsize=10, fontweight='light', zorder=3) ax.text(0.8, 0.4, '.  .  . ', ha=\"center\", va=\"center\", color='black', fontsize=10, fontweight='light', zorder=3) ax.text(1.1, 0.4, 'Estrato H', ha=\"center\", va=\"center\", color='black', fontsize=10, fontweight='light', zorder=3)  ax.add_line(Line2D([1.1, 0.2], [0.55, 0.55], linewidth=0.5, color='black', zorder=1)) ax.add_line(Line2D([0.5, 0.5], [0.5, 0.55], linewidth=0.5, color='black', zorder=1)) ax.add_line(Line2D([0.2, 0.2], [0.5, 0.55], linewidth=0.5, color='black', zorder=1))  ax.add_line(Line2D([0.6, 0.6], [0.6, 0.55], linewidth=0.5, color='black', zorder=1)) ax.add_line(Line2D([1.1, 1.1], [0.5, 0.55], linewidth=0.5, color='black', zorder=1))  ax.set_xlim(0, 1.5) ax.set_ylim(0, 1) ax.axis('off')  # Mostrar la figura con el \u00fanico diagrama plt.show()      <p>un estrato son parecidos, \u00e9ste tendr\u00e1 una varianza peque\u00f1a. Por tanto, con muestras relativamente peque\u00f1as de los estratos se obtienen buenas estimaciones de sus caracter\u00edsticas. Si \u00e9stos son homog\u00e9neos, el muestreo aleatorio estratifi cado proporciona resultados tan precisos como los de un muestreo aleatorio simple, pero con una muestra de tama\u00f1o total menor.</p> <p> Figura 7.13 Diagrama del muestreo por conglomerados </p> In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nfrom matplotlib.patches import FancyBboxPatch, Rectangle\nfrom matplotlib.lines import Line2D\n\n# Crear una figura con un solo subgr\u00e1fico\nfig, ax = plt.subplots(figsize=(9, 4))\nfig.patch.set_facecolor('#D4F8B7')  # Cambiar el color de fondo de la figura a verde\n\n# Tama\u00f1o de los rect\u00e1ngulos\nrect_width = 0.3\nrect_height = 0.2\n\n# A\u00f1adir rect\u00e1ngulos y l\u00edneas en el diagrama\nrect1 = FancyBboxPatch((0.5, 0.7), rect_width, 0.0, boxstyle=\"round,pad=0.1\", fill=True, color='#5CCB5F', linewidth=0.5, zorder=2)\nrect2 = Rectangle((0.05, 0.3), rect_width, rect_height, fill=True, color='#5CCB5F', linewidth=0.5, zorder=2)\nrect3 = Rectangle((0.45, 0.3), rect_width, rect_height, fill=True, color='#5CCB5F', linewidth=0.5, zorder=2)\nrect5 = Rectangle((1.05, 0.3), rect_width, rect_height, fill=True, color='#5CCB5F', linewidth=0.5, zorder=2)\n\nax.add_patch(rect1)\nax.add_patch(rect2)\nax.add_patch(rect3)\nax.add_patch(rect5)\n\nfor rect in [rect1, rect2, rect3, rect5]:\n    rect.set_edgecolor('black')\n\nax.text(0.65, 0.7, 'Poblaci\u00f3n', ha=\"center\", va=\"center\", color='black', fontsize=10, fontweight='light', zorder=3)\nax.text(0.2, 0.4, 'Conglomerado 1', ha=\"center\", va=\"center\", color='black', fontsize=10, fontweight='light', zorder=3)\nax.text(0.6, 0.4, 'Conglomerado 2', ha=\"center\", va=\"center\", color='black', fontsize=10, fontweight='light', zorder=3)\nax.text(0.9, 0.4, '.  .  . ', ha=\"center\", va=\"center\", color='black', fontsize=10, fontweight='light', zorder=3)\nax.text(1.2, 0.4, 'Conglomerado K ', ha=\"center\", va=\"center\", color='black', fontsize=10, fontweight='light', zorder=3)\n\nax.add_line(Line2D([1.2, 0.2], [0.55, 0.55], linewidth=0.5, color='black', zorder=1))\nax.add_line(Line2D([0.6, 0.6], [0.5, 0.55], linewidth=0.5, color='black', zorder=1))\nax.add_line(Line2D([0.2, 0.2], [0.5, 0.55], linewidth=0.5, color='black', zorder=1))\nax.add_line(Line2D([0.65, 0.65], [0.6, 0.55], linewidth=0.5, color='black', zorder=1))\nax.add_line(Line2D([1.2, 1.2], [0.5, 0.55], linewidth=0.5, color='black', zorder=1))\n\nax.set_xlim(0, 1.5)\nax.set_ylim(0, 1)\nax.axis('off')\n\n# Mostrar la figura con el \u00fanico diagrama\nplt.show()\n</pre> import matplotlib.pyplot as plt from matplotlib.patches import FancyBboxPatch, Rectangle from matplotlib.lines import Line2D  # Crear una figura con un solo subgr\u00e1fico fig, ax = plt.subplots(figsize=(9, 4)) fig.patch.set_facecolor('#D4F8B7')  # Cambiar el color de fondo de la figura a verde  # Tama\u00f1o de los rect\u00e1ngulos rect_width = 0.3 rect_height = 0.2  # A\u00f1adir rect\u00e1ngulos y l\u00edneas en el diagrama rect1 = FancyBboxPatch((0.5, 0.7), rect_width, 0.0, boxstyle=\"round,pad=0.1\", fill=True, color='#5CCB5F', linewidth=0.5, zorder=2) rect2 = Rectangle((0.05, 0.3), rect_width, rect_height, fill=True, color='#5CCB5F', linewidth=0.5, zorder=2) rect3 = Rectangle((0.45, 0.3), rect_width, rect_height, fill=True, color='#5CCB5F', linewidth=0.5, zorder=2) rect5 = Rectangle((1.05, 0.3), rect_width, rect_height, fill=True, color='#5CCB5F', linewidth=0.5, zorder=2)  ax.add_patch(rect1) ax.add_patch(rect2) ax.add_patch(rect3) ax.add_patch(rect5)  for rect in [rect1, rect2, rect3, rect5]:     rect.set_edgecolor('black')  ax.text(0.65, 0.7, 'Poblaci\u00f3n', ha=\"center\", va=\"center\", color='black', fontsize=10, fontweight='light', zorder=3) ax.text(0.2, 0.4, 'Conglomerado 1', ha=\"center\", va=\"center\", color='black', fontsize=10, fontweight='light', zorder=3) ax.text(0.6, 0.4, 'Conglomerado 2', ha=\"center\", va=\"center\", color='black', fontsize=10, fontweight='light', zorder=3) ax.text(0.9, 0.4, '.  .  . ', ha=\"center\", va=\"center\", color='black', fontsize=10, fontweight='light', zorder=3) ax.text(1.2, 0.4, 'Conglomerado K ', ha=\"center\", va=\"center\", color='black', fontsize=10, fontweight='light', zorder=3)  ax.add_line(Line2D([1.2, 0.2], [0.55, 0.55], linewidth=0.5, color='black', zorder=1)) ax.add_line(Line2D([0.6, 0.6], [0.5, 0.55], linewidth=0.5, color='black', zorder=1)) ax.add_line(Line2D([0.2, 0.2], [0.5, 0.55], linewidth=0.5, color='black', zorder=1)) ax.add_line(Line2D([0.65, 0.65], [0.6, 0.55], linewidth=0.5, color='black', zorder=1)) ax.add_line(Line2D([1.2, 1.2], [0.5, 0.55], linewidth=0.5, color='black', zorder=1))  ax.set_xlim(0, 1.5) ax.set_ylim(0, 1) ax.axis('off')  # Mostrar la figura con el \u00fanico diagrama plt.show()    <p>numeros aleatorios y despu\u00e9s contar y recorrer toda una lista de la poblaci\u00f3n hasta encontrar los elementos correspondientes. Una alternativa al  muestreo aleatorio muestreo aleatorio simple es el muestreo sistem\u00e1tico. Por ejemplo, si se quiere una muestra de tama\u00f1o 50 de una poblaci\u00f3n que tiene 5 000 elementos, se muestrea uno de cada 5 000$/$50$=$100 elementos de la poblaci\u00f3n. En este caso, un muestreo sistem\u00e1tico consiste en seleccionar en forma aleatoria uno de los primeros 100 elementos de la lista de la poblaci\u00f3n. Los otros se identifi can empezando con el primer elemento muestreado y seleccionando cada 100o. elemento que siga en la lista. En efecto, los elementos de la muestra de 50 se identifi can movi\u00e9ndose sistem\u00e1ticamente entre la poblaci\u00f3n e identifi cando cada 100o. elemento despu\u00e9s del primero seleccionado aleatoriamente. Por lo general, de esta manera es m\u00e1s f\u00e1cil identifi car la muestra de 50 que si se utilizara el muestreo aleatorio simple. Como el primer elemento que se selecciona es elegido al azar, se supone que una muestra sistem\u00e1tica tiene las propiedades de una muestra aleatoria simple. Este supuesto es aplicable, en especial, cuando la lista de los elementos de la poblaci\u00f3n constituye un orden aleatorio de los elementos.</p> <p>En este cap\u00edtulo se presentaron los conceptos de muestreo aleatorio simple y distribuci\u00f3n de muestreo. Se describi\u00f3 c\u00f3mo seleccionar una muestra aleatoria simple de una poblaci\u00f3n finita y una muestra aleatoria de una poblaci\u00f3n infi nita. Los datos recolectados de tales muestras se pueden utilizar para obtener estimadores puntuales de los par\u00e1metros poblacionales. Ya que distintas muestras proporcionan valores diferentes de los estimadores puntuales, los estimadores puntuales como  x\u0304  y  p\u0304  son variables aleatorias. A la distribuci\u00f3n de probabilidad de una variable aleatoria de este tipo se le conoce como distribuci\u00f3n de muestreo. En particular, se describieron las distribuciones de muestreo de la media muestral x y de la proporci\u00f3n muestral  p\u00af .</p> <p>Al estudiar las caracter\u00edsticas de las distribuciones de muestreo de  x\u0304  y de  p\u0304 , se estableci\u00f3 que  E(x\u0304) = \u03bc  y que  E(p\u0304)   =   p . Despu\u00e9s de proporcionar las f\u00f3rmulas para la desviaci\u00f3n est\u00e1ndar o error est\u00e1ndar de dichos estimadores, se describieron las condiciones necesarias para que las distribuciones de muestreo de  x\u0304  y de  p\u0304  sigan una distribuci\u00f3n normal. Otros m\u00e9todos de muestreo que tambi\u00e9n se abordaron son el muestreo aleatorio estratifi cado, por conglomerados o clusters, sistem\u00e1tico, por conveniencia y subjetivo.</p> <p>Consistencia   Propiedad de un estimador puntual que se hace presente siempre que muestras m\u00e1s grandes tienden a proporcionar estimaciones puntuales m\u00e1s cercanas al par\u00e1metro poblacional.</p> <p>Distribuci\u00f3n de muestreo o muestral Distribuci\u00f3n de probabilidad que consta de todos los posibles valores de un estad\u00edstico muestral.</p> <p>Eficiencia relativa Dados dos estimadores puntuales insesgados de un mismo par\u00e1metro poblacional, el estimador puntual con menor error est\u00e1ndar ser\u00e1 m\u00e1s efi ciente.</p> <p>Error est\u00e1ndar Desviaci\u00f3n est\u00e1ndar de un estimador puntual.</p> <p>Estad\u00edstico muestral Caracter\u00edstica muestral, por ejemplo, la media muestral $\\bar{x}$, la desviaci\u00f3n est\u00e1ndar muestral $s$, la proporci\u00f3n muestral $\\bar{p}$, etc. El valor del estad\u00edstico muestral se utiliza para estimar el valor del par\u00e1metro poblacional correspondiente.</p> <p>Estimaci\u00f3n puntual Valor de un estimador que se utiliza en una situaci\u00f3n particular como estimaci\u00f3n del par\u00e1metro poblacional.</p> <p>Estimador puntual Un estad\u00edstico muestral como $\\bar{x}$, $s$ $o$ $\\bar{p}$ que proporciona una estimaci\u00f3n puntual del par\u00e1metro poblacional correspondiente.</p> <p>Factor de correcci\u00f3n para una poblaci\u00f3n finita Es el t\u00e9rmino $\\sqrt{{{(N-n)/(N-1)}}}$ utilizado en las f\u00f3rmulas de $\u03c3$<sub>$\\bar{x}$</sub> $y$ $\u03c3$<sub>$\\bar{p}$</sub> siempre que se muestrea de una poblaci\u00f3n fi nita y no de una poblaci\u00f3n infi nita. Sin embargo, hay una regla generalmente aceptada: ignorar el factor de correcci\u00f3n en una poblaci\u00f3n fi nita siempre que $n/N$   $\\leq$   $0.05$</p> <p>Insesgadez Propiedad de un estimador puntual que se hace presente cuando el valor esperado del estimador es igual al par\u00e1metro poblacional que se est</p> <p>Marco Lista de los elementos de donde se selecciona la muestra.</p> <p>Muestreo aleatorio  Muestra aleatoria de una poblaci\u00f3n infi nita seleccionada de manera tal que se satisfagan las condiciones siguientes: 1) cada elemento escogido proviene de la misma poblaci\u00f3n y, 2) cada elemento se selecciona de manera independiente.</p> <p>Muestreo aleatorio estratificado M\u00e9todo probabil\u00edstico en el que primero se divide la poblaci\u00f3n en estratos y despu\u00e9s se toma una muestra aleatoria simple de cada estrato.</p> <p>Muestreo aleatorio simple Muestra aleatoria simple de tama\u00f1o $n$ de una poblaci\u00f3n finita de tama\u00f1o $N$ seleccionada de manera que cada posible muestra de tama\u00f1o $n$ tenga la misma probabilidad de ser seleccionada.</p> <p>Muestreo con remplazo Una vez que un elemento se ha incluido en la muestra, se regresa a la poblaci\u00f3n. Un elemento ya seleccionado puede nuevamente ser elegido y aparecer m\u00e1s de una vez en la muestra.</p> <p>Muestreo por conglomerados o clusters M\u00e9todo probabil\u00edstico en el que primero se divide la poblaci\u00f3n en conglomerados y despu\u00e9s se toma una muestra aleatoria de \u00e9stos.</p> <p>Muestreo sin remplazo Una vez que un elemento ha sido incluido en la muestra, se retira de la poblaci\u00f3n y ya no se selecciona m\u00e1s.</p> <p>Muestreo sistem\u00e1tico M\u00e9todo probabil\u00edstico en el que primero se selecciona uno de los primeros $k$ elementos de una poblaci\u00f3n y despu\u00e9s cada $k$-\u00e9simo elemento.</p> <p>Muestreo subjetivo M\u00e9todo no probabil\u00edstico en el que la selecci\u00f3n de los elementos para la muestra se realiza de acuerdo con la opini\u00f3n de la persona que efect\u00faa el estudio.</p> <p>Par\u00e1metro Caracter\u00edstica num\u00e9rica de una poblaci\u00f3n, por ejemplo, media poblacional $\u03bc$, desviaci\u00f3n est\u00e1ndar poblacional \u03c3, proporci\u00f3n poblacional $p$, etc\u00e9ter.</p> <p>Poblaci\u00f3n muestreada Poblaci\u00f3n de la cual se extrae la muestra.</p> <p>Poblaci\u00f3n objetivo Es aquella de la cual se hacen inferencias estad\u00edsticas como estimaciones puntuales. Es importante que la poblaci\u00f3n objetivo corresponda tan cercanamente como sea posible a la poblaci\u00f3n muestreada.</p> <p>Teorema del l\u00edmite central Permite usar la distribuci\u00f3n de probabilidad normal para aproximar la distribuci\u00f3n de muestreo de $x$ siempre que la muestra sea grande.</p> In\u00a0[\u00a0]: Copied! <pre>from IPython.display import HTML\n\n# Crear la cadena con formato HTML m\u00e1s grande y en negrita\nhtml_text = '&lt;p style=\"color:green; font-size: 24px; font-weight: bold;\"&gt;Ejercicios Resueltos&lt;/p&gt;'\n\n# Mostrar la cadena en formato HTML\ndisplay(HTML(html_text))\n</pre> from IPython.display import HTML  # Crear la cadena con formato HTML m\u00e1s grande y en negrita html_text = '<p>Ejercicios Resueltos</p>'  # Mostrar la cadena en formato HTML display(HTML(html_text)) <p>Ejercicios Resueltos</p> In\u00a0[\u00a0]: Copied! <pre># Instala la biblioteca IPython para mostrar HTML\n!pip install IPython\n\n# Importa la clase HTML de la biblioteca IPython\nfrom IPython.display import HTML\n\n# Define la funci\u00f3n para mostrar el video de YouTube centrado\ndef display_centered_youtube_video(video_id, width=560, height=315):\n    video_url = f\"https://www.youtube.com/embed/{video_id}\"\n    iframe_code = f'&lt;div style=\"display: flex; justify-content: center; align-items: center; height: 100%;\"&gt;&lt;iframe width=\"{width}\" height=\"{height}\" src=\"{video_url}\" frameborder=\"0\" allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt;'\n    display(HTML(iframe_code))\n\n# Reemplaza \"petvgLEk0SY\" con el ID de tu nuevo video de YouTube\nvideo_id = \"petvgLEk0SY\"\n\n# Muestra el nuevo video de YouTube centrado\ndisplay_centered_youtube_video(video_id)\n</pre> # Instala la biblioteca IPython para mostrar HTML !pip install IPython  # Importa la clase HTML de la biblioteca IPython from IPython.display import HTML  # Define la funci\u00f3n para mostrar el video de YouTube centrado def display_centered_youtube_video(video_id, width=560, height=315):     video_url = f\"https://www.youtube.com/embed/{video_id}\"     iframe_code = f''     display(HTML(iframe_code))  # Reemplaza \"petvgLEk0SY\" con el ID de tu nuevo video de YouTube video_id = \"petvgLEk0SY\"  # Muestra el nuevo video de YouTube centrado display_centered_youtube_video(video_id)  <pre>Requirement already satisfied: IPython in /usr/local/lib/python3.10/dist-packages (7.34.0)\nRequirement already satisfied: setuptools&gt;=18.5 in /usr/local/lib/python3.10/dist-packages (from IPython) (67.7.2)\nRequirement already satisfied: jedi&gt;=0.16 in /usr/local/lib/python3.10/dist-packages (from IPython) (0.19.1)\nRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from IPython) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from IPython) (0.7.5)\nRequirement already satisfied: traitlets&gt;=4.2 in /usr/local/lib/python3.10/dist-packages (from IPython) (5.7.1)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0 in /usr/local/lib/python3.10/dist-packages (from IPython) (3.0.41)\nRequirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from IPython) (2.16.1)\nRequirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from IPython) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from IPython) (0.1.6)\nRequirement already satisfied: pexpect&gt;4.3 in /usr/local/lib/python3.10/dist-packages (from IPython) (4.9.0)\nRequirement already satisfied: parso&lt;0.9.0,&gt;=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi&gt;=0.16-&gt;IPython) (0.8.3)\nRequirement already satisfied: ptyprocess&gt;=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect&gt;4.3-&gt;IPython) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0-&gt;IPython) (0.2.12)\n</pre> <ol> <li>Un investigador reporta sus resultados diciendo que el error est\u00e1ndar de la media es 20 y la desviaci\u00f3n est\u00e1ndar poblacional es 500. a) \u00bfDe qu\u00e9 tama\u00f1o fue la muestra utilizada en esta investigaci\u00f3n? b) \u00bfCu\u00e1l es la probabilidad de que la estimaci\u00f3n puntual est\u00e9 a no m\u00e1s de $\\pm25$ de la media poblacional?</li> </ol> <p>Los datos dados del problema son: SE = 20, $\\sigma$ = 500</p> <p>Las f\u00f3rmulas a emplear son: n = $\\left(\\frac{\\sigma}{SE}\\right)^2$</p> In\u00a0[\u00a0]: Copied! <pre>from IPython.display import HTML\n\nerror_estandar_media = 20\ndesviacion_estandar_poblacional = 500\n\nn = (desviacion_estandar_poblacional / error_estandar_media) ** 2\n\nhtml_resultado = f\"\"\"\n&lt;p&gt;&lt;strong&gt;Tama\u00f1o de la muestra:&lt;/strong&gt; {int(n)}&lt;/p&gt;\n\"\"\"\ndisplay(HTML(html_resultado))\n</pre> from IPython.display import HTML  error_estandar_media = 20 desviacion_estandar_poblacional = 500  n = (desviacion_estandar_poblacional / error_estandar_media) ** 2  html_resultado = f\"\"\" <p>Tama\u00f1o de la muestra: {int(n)}</p> \"\"\" display(HTML(html_resultado)) <p>Tama\u00f1o de la muestra: 625</p> <p>El valor z para $\\pm25$ con un error est\u00e1ndar de 20 es: $Z_{+25} = \\frac{25-0}{20} = 1.25$ $Z_{+25} = \\frac{-25-0}{20} = -1.25$ La probabilidad de que la estimaci\u00f3n puntual est\u00e9 dentro de \u00b125 de la media poblacional es la suma de las \u00e1reas bajo la curva normal est\u00e1ndar para $Z=1.25$ y $Z=-1.25$. Para un z-score de 1.25, la probabilidad acumulada es aproximadamente 0.8944 (usando una tabla de distribuci\u00f3n normal est\u00e1ndar). Esta es la probabilidad de estar dentro de 1.25 desviaciones est\u00e1ndar por encima de la media. La misma probabilidad aplica para -1.25 por debajo de la media. Entonces, la probabilidad total es la suma de estas dos probabilidades:  $P(Z \\leq 1.25) = 0.8944$ $P(Z \\geq -1.25) = 0.8944$ Cuando sumamos estas probabilidades para considerar ambos lados de la distribuci\u00f3n, no podemos simplemente sumarlas, ya que estar\u00edamos contando el \u00e1rea bajo la curva dos veces. Entonces, para obtener la probabilidad de que la estimaci\u00f3n puntual est\u00e9 dentro de \u00b125 de la media poblacional, podemos utilizar una de las dos probabilidades y restarle la otra, o simplemente encontrar la probabilidad de un rango de valores usando el z-score de \u00b125 directamente.</p> <p>La probabilidad de estar dentro de \u00b125 de la media poblacional es: $P(-1.25 \\leq Z \\leq 1.25) = P(Z \\leq 1.25) - (Z \\leq -1.25) = 0.8944\u2212(1\u22120.8944) = 0.7888$ Por lo tanto, la probabilidad de que la estimaci\u00f3n puntual est\u00e9 a no m\u00e1s de \u00b125 de la media poblacional es aproximadamente 0.7888, es decir, alrededor del 78.88%.</p> <ol> <li>Lori Jeffrey es una exitosa representante de ventas de libros universitarios. Hist\u00f3ricamente, ella consigue una adopci\u00f3n de libros de texto en 25% de sus llamadas de ventas. Considere sus telefonemas de ventas de un mes como muestra de todas sus posibles llamadas; suponga que en el an\u00e1lisis estad\u00edstico de los datos se encuentra que el error est\u00e1ndar de la proporci\u00f3n es 0.0625. a) \u00bfDe qu\u00e9 tama\u00f1o fue la muestra que se utiliz\u00f3 en el an\u00e1lisis? Es decir, \u00bfcu\u00e1ntas llamadas hizo Lori Jeffrey en ese mes? b) Sea $\\overline{p}$ la proporci\u00f3n muestral de adopciones de libros de texto en el mes. Presente la distribuci\u00f3n de muestreo de $\\overline{p}$. c) Mediante la distribuci\u00f3n de muestreo de $\\overline{p}$, calcule la probabilidad de que Lori lograr\u00e1 adopciones de libros de texto en 30% o m\u00e1s de sus llamadas de ventas en el lapso de un mes.</li> </ol> <p>F\u00f3rmulas utilizadas:</p> <p>a) Tama\u00f1o de la muestra n: $SE_p$ = $\\sqrt{\\frac{p(1-p)}{n}}$ n = $\\frac{p(1-p)}{SE_p^2}$</p> <p>b) Distribuci\u00f3n de muestreo de $\\bar{p}$: La distribuci\u00f3n sigue una distribuci\u00f3n normal con media $\\overline{p}$ y error est\u00e1ndar $SE_p$.</p> <p>c) C\u00e1lculo del Z-score: Z = $\\frac{\\bar{p} - p}{SE_p}$</p> In\u00a0[\u00a0]: Copied! <pre>from IPython.display import HTML\n\np = 0.25\nSE_p = 0.0625\n\nn = p * (1 - p) / SE_p ** 2\n\np_barra = 0.30\nZ = (p_barra - p) / SE_p\n\nhtml_resultado = f\"\"\"\n&lt;p&gt;&lt;strong&gt;Tama\u00f1o de la muestra:&lt;/strong&gt; {n:.2f}&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Z-score:&lt;/strong&gt; {Z:.2f}&lt;/p&gt;\n\"\"\"\n\ndisplay(HTML(html_resultado))\n</pre> from IPython.display import HTML  p = 0.25 SE_p = 0.0625  n = p * (1 - p) / SE_p ** 2  p_barra = 0.30 Z = (p_barra - p) / SE_p  html_resultado = f\"\"\" <p>Tama\u00f1o de la muestra: {n:.2f}</p> <p>Z-score: {Z:.2f}</p> \"\"\"  display(HTML(html_resultado)) <p>Tama\u00f1o de la muestra: 48.00</p> <p>Z-score: 0.80</p> In\u00a0[\u00a0]: Copied! <pre>from IPython.display import HTML\n\nhtml_code = \"\"\"\n&lt;center&gt;\nTABLA 7.6 Puntuaci\u00f3n general para las primeras 10 \u00e1reas metropolitanas en el conjunto\nde datos MetAreas.\n&lt;style&gt;\n  table {\n    border: 1px solid #009929;\n    background-color: #D4F8B7;\n  }\n\n  th {\n    text-align: center;\n  }\n&lt;/style&gt;\n\n&lt;table&gt;\n  &lt;thead&gt;\n    &lt;tr&gt;\n      &lt;th&gt;Metropolitan Area&lt;/th&gt;\n      &lt;th&gt;Rating&lt;/th&gt;\n    &lt;/tr&gt;\n  &lt;/thead&gt;\n  &lt;tbody&gt;\n    &lt;tr&gt;\n      &lt;td&gt;Albany, NY&lt;/td&gt;\n      &lt;td&gt;64.18&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;td&gt;Albuquerque, NM&lt;/td&gt;\n      &lt;td&gt;66.16&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;td&gt;Appleton, WI&lt;/td&gt;\n      &lt;td&gt;60.56&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;td&gt;Atlanta, GA&lt;/td&gt;\n      &lt;td&gt;69.97&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;td&gt;Austin, TX&lt;/td&gt;\n      &lt;td&gt;71.48&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;td&gt;Baltimore, MD&lt;/td&gt;\n      &lt;td&gt;69.75&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;td&gt;Birmingham, AL&lt;/td&gt;\n      &lt;td&gt;69.59&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;td&gt;Boise City, ID&lt;/td&gt;\n      &lt;td&gt;68.36&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;td&gt;Boston, MA&lt;/td&gt;\n      &lt;td&gt;68.99&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;td&gt;Buffalo, NY&lt;/td&gt;\n      &lt;td&gt;66.10&lt;/td&gt;\n    &lt;/tr&gt;\n  &lt;/tbody&gt;\n&lt;/table&gt;\n&lt;/center&gt;\n\"\"\"\n\ndisplay(HTML(html_code))\n</pre> from IPython.display import HTML  html_code = \"\"\"  TABLA 7.6 Puntuaci\u00f3n general para las primeras 10 \u00e1reas metropolitanas en el conjunto de datos MetAreas.  Metropolitan Area Rating Albany, NY 64.18 Albuquerque, NM 66.16 Appleton, WI 60.56 Atlanta, GA 69.97 Austin, TX 71.48 Baltimore, MD 69.75 Birmingham, AL 69.59 Boise City, ID 68.36 Boston, MA 68.99 Buffalo, NY 66.10  \"\"\"  display(HTML(html_code))  TABLA 7.6 Puntuaci\u00f3n general para las primeras 10 \u00e1reas metropolitanas en el conjunto de datos MetAreas.  Metropolitan Area Rating Albany, NY 64.18 Albuquerque, NM 66.16 Appleton, WI 60.56 Atlanta, GA 69.97 Austin, TX 71.48 Baltimore, MD 69.75 Birmingham, AL 69.59 Boise City, ID 68.36 Boston, MA 68.99 Buffalo, NY 66.10 <p>Las filas de cualquier conjunto de datos en Excel se pueden colocar en orden aleatorio agregando una columna al conjunto de datos y llenando la columna con n\u00fameros aleatorios mediante la funci\u00f3n = RAND(). Despu\u00e9s, con la herramienta de Excel para ordenar en forma ascendente aplicada a la columna de n\u00fameros aleatorios, las fi las del conjunto de datos se reordenan de forma aleatoria. La muestra aleatoria de tama\u00f1o n aparecer\u00e1 en las n primeras f  las del conjunto de datos reordenado. En el conjunto de datos MetAreas, los encabezados aparecen en la fila 1 y las 100 \u00e1reas metropolitanas se encuentran en las filas 2 a 101. Para seleccionar una muestra aleatoria de 30 \u00e1reas metropolitanas aplique los pasos siguientes. Paso 1. Ingrese RAND() en la celda C2. Paso 2. Copie la celda C2 a las celdas C3:C101. Paso 3. Seleccione cualquier celda de la columna C. Paso 4. Haga clic en la ficha Home sobre la cinta. Paso 5. En el grupo Editing, d\u00e9 clic en Sort &amp; Filter. Paso 6. Haga clic en Sort Smallest to Largest.</p> <p>La muestra aleatoria con 30 \u00e1reas metropolitanas aparecer\u00e1 en las filas 2 a 31 del conjunto de datos reordenado. Los n\u00fameros aleatorios de la columna C ya no son necesarios y pueden borrarse si se desea.</p>"},{"location":"capitulo7/#71-el-problema-de-muestreo-de-electronics-associates","title":"7.1 El problema de muestreo de Electronics Associates\u00b6","text":""},{"location":"capitulo7/#72-seleccion-de-una-muestra","title":"7.2 Seleccion de una muestra\u00b6","text":""},{"location":"capitulo7/#73-estimacion-puntual","title":"7.3 Estimacion puntual\u00b6","text":""},{"location":"capitulo7/#consejo-practico","title":"Consejo practico\u00b6","text":"<p>El tema de la mayor parte del resto de este libro se relaciona con la inferencia estad\u00edstica. La estimaci\u00f3n puntual es una de sus formas. Se utiliza un estad\u00edstico de muestra para hacer una inferencia acerca de un par\u00e1metro poblacional. Al realizar inferencias acerca de una poblaci\u00f3n basada en una muestra, es importante tener una correspondencia cerrada entre la poblaci\u00f3n muestreada y la poblaci\u00f3n objetivo. La poblaci\u00f3n objetivo es aquella de la cual buscamos hacer inferencias, en tanto que la poblaci\u00f3n muestreada es aquella de la cual se toma realmente la muestra. En esta secci\u00f3n se describe el proceso de tomar una muestra aleatoria simple de la poblaci\u00f3n de gerentes en EAI y establecer puntos estimados de caracter\u00edsticas de la misma poblaci\u00f3n. As\u00ed, la poblaci\u00f3n muestreada y la poblaci\u00f3n objetivo son id\u00e9nticas, que es la situaci\u00f3n deseada. En otros casos, sin embargo, no es f\u00e1cil obtener una correspondencia cerrada entre ambos tipos de poblaciones.</p> <p>Piense en el caso de un parque tem\u00e1tico seleccionando una muestra de sus clientes para conocer algunas de sus caracter\u00edsticas, como la edad y el tiempo que pasan en el parque. Suponga que todos los elementos de la muestra se seleccionan en un d\u00eda en que la entrada al parque est\u00e1 restringida a los empleados de una gran empresa. Entonces la poblaci\u00f3n muestreada estar\u00eda compuesta de los empleados de dicha empresa y los miembros de su familia. Si la poblaci\u00f3n objetivo se busca para realizar inferencias acerca de los clientes usuales durante un verano com\u00fan, se podr\u00eda encontrar una diferencia signifi cativa entre la poblaci\u00f3n muestreada y la poblaci\u00f3n objetivo. En tal caso, se podr\u00eda cuestionar la validez de los puntos de estimaci\u00f3n que se est\u00e1n realizando. La gerencia del parque estar\u00eda en mejor posici\u00f3n para saber si una muestra tomada en un d\u00eda espec\u00edfi co parecer\u00eda ser representativa de la poblaci\u00f3n objetivo.</p> <p>En resumen, cada vez que se utiliza una muestra para hacer inferencias acerca de una poblaci\u00f3n, debemos estar seguros de que el estudio est\u00e1 dise\u00f1ado para que la poblaci\u00f3n muestreada y la poblaci\u00f3n objetivo est\u00e9n en un acuerdo cerrado. El buen juicio es un ingrediente necesario en una pr\u00e1ctica estad\u00edstica s\u00f3lida.</p>"},{"location":"capitulo7/#74-introduccion-a-las-distribuciones-muestrales-o-de-muestreo","title":"7.4 Introducci\u00f3n a las distribuciones muestrales o de muestreo\u00b6","text":""},{"location":"capitulo7/#75-distribucion-de-muestreo-de-x","title":"7.5 Distribuci\u00f3n de muestreo de x\u0304\u00b6","text":""},{"location":"capitulo7/#valor-esperado-de-x","title":"**Valor esperado de *x\u0304***\u00b6","text":"<p>En el problema de muestreo de EAI se vio que en distintas muestras aleatorias simples se obtienen valores diferentes para la media muestral x\u0304. Como la variable aleatoria x\u0304 puede tener muchos valores diversos, suele ser de inter\u00e9s conocer la media de todos los valores de x\u0304 que se obtienen con diferentes muestras aleatorias simples. La media de la variable aleatoria x\u0304 es el valor esperado de x\u0304; sea \u00e9ste E(x\u0304) y \u03bc la media de la poblaci\u00f3n de la que se selecciona una muestra aleatoria simple. Se puede demostrar que cuando se emplea el muestreo aleatorio simple, E(x\u0304) y \u03bc son iguales.</p>"},{"location":"capitulo7/#valor-esperado-de-x","title":"VALOR ESPERADO DE x\u0304\u00b6","text":"<p>$$E(\\bar{x}) = \u03bc$$ donde: $$E(\\bar{x}) = \\text{valor esperado de } \\bar{x}$$ $$\u03bc = \\text{media poblacional}$$</p>"},{"location":"capitulo7/#desviacion-estandar-de-x","title":"**Desviaci\u00f3n est\u00e1ndar de *x\u0304***\u00b6","text":"<p>Ahora se defi nir\u00e1 la desviaci\u00f3n est\u00e1ndar de la distribuci\u00f3n de muestreo de x\u0304. Se emplear\u00e1 la notaci\u00f3n siguiente.</p>  \u03c3<sub>x\u0304</sub> = desviaci\u00f3n est\u00e1ndar de x\u0304  <p>\u03c3 = desviaci\u00f3n est\u00e1ndar de la poblaci\u00f3n</p> <p>n = tama\u00f1o de la muestra</p> <p>N = tama\u00f1o de la poblaci\u00f3n</p> <p>Es posible demostrar que la f\u00f3rmula de la desviaci\u00f3n est\u00e1ndar de x\u0304 depende de que la poblaci\u00f3n sea finita o infinita. Las dos f\u00f3rmulas para la desviaci\u00f3n est\u00e1ndar de x\u0304 son las siguientes.</p>"},{"location":"capitulo7/#desviacion-estandar-de-x","title":"DESVIACI\u00d3N EST\u00c1NDAR DE x\u0304\u00b6","text":"<p>Poblaci\u00f3n finita $$\\sigma_{\\bar{x}} = \\sqrt{\\frac{N-n}{N-1}}(\\frac{\\sigma}{\\sqrt{n}})$$</p> <p>Poblaci\u00f3n infinita $$\\frac{\\sigma}{\\sqrt{n}}$$</p>"},{"location":"capitulo7/#usar-la-expresion-siguiente-para-calcular-la-desviacion-estandar-de-barx","title":"USAR LA EXPRESION SIGUIENTE PARA CALCULAR LA DESVIACI\u00d3N EST\u00c1NDAR DE $\\bar{x}$\u00b6","text":"<p>$$\\sigma_x = \\frac{\\sigma}{\\sqrt{n}}$$ siempre que</p> <ol> <li>La poblaci\u00f3n sea infinita; o</li> <li>La poblacion sea finita y el tama\u00f1o de la muestra sea menor o iguala 5% del tama\u00f1o de la poblaci\u00f3n; es decir, n/N $\\leq$ 0.05.</li> </ol>"},{"location":"capitulo7/#forma-de-la-distribucion-de-muestreo-de-x","title":"**Forma de la distribuci\u00f3n de muestreo de *x\u0304***\u00b6","text":"<p>Los resultados anteriores respecto del valor esperado y la desviaci\u00f3n est\u00e1ndar en la distribuci\u00f3n de muestreo de x\u0304 son aplicables a cualquier poblaci\u00f3n. El paso fi nal para identificarlas caracter\u00edsticas de la distribuci\u00f3n de muestreo de x\u0304 consiste en determinar la forma de la distribuci\u00f3n de muestreo. Se considerar\u00e1n dos casos: 1) La poblaci\u00f3n tiene distribuci\u00f3n normal, y 2) La poblaci\u00f3n no tiene distribuci\u00f3n normal.</p> <p>La poblaci\u00f3n tiene distribuci\u00f3n normal. En muchas situaciones es razonable suponer que la poblaci\u00f3n de la que se selecciona la muestra aleatoria simple tiene distribuci\u00f3n normal o casi normal. Cuando esto ocurre, la distribuci\u00f3n de muestreo de x\u0304 est\u00e1 distribuida normalmente cualquiera que sea el tama\u00f1o de la muestra.</p> <p>La poblaci\u00f3n no tiene distribuci\u00f3n normal. Cuando la poblaci\u00f3n de la que se tom\u00f3 la muestra aleatoria simple no tiene distribuci\u00f3n normal, el teorema del l\u00edmite central ayuda a determinar la forma de la distribuci\u00f3n de muestreo de x\u0304. El enunciado de este teorema aplicado a la distribuci\u00f3n de muestreo de x\u0304 dice lo siguiente.</p>"},{"location":"capitulo7/#distribucion-de-muestreo-de-x-en-el-problema-de-eai","title":"Distribuci\u00f3n de muestreo de x\u0304 en el problema de EAI\u00b6","text":"<p>En el problema de EAI, para el que ya previamente se mostr\u00f3 que E(x\u0304) = $51800 y \u03c3<sub>x\u0304</sub> = 730.3, no se cuenta con ninguna informaci\u00f3n acerca de la distribuci\u00f3n de la poblaci\u00f3n, que puede estar o no distribuida normalmente. Si se da el segundo caso, la distribuci\u00f3n muestral de x\u0304 estar\u00e1 distribuida normalmente. Si la poblaci\u00f3n no tiene una distribuci\u00f3n normal, la muestra aleatoria simple de 30 gerentes y el teorema del l\u00edmite central permiten concluir que la distribuci\u00f3n de muestreo de x\u0304 puede aproximarse mediante una distribuci\u00f3n normal. En cualquiera de los casos, se concluye que la distribuci\u00f3n de muestreo de x\u0304 se describe mediante una distribuci\u00f3n normal como la que se muestra en la figura 7.4.</p>"},{"location":"capitulo7/#valor-practico-de-la-distribucion-de-muestreo-de-x","title":"**Valor pr\u00e1ctico de la distribuci\u00f3n de muestreo de *x\u0304***\u00b6","text":"<p>Siempre que se seleccione una muestra aleatoria simple y se use el valor de la media muestral para estimar el valor de la media poblacional \u03bc, no se podr\u00e1 esperar que la media muestral sea exactamente igual a la media poblacional. La raz\u00f3n pr\u00e1ctica por la que interesa la distribuci\u00f3n de muestreo de x\u0304 estriba en que se puede usar para proporcionar informaci\u00f3n probabil\u00edstica acerca de la diferencia entre la media muestral y la media poblacional. Para demostrar este uso, se retomar\u00e1 el problema de EAI.</p> <p>Suponga que el director de personal cree que la media muestral ser\u00e1 una estimaci\u00f3n aceptable de la media poblacional si la primera est\u00e1 en un margen de $500 de la segunda. Sin embargo, no es posible garantizar que la media muestral est\u00e9 en un margen de $500 de la media poblacional. En efecto, en la tabla 7.5 y en la figura 7.1 se observa que algunas de las 500 medias muestrales difieren en m\u00e1s de $2000 de la media poblacional. Entonces hay que pensar en el requerimiento del director de personal en t\u00e9rminos de probabilidad. Es decir, a \u00e9ste le interesa la interrogante siguiente: \u00bfcu\u00e1l es la probabilidad de que la media muestral obtenida usando una muestra aleatoria simple de 30 gerentes de EAI se encuen tre en un margen de $500 de la media poblacional?</p>"},{"location":"capitulo7/#margen-de-error-y-estimacion-por-intervalo","title":"Margen de error y estimaci\u00f3n por intervalo\u00b6","text":"<p>Suponga que en el problema de muestreo de EAI se toma una muestra aleatoria simple de 100 gerentes en lugar de los 30 considerados. La intuici\u00f3n indica que teniendo m\u00e1s datos proporcionados por una muestra mayor, la media muestral basada en $n=100$ proporcionar\u00e1 una mejor estimaci\u00f3n de la media poblacional que la basada en $n=30$. Para ver cu\u00e1n mejor es, se considerar\u00e1 la relaci\u00f3n entre el tama\u00f1o de la muestra y la distribuci\u00f3n de muestreo de $\\bar{x}$. Primero observe que $E(\\bar{x})=\\mu$ independientemente del tama\u00f1o de la muestra. Entonces, la media de todos los valores posibles de $\\bar{x}$ es igual a la media poblacional \u03bc independientemente del tama\u00f1o n de la muestra. No obstante, el error est\u00e1ndar de la media, $\\sigma_{\\bar{x}}=\\sigma/\\sqrt{n}$, est\u00e1 relacionado con la ra\u00edz cuadrada del tama\u00f1o de la muestra. Siempre que este tama\u00f1o aumente, el error est\u00e1ndar de la media $\u03c3_{\\bar{x}}$ disminuir\u00e1. Con $n=30$, el error est\u00e1ndar de la media en el problema de EAI es 730.3. Sin embargo, aumentando el tama\u00f1o de la muestra a $n = 100$, el error est\u00e1ndar de la media disminuye a $$\u03c3_{\\bar{x}}=\\frac{\u03c3}{\\sqrt{n}}=\\frac{4000}{\\sqrt{100}}=400$$ En la figura 7.6 se ilustran las distribuciones de muestreo de $\\bar{x}$ correspondientes a $n=30$ y a $n=100$. Como la distribuci\u00f3n muestral con $n=100$ tiene un error est\u00e1ndar m\u00e1s peque\u00f1o, habr\u00e1 menos variaci\u00f3n entre los valores de $\\bar{x}$ y \u00e9stos tender\u00e1n a estar m\u00e1s cerca de la media poblacional que los valores de $bar{x}$ con $n=30$. \\ La distribuci\u00f3n de muestreo de $\\bar{x}$, en el caso de $n=100$, puede emplearse para calcular la probabilidad de que una muestra aleatoria simple de 100 gerentes de EAI d\u00e9 una media muestral que no difi era de los $500 de la media poblacional. Como la distribuci\u00f3n de muestreo es normal y su media es $51 800 y el error est\u00e1ndar de la media es 400, se emplea la tabla de probabilidad normal est\u00e1ndar para determinar el \u00e1rea o la probabilidad. \\ Para $ \\bar{x}= 52 300$ (figura 7.7) tenemos $$z=\\frac{52300-51800}{400}=1.25$$</p>"},{"location":"capitulo7/#ejercicios","title":"Ejercicios\u00b6","text":""},{"location":"capitulo7/#metodo","title":"Metodo\u00b6","text":"<p>Ejercicio 18. La media de una poblaci\u00f3n es 200 y su desviaci\u00f3n est\u00e1ndar es 50. Se tomar\u00e1 una muestra aleatoria simple de tama\u00f1o 100 y se utilizar\u00e1 la media muestral x para estimar la media poblacional.</p> <p>$a)$ \u00bfCu\u00e1l es el valor esperado de x?</p> <p>$b)$ \u00bfCu\u00e1l es la desviaci\u00f3n est\u00e1ndar de x?</p> <p>$c)$ Ilustre la distribuci\u00f3n de muestreo de x.</p> <p>$d)$ \u00bfQu\u00e9 expresa la distribuci\u00f3n de muestreo de x?</p> <p>Solucion: </p> <p>$a)$ El valor esperado (o esperanza matem\u00e1tica) de la media muestral ($\\bar{x}$) es igual a la media poblacional ($\u03bc$): $$E(\\bar{x})=\u03bc$$ Reemplazamos datos $$E(\\bar{x})=200$$ $b)$ La desviaci\u00f3n est\u00e1ndar de la media muestral  ($\u03c3_{\\bar{x}}$) se calcula dividiendo la desviaci\u00f3n est\u00e1ndar poblacional ($\u03c3$) por la ra\u00edz cuadrada del tama\u00f1o de la muestra ($n$): $$\u03c3_{\\bar{x}}=\\frac{\u03c3}{\\sqrt{n}}$$ Reemplazamos datos: $$\u03c3=\\frac{50}{\\sqrt{100}}=5$$ $$\u03c3=5$$ $c)$ Ilustraci\u00f3n de la distribuci\u00f3n de muestreo de la media muestral:</p>"},{"location":"capitulo7/#apliciones","title":"Apliciones\u00b6","text":"<p>Ejercicio 26. El costo medio anual de un seguro para autom\u00f3vil es de $939 (CNBC, 23 de febrero de 2006). Suponga que la desviaci\u00f3n est\u00e1ndar es $\u03c3=\\$245$.</p> <p>$a)$ \u00bfCu\u00e1l es la probabilidad de que en una muestra aleatoria simple de p\u00f3lizas de seguros de autom\u00f3vil la media muestral no difiera m\u00e1s de $25 de la media poblacional si el tama\u00f1o de la muestra es 30, 50, 100 y 400?</p> <p>$b)$ \u00bfQu\u00e9 ventaja tiene una muestra m\u00e1s grande cuando se quiere estimar la media poblacional?</p> <p>Solucion: </p> <p>$a)$ Para resolver este insciso, podemos utilizar la distribuci\u00f3n normal est\u00e1ndar (z) para encontrar las probabilidades asociadas con la diferencia entre la media muestral y la media poblacional. La f\u00f3rmula para la puntuaci\u00f3n z es: $$z=\\frac{\\bar{x}-\u03bc}{\\frac{\u03c3}{\\sqrt{n}}}$$ Donde: \\ $\\bar{x}$ es la media muestral, \u03bc es la media poblacional, \u03c3 es la desviaci\u00f3n est\u00e1ndar poblacional y n es el tama\u00f1o de la muestra. Ahora reemplzamos los datos para cada caso: \\ Para n=30 $$z=\\frac{\\bar{x}-\u03bc}{\\frac{\u03c3}{\\sqrt{n}}}=\\frac{25}{\\frac{245}{\\sqrt{30}}}$$ $$z=0.5589$$ Ahora buscando valor de z en una tabla de la distribuci\u00f3n normal est\u00e1ndar, nos da que para un $n=30$ la probabilidad es de 0.4246. \\ Para n=50 $$z=\\frac{\\bar{x}-\u03bc}{\\frac{\u03c3}{\\sqrt{n}}}=\\frac{25}{\\frac{245}{\\sqrt{50}}}$$ $$z=0.7215$$ Ahora buscando valor de z en una tabla de la distribuci\u00f3n normal est\u00e1ndar, nos da que para un $n=30$ la probabilidad es de 0.5284. \\ Para n=100 $$z=\\frac{\\bar{x}-\u03bc}{\\frac{\u03c3}{\\sqrt{n}}}=\\frac{25}{\\frac{245}{\\sqrt{100}}}$$ $$z=1.02$$ Ahora buscando valor de z en una tabla de la distribuci\u00f3n normal est\u00e1ndar, nos da que para un $n=30$ la probabilidad es de 0.6922. \\ Para n=400 $$z=\\frac{\\bar{x}-\u03bc}{\\frac{\u03c3}{\\sqrt{n}}}=\\frac{25}{\\frac{245}{\\sqrt{400}}}$$ $$z=2.04$$ Ahora buscando valor de z en una tabla de la distribuci\u00f3n normal est\u00e1ndar, nos da que para un $n=30$ la probabilidad es de 0.9586.</p> <p>$b)$ La ventaja de tener una muestra m\u00e1s grande al estimar la media poblacional est\u00e1 relacionada con la precisi\u00f3n de la estimaci\u00f3n. Cuando el tama\u00f1o de la muestra es m\u00e1s grande, la estimaci\u00f3n de la media muestral tiende a acercarse m\u00e1s a la media poblacional. Esto se debe a la propiedad del Teorema del L\u00edmite Central, que establece que, para muestras lo suficientemente grandes, la distribuci\u00f3n de las medias muestrales se aproxima a una distribuci\u00f3n normal, independientemente de la forma de la distribuci\u00f3n original.\\ En resumen, una muestra m\u00e1s grande proporciona estimaciones m\u00e1s precisas de la media poblacional y reduce la variabilidad en las estimaciones muestrales.</p> <p>Solucion con phyton: </p>"},{"location":"capitulo7/#76-distribucion-de-muestreo-barp","title":"7.6 Distribuci\u00f3n de muestreo $\\bar{p}$\u00b6","text":"<p>La proporci\u00f3n muestral $\\bar{p}$ es el estimador puntual de la proporci\u00f3n poblacional $p$. La f\u00f3rmula para calcular la proporci\u00f3n muestral es $$\\bar{p}=\\frac{x}{n}$$ donde $$x=n\u00famero de elementos de la muestra que poseen la caracter\u00edstica de inter\u00e9s$$ $$n=tama\u00f1o de la muestra$$ Como se indica en la secci\u00f3n 7.4, la proporci\u00f3n muestral $\\bar{p}$ es una variable aleatoria y su distribuci\u00f3n de probabilidad se conoce como distribuci\u00f3n de muestreo de $\\bar{p}$.</p> <p>Distribuci\u00f3n de muestreo de $\\bar{p}$</p> <p>La distribuci\u00f3n de muestreo de $\\bar{p}$ es la distribuci\u00f3n de probabilidad de todos los posibles valores de la proporci\u00f3n muestral $\\bar{p}$.</p> <p>Para determinar qu\u00e9 tan cerca est\u00e1 la proporci\u00f3n muestral $\\bar{p}$ de la proporci\u00f3n poblacional $\\bar{p}$, es necesario entender las propiedades de la distribuci\u00f3n de muestreo de p: el valor esperado de $\\bar{p}$, la desviaci\u00f3n est\u00e1ndar de $\\bar{p}$ y la forma de la distribuci\u00f3n de muestreo de $\\bar{p}$.</p>"},{"location":"capitulo7/#valor-esperado-de-barp","title":"Valor esperado de $\\bar{p}$\u00b6","text":"<p>El valor esperado de $\\bar{p}$, la media de todos los posibles valores de $\\bar{p}$, es igual a la proporci\u00f3n poblacional $\\bar{p}$.</p> <p>VALOR ESPERADO DE $\\bar{p}$ $$E(\\bar{p})=p$$ donde $$E(\\bar{p})=valor\\ esperado\\ de\\ \\bar{p}$$ $$p=proporci\u00f3n\\ poblacional$$ Como $E(\\bar{p})=p$, $\\bar{p}$ es un estimador insesgado de $p$. Recuerde que en la secci\u00f3n 7.1 se encontr\u00f3 que en la poblaci\u00f3n de EAI, p  0.60, siendo $p$ la proporci\u00f3n de la poblaci\u00f3n de gerentes que han participado en el programa de capacitaci\u00f3n de la empresa. Por tanto, el valor esperado de $\\bar{p}$ en el problema de muestreo de EAI es 0.60. \\ Desviaci\u00f3n est\u00e1ndar de $\\bar{p}$ \\ Como en el caso de la desviaci\u00f3n est\u00e1ndar de $\\bar{x}$, la desviaci\u00f3n est\u00e1ndar de $\\bar{p}$ depende de si la poblaci\u00f3n es fi nita o infi nita. Las dos f\u00f3rmulas para calcularla se presentan a continuaci\u00f3n. \\ DESVIACI\u00d3N EST\u00c1NDAR DE $\\bar{p}$ \\ Polaci\u00f3n finita $$\u03c3_{\\bar{p}}=\\sqrt{\\frac{N-n}{N-1}}\\sqrt{\\frac{p(1-p)}{n}}$$ Polaci\u00f3n infinita $$\u03c3_{\\bar{p}}=\\sqrt{\\frac{p(1-p)}{n}}$$</p> <p>Al comparar las dos f\u00f3rmulas en (7.5) se aprecia que la \u00fanica diferencia es el uso del factor de correcci\u00f3n para una poblaci\u00f3n finita $\\sqrt{(N-n)(N-1)}$. \\ Como en el caso de la media muestral $\\bar{x}$, la diferencia entre las expresiones para una poblaci\u00f3n fi nita y una infi nita es despreciable si el tama\u00f1o de la poblaci\u00f3n finita es grande en comparaci\u00f3n con el tama\u00f1o de la muestra. Se seguir\u00e1 la misma regla recomendada para la media muestral. Es decir, si la poblaci\u00f3n es finita y $n/N\\leq 0.5$ se usar\u00e1 $\u03c3_{\\bar{p}}=\\sqrt{p(1-p)/n}$. Pero si la poblaci\u00f3n es finita y $n/N&gt;0.5$, entonces deber\u00e1 utilizarse el factor de correcci\u00f3n para una poblaci\u00f3n finita. Tambi\u00e9n, a menos que se especifique otra cosa, en este libro se supondr\u00e1 que el tama\u00f1o de la poblaci\u00f3n es grande en comparaci\u00f3n con el tama\u00f1o de la muestra y, por tanto, el factor de correcci\u00f3n para una poblaci\u00f3n finita no ser\u00e1 necesario. \\ En la secci\u00f3n 7.5 se utiliz\u00f3 el t\u00e9rmino error est\u00e1ndar de la media para referirse a la desviaci\u00f3n est\u00e1ndar de $\\bar{x}$. Se dijo que en general la expresi\u00f3n error est\u00e1ndar se refiere a la desviaci\u00f3n est\u00e1ndar de un estimador puntual. As\u00ed, en el caso de proporciones, se usa el error est\u00e1ndar de la proporci\u00f3n para referirse a la desviaci\u00f3n est\u00e1ndar de $\\bar{p}$. Ahora se vuelve al ejemplo de EAI para calcular el error est\u00e1ndar de la proporci\u00f3n asociada con la muestra aleatoria simple de los 30 gerentes de EAI. \\ En el estudio de EAI se sabe que la proporci\u00f3n poblacional de gerentes que han participado en el programa de capacitaci\u00f3n es $p=0.60$. Como $n/N=0/2 500=0.012$, se puede ignorar el factor de correcci\u00f3n para una poblaci\u00f3n fi nita al calcular el error est\u00e1ndar de la proporci\u00f3n. En la muestra aleatoria simple de 30 gerentes, $\u03c3_{\\bar{p}}$ es $$\u03c3_{\\bar{p}}=\\sqrt{\\frac{p(1-p)}{n}}=\\sqrt{\\frac{0.60(1-0.60)}{30}}=0.0894$$</p>"},{"location":"capitulo7/#forma-de-la-distribucion-de-muestreo-de-barp","title":"Forma de la distribuci\u00f3n de muestreo de $\\bar{p}$\u00b6","text":"<p>Ahora que se conoce la media y la desviaci\u00f3n est\u00e1ndar de la distribuci\u00f3n de muestreo de $\\bar{p}$, el \u00fal-timo paso es determinar la forma de esta distribuci\u00f3n. La proporci\u00f3n muestral es $\\bar{p}  =x/n$. En una muestra aleatoria simple de una poblaci\u00f3n grande, el valor de $\\bar{x}$ es una variable aleatoria binomial que indica el n\u00famero de los elementos de la muestra que tienen la caracter\u00edstica de inter\u00e9s. Como $n$ es una constante, la probabilidad de $x/n$ es la misma que la probabilidad binomial de $\\bar{x}$, lo cual signifi ca que la distribuci\u00f3n de muestreo de $\\bar{p}$ tambi\u00e9n es una distribuci\u00f3n de probabilidad discreta y la probabilidad de cada $x/n$ es la misma que la de $\\bar{x}$. \\ En el cap\u00edtulo 6 se estableci\u00f3 que una distribuci\u00f3n binomial se aproxima mediante una distribuci\u00f3n normal, siempre que el tama\u00f1o de la muestra sea lo sufi cientemente grande para satisfacer las dos condiciones siguientes. $$np\\geq 5$$ y $$n(1-p)\\geq5$$ Suponiendo que se satisfagan estas dos condiciones, la distribuci\u00f3n de probabilidad de x en la proporci\u00f3n muestral, $\\bar{p}=x/n$, puede aproximarse por medio de una distribuci\u00f3n normal. Y como $n$ es una constante, la distribuci\u00f3n de muestreo de $\\bar{p}$ tambi\u00e9n se aproxima mediante una distribuci\u00f3n normal. Esta aproximaci\u00f3n se formula como se indica enseguida: \\ La distribuci\u00f3n de muestreo de $\\bar{p}$ se aproxima mediante una distribuci\u00f3n normal, siempre que $np\\geq5$ y $n(1-p)\\geq5$. \\ En las aplicaciones pr\u00e1cticas, cuando se requiere una estimaci\u00f3n de la proporci\u00f3n poblacional, casi siempre se encuentra que el tama\u00f1o de la muestra es sufi cientemente grande para permitir usar la aproximaci\u00f3n normal para la distribuci\u00f3n de muestreo de $\\bar{p}$. \\ Recuerde que en el problema de muestreo de EAI la proporci\u00f3n poblacional de gerentes que han participado en el programa de capacitaci\u00f3n es $p=0.60$. Con una muestra aleatoria simple de tama\u00f1o 30, se tiene $np = 30(0.60)  =18$ y $n(l-p)=  30 (0.40) = 12$. Por tanto, la distribuci\u00f3n de muestreo de p se calcula mediante la distribuci\u00f3n normal que se presenta en la figura 7.8. \\</p>"},{"location":"capitulo7/#valor-practico-de-la-distribucion-de-muestreo-de-barp","title":"Valor pr\u00e1ctico de la distribuci\u00f3n de muestreo de $\\bar{p}$\u00b6","text":"<p>El valor pr\u00e1ctico de la distribuci\u00f3n de muestreo de $\\bar{p}$ radica en que permite obtener informaci\u00f3n probabil\u00edstica acerca de la diferencia entre la proporci\u00f3n muestral y la proporci\u00f3n poblacional. Por ejemplo, en el problema de EAI, el director de personal desea saber cu\u00e1l es la probabilidad de obtener un valor de $\\bar{p}$ que no difi era en m\u00e1s de 0.05 de la proporci\u00f3n poblacional de los gerentes de EAI que han participado en el programa de capacitaci\u00f3n. Es decir, \u00bfcu\u00e1l es la probabilidad de tener una muestra en la que la proporci\u00f3n muestral $\\bar{p}$ est\u00e9 entre 0.55 y 0.65? El \u00e1rea sombreada de la figura 7.9 corresponde a esta probabilidad. A partir de que la distribuci\u00f3n de muestreo de $\\bar{p}$ se aproxima mediante una distribuci\u00f3n normal con media 0.60 y un error est\u00e1ndar de la proporci\u00f3n $\u03c3_{\\bar{p}}=  0.0894$, se encuentra que la variable aleatoria normal est\u00e1ndar correspondiente a $\\bar{p}=0.65$ tiene el valor $z  (0.65 - 0.60)/0.0894 =0.56$. En la tabla de probabilidad normal est\u00e1ndar aparece que la probabilidad acumulada que corresponde a $z= 0.56$ es 0.7123. De manera similar para $\\bar{p}=0.55$, se encuentra que $z = (0.55 - 0.60)/0.0894= -0.56$. En la misma tabla se aprecia que la probabilidad acumulada correspondiente a $z= -0.56$ es 0.2877. De esta manera, la probabilidad de seleccionar una muestra en la cual el valor de $\\bar{p}$ no difiera m\u00e1s de 0.05 de la proporci\u00f3n poblacional p est\u00e1 dada por 0.7123 - 0.2877 = 0.4246.</p> <p> Figura 7.8 Distribuci\u00f3n de muestreo de $\\bar{p}$ para la proporci\u00f3n de gerentes que ha participado en el programa de capacitaci\u00f3n de EAI </p>"},{"location":"capitulo7/#ejercicios","title":"Ejercicios\u00b6","text":""},{"location":"capitulo7/#metodo","title":"Metodo\u00b6","text":"<ol> <li>Una muestra aleatoria de tama\u00f1o 100 es seleccionada de una poblaci\u00f3n en la que $p=$ 0.40.</li> </ol> <p>$a)$  $\u00bf$Cu\u00e1l es el valor esperado de $\\bar{p}?$</p> <p>$b)$  $\u00bf$Cu\u00e1l es el error est\u00e1ndar de $\\bar{p}?$</p> <p>$c)$ Exprese la distribuci\u00f3n de muestreo de $\\bar{p}$.</p> <p>$d)$ $\u00bf$Qu\u00e9 indica esta distribuci\u00f3n$?$</p> <ol> <li>Una proporci\u00f3n poblacional es 0.40. Se toma una muestra aleatoria simple de tama\u00f1o 200 y la proporci\u00f3n muestral $\\bar{p}$ se usa para estimar la proporci\u00f3n poblacional.</li> </ol> <p>$a)$ $\u00bf$Cu\u00e1l es la probabilidad de que la proporci\u00f3n muestral est\u00e9 entre $\\pm$0.03 de la proporci\u00f3n poblacional$?$</p> <p>$b)$ $\u00bf$ Cu\u00e1l es la probabilidad de que la proporci\u00f3n muestral se encuentre entre $\\pm$0.05 de la proporci\u00f3n poblacional$?$</p> <ol> <li>Suponga que la proporci\u00f3n poblacional es 0.55. Calcule el error est\u00e1ndar de la proporci\u00f3n, $\u03c3\\small{\\bar{p}}$ , para los tama\u00f1os de muestra 100, 200, 500 y 1 000. $\u00bf$Qu\u00e9 puede decir acerca del tama\u00f1o del error est\u00e1ndar a medida que el tama\u00f1o de la muestra aumenta$?$</li> <li>La proporci\u00f3n poblacional es 0.30. \u00bfCu\u00e1l es la probabilidad de que las proporciones muestral y poblacional est\u00e9n entre $\\pm$0.04 con los tama\u00f1os de muestra siguientes$?$ $a)$    $n=$100</li> </ol> <p>$b)$    $n=$200</p> <p>$c)$    $n=$500</p> <p>$d)$    $n=$1000</p> <p>$e)$    $\u00bf$Qu\u00e9 ventaja tiene un tama\u00f1o grande de muestra$?$</p>"},{"location":"capitulo7/#aplicacion","title":"Aplicacion\u00b6","text":"<ol> <li>El director de Doerman Distributors, Inc. piensa que 30% de los pedidos proviene de nuevos clientes. Para ver la proporci\u00f3n de clientes nuevos se usar\u00e1 una muestra aleatoria simple de 100 pedidos.</li> </ol> <p>$a)$ Supongamos que el director est\u00e1 en lo cierto y que $p$ 0.30. $\u00bf$Cu\u00e1l es la distribuci\u00f3n de muestreo de $\\bar{p}$ en este estudio$?$</p> <p>$b)$ $\u00bf$Cu\u00e1l es la probabilidad de que la proporci\u00f3n muestral de $\\bar{p}$ est\u00e9 entre 0.20 y 0.40$?$</p> <p>$c)$ $\u00bf$Cu\u00e1l es la probabilidad de que est\u00e9 entre 0.25 y 0.35$?$</p> <ol> <li>The Cincinnati Enquirer informa que en Estados Unidos 66% de los adultos y 87% de los j\u00f3venes entre 12 y 17 a\u00f1os usan Internet (The Cincinnati Enquirer, 7 de febrero de 2006). Considere estos datos como proporciones poblacionales y suponga que se usar\u00e1 una muestra de 300 adultos y 300 j\u00f3venes para obtener informaci\u00f3n respecto de su opini\u00f3n acerca de la seguridad en Internet.</li> </ol> <p>$a)$ Exponga la distribuci\u00f3n de muestreo de $\\bar{p}$, siendo $\\bar{p}$ la proporci\u00f3n muestral de adultos que usan Internet.</p> <p>$b)$ $\u00bf$Cu\u00e1l es la probabilidad de que la diferencia entre la proporci\u00f3n muestral y la proporci\u00f3n poblacional de adultos que usan Internet no sea mayor que $\\pm$ 0.04$?$</p> <p>$c)$ $\u00bf$ Cula se que la diferencia entre la proporci\u00f3n muestral y la proporci\u00f3n poblacional de j\u00f3venes que usan Internet no sea mayor que  $\\pm$ 0.04$?$</p> <p>$d)$ $\u00bf$Son diferentes las probabilidades del inciso $b)$ y del inciso $c)?$ Si es as\u00ed, $\u00bf$por qu\u00e9$?$</p> <p>$e)$ Responda al inciso $b)$ en el caso de que el tama\u00f1o de la muestra sea 600. $\u00bf$Es menor la probabilidad$?$ $\u00bf$Por qu\u00e9$?$</p> <ol> <li>Las personas terminan por desechar 12% de lo que compran en el supermercado (Reader\u2019s Digest, marzo de 2009). Asuma que \u00e9sta es la verdadera proporci\u00f3n poblacional y que planea realizar una encuesta por muestreo de 450 compradores para investigar m\u00e1s acerca de su comportamiento.</li> </ol> <p>$a)$ Presente la distribuci\u00f3n de muestreo de $\\bar{p}$, la proporci\u00f3n de mercanc\u00eda que desechan los encuestados de la muestra.</p> <p>$b)$ $\u00bf$Cu\u00e1l es la probabilidad de que la encuesta genere una proporci\u00f3n muestral de $\\pm$ 0.03 de la proporci\u00f3n poblacional$?$</p> <p>$c)$ $\u00bf$Cu\u00e1l es la probabilidad de que la encuesta genere una proporci\u00f3n muestral de $\\pm$ 0.015 de la proporci\u00f3n poblacional$?$</p> <ol> <li>Roper ASW realiz\u00f3 una encuesta para obtener informaci\u00f3n acerca de la opini\u00f3n de los estadounidenses respecto del dinero y la felicidad (Money, octubre de 2003). De los entrevistados, 56% dijo revisar el estado de su chequera por lo menos una vez al mes.</li> </ol> <p>$a)$ Suponga que se toma una muestra de 400 estadounidenses adultos. Indique la distribuci\u00f3n de muestreo de la proporci\u00f3n de \u00e9stos que revisa el estado de su chequera por lo menos una vez al mes.</p> <p>$b)$ $\u00bf$Cu\u00e1l es la probabilidad de que la diferencia entre las proporciones muestral y poblacional no sea mayor que $\\pm$ 0.02$?$</p> <p>$c)$ $\u00bf$Cu\u00e1l es la probabilidad de que dicha diferencia no sea mayor que $\\pm$0.04$?$</p> <ol> <li>En 2008, el Better Business Bureau resolvi\u00f3 75% de las quejas que recibi\u00f3 (USA Today, 2 de marzo de 2009). Suponga que ha sido contratado por esta oficina para investigar los reclamos que recibi\u00f3 este a\u00f1o y que involucran a nuevos concesionarios automotrices. Usted planea seleccionar una muestra de las quejas de estos \u00faltimos para estimar la proporci\u00f3n que el Better Business Bureau est\u00e1 en posibilidad de resolver. Asuma que la proporci\u00f3n poblacional de quejas resueltas de nuevos concesionarios automotrices es 0.75, la misma que la proporci\u00f3n general de reclamos resueltos en 2008.</li> </ol> <p>$a)$ Suponga que selecciona una muestra de 450 quejas que involucran a nuevos concesionarios automotrices. Presente la distribuci\u00f3n muestral de $\\bar{p}$.</p> <p>$b)$ Con base en la muestra de 450 quejas, \u00bfcu\u00e1l es la probabilidad de que la diferencia entre las proporciones muestral y poblacional no sea mayor que 0.04?</p> <p>$c)$ Suponga que selecciona una muestra de 200 quejas que involucran a nuevos concesionarios automotrices. Presente la distribuci\u00f3n de muestreo de $\\bar{p}$.</p> <p>$d)$ Con base en la muestra m\u00e1s peque\u00f1a de s\u00f3lo 200 quejas, \u00bfcu\u00e1l es la probabilidad de que la diferencia entre las proporciones muestral y poblacional no sea mayor que 0.04?</p> <p>$e)$ Con base en lo determinado por el incremento en la probabilidad, \u00bfqu\u00e9 tanto se ganar\u00eda en precisi\u00f3n si se tomara la muestra m\u00e1s grande en el inciso $b)$?</p> <ol> <li>The Grocery Manufacturers of America informa que 76% de los consumidores lee los ingredientes que se mencionan en la etiqueta de un producto. Suponga que la proporci\u00f3n poblacional es $p$ = 0.76 y que de la poblaci\u00f3n de consumidores se selecciona una muestra de 400.</li> </ol> <p>$a)$ Exprese la distribuci\u00f3n de muestreo de la proporci\u00f3n muestral $\\bar{p}, si $\\bar{p} es la proporci\u00f3n de consumidores de la muestra que lee los ingredientes que se mencionan en la etiqueta.</p> <p>$b)$ \u00bfCu\u00e1l es la probabilidad de que la diferencia entre las proporciones muestral y poblacional no sea mayor que $\\pm$ 0.03?</p> <p>$c)$ Conteste el inciso $b)$ si el tama\u00f1o de la muestra es 750 consumidores.</p> <ol> <li>El Food Marketing Institute informa que 17% de los hogares gasta m\u00e1s de $100 en productos de abarrotes. Suponga que la proporci\u00f3n poblacional es p 0.17 y que de la poblaci\u00f3n se toma una muestra aleatoria simple de 800 hogares.</li> </ol> <p>$a)$ Exprese la distribuci\u00f3n de muestreo de $\\bar{p}$, la proporci\u00f3n muestral de hogares que gastan m\u00e1s de $100 semanales en abarrotes.</p> <p>$b)$ \u00bfCu\u00e1l es la probabilidad de que la proporci\u00f3n poblacional no difiera en m\u00e1s de 0.02 de la proporci\u00f3n poblacional?</p> <p>$c)$ Conteste el inciso b) en caso de que el tama\u00f1o de la muestra sea de 1 600 hogares.</p>"},{"location":"capitulo7/#78-propiedades-de-los-estimadores-puntuales","title":"7.8 Propiedades de los estimadores puntuales\u00b6","text":""},{"location":"capitulo7/#insesgadez","title":"Insesgadez\u00b6","text":"<p>Si el valor esperado del estad\u00edstico muestral es igual al par\u00e1metro poblacional que se estima, se dice que el estad\u00edstico muestral es un estimador insesgado del par\u00e1metro poblacional.</p>"},{"location":"capitulo7/#eficiencia","title":"Eficiencia\u00b6","text":"<p>Suponga que se usa una muestra aleatoria simple de n elementos para obtener dos estimadores puntuales insesgados de un mismo par\u00e1metro poblacional. En estas circunstancias, se preferir\u00e1 usar el estimador puntual con el menor error est\u00e1ndar, ya que tender\u00e1 a dar estimaciones m\u00e1s cercanas al par\u00e1metro poblacional. Se dice que el estimador puntual con menor error est\u00e1ndar tiene mayor eficiencia relativa que los otros.</p> <p>En la fi gura 7.11 se presentan las distribuciones de muestreo de dos estimadores puntuales insesgados, $\\hat{\\theta}$<sub>1</sub> y $\\hat{\\theta}$<sub>2</sub>. Observe que el error est\u00e1ndar de $\\hat{\\theta}$<sub>1</sub> es menor que el error est\u00e1ndar de  $\\hat{\\theta}$<sub>2</sub>; por</p>"},{"location":"capitulo7/#consistencia","title":"Consistencia\u00b6","text":"<p>La tercera propiedad relacionada con un buen estimador puntual es la consistencia. Dicho de manera sencilla, un estimador puntual es consistente si su valor tiende a estar m\u00e1s cerca del par\u00e1metro poblacional a medida que el tama\u00f1o de la muestra aumenta. En otras palabras, una muestra grande tiende a proporcionar mejor estimaci\u00f3n puntual que una peque\u00f1a. Observe que en el caso de la media muestral $\\bar{x}$ , el error est\u00e1ndar de $\\bar{x}$  est\u00e1 dado por $\u03c3$<sub>$\\bar{x}$</sub> $=$ $\u03c3/$$\\sqrt{{{n}}}$. Puesto que $\u03c3$&lt;sub&gt;$\\bar{x}$&lt;/sub&gt; est\u00e1 vinculado con el tama\u00f1o de la muestra, de manera que muestras mayores dan valores menores de $\u03c3$&lt;sub&gt;$\\bar{x}$&lt;/sub&gt;, entonces las de tama\u00f1o grande tienden a proporcionar estimadores puntuales m\u00e1s cercanos a la media de la poblaci\u00f3n $\u03bc$. Mediante un razonamiento similar, tambi\u00e9n se puede concluir que la proporci\u00f3n muestral $\\bar{p}$ es un estimador consistente de la proporci\u00f3n poblacional $p$.</p>"},{"location":"capitulo7/#78-otros-metodos-de-muestreo","title":"7.8 Otros m\u00e9todos de muestreo\u00b6","text":""},{"location":"capitulo7/#muestreo-aleatorio-estratificado","title":"Muestreo aleatorio estratificado\u00b6","text":"<p>En el muestreo aleatorio estratificado los elementos de la poblaci\u00f3n primero se dividen en grupos, a los que se les llama estratos, de manera que cada elemento pertenezca a uno y s\u00f3lo un estrato. La base para la formaci\u00f3n de los estratos, que pueden ser departamento, edad, tipo de industria, etc., est\u00e1 a discreci\u00f3n de la persona que dise\u00f1a la muestra. Sin embargo, se obtienen mejores resultados cuando los elementos que los forman son lo m\u00e1s parecidos posible. La figura 7.12 es el diagrama de una poblaci\u00f3n dividida en H estratos.</p> <p>Una vez formados los estratos, se toma una muestra aleatoria simple de cada uno. Existen f\u00f3rmulas para combinar los resultados de las muestras de varios estratos individuales en una estimaci\u00f3n del par\u00e1metro poblacional de inter\u00e9s. El valor del muestreo aleatorio estratifi cado depende de qu\u00e9 tan homog\u00e9neos sean los elementos dentro de cada grupo. Si los elementos de</p>"},{"location":"capitulo7/#muestreo-por-conglomerados","title":"Muestreo por conglomerados\u00b6","text":"<p>En el muestreo por conglomerados, la poblaci\u00f3n se divide en grupos llamados conglomerados, y se selecciona aleatoriamente un subconjunto de conglomerados para formar la muestra. Este m\u00e9todo es eficaz cuando los elementos dentro de los conglomerados son diversos. Es especialmente aplicable en el muestreo de \u00e1reas, donde los conglomerados representan unidades geogr\u00e1ficas, como las manzanas de una ciudad. Aunque se necesitan tama\u00f1os de muestra m\u00e1s grandes, permite reducir costos al recopilar muchas observaciones en un conglomerado con un solo entrevistador. Esto proporciona una muestra representativa a un costo menor.</p>"},{"location":"capitulo7/#muestreo-sistematico","title":"Muestreo sistem\u00e1tico\u00b6","text":"<p>Para ciertos muestreos, en especial en aquellos con poblaciones grandes, se necesita mucho tiempo para tomar una muestra aleatoria simple, pues se requiere determinar primero los n\u00fameros</p>"},{"location":"capitulo7/#muestreo-de-conveniencia","title":"Muestreo de conveniencia\u00b6","text":"<p>Los m\u00e9todos de muestreo hasta ahora analizados se conocen como t\u00e9cnicas probabil\u00edsticas de muestreo. Los elementos seleccionados de una poblaci\u00f3n tienen una probabilidad conocida de ser incluidos en la muestra. La ventaja del muestreo probabil\u00edstico estriba en que, por lo general, se identifi ca la distribuci\u00f3n de muestreo del estad\u00edstico muestral correspondiente. Para determinar las propiedades de la distribuci\u00f3n de muestreo se usan las f\u00f3rmulas para el muestreo aleatorio simple presentadas en este cap\u00edtulo. La distribuci\u00f3n de muestreo permite plantear afirmaciones probabil\u00edsticas acerca del error asociado con el uso de los resultados muestrales al hacer inferencias de la poblaci\u00f3n.</p> <p>El  muestreo de conveniencia es una t\u00e9cnica de muestreo no probabil\u00edstica. Como el nombre lo indica, la muestra se determina principalmente por conveniencia. Los elementos se incluyen sin que haya una probabilidad previamente especifi cada o conocida de que sean incorporados en la muestra. Por ejemplo, un profesor que realiza una investigaci\u00f3n en una universidad puede usar estudiantes voluntarios para que constituyan una muestra simplemente porque los tiene al alcance y participar\u00e1n como sujetos a un costo bajo o sin costo. De manera similar, un inspector puede muestrear un cargamento de naranjas seleccion\u00e1ndolas al azar de varias cajas. Marcar cada naranja y usar un m\u00e9todo probabil\u00edstico de muestreo puede no resultar pr\u00e1ctico. Muestras como capturas en la vida salvaje y paneles de voluntarios en investigaciones del consumidor son tambi\u00e9n de conveniencia.</p> <p>La t\u00e9cnica de muestra de conveniencia tiene la ventaja de ser f\u00e1cil de seleccionar y recopilar datos, pero carece de la capacidad de evaluar su representatividad en t\u00e9rminos de la poblaci\u00f3n. No se puede realizar una evaluaci\u00f3n estad\u00edstica de la calidad de los resultados muestrales, ya que esta muestra puede arrojar resultados buenos o malos sin justificaci\u00f3n estad\u00edstica. A veces, los investigadores aplican m\u00e9todos estad\u00edsticos destinados a muestras probabil\u00edsticas a las muestras de conveniencia, trat\u00e1ndolas como si fueran probabil\u00edsticas. Sin embargo, estos argumentos carecen de fundamento y es crucial tener precauci\u00f3n al interpretar los resultados de muestras de conveniencia utilizadas para hacer inferencias sobre las poblaciones.</p>"},{"location":"capitulo7/#muestreo-subjetivo","title":"Muestreo subjetivo\u00b6","text":"<p>tra t\u00e9cnica de muestreo no probabil\u00edstica es el muestreo subjetivo. En este m\u00e9todo la persona que m\u00e1s sabe sobre un asunto selecciona elementos de la poblaci\u00f3n a los que considera los m\u00e1s representativos. Este m\u00e9todo suele representar una manera relativamente f\u00e1cil de seleccionar una muestra. Por ejemplo, un reportero puede elegira dos o tres senadores considerando que \u00e9stos refl ejan la opini\u00f3n general de todos los senadores. Sin embargo, la calidad de los resultados muestrales depende de la persona que selecciona la muestra. Aqu\u00ed tambi\u00e9n hay que tener mucho cuidado al hacer inferencias acerca de las poblaciones a partir de muestreos subjetivos.</p>"},{"location":"capitulo7/#resumen","title":"Resumen\u00b6","text":""},{"location":"capitulo7/#glosario","title":"Glosario\u00b6","text":""},{"location":"capitulo7/#ejercicios-complementarios","title":"Ejercicios complementarios\u00b6","text":"<ol> <li><p>U. S. News &amp; World Report publica informaci\u00f3n extensa acerca de las mejores universidades de Estados Unidos (America\u2019s Best Colleges, ed. 2009). Entre otras cosas, proporciona una lista de las 133 mejores universidades a nivel nacional. Se desea tomar una muestra de tales instituciones para realizar un estudio de seguimiento de sus alumnos. Inicie en la parte inferior de la tercera columna de d\u00edgitos aleatorios de la tabla 7.1. Ignore los dos primeros d\u00edgitos de cada conjunto de cinco n\u00fameros usando n\u00fameros aleatorios de tres cifras. Empiece con 959, lea hacia arriba de la columna para identificar el n\u00famero (de 1 a 133) de las siete primeras universidades a incluir en una muestra aleatoria simple. Contin\u00fae iniciando en la parte inferior de las columnas cuarta y quinta, y lea hacia arriba si es necesario.</p> </li> <li><p>Los estadounidenses est\u00e1n cada vez m\u00e1s preocupados por el aumento en los costos de Medicare. En 1990 el promedio de gastos anuales de un derechohabiente de Medicare ascend\u00eda a $\\$3267$; en 2003 este promedio hab\u00eda aumentado a $\\$6883$ (Money, oto\u00f1o de 2003). Suponga que usted contrata a una firma de consultor\u00eda para tomar una muestra de 50 de los derechohabientes de Medicare en 2003 con objeto de investigar los gastos. Asuma que la desvia ci\u00f3n est\u00e1ndar poblacional en 2003 fue $\\$2000$  a) Presente la distribuci\u00f3n de muestreo de la cantidad media de los gastos de Medicare para una muestra de 50 derechohabientes en 2003. b) \u00bfCu\u00e1l es la probabilidad de que la media muestral no se aleje m\u00e1s de $\\pm\\$300$ de la media poblacional? c) \u00bfCu\u00e1l es la probabilidad de que la media muestral sea mayor que $\\$7500$? Si la empresa que contrat\u00f3 le dice que la media muestral para los derechohabientes que entrevist\u00f3 es $\\$7500$, \u00bfdudar\u00eda de que la empresa contratada hubiera hecho un procedimiento de muestreo aleatorio simple adecuado? \u00bfPor qu\u00e9?</p> </li> <li><p>BusinessWeek encuesta a exalumnos de administraci\u00f3n 10 a\u00f1os despu\u00e9s de terminados sus estudios (BusinessWeek, 22 de septiembre de 2003). Uno de sus hallazgos indica que gastan en promedio $\\$115.50$ semanales en comidas sociales. A usted se le pide que realice un estudio con una muestra de 40 de estos exalumnos. Asuma que la desviaci\u00f3n est\u00e1ndar poblacional es $\\$35$. a) Presente la distribuci\u00f3n de muestreo de $\\overline{x}$, la media muestral de los gastos semanales de los 40 exalumnos de administraci\u00f3n. b) \u00bfCu\u00e1l es la probabilidad de que la media muestral no se aleje en m\u00e1s o menos $\\$10$ de la media poblacional? c) Suponga que encuentra una media muestral de $\\$100$. \u00bfCu\u00e1l es la probabilidad de hallar una media muestral de $\\$100$ o menos? \u00bfConsiderar\u00eda que los exalumnos de esta muestra son un grupo con un gasto inusualmente bajo? \u00bfPor qu\u00e9?</p> </li> <li><p>El tiempo promedio que un estadounidense destina a ver televisi\u00f3n es de 15 horas por semana (Money, noviembre de 2003). Suponga que se toma una muestra de 60 estadounidenses para investigar con m\u00e1s detalle sus h\u00e1bitos a este respecto. Asuma que la desviaci\u00f3n est\u00e1ndar poblacional en las horas de televisi\u00f3n semanales es \u03c3 = 4 horas. a) \u00bfCu\u00e1l es la probabilidad de que la media muestral no se aleje m\u00e1s o menos de 1 hora de la media poblacional? b) \u00bfCu\u00e1l es la probabilidad de que la media muestral no se aleje m\u00e1s o menos de 45 minutos de la media poblacional?</p> </li> <li><p>Despu\u00e9s de deducir los gastos necesarios, el costo promedio por asistir a la Universidad del Sur de California (USC) es de $\\$27175$ (U. S. News &amp; World Report, America\u2019s Best Colleges, ed. 2009). Suponga que la desviaci\u00f3n est\u00e1ndar poblacional es $\\$7400$. Asuma que se selecciona una muestra aleatoria de 60 estudiantes de la USC de esta poblaci\u00f3n. a) \u00bfCu\u00e1l es el valor del error est\u00e1ndar de la media? b) \u00bfCu\u00e1l es la probabilidad de que la media muestral sea mayor que $\\$27175$? c) \u00bfCu\u00e1l es la probabilidad de que la media muestral no se aleje m\u00e1s o menos de $\\$1000$ de la media poblacional? d) \u00bfQu\u00e9 tanto variar\u00eda la probabilidad del inciso c) si el tama\u00f1o de la muestra se aumentara a 100?</p> </li> <li><p>Tres empresas transportan inventarios de distintos tama\u00f1os. El inventario de la empresa A contiene 2000 art\u00edculos, el de la empresa B, 5000 art\u00edculos y el de la empresa C, 10000 art\u00edculos. La desviaci\u00f3n est\u00e1ndar poblacional de los costos de los art\u00edculos en los inventarios de estas empresas es \u03c3 = 144. Un consultor de estad\u00edstica recomienda que cada compa\u00f1\u00eda tome una muestra de 50 art\u00edculos de su inventario para obtener una estimaci\u00f3n estad\u00edstica v\u00e1lida del costo promedio por unidad. Los gerentes de la firma m\u00e1s peque\u00f1a opinan que, como su poblaci\u00f3n es menor, se podr\u00e1 hacer la estimaci\u00f3n con una muestra mucho menor de la que se requiere para la empresa m\u00e1s grande. Sin embargo, el consultor opina que para tener el mismo error est\u00e1ndar y, por tanto, la misma precisi\u00f3n en los resultados muestrales, todas las compa\u00f1\u00edas deber\u00e1n emplear el mismo tama\u00f1o de muestra, sin importar el tama\u00f1o de la poblaci\u00f3n. a) Utilizando el factor de correcci\u00f3n para una poblaci\u00f3n finita, calcule el error est\u00e1ndar de cada una de las tres empresas para un tama\u00f1o de muestra de 50. b) \u00bfCu\u00e1l es la probabilidad para cada firma de que la media muestral $\\overline{x}$ est\u00e9 a no m\u00e1s de $\\pm25$ de la media poblacional $\u03bc$?</p> </li> <li><p>Un investigador reporta sus resultados diciendo que el error est\u00e1ndar de la media es 20 y la desviaci\u00f3n est\u00e1ndar poblacional es 500. a) \u00bfDe qu\u00e9 tama\u00f1o fue la muestra utilizada en esta investigaci\u00f3n? b) \u00bfCu\u00e1l es la probabilidad de que la estimaci\u00f3n puntual est\u00e9 a no m\u00e1s de $\\pm25$ de la media poblacional?</p> </li> <li><p>Un inspector de control de calidad vigila peri\u00f3dicamente un proceso de producci\u00f3n. El inspector selecciona muestras aleatorias simples de 30 art\u00edculos ya terminados y calcula la media muestral del peso del producto $\\overline{x}$. Si en un periodo largo se encuentra que 5% de los valores de $\\overline{x}$ son mayores que 2.1 libras y 5% son menores que 1.9 libras, \u00bfcu\u00e1les son la media y la desviaci\u00f3n est\u00e1ndar de la poblaci\u00f3n de los productos elaborados en este proceso?</p> </li> <li><p>Cerca de 28% de las empresas privadas tiene como propietario a una mujer (The Cincinnati Enquirer, 26 de enero de 2006). Responda estas preguntas con base en una muestra de 240 empresas privadas. a) Desarrolle la distribuci\u00f3n de muestreo de $\\overline{p}$, la proporci\u00f3n muestral de las empresas propiedad de una mujer. b) \u00bfCu\u00e1l es la probabilidad de que la proporci\u00f3n muestral est\u00e9 a no m\u00e1s de $\\pm0.04$ de la proporci\u00f3n poblacional? c) \u00bfCu\u00e1l es la probabilidad de que la proporci\u00f3n muestral est\u00e9 a no m\u00e1s de $\\pm0.02$ de la proporci\u00f3n poblacional?</p> </li> <li><p>Una firma de investigaci\u00f3n de mercados realiza encuestas telef\u00f3nicas con una tasa hist\u00f3rica de respuesta de 40%. \u00bfCu\u00e1l es la probabilidad de que en una nueva muestra de 400 n\u00fameros telef\u00f3nicos, por lo menos 150 personas cooperen y respondan las preguntas? En otras palabras, \u00bfcu\u00e1l es la probabilidad de que la proporci\u00f3n muestral sea por lo menos 150/400 = 0.375?</p> </li> <li><p>Los publicistas contratan a proveedores de servicios de Internet y motores de b\u00fasqueda para</p> </li> </ol> colocar sus anuncios en los sitios web. Pagan una cuota con base en el n\u00famero de clientes potenciales que hacen clic en su publicidad. Desafortunadamente, el fraude por clic (la pr\u00e1ctica de hacer clic en una publicidad con el solo objeto de aumentar las ganancias) se ha convertido en un problema. El 40% de los anunciantes se queja de haber sido v\u00edctima de fraude por clic (*BusinessWeek*, 13 de marzo de 2006). Suponga que se toma una muestra aleatoria de 380 publicistas con objeto de aprender m\u00e1s acerca de c\u00f3mo son afectados por esta pr\u00e1ctica. a) \u00bfCu\u00e1l es la probabilidad de que la proporci\u00f3n muestral est\u00e9 a no m\u00e1s de $\\pm0.04$ de la proporci\u00f3n poblacional que ha experimentado fraude por clic? b) \u00bfCu\u00e1l es la probabilidad de que la proporci\u00f3n muestral sea mayor que 0.45?  <ol> <li><p>La proporci\u00f3n de personas aseguradas por All-Driver Automobile Insurance Company que contraen una multa de tr\u00e1fico en el periodo de cinco a\u00f1os es 0.15. a) Indique la distribuci\u00f3n de muestreo de $\\overline{p}$ si se emplea una muestra aleatoria de 150 asegurados para determinar la proporci\u00f3n de quienes han contra\u00eddo por lo menos una multa. b) \u00bfCu\u00e1l es la probabilidad de que la proporci\u00f3n muestral est\u00e9 a no m\u00e1s de $\\pm0.03$ de la proporci\u00f3n poblacional?</p> </li> <li><p>Lori Jeffrey es una exitosa representante de ventas de libros universitarios. Hist\u00f3ricamente, ella consigue una adopci\u00f3n de libros de texto en 25% de sus llamadas de ventas. Considere sus telefonemas de ventas de un mes como muestra de todas sus posibles llamadas; suponga que en el an\u00e1lisis estad\u00edstico de los datos se encuentra que el error est\u00e1ndar de la proporci\u00f3n es 0.0625. a) \u00bfDe qu\u00e9 tama\u00f1o fue la muestra que se utiliz\u00f3 en el an\u00e1lisis? Es decir, \u00bfcu\u00e1ntas llamadas hizo Lori Jeffrey en ese mes? b) Sea $\\overline{p}$ la proporci\u00f3n muestral de adopciones de libros de texto en el mes. Presente la distribuci\u00f3n de muestreo de $\\overline{p}$. c) Mediante la distribuci\u00f3n de muestreo de $\\overline{p}$, calcule la probabilidad de que Lori lograr\u00e1 adopciones de libros de texto en 30% o m\u00e1s de sus llamadas de ventas en el lapso de un mes.</p> </li> </ol>"},{"location":"capitulo7/#valor-esperado-y-desviacion-estandar-de-overlinex","title":"Valor esperado y desviaci\u00f3n est\u00e1ndar de $\\overline{x}$\u00b6","text":"<p>En este ap\u00e9ndice se presentan las bases matem\u00e1ticas de las expresiones $E(\\overline{x})$, valor esperado de $\\overline{x}$ dado en la ecuaci\u00f3n (7.1), y $\\sigma_{\\overline{x}}$, la desviaci\u00f3n est\u00e1ndar de $\\overline{x}$ dada por la ecuaci\u00f3n (7.2).</p>"},{"location":"capitulo7/#valor-esperado-de-overlinex","title":"Valor esperado de $\\overline{x}$\u00b6","text":"<p>Se tiene una poblaci\u00f3n con media \u03bc y varianza $\\sigma^{2}$. Se selecciona una muestra aleatoria simple de tama\u00f1o n cuyas observaciones individuales se denotan $x_1,x_2,...,x_n$. La media muestral $\\overline{x}$ se calcula como sigue. </p>  $\\overline{x} = \\frac{\\sum x_i}{n}$  <p>Si se repiten los muestreos aleatorios simples de tama\u00f1o n, $\\overline{x}$ ser\u00e1 una variable aleatoria que tomar\u00e1 diferentes valores dependiendo de los n elementos que formen la muestra. El valor esperado de la variable aleatoria $\\overline{x}$ es la media de todos los posibles valores de $\\overline{x}$. </p>  Media de $\\overline{x} = E(\\overline{x}) = E(\\frac{\\sum x_i}{n})$  $= \\frac{1}{n} [E(x_1 + x_2 + ... + x_n)]$  $= \\frac{1}{n} [E(x_1) + E(x_2) + ... + E(x_n)]$   Para cada xi se tiene $E(x_i) = \\mu$; por tanto, escribimos   $E(\\overline{x}) = \\frac{1}{n} (\\mu + \\mu + ... + \\mu)$  $\\frac{1}{n} (n \\mu) = \\mu$   ste resultado indica que la media de todos los posibles valores de $\\overline{x}$ es igual a la media poblacional \u03bc. Es decir, $E(\\overline{x}) = \u03bc$."},{"location":"capitulo7/#desviacion-estandar-de-overlinex","title":"Desviaci\u00f3n est\u00e1ndar de $\\overline{x}$\u00b6","text":"<p>Se tiene, de nuevo, una poblaci\u00f3n con media \u03bc y varianza $\\sigma^2$, y una media muestral dada por </p>  $\\overline{x} = \\frac{\\sum x_i}{n}$   Se sabe que $\\overline{x}$ es una variable aleatoria que toma distintos valores num\u00e9ricos, con repetidas muestras aleatorias simples de tama\u00f1o *n*, dependiendo de los *n* elementos que integran la muestra. Lo que sigue es una derivaci\u00f3n de la f\u00f3rmula para la desviaci\u00f3n est\u00e1ndar de los valores de $\\overline{x}$, $\\sigma_{\\overline{x}}$, en el caso de que la poblaci\u00f3n sea infi nita. La deducci\u00f3n de la f\u00f3rmula para $\\sigma_{\\overline{x}}$ cuando la poblaci\u00f3n es fi nita y el muestreo se realiza sin remplazo es m\u00e1s complicada, y queda fuera de los alcances de este libro. De vuelta al caso de una poblaci\u00f3n infi nita, recuerde que una muestra aleatoria simple de una poblaci\u00f3n infi nita consta de observaciones $x_1, x_2,...,x_n$ que son independientes. Las dos expresiones siguientes son f\u00f3rmulas generales para la varianza de variables aleatorias.   $Var(ax) = a^2 Var(x)$   donde a es una constante y x es una variable aleatoria, y   $Var(x + y) = Var(x) + Var(y)$   donde x y y son variables aleatorias *independientes*. Utilizando las dos ecuaciones anteriores, se puede deducir la f\u00f3rmula para la varianza de la variable aleatoria $\\overline{x}$ como sigue.   $Var(\\overline{x}) = Var(\\frac{\\sum x_i}{n}) = Var(\\frac{1}{n} \\sum x_i)$   Entonces, como *1/n* es una constante, tenemos   $Var(\\overline{x}) = (\\frac{1}{n})^2 Var(\\sum x_i)$  $ = (\\frac{1}{n})^2 Var(x_1 + x_2 + ... + x_n)$   En el caso de una poblaci\u00f3n infinita, las variables aleatorias $x_1, x_2, ...,x_n$ son independientes, lo que permite escribir   $Var(\\overline{x}) = (\\frac{1}{n})^2 [Var(x_1) + Var(x_2) + ... + Var(x_n)]$   Para toda $x_i$ se tiene $Var(x_i) = \\sigma^2$; por tanto, obtenemos   $Var(\\overline{x}) = (\\frac{1}{n})^2 [\\sigma^2 + \\sigma^2 + ... + \\sigma^2]$   Como en esta expresi\u00f3n hay *n* valores $\\sigma^2$, tenemos   $Var(\\overline{x}) = (\\frac{1}{n})^2 (n\\sigma^2) = \\frac{\\sigma^2}{n}$   Calculando ahora la ra\u00edz cuadrada, se obtiene la f\u00f3rmula de la desviaci\u00f3n est\u00e1ndar de $\\overline{x}$.   $\\sigma_{\\overline{x}} = \\sqrt{Var(\\overline{x}} = \\frac{\\sigma}{\\sqrt{n}}$  <p>Muestreo aleatorio con Minitab</p>"},{"location":"capitulo7/#muestreo-aleatorio-con-minitab","title":"Muestreo aleatorio con Minitab\u00b6","text":"<p>Si en un archivo de Minitab se encuentra una lista con los elementos de una poblaci\u00f3n, se puede usar dicho software para seleccionar una muestra aleatoria simple. Por ejemplo, en la columna 1 del conjunto de datos MetAreas se proporciona una lista de las 100 principales \u00e1reas metropolitanas de Estados Unidos y Canad\u00e1 (Places Rated Almanac\u2013The Millenium Edition 2000). La columna 2 contiene la puntuaci\u00f3n general asignada a cada \u00e1rea. En la tabla 7.6 se presentan las primeras 10 \u00e1reas metropolitanas con sus puntuaciones correspondientes. Suponga que pretende seleccionar una muestra aleatoria simple de 30 \u00e1reas metropolitanas con objeto de hacer un estudio sobre el costo de la vida en Estados Unidos y Canad\u00e1. Para seleccionar la muestra aleatoria se siguen los pasos que se indican a continuaci\u00f3n.  Paso 1. Seleccione el men\u00fa desplegable Calc. Paso 2. Elija Random Data. Paso 3. Seleccione Sample From Columns. Paso 4. Cuando el cuadro de di\u00e1logo Sample From Columns aparezca: Ingrese 30 en el cuadro Number of rows to sample. Introduzca Cl C2 en el cuadro From columns que se encuentra debajo. Ingrese C3 C4 en el cuadro Store samples in. Paso 5. Haga clic en OK.</p> <p>La muestra aleatoria con las 30 \u00e1reas metropolitanas aparece en las columnas C3 y C4.</p>"},{"location":"capitulo7/#muestreo-aleatorio-con-excel","title":"Muestreo aleatorio con Excel\u00b6","text":"<p>Si en un archivo de Excel se encuentra una lista con los elementos de una poblaci\u00f3n, se podr\u00e1 usar dicho software para seleccionar una muestra aleatoria simple. Por ejemplo, en la columna A del conjunto de datos MetAreas se proporciona una lista de las 100 principales \u00e1reas metropolitanas de Estados Unidos y Canad\u00e1 (Places Rated Almanac\u2013The Millenium Edition 2000). La columna B contiene el rating general asignado a cada \u00e1rea. En la tabla 7.6 se presentan las primeras 10 \u00e1reas metropolitanas con sus puntuaciones correspondientes. Suponga que quiere seleccionar una muestra aleatoria simple de 30 \u00e1reas metropolitanas con objeto de hacer un estudio de profundidad sobre el costo de la vida en Estados Unidos y Canad\u00e1.</p>"},{"location":"capitulo7/#muestreo-aleatorio-con-stattools","title":"Muestreo aleatorio con StatTools\u00b6","text":"<p>Si en un archivo de Excel se encuentra una lista con los elementos de una poblaci\u00f3n, se podr\u00e1 usar StatTools Random Sample Utility para seleccionar una muestra aleatoria simple. Por ejemplo, en la columna A del conjunto de datos MetAreas se proporciona una lista de las 100 principales \u00e1reas metropolitanas de Estados Unidos y Canad\u00e1 (Places Rated Almanac\u2013The Millenium Edition 2000). La columna B contiene la puntuaci\u00f3n general asignada a cada \u00e1rea. Suponga que quiere seleccionar una muestra aleatoria simple de 30 \u00e1reas metropolitanas con objeto de hacer un estudio de profundidad sobre el costo de la vida en Estados Unidos y Canad\u00e1. Se inicia con Data Set Manager a efecto de crear un conjunto de datos de StatTools utilizando el procedimiento descrito en el ap\u00e9ndice del cap\u00edtulo 1. Los pasos siguientes se utilizan para generar una muestra aleatoria simple de 30 \u00e1reas metropolitanas.</p> <p>Paso 1. D\u00e9 clic en la ficha **StatTools sobre la cinta. Paso 2. En el grupo Data Group, haga clic en **Data Utilities. Paso 3. Seleccione la opci\u00f3n **Random Sample. Paso 4. Cuando el cuadro de di\u00e1logo StatTools\u2013Random Sample aparezca: En la secci\u00f3n **Variables: Seleccione Metropolitan Area. Elija Rating. En la secci\u00f3n Options: Ingrese 1 en el cuadro Number of Samples. Ingrese 30 en el cuadro Sample Size. Haga clic en OK. La muestra aleatoria de 30 \u00e1reas metropolitanas aparecer\u00e1 en las columnas A y B de la hoja de trabajo titulada Random Sample.</p>"},{"location":"capitulo8/","title":"Capitulo 8","text":"8.1 Media poblacional:  $\\sigma$ conocida  <p>Para obtener una estimaci\u00f3n por intervalo para la media poblacional, es necesario conocer la desviaci\u00f3n est\u00e1ndar poblacional $(\\sigma)$ o la desviaci\u00f3n est\u00e1ndar muestral (s) para calcular el margen de error. En muchos casos, la desviaci\u00f3n est\u00e1ndar poblacional $(\\sigma)$ es desconocida, y se utiliza la desviaci\u00f3n est\u00e1ndar muestral (s) para calcular el margen de error. Sin embargo, en situaciones donde se dispone de datos hist\u00f3ricos o en aplicaciones de control de calidad, se puede conocer la desviaci\u00f3n est\u00e1ndar poblacional.</p> <p>En un ejemplo espec\u00edfico, Boutique Andina realiza estudios semanales seleccionando una muestra aleatoria simple de 100 clientes para conocer la cantidad que gastan en cada visita. Suponen que la desviaci\u00f3n est\u00e1ndar poblacional $(\\sigma)$ es conocida y tiene un valor de $\\sigma = 20Bs$, bas\u00e1ndose en datos hist\u00f3ricos que indican una distribuci\u00f3n normal en la poblaci\u00f3n. En una semana reciente, la media muestral obtenida fue $\\bar{x}=82Bs$. Esta media muestral sirve como estimaci\u00f3n puntual de la media poblacional $(\\mu)$.</p> <p>A continuaci\u00f3n, se aborda c\u00f3mo calcular un margen de error para esta estimaci\u00f3n y c\u00f3mo desarrollar una estimaci\u00f3n por intervalo para la media poblacional.</p>    Margen de error y estimaci\u00f3n por intervalo  <p>En el cap\u00edtulo 7 se menciona que la distribuci\u00f3n de muestreo de $\\bar{x}$ sirve para calcular la probabilidad de que $\\bar{x}$ est\u00e9 dentro de una distancia dada de $\\mu$. En el ejemplo de Boutique Andina, los datos hist\u00f3ricos indican que la poblaci\u00f3n constituida por las cantidades gastadas est\u00e1 distribuida normalmente y que su desviaci\u00f3n est\u00e1ndar es $\\sigma = 20$. De esta manera, utilizando lo aprendido en el cap\u00edtulo 7, se puede concluir que la distribuci\u00f3n de muestreo de $\\bar{x}$ sigue una distribuci\u00f3n normal con un error est\u00e1ndar de $\\sigma_{\\bar{x}}=\\sigma/\\sqrt{n}=20/ \\sqrt{100}=2$. En la fi gura 8.1 se presenta esta distribuci\u00f3n de muestreo. Puesto que indica c\u00f3mo est\u00e1n distribuidos los valores de x en torno a la media poblacional $\\mu$, la distribuci\u00f3n de muestreo de $\\bar{x}$ proporciona informaci\u00f3n acerca de la posible diferencia entre $\\bar{x}$ y $\\mu$.</p> <p>Figura 8.1 Distribuci\u00f3n de muestreo de la media muestral de las cantidades gastadas para muestras aleatorias simples de 100 clientes</p> In\u00a0[12]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\n\n# Nivel de significancia\nalfa = 0.05\n\n# Generar datos para la distribuci\u00f3n normal est\u00e1ndar (z)\nx = np.linspace(-4, 4, 1000)\ny = stats.norm.pdf(x)\n\n# Encontrar el valor cr\u00edtico para el nivel de significancia alfa/2\nvalor_critico = stats.norm.ppf(1 - alfa/2)\n\n# Crear el gr\u00e1fico con la l\u00ednea de color verde y etiqueta con el s\u00edmbolo mu (\u03bc)\nplt.figure(figsize=(9, 4))\nplt.plot(x, y, label=r'Distribuci\u00f3n Normal Est\u00e1ndar ($\\mu$)', color='green')  # Cambi\u00e9 el color a verde y a\u00f1ad\u00ed el s\u00edmbolo mu\n\n# Sombrear el \u00e1rea debajo de la l\u00ednea con un verde m\u00e1s oscuro\nplt.fill_between(x, y, color='#5CCB5F', alpha=0.3)\n\n# Etiqueta de texto 1: Distribuci\u00f3n de muestreo de x\u0304\nplt.text(-4, 0.20, 'Distribuci\u00f3n de muestreo\\n   de $\\\\bar{x}$', ha='left')\n\n# Etiqueta de texto 2: \u03c3/\u221an\nplt.text(4, 0.20, r'$\\sigma_{\\bar{x}}=\\frac{\\sigma}{\\sqrt{n}}= \\frac{20}{\\sqrt{100}} = 2$', fontsize=12, ha='right')\n\n# Establecer el color de fondo\nplt.gca().set_facecolor('#d4f8b7')  \n\n# Mostrar el gr\u00e1fico\nplt.grid(False)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt import scipy.stats as stats  # Nivel de significancia alfa = 0.05  # Generar datos para la distribuci\u00f3n normal est\u00e1ndar (z) x = np.linspace(-4, 4, 1000) y = stats.norm.pdf(x)  # Encontrar el valor cr\u00edtico para el nivel de significancia alfa/2 valor_critico = stats.norm.ppf(1 - alfa/2)  # Crear el gr\u00e1fico con la l\u00ednea de color verde y etiqueta con el s\u00edmbolo mu (\u03bc) plt.figure(figsize=(9, 4)) plt.plot(x, y, label=r'Distribuci\u00f3n Normal Est\u00e1ndar ($\\mu$)', color='green')  # Cambi\u00e9 el color a verde y a\u00f1ad\u00ed el s\u00edmbolo mu  # Sombrear el \u00e1rea debajo de la l\u00ednea con un verde m\u00e1s oscuro plt.fill_between(x, y, color='#5CCB5F', alpha=0.3)  # Etiqueta de texto 1: Distribuci\u00f3n de muestreo de x\u0304 plt.text(-4, 0.20, 'Distribuci\u00f3n de muestreo\\n   de $\\\\bar{x}$', ha='left')  # Etiqueta de texto 2: \u03c3/\u221an plt.text(4, 0.20, r'$\\sigma_{\\bar{x}}=\\frac{\\sigma}{\\sqrt{n}}= \\frac{20}{\\sqrt{100}} = 2$', fontsize=12, ha='right')  # Establecer el color de fondo plt.gca().set_facecolor('#d4f8b7')    # Mostrar el gr\u00e1fico plt.grid(False) plt.show() <p>En la introducci\u00f3n de este cap\u00edtulo se mencion\u00f3 la f\u00f3rmula general para estimar un intervalo de la media poblacional $\\mu$, la cual es $\\bar{x} \\pm \\text{margen de error}$. En el ejemplo de Boutique Andina, asumamos un margen de error de $3.92$ y calculemos una estimaci\u00f3n por intervalo para $\\mu$ usando $\\bar{x} \\pm 3.92$. Para comprender c\u00f3mo se interpreta esta estimaci\u00f3n por intervalo, consideremos los valores de $x$ que podr\u00edan obtenerse si se tomaran tres muestras aleatorias simples diferentes, cada una de $100$ clientes de Boutique Andina.</p> <p>La primera media muestral podr\u00eda dar el valor $\\bar{x}_1$. En este caso, el intervalo obtenido al restar $3.92$ de $\\bar{x}_1$ y sumar $3.92$ a $\\bar{x}_1$ abarca la media poblacional $\\mu$. Ahora, al razonar sobre la segunda media muestral con el valor $\\bar{x}_2$, observamos que el intervalo obtenido tambi\u00e9n comprende $\\mu$. Sin embargo, en el caso de la tercera media muestral con el valor $\\bar{x}_3$, el intervalo obtenido no abarca $\\mu$. Esto se debe a que $\\bar{x}_3$ cae en la cola superior de la distribuci\u00f3n de muestreo y dista m\u00e1s de $3.92$ de $\\mu$. Al restar y sumar $3.92$ a $\\bar{x}_3$, obtenemos un intervalo que no incluye $\\mu$.</p> <p>Figura 8.3 Intervalos obtenidos a partir de algunas medias muestrales localizadas en $\\bar{x}_1$, $\\bar{x}_2$ y $\\bar{x}_3$</p> In\u00a0[3]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\n\n# Nivel de significancia\nalfa = 0.05\n\n# Generar datos para la distribuci\u00f3n normal est\u00e1ndar (z)\nx = np.linspace(-4, 4, 1000)\ny = stats.norm.pdf(x)\n\n# Encontrar el valor cr\u00edtico para el nivel de significancia alfa/2\nvalor_critico = stats.norm.ppf(1 - alfa/2)\n\n# Crear el gr\u00e1fico con la l\u00ednea de color verde y etiqueta con el s\u00edmbolo mu (\u03bc)\nplt.figure(figsize=(9, 4))\nplt.plot(x, y, label=r'Distribuci\u00f3n Normal Est\u00e1ndar ($\\mu$)', color='green')  # Cambi\u00e9 el color a verde y a\u00f1ad\u00ed el s\u00edmbolo mu\n\n# Sombrear el \u00e1rea debajo de la l\u00ednea con un verde m\u00e1s oscuro\nplt.fill_between(x, y, where=(x &gt; -valor_critico) &amp; (x &lt; valor_critico), color='#5CCB5F', alpha=0.3)\n\n# Agregar l\u00edneas verticales en ambos lados\nplt.axvline(-valor_critico, color='black', linestyle='-', linewidth=1, ymax=0.2)\nplt.axvline(valor_critico, color='black', linestyle='-', linewidth=1, ymax=0.2)\nplt.axvline(0, color='black', linestyle='--', linewidth=1, ymax=0.55)\n\n# Etiqueta de texto 1: Distribuci\u00f3n de muestreo de x\u0304\nplt.text(-4, 0.20, 'Distribuci\u00f3n de muestreo\\n   de $\\\\bar{x}$', ha='left')\n\n# Etiqueta de texto 2: \u03c3/\u221an\nplt.text(4, 0.20, r'$\\sigma_{\\bar{x}} = 2$', fontsize=12, ha='right')\n\n# Etiqueta de texto 1: Distribuci\u00f3n de muestreo de x\u0304\nplt.text(0, 0.25, '$95\\%$ de todos los\\n   valores de $\\\\bar{x}$', ha='center')\n\n# Establecer el color de fondo\nplt.gca().set_facecolor('#d4f8b7')  \n\n# Mostrar el gr\u00e1fico\nplt.grid(False)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt import scipy.stats as stats  # Nivel de significancia alfa = 0.05  # Generar datos para la distribuci\u00f3n normal est\u00e1ndar (z) x = np.linspace(-4, 4, 1000) y = stats.norm.pdf(x)  # Encontrar el valor cr\u00edtico para el nivel de significancia alfa/2 valor_critico = stats.norm.ppf(1 - alfa/2)  # Crear el gr\u00e1fico con la l\u00ednea de color verde y etiqueta con el s\u00edmbolo mu (\u03bc) plt.figure(figsize=(9, 4)) plt.plot(x, y, label=r'Distribuci\u00f3n Normal Est\u00e1ndar ($\\mu$)', color='green')  # Cambi\u00e9 el color a verde y a\u00f1ad\u00ed el s\u00edmbolo mu  # Sombrear el \u00e1rea debajo de la l\u00ednea con un verde m\u00e1s oscuro plt.fill_between(x, y, where=(x &gt; -valor_critico) &amp; (x &lt; valor_critico), color='#5CCB5F', alpha=0.3)  # Agregar l\u00edneas verticales en ambos lados plt.axvline(-valor_critico, color='black', linestyle='-', linewidth=1, ymax=0.2) plt.axvline(valor_critico, color='black', linestyle='-', linewidth=1, ymax=0.2) plt.axvline(0, color='black', linestyle='--', linewidth=1, ymax=0.55)  # Etiqueta de texto 1: Distribuci\u00f3n de muestreo de x\u0304 plt.text(-4, 0.20, 'Distribuci\u00f3n de muestreo\\n   de $\\\\bar{x}$', ha='left')  # Etiqueta de texto 2: \u03c3/\u221an plt.text(4, 0.20, r'$\\sigma_{\\bar{x}} = 2$', fontsize=12, ha='right')  # Etiqueta de texto 1: Distribuci\u00f3n de muestreo de x\u0304 plt.text(0, 0.25, '$95\\%$ de todos los\\n   valores de $\\\\bar{x}$', ha='center')  # Establecer el color de fondo plt.gca().set_facecolor('#d4f8b7')    # Mostrar el gr\u00e1fico plt.grid(False) plt.show() <p>Cualquier media muestral $\\bar{x}$ que se encuentre dentro de la regi\u00f3n sombreada en la figura 8.3 generar\u00e1 un intervalo que contiene la media poblacional $\\mu$. Dado que el $95\\%$ de todas las posibles medias muestrales se ubican en la regi\u00f3n sombreada m\u00e1s oscura, el $95\\%$ de todos los intervalos construidos restando $3.92$ de $\\bar{x}$ y sumando $3.92$ a $\\bar{x}$ abarcar\u00e1n la media poblacional $\\mu$.</p> <p>En la \u00faltima semana, el equipo encargado de asegurar la calidad de Boutique Andina encuest\u00f3 a $100$ clientes y obtuvo una media muestral $\\bar{x}$ de $82$. Utilizando $\\bar{x} \\pm 3.92$ para construir la estimaci\u00f3n por intervalo, se obtiene $82 \\pm 3.92$. Por lo tanto, la estimaci\u00f3n por intervalo de $\\mu$ basada en los datos de la \u00faltima semana va de $78.08$ a $85.92$. Dado que el $95\\%$ de todos los intervalos construidos usando $\\bar{x} \\pm 3.92$ contendr\u00e1n la media poblacional, se tiene un $95\\%$ de confianza de que el intervalo de $78.08$ a $85.92$ contiene $\\mu$. Este intervalo tiene un nivel de confianza del $95\\%$. Al valor $0.95$ se le conoce como coeficiente de confianza, y al intervalo de $78.08$ a $85.92$ como intervalo de confianza del $95\\%$.</p> <p>Como el margen de error est\u00e1 dado por $z_{\\alpha/2}(\\sigma\\sqrt{n})$, la f\u00f3rmula general de una estimaci\u00f3n por intervalo de la media poblacional con \u03c3 conocida es la siguiente. En el ejemplo de Boutique Andina, mediante la expresi\u00f3n (8.1) se construye un intervalo de confianza de $95\\%$</p> <p>ESTIMACI\u00d3N POR INTERVALO DE LA MEDIA POBLACIONAL: \u03c3 CONOCIDA</p>     $$     \\begin{equation}     \\bar{x} \\pm z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} \\tag{8.1}     \\end{equation}     $$     <p>donde $1-\\alpha$ es el coeficiente de confianza y $z_{\\alpha/2}$ es el valor de $z$ que proporciona un \u00e1rea $\\alpha/2$ en la cola superior de la distribuci\u00f3n de probabilidad normal est\u00e1ndar.</p> <p>Con un coeficiente de confianza $(1 - \\alpha) = 0.95$, por lo tanto, $\\alpha = 0.05$. En la tabla de distribuci\u00f3n normal est\u00e1ndar se observa que un \u00e1rea de $\\alpha/2 = 0.05/2 = 0.025$ en la cola superior corresponde a $z_{0.025} = 1.96$. En el ejemplo de Boutique Andina, donde la media muestral es $\\bar{x} = 82$, la desviaci\u00f3n est\u00e1ndar es $\\sigma = 20$, y el tama\u00f1o de la muestra es $n = 100$, se obtiene</p>      $$     \\begin{equation}     82 \\pm 1.96\\frac{20}{\\sqrt{100}}     \\end{equation}     $$     $$     \\begin{equation}     82 \\pm 3.92     \\end{equation}     $$  <p>Por tanto, al emplear la expresi\u00f3n (8.1), el margen de error es 3.92 y el intervalo de confianza de $95\\%$ va de $82-3.92=78.08$ a $82+3.92=85.92.$ Aunque a menudo se usa un nivel de confi anza de $95\\%$, tambi\u00e9n suelen utilizarse otros niveles, como $90$ y $99\\%$. En la tabla 8.1 se muestran los valores de $z_{\\alpha/2}$ correspondientes a los niveles de confianza m\u00e1s utilizados. A partir de estos valores y de la expresi\u00f3n (8.1), el intervalo de confianza de $90\\%$ en el ejemplo de Boutique Andina es</p>      $$     \\begin{equation}     82 \\pm 1.645\\frac{20}{\\sqrt{100}}     \\end{equation}     $$     $$     \\begin{equation}     82 \\pm 3.29     \\end{equation}     $$  <p>Tabla 8.1 Valores de $z_{\\alpha/2}$ para los niveles de confianza m\u00e1s utilizados</p> Nivel de confianza $\\alpha$ $\\alpha/2$ $z_{\\alpha/2}$ 90% 0.10 0.05 1.645 95% 0.05 0.025 1.960 99% 0.01 0.005 2.576 <p>Por tanto, para $90\\%$ de confianza, el margen de error es $3.29$ y el intervalo de confianza es $82-3.29=78.71$ a $82+3.29=85.29$. De manera similar, el intervalo de $99\\%$ es</p>      $$     \\begin{equation}     82 \\pm 2.576\\frac{20}{\\sqrt{100}}     \\end{equation}     $$     $$     \\begin{equation}     82 \\pm 5.15     \\end{equation}     $$  <p>Entonces, para 99% de confi anza el margen de error es $5.15$ y el intervalo de confi anza es $82-5.15=76.85$ a $82+5.15=87.15$.</p> <p>Al comparar los resultados para los niveles de $90$, $95$ y $99\\%$, es claro que para tener mayor grado de confi anza, el margen de error, y con esto la amplitud del intervalo de confianza, debe ser mayor.</p>    Consejo pr\u00e1ctico  <p>Si la poblaci\u00f3n sigue una distribuci\u00f3n normal, la expresi\u00f3n (8.1) proporciona intervalos de confianza exactos, garantizando que el $95\\%$ de ellos contendr\u00e1n la media poblacional al usarla repetidamente. En situaciones no normales, la aproximaci\u00f3n del intervalo de confianza depende de la distribuci\u00f3n y del tama\u00f1o de la muestra. En general, un tama\u00f1o de muestra $\\geq 30$ es adecuado, aunque tama\u00f1os hasta 15 pueden ser aceptables si la poblaci\u00f3n es sim\u00e9trica. Para tama\u00f1os menores, se debe usar la expresi\u00f3n (8.1) solo con la suposici\u00f3n de aproximada normalidad.</p> NOTAS Y COMENTARIOS <ol> <li>En este m\u00e9todo de estimaci\u00f3n por intervalo, se asume que la desviaci\u00f3n est\u00e1ndar poblacional $\\sigma$ es conocida. Esta asunci\u00f3n implica tener datos hist\u00f3ricos o informaci\u00f3n previa que permita obtener una estimaci\u00f3n precisa de \u03c3 antes de tomar la muestra utilizada para estimar la media poblacional. Aunque no implica certeza absoluta sobre \u03c3, garantiza que la estimaci\u00f3n de la desviaci\u00f3n est\u00e1ndar se realiza antes de la toma de la muestra, evitando utilizar la misma muestra para estimar tanto la media como la desviaci\u00f3n est\u00e1ndar poblacionales.</li> <li>La expresi\u00f3n (8.1) para la estimaci\u00f3n por intervalo incluye el tama\u00f1o de la muestra $n$ en el denominador. Por lo tanto, si el tama\u00f1o de muestra actual resulta en un intervalo demasiado amplio para ser pr\u00e1ctico, se sugiere aumentar el tama\u00f1o de la muestra. Con un tama\u00f1o de muestra mayor, se logra un margen de error menor, un intervalo m\u00e1s estrecho y una mayor precisi\u00f3n en la estimaci\u00f3n. C\u00f3mo determinar el tama\u00f1o necesario de la muestra para alcanzar una precisi\u00f3n espec\u00edfica se aborda en la secci\u00f3n 8.3.</li> </ol> 8.2Media poblacional: $\\sigma$ desconocida          William Sealy Gosset, es el creador de la distribuci\u00f3n t. Gosset, que estudi\u00f3 matem\u00e1ticas en Oxford, trabajaba para Guinness Brewery en Dubl\u00edn, Irlanda. Desarroll\u00f3 la distribuci\u00f3n t cuando trabajaba sobre materiales a peque\u00f1a escala y con experimentos de temperatura               Se usa la misma muestra para calcular $\ud835\udf07$ y $\\sigma$. Cuando se utiliza s para estimar $\\sigma$, el margen de error y la estimaci\u00f3n por intervalo de la media poblacional se basan en una distribuci\u00f3n de probabilidad conocida como distribucion t. Aunque el desarrollo matem\u00e1tico de esta \u00faltima parte del supuesto de que la poblaci\u00f3n muestreada tiene una distribuci\u00f3n normal. La distribucion *t* depende del par\u00e1metro conocido como grados de libertad. Para un grado de libertad es \u00fanica, como lo es para dos grados o tres grados de libertad, etc. A medida que este n\u00famero aumenta, la diferencia entre la distribuci\u00f3n t y la distribuci\u00f3n normal est\u00e1ndar se reduce. La siguiente figura (figura 8.4) muestra las distribuciones t para 10 y 20 grados de libertad y su relaci\u00f3n con la distribuci\u00f3n de probabilidad normal est\u00e1ndar.      <p> Figura 8.4 Comparaci\u00f3n de la distribuci\u00f3n normal est\u00e1ndar con las distribuciones t para 10 y 20 grados de libertad</p> In\u00a0[13]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import t, norm\n\n# Generar datos para las distribuciones t y normal est\u00e1ndar\nx = np.linspace(-6, 6, 80)\ny_t_10 = t.pdf(x, df=10)\ny_t_20 = t.pdf(x, df=20)\ny_normal = norm.pdf(x)\n\n# Crear el gr\u00e1fico\nplt.figure(figsize=(10, 8))\nplt.plot(x, y_t_10, label='t-distribuci\u00f3n 10 grados de libertad', linewidth=2, color='black')\nplt.plot(x, y_t_20, label='t-distribuci\u00f3n 20 grados de libertad', linewidth=2, color='green')\nplt.plot(x, y_normal, label='Distribuci\u00f3n normal est\u00e1ndar', linestyle='dashed', linewidth=2, color='green')\n\n# Configurar el gr\u00e1fico\nplt.title('Comparaci\u00f3n de Distribuciones t y Normal Est\u00e1ndar')\nplt.grid(False)\nplt.ylim(-0.01, 0.43)\n\n# A\u00f1adir etiquetas directamente sobre las l\u00edneas\nplt.text(1.3, 0.20, 't-distribuci\u00f3n 10 grados de libertad', fontsize=9, color='black')\nplt.text(-5, 0.20, 't-distribuci\u00f3n 20 grados de libertad', fontsize=9, color='black')\nplt.text(-1, 0.40, 'Distribuci\u00f3n normal', fontsize=9, color='green')\n\n# Establecer el color de fondo\nplt.gca().set_facecolor('#d4f8b7')  \n\n# Pintar el fondo externo del gr\u00e1fico\nplt.gcf().patch.set_facecolor('#D4F8B7')\n\n# Mostrar el gr\u00e1fico\nplt.ylabel('Densidad de Probabilidad', fontsize=12)\nplt.legend()\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import t, norm  # Generar datos para las distribuciones t y normal est\u00e1ndar x = np.linspace(-6, 6, 80) y_t_10 = t.pdf(x, df=10) y_t_20 = t.pdf(x, df=20) y_normal = norm.pdf(x)  # Crear el gr\u00e1fico plt.figure(figsize=(10, 8)) plt.plot(x, y_t_10, label='t-distribuci\u00f3n 10 grados de libertad', linewidth=2, color='black') plt.plot(x, y_t_20, label='t-distribuci\u00f3n 20 grados de libertad', linewidth=2, color='green') plt.plot(x, y_normal, label='Distribuci\u00f3n normal est\u00e1ndar', linestyle='dashed', linewidth=2, color='green')  # Configurar el gr\u00e1fico plt.title('Comparaci\u00f3n de Distribuciones t y Normal Est\u00e1ndar') plt.grid(False) plt.ylim(-0.01, 0.43)  # A\u00f1adir etiquetas directamente sobre las l\u00edneas plt.text(1.3, 0.20, 't-distribuci\u00f3n 10 grados de libertad', fontsize=9, color='black') plt.text(-5, 0.20, 't-distribuci\u00f3n 20 grados de libertad', fontsize=9, color='black') plt.text(-1, 0.40, 'Distribuci\u00f3n normal', fontsize=9, color='green')  # Establecer el color de fondo plt.gca().set_facecolor('#d4f8b7')    # Pintar el fondo externo del gr\u00e1fico plt.gcf().patch.set_facecolor('#D4F8B7')  # Mostrar el gr\u00e1fico plt.ylabel('Densidad de Probabilidad', fontsize=12) plt.legend() plt.show() <p>Como se observa una distribuci\u00f3n t con m\u00e1s grados de libertad exhibe menos variabilidad y un mayor parecido con la distribuci\u00f3n normal est\u00e1ndar. Note tambi\u00e9n que la media de toda distribuci\u00f3n t es cero.</p> <p>Para denotar el \u00e1rea en la cola superior de la distribuci\u00f3n t, se le coloca un sub\u00edndice. Por ejemplo, as\u00ed como se us\u00f3 $z_{0.025}$ para el valor de z, tambi\u00e9n se usar\u00e1 $t_{0.025}$ para el valor de t que deja en la cola superior de la distribuci\u00f3n t. En general, se manejar\u00e1 la notaci\u00f3n $t_{\\frac{\u03b1}{2}}$ para representar el valor de t que deja un \u00e1rea de $\\frac{\u03b1}{2}$ en la cola superior de la distribuci\u00f3n t (figura 8.5).</p> <p> Figura 8.5 Distribuci\u00f3n t con un \u00e1rea o probabilidad \u03b1/2 en la cola superior</p> In\u00a0[14]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\n\n# Par\u00e1metros de la distribuci\u00f3n t\ngrados_libertad = 10\nalfa = 0.05  # Nivel de significancia\n\n# Generar datos para la distribuci\u00f3n t\nx = np.linspace(-4, 4, 1000)\ny = stats.t.pdf(x, df=grados_libertad)\n\n# Encontrar el valor cr\u00edtico para el nivel de significancia alfa/2\nvalor_critico = stats.t.ppf(1 - alfa/2, df=grados_libertad)\n\n# Crear el gr\u00e1fico\nplt.figure(figsize=(8, 6))\n\n# Plotear la l\u00ednea\nplt.plot(x, y, color='#5CCB5f', label=f'Distribuci\u00f3n t con {grados_libertad} grados de libertad')\n\n# Resaltar el \u00e1rea en la cola superior con fondo verde\nx_fill = np.linspace(valor_critico, 4, 100)\ny_fill = stats.t.pdf(x_fill, df=grados_libertad)\nplt.fill_between(x_fill, y_fill, color='green', alpha=0.3, label=f'\u00c1rea de probabilidad {alfa/2} en la cola superior', edgecolor='black')\n\n# Calcular la altura del \u00e1rea resaltada\naltura_area_resaltada = np.max(y_fill)\n\n# Marcar el valor cr\u00edtico en el eje x y ajustar la l\u00ednea a la altura del \u00e1rea resaltada\nplt.axvline(valor_critico, ymax=altura_area_resaltada, color='green', linestyle='-', label=f'Valor cr\u00edtico: {valor_critico:.2f}')\n\n# A\u00f1adir etiquetas y leyenda\nplt.title('Distribuci\u00f3n t con \u00c1rea de Probabilidad en la Cola Superior')\nplt.xlabel('X')\nplt.ylabel('Densidad de Probabilidad')\nplt.legend()\n\n# Establecer el color de fondo\nplt.gca().set_facecolor('#d4f8b7')  \n\n# Pintar el fondo externo del gr\u00e1fico\nplt.gcf().set_facecolor('#D4F8B7')\n\n# Mostrar el gr\u00e1fico\nplt.grid(False)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt import scipy.stats as stats  # Par\u00e1metros de la distribuci\u00f3n t grados_libertad = 10 alfa = 0.05  # Nivel de significancia  # Generar datos para la distribuci\u00f3n t x = np.linspace(-4, 4, 1000) y = stats.t.pdf(x, df=grados_libertad)  # Encontrar el valor cr\u00edtico para el nivel de significancia alfa/2 valor_critico = stats.t.ppf(1 - alfa/2, df=grados_libertad)  # Crear el gr\u00e1fico plt.figure(figsize=(8, 6))  # Plotear la l\u00ednea plt.plot(x, y, color='#5CCB5f', label=f'Distribuci\u00f3n t con {grados_libertad} grados de libertad')  # Resaltar el \u00e1rea en la cola superior con fondo verde x_fill = np.linspace(valor_critico, 4, 100) y_fill = stats.t.pdf(x_fill, df=grados_libertad) plt.fill_between(x_fill, y_fill, color='green', alpha=0.3, label=f'\u00c1rea de probabilidad {alfa/2} en la cola superior', edgecolor='black')  # Calcular la altura del \u00e1rea resaltada altura_area_resaltada = np.max(y_fill)  # Marcar el valor cr\u00edtico en el eje x y ajustar la l\u00ednea a la altura del \u00e1rea resaltada plt.axvline(valor_critico, ymax=altura_area_resaltada, color='green', linestyle='-', label=f'Valor cr\u00edtico: {valor_critico:.2f}')  # A\u00f1adir etiquetas y leyenda plt.title('Distribuci\u00f3n t con \u00c1rea de Probabilidad en la Cola Superior') plt.xlabel('X') plt.ylabel('Densidad de Probabilidad') plt.legend()  # Establecer el color de fondo plt.gca().set_facecolor('#d4f8b7')    # Pintar el fondo externo del gr\u00e1fico plt.gcf().set_facecolor('#D4F8B7')  # Mostrar el gr\u00e1fico plt.grid(False) plt.show() <p>En la tabla 8.2 se muestra una parte de la distribucion t. Cada fila corresponde a una distribuci\u00f3n t distinta con los grados de libertad que se indican. Por ejemplo, en la distribuci\u00f3n t con  9  grados de libertad,  $t_{0.025}=2.262$ . De manera similar, en la distribuci\u00f3n t con  60  grados de libertad,  $t_{0.025}=2.000$ . A medida que estos grados aumentan,  $t_{0.025}$  se aproxima a  $z_{0.025}=1.96$ El valor  z  de la distribuci\u00f3n normal est\u00e1ndar se encuentra en la fila correspondiente a infinitos grados de libertad (etiquetado como  \u221e ) de la tabla de distribuciones t. Si los grados de libertad son m\u00e1s de 100, se puede usar la fila correspondiente a infinitos grados para aproximar el verdadero valor de t; en otras palabras, para m\u00e1s de 100 grados de libertad, el valor z normal est\u00e1ndar proporciona una buena aproximaci\u00f3n del valor t</p> <p>TABLA 8.2  Valores seleccionados de la tabla de distribuci\u00f3n t*</p> Grados de libertad \u00c1rea en la cola superior 0.20 0.10 0.05 0.025 0.01 0.005 1 1.376 3.078 6.314 12.706 31.821 63.656 2 1.061 1.886 2.920 4.303 6.965 9.925 3 0.978 1.638 2.353 3.182 4.541 5.841 4 0.941 1.533 2.132 2.776 3.747 4.604 5 0.920 1.476 2.015 2.571 3.365 4.032 6 0.906 1.440 1.943 2.447 3.143 3.707 7 0.896 1.415 1.895 2.365 2.998 3.499 8 0.889 1.397 1.860 2.306 2.896 3.355 9 0.883 1.383 1.833 2.262 2.821 3.250 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 60 0.848 1.296 1.671 2.000 2.390 2.660 61 0.848 1.296 1.670 2.000 2.389 2.659 62 0.847 1.295 1.670 1.999 2.388 2.657 63 0.847 1.295 1.669 1.998 2.387 2.656 64 0.847 1.295 1.669 1.998 2.386 2.655 65 0.847 1.295 1.669 1.997 2.385 2.654 66 0.847 1.295 1.668 1.997 2.384 2.652 67 0.847 1.294 1.668 1.996 2.383 2.651 68 0.847 1.294 1.668 1.995 2.382 2.650 69 0.847 1.294 1.667 1.995 2.382 2.649 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 90 0.846 1.291 1.662 1.987 2.368 2.632 91 0.846 1.291 1.662 1.986 2.368 2.631 92 0.846 1.291 1.662 1.986 2.368 2.630 93 0.846 1.291 1.661 1.986 2.367 2.630 94 0.845 1.291 1.661 1.986 2.367 2.629 95 0.845 1.291 1.661 1.985 2.366 2.629 96 0.845 1.290 1.661 1.985 2.366 2.628 97 0.845 1.290 1.661 1.985 2.365 2.627 98 0.845 1.290 1.661 1.984 2.365 2.627 99 0.845 1.290 1.660 1.984 2.364 2.626 100 0.845 1.290 1.660 1.984 2.364 2.626 \u221e 0.842 1.282 1.645 1.960 2.326 2.576 <p>ESTIMACI\u00d3N POR INTERVALO DE LA MEDIA POBLACIONAL: \u03c3 DESCONOCIDA</p>               $$ \\bar{x} \\pm t_{\u03b1/2}  \\frac{s}{\\sqrt{n}}\\tag{8.2}$$          <p>Donde:</p> <p>s es la desviaci\u00f3n est\u00e1ndar muestral.</p> <p>($1-\\alpha$) es el coeficiente de confianza y $t_{\u03b1/2}$ es el valor de t que proporciona un \u00e1rea ${\u03b1/2}$ en la cola superior de la distribuci\u00f3n t con $n - 1$ grados de libertad. </p> <p>El n\u00famero de grados de libertad (n-1) para el valor de t en la expresi\u00f3n (8.2) se debe al uso de s como estimaci\u00f3n de la desviaci\u00f3n est\u00e1ndar poblacional $\u03c3$. La expresi\u00f3n para calcular la desviaci\u00f3n est\u00e1ndar muestral es</p> <p>$$ s=\\sqrt{\\frac{\u03a3(x_{i}-\\bar{x})^2}{n-1}}$$</p> <p>Los grados de libertad se refieren al n\u00famero de valores independientes en el c\u00e1lculo de $\u03a3(x_{i}-\\bar{x})^2$ es decir $x_{1}-\\bar{x},x_{2}-\\bar{x},\u22ef,x_{n}-\\bar{x}$ Se hab\u00eda indicado que en cualquier conjunto de datos $\u03a3(x_{i}-\\bar{x})^2=0$. Por tanto, \u00fanicamente n -1 de los valores $x_{i}-\\bar{x}$ son independientes; si (n-1) valores se conocen, el restante puede determinarse con la condicion que $x_{i}-\\bar{x}$ sume $0$</p> <p>Para ilustrar la estimaci\u00f3n por intervalo en el caso de $\u03c3$ desconocida, se considerar\u00e1 un estudio realizado para estimar la media del adeudo en las tarjetas de cr\u00e9dito en la poblaci\u00f3n de familias de Boliva. En la tabla 8.3 se presentan los saldos en las tarjetas de cr\u00e9dito de una muestra de n = 70 familias.</p> <p> Tabla 8.3  Saldos en las tarjetas de cr\u00e9dito de una muestra de 70 familias </p> 9430 14661 7159 9071 9691 11032 7535 12195 8137 3603 11448 6525 4078 10544 9467 16804 8279 5239 5604 13659 12595 13479 5649 6195 5179 7061 7917 14044 11298 12584 4416 6245 11346 6817 4353 15415 10676 13021 12806 6845 3467 15917 1627 9719 4972 10493 6191 12591 10112 2200 11356 615 12851 9743 6567 10746 7117 13627 5337 10324 13627 12744 9465 12557 8372 18719 5742 19263 6232 <p>En esta ocasi\u00f3n no se cuenta con una estimaci\u00f3n previa de la desviaci\u00f3n est\u00e1ndar poblacional $\u03c3$. Por tanto, deber\u00e1n utilizarse los datos muestrales para estimar tanto la media como la desviaci\u00f3n est\u00e1ndar poblacionales. Con los datos de la tabla 8.3 calculamos la media muestral $\\bar{x}=9 312$ Bs. y la desviaci\u00f3n est\u00e1ndar muestral $s=4 007$ Bs. Con 95% de confianza y n-1 = 69 grados de libertad podemos usar la tabla 8.2 para obtener el valor apropiado de $t_{0.025}$ El valor de t que se necesita est\u00e1 en la fila que indica 69 grados de libertad y en la columna correspondiente a 0.025 en la cola superior. El valor que se encuentra en $t_{0.025} =1.995$.</p> <p>Con la expresi\u00f3n (8.2) para calcular la estimaci\u00f3n por intervalo de la media poblacional de los saldos en las tarjetas de cr\u00e9dito tenemos:</p> <p>$$9312\u00b11.995\\frac{4007}{\\sqrt{70}}$$</p> <p>$$9312\u00b1995$$</p> <p>La estimaci\u00f3n puntual de la media poblacional es 9312 Bs , el margen de error es 955 Bs y el intervalo de confianza de 95% va de $9312-955=8 357$ Bs a $9 312 + 955 = 10 267 $ Bs</p> <p>En consecuencia,se tiene 95% de confianza de que la media de los saldos en las tarjetas de cr\u00e9dito de la poblaci\u00f3n de todas las familias est\u00e1 entre 8357 Bs y 10 267 Bs.</p> <p> TABLA 8.4  Duraci\u00f3n de la capacitaci\u00f3n, en d\u00edas, para la muestra de 20 empleados de Wiltech</p> 52 59 54 42 44 50 42 48 55 54 60 55 44 62 62 57 45 46 43 56 <p>En la figura 8.7 aparece un histograma de los datos. Con base en \u00e9ste, \u00bfqu\u00e9 se puede decir de la distribuci\u00f3n de la poblaci\u00f3n?  Figura 8.7 Histograma sobre la duraci\u00f3n de la capacitaci\u00f3n en la muestra de Wiltech </p> In\u00a0[15]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Datos proporcionados\nduraciones = [40, 45, 50, 55, 60, 65]\nfrecuencias = [5, 3, 4, 5, 3]\n\n# Crear figura\nfig, ax = plt.subplots()\n\n# Crear histograma con color personalizado\nax.bar(duraciones[:-1], frecuencias, width=5, edgecolor='black', color='#5ccb5f')\n\n# Configurar etiquetas y t\u00edtulo\nax.set_xlabel('Duraci\u00f3n de capacitaci\u00f3n (d\u00edas)')\nax.set_ylabel('Frecuencia')\nax.set_title('Histograma de Duraci\u00f3n de Capacitaci\u00f3n')\n\n# Ajustar el color de fondo\nax.set_facecolor(\"#d4f8b7\")\n# Pintar el fondo externo del gr\u00e1fico\nfig.patch.set_facecolor('#D4F8B7')\n\n# Agregar borde externo\nfor spine in ax.spines.values():\n    spine.set_edgecolor('#009929')\n\n# Mostrar el histograma\nplt.show()\n</pre> import matplotlib.pyplot as plt  # Datos proporcionados duraciones = [40, 45, 50, 55, 60, 65] frecuencias = [5, 3, 4, 5, 3]  # Crear figura fig, ax = plt.subplots()  # Crear histograma con color personalizado ax.bar(duraciones[:-1], frecuencias, width=5, edgecolor='black', color='#5ccb5f')  # Configurar etiquetas y t\u00edtulo ax.set_xlabel('Duraci\u00f3n de capacitaci\u00f3n (d\u00edas)') ax.set_ylabel('Frecuencia') ax.set_title('Histograma de Duraci\u00f3n de Capacitaci\u00f3n')  # Ajustar el color de fondo ax.set_facecolor(\"#d4f8b7\") # Pintar el fondo externo del gr\u00e1fico fig.patch.set_facecolor('#D4F8B7')  # Agregar borde externo for spine in ax.spines.values():     spine.set_edgecolor('#009929')  # Mostrar el histograma plt.show() <ul> <li>Primero, con base en los datos muestrales, no es posible concluir que la poblaci\u00f3n sea normal, si bien no se tienen evidencias de sesgo o de observaciones at\u00edpicas. Por tanto, mediante los lineamientos de la subsecci\u00f3n anterior, se concluye que una estimaci\u00f3n por intervalo basada en la distribuci\u00f3n t parece ser aceptable para esta muestra de 20 empleados.</li> </ul> <p>A continuaci\u00f3n se calcula la media muestral y la desviaci\u00f3n est\u00e1ndar muestral. $$\\bar{x}=\\frac{\u03a3x_{i}}{n}=\\frac{1030}{20}=51.5 d\u00edas$$</p> <p>$$s=\\sqrt{\\frac{\u03a3(x_{i}-\\bar{x})^2}{n-1}}=\\sqrt{\\frac{889}{20-1}}=6.84 d\u00edas$$ Para dar un intervalo de confianza de 95%, se usa la tabla 8.2 con $n-1=19$ grados de libertad y se obtiene $t_{0.025}=2.093$. La expresi\u00f3n (8.2) suministra la estimaci\u00f3n por intervalo de la media poblacional. $$51.5 \u00b1 2.093(\\frac{6.84}{\\sqrt{20}})$$ $$51.5 \u00b1 3.2$$ La estimaci\u00f3n puntual de la media poblacional es 51.5 d\u00edas. El margen de error es 3.2 d\u00edas y el intervalo de confianza de 95% va de $51.5 - 3.2 = 48.3$ d\u00edas a $51.5 + 3.2 = 54.7$ d\u00edas. Usar un histograma de los datos muestrales para tener informaci\u00f3n acerca de la distribuci\u00f3n de la poblaci\u00f3n no es siempre concluyente, pero en muchos casos es la \u00fanica informaci\u00f3n disponible. El histograma, junto con la opini\u00f3n del analista, suele utilizarse para decidir si es adecuado usar la expresi\u00f3n (8.2) para obtener una estimaci\u00f3n por intervalo.</p> In\u00a0[\u00a0]: Copied! <pre>from scipy.stats import t\n\ngrados_libertad = 16\n\n# a) A la derecha de 2.120\narea_a = t.sf(2.120, df=grados_libertad)\nprint(\"a) A la derecha de 2.120:\", area_a)\n\n# b) A la izquierda de 1.337\narea_b = t.cdf(1.337, df=grados_libertad)\nprint(\"b) A la izquierda de 1.337:\", area_b)\n\n# c) A la izquierda de -1.746\narea_c = t.cdf(-1.746, df=grados_libertad)\nprint(\"c) A la izquierda de -1.746:\", area_c)\n\n# d) A la derecha de 2.583\narea_d = t.sf(2.583, df=grados_libertad)\nprint(\"d) A la derecha de 2.583:\", area_d)\n\n# e) Entre -2.120 y 2.120\narea_e = t.cdf(2.120, df=grados_libertad) - t.cdf(-2.120, df=grados_libertad)\nprint(\"e) Entre -2.120 y 2.120:\", area_e)\n\n# f) Entre -1.746 y 1.746\narea_f = t.cdf(1.746, df=grados_libertad) - t.cdf(-1.746, df=grados_libertad)\nprint(\"f) Entre -1.746 y 1.746:\", area_f)\n</pre> from scipy.stats import t  grados_libertad = 16  # a) A la derecha de 2.120 area_a = t.sf(2.120, df=grados_libertad) print(\"a) A la derecha de 2.120:\", area_a)  # b) A la izquierda de 1.337 area_b = t.cdf(1.337, df=grados_libertad) print(\"b) A la izquierda de 1.337:\", area_b)  # c) A la izquierda de -1.746 area_c = t.cdf(-1.746, df=grados_libertad) print(\"c) A la izquierda de -1.746:\", area_c)  # d) A la derecha de 2.583 area_d = t.sf(2.583, df=grados_libertad) print(\"d) A la derecha de 2.583:\", area_d)  # e) Entre -2.120 y 2.120 area_e = t.cdf(2.120, df=grados_libertad) - t.cdf(-2.120, df=grados_libertad) print(\"e) Entre -2.120 y 2.120:\", area_e)  # f) Entre -1.746 y 1.746 area_f = t.cdf(1.746, df=grados_libertad) - t.cdf(-1.746, df=grados_libertad) print(\"f) Entre -1.746 y 1.746:\", area_f) <ol> <li>Encuentre los valores de t para las situaciones siguientes.</li> </ol> <p>a) Un \u00e1rea de 0.025 en la cola superior, con 12 grados de libertad.</p> <p>b) Un \u00e1rea de 0.05 en la cola inferior, con 50 grados de libertad.</p> <p>c) Un \u00e1rea de 0.01 en la cola superior, con 30 grados de libertad.</p> <p>d) Entre los que queda 90% del \u00e1rea, con 25 grados de libertad.</p> <p>e) Entre los que queda 95% del \u00e1rea, con 45 grados de libertad.</p> In\u00a0[16]: Copied! <pre>from scipy.stats import t\n\n# a) Un \u00e1rea de 0.025 en la cola superior, con 12 grados de libertad.\nt_a = round(t.ppf(1 - 0.025, df=12), 3)\nprint(\"a) Valor de t:\", t_a)\n\n# b) Un \u00e1rea de 0.05 en la cola inferior, con 50 grados de libertad.\nt_b = round(t.ppf(0.05, df=50), 3)\nprint(\"b) Valor de t:\", t_b)\n\n# c) Un \u00e1rea de 0.01 en la cola superior, con 30 grados de libertad.\nt_c = round(t.ppf(1 - 0.01, df=30), 3)\nprint(\"c) Valor de t:\", t_c)\n\n# d) Entre los que queda 90% del \u00e1rea, con 25 grados de libertad.\nt_d_lower = round(t.ppf(0.05, df=25), 3)\nt_d_upper = round(t.ppf(0.95, df=25), 3)\nprint(\"d) Valores de t:\", t_d_lower, t_d_upper)\n\n# e) Entre los que queda 95% del \u00e1rea, con 45 grados de libertad.\nt_e_lower = round(t.ppf(0.025, df=45), 3)\nt_e_upper = round(t.ppf(0.975, df=45), 3)\nprint(\"e) Valores de t:\", t_e_lower, t_e_upper)\n</pre> from scipy.stats import t  # a) Un \u00e1rea de 0.025 en la cola superior, con 12 grados de libertad. t_a = round(t.ppf(1 - 0.025, df=12), 3) print(\"a) Valor de t:\", t_a)  # b) Un \u00e1rea de 0.05 en la cola inferior, con 50 grados de libertad. t_b = round(t.ppf(0.05, df=50), 3) print(\"b) Valor de t:\", t_b)  # c) Un \u00e1rea de 0.01 en la cola superior, con 30 grados de libertad. t_c = round(t.ppf(1 - 0.01, df=30), 3) print(\"c) Valor de t:\", t_c)  # d) Entre los que queda 90% del \u00e1rea, con 25 grados de libertad. t_d_lower = round(t.ppf(0.05, df=25), 3) t_d_upper = round(t.ppf(0.95, df=25), 3) print(\"d) Valores de t:\", t_d_lower, t_d_upper)  # e) Entre los que queda 95% del \u00e1rea, con 45 grados de libertad. t_e_lower = round(t.ppf(0.025, df=45), 3) t_e_upper = round(t.ppf(0.975, df=45), 3) print(\"e) Valores de t:\", t_e_lower, t_e_upper)  <pre>a) Valor de t: 2.179\nb) Valor de t: -1.676\nc) Valor de t: 2.457\nd) Valores de t: -1.708 1.708\ne) Valores de t: -2.014 2.014\n</pre> 8.3Determinaci\u00f3n del tama\u00f1o de la muestra          En esta seccion se presenta un procedimiento para determinar el tama\u00f1o de muestra que se necesita para teer un margen de error especifico establecido antes de tomar la muestra.               En los consejos pr\u00e1cticos de las dos secciones anteriores se habl\u00f3 del papel del tama\u00f1o de la  muestra para obtener una buena aproximaci\u00f3n a los intervalos de confi anza en los casos en  que la poblaci\u00f3n no tiene una distribuci\u00f3n normal. Ahora se enfoca la atenci\u00f3n en otro aspecto  relacionado con el tama\u00f1o de la muestra, y se describe c\u00f3mo elegir un tama\u00f1o sufi cientemente  grande para obtener un margen de error deseado. Para explicar esto, se vuelve al caso de la  secci\u00f3n 8.1 en el que se ten\u00eda una \u03c3 conocida. Con la expresi\u00f3n (8.1), el intervalo de estimaci\u00f3n  est\u00e1 dado por:                       $$ \\bar{x} \\pm t_{\u03b1/2}  \\frac{s}{\\sqrt{n}}$$          <pre></pre> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p>         La ecuacion(8.3) proporciona una buena recomendacion del tama\u00f1o de la muestra.         Sin embargo, la opinion del analista cuenta para determinar si el tama\u00f1o de muestra final debe ajustarse hacia arriba.      <p>La cantidad \\( z_{\\alpha/2} \\left( \\frac{\\sigma}{\\sqrt{n}} \\right) \\) es el margen de error. De manera que, como se ve, \\( z_{\\alpha/2} \\), la desviaci\u00f3n est\u00e1ndar poblacional \\( \\sigma \\), y el tama\u00f1o de la muestra \\( n \\) se combinan para determinar el margen de error. Una vez que se selecciona el coeficiente de confianza \\(1 - \\alpha\\), \\( z_{\\alpha/2} \\) puede ser determinado. Por tanto, si se tiene el valor de \\( \\sigma \\), es posible encontrar el tama\u00f1o de muestra \\( n \\) necesario para proporcionar cualquier margen de error deseado. A continuaci\u00f3n se presenta el desarrollo de la f\u00f3rmula utilizada para calcular el tama\u00f1o \\( n \\) de muestra deseado.    <p> Sea E = el margen de error deaseado:</p> </p>              $$ E = z_{\\alpha/2} \\left( \\frac{\\sigma}{\\sqrt{n}} \\right) $$          <p>Al despejar \\( \\sqrt{n} \\) tenemos</p>              $$ \\sqrt{n} = \\left( \\frac{z_{\\frac{\\alpha}{2}} \\sigma}{E} \\right) $$          <p>Al elevar al cuadrado ambos lados de esta ecuaci\u00f3n, se obtiene la expresi\u00f3n siguiente para el  tama\u00f1o de la muestra.     </p> <p> </p> TAMA\u00d1O DE LA MUESTRA PARA UNA ESTIMACI\u00d3N POR INTERVALO DE LA MEDIA POBLACIONAL <p> </p>              $$ n = \\left( \\frac{(z_{\\frac{\\alpha}{2}})^2 \\sigma} {E^2}^2 \\right)\\tag{8,3}$$          <p> Este tama\u00f1o de muestra proporciona el margen de error deseado al nivel de confianza elegido. En la ecuaci\u00f3n (8.3), \\( E \\) es el margen de error que el usuario est\u00e1 dispuesto a aceptar, y el valor \\( z_{\\alpha/2} \\) es consecuencia directa del nivel de confianza que se utilizar\u00e1 para calcular la estimaci\u00f3n por intervalo. A reserva de la decisi\u00f3n del usuario, el 95% de confianza es el valor m\u00e1s frecuentemente elegido (\\( z_{0.025} \\approx 1.96 \\)).</p> <p>Por \u00faltimo, para usar la ecuaci\u00f3n (8.3) es necesario contar con el valor de la desviaci\u00f3n est\u00e1ndar poblacional \\( \\sigma \\). Sin embargo, aun cuando este valor no se conozca, puede utilizarse la ecuaci\u00f3n (8.3) siempre que se tenga un valor preliminar o un valor planeado de \\( \\sigma \\). En la pr\u00e1ctica, suele usarse alguno de los procedimientos siguientes para obtenerlo.</p> <p>El valor planeado de la desviacion estandar poblacional o debe especificarse antes de determinar el tama\u00f1o de la muestra. Aqui se ofrecen tres metodos para obtener este valor planeado de \\(\\sigma\\) </p> <li>Se utiliza como valor planeado de \\( \\sigma \\) una estimaci\u00f3n de la desviaci\u00f3n est\u00e1ndar poblacional calculada a partir de datos de estudios anteriores.</li> <li>Se opta por un estudio piloto seleccionando una muestra preliminar. La desviaci\u00f3n est\u00e1ndar muestral obtenida de la muestra preliminar puede usarse como valor planeado de \\( \\sigma \\).</li> <li>Se usa el juicio personal para \u201cadivinar el mejor\u201d valor de \\( \\sigma \\). Por ejemplo, se puede empezar por estimar el mayor y el menor valor en los datos de la poblaci\u00f3n. La diferencia entre ambos valores proporciona una estimaci\u00f3n del rango de los datos. Por \u00faltimo, este valor dividido entre 4 suele considerarse como una aproximaci\u00f3n burda a la desviaci\u00f3n est\u00e1ndar y tomarse como un valor planeado aceptable de \\( \\sigma \\).</li> <pre></pre> <p><p>Se considera el ejemplo siguiente para mostrar el uso de la ecuaci\u00f3n (8.3) en la determinaci\u00f3n del tama\u00f1o de la muestra. En un estudio previo para investigar el costo de la renta de autom\u00f3viles en Bolivia se encontr\u00f3 que el costo medio de rentar un veh\u00edculo mediano era aproximadamente de 200Bs por d\u00eda. Suponga que la organizaci\u00f3n que realiz\u00f3 dicho estudio quiere realizar otro para estimar la media poblacional del costo de las rentas por d\u00eda de autom\u00f3viles medianos en Bolivia.</p> </p> <p>Al dise\u00f1ar el nuevo estudio, el director del proyecto especific\u00f3 que la media poblacional de las rentas por d\u00eda debe estimarse con un margen de error de 2Bs y que se desea un nivel de 95% de confianza. El director del proyecto especific\u00f3 un margen de error deseable de \\( E = 2 \\), y el nivel de confianza del 95% indica que \\( z_{0.025} \\approx 1.96 \\). Por tanto, s\u00f3lo falta el valor planeado de la desviaci\u00f3n est\u00e1ndar poblacional \\( \\sigma \\) para calcular el tama\u00f1o de muestra deseado. En este punto, un analista revis\u00f3 los datos muestrales del estudio anterior y encontr\u00f3 que la desviaci\u00f3n est\u00e1ndar muestral del costo de la renta diaria era 9.65Bs. Al utilizar 9.65Bs como valor planeado de \\( \\sigma \\), tenemos:     </p> <p>\\(n = \\left( \\frac{(z_{\\frac{\\alpha}{2}})^2 \\sigma} {E^2}^2 \\right)\\)</p> <p>\\( n = \\frac{(1.96)^2 \\cdot (9.65)^2}{(2)^2} \\approx 89.43 \\)</p> <p>De esta manera, el tama\u00f1o de muestra necesario para obtener un margen de error de 2Bs debe ser de por lo menos 89.43 rentas de autom\u00f3viles medianos. En casos como \u00e9ste, en los que el valor de \\( n \\) no es un n\u00famero entero, se redondea al siguiente valor entero; as\u00ed que el tama\u00f1o de muestras que se aconseja es 90 rentas de autom\u00f3viles medianos.</p> <p>Ahora  resolvemos el ejemplo anterior con python</p> In\u00a0[11]: Copied! <pre>import math\n\n# Datos dados\nE = 2  # Margen de error deseado\nconfianza = 0.95  # Nivel de confianza\nz = 1.96  # Valor cr\u00edtico para el nivel de confianza del 95%\nsigma = 9.65  # Desviaci\u00f3n est\u00e1ndar muestral\n\n# Calcular el tama\u00f1o de muestra\nn = math.ceil((z ** 2 * sigma ** 2) / E ** 2)\n\nprint(f\"Tama\u00f1o de muestra necesario: {n}\")\n#redondeando el resultado seria 90\n</pre> import math  # Datos dados E = 2  # Margen de error deseado confianza = 0.95  # Nivel de confianza z = 1.96  # Valor cr\u00edtico para el nivel de confianza del 95% sigma = 9.65  # Desviaci\u00f3n est\u00e1ndar muestral  # Calcular el tama\u00f1o de muestra n = math.ceil((z ** 2 * sigma ** 2) / E ** 2)  print(f\"Tama\u00f1o de muestra necesario: {n}\") #redondeando el resultado seria 90 <pre>Tama\u00f1o de muestra necesario: 90\n</pre> <p>$M\u00e9todos$</p> <p>1. \u00bfQu\u00e9 tan grande debe seleccionarse una muestra para tener un intervalo de confianza de 95%  con un margen de error de 10? Suponga que la desviaci\u00f3n est\u00e1ndar poblacional es 40. </p> In\u00a0[10]: Copied! <pre>import math\n\n# Datos dados\nconfianza = 0.95  # Nivel de confianza\nz= 1.96  # Valor cr\u00edtico para el nivel de confianza del 95%\nsigma = 40  # Desviaci\u00f3n est\u00e1ndar poblacional\nE = 10  # Margen de error deseado\n\n# Calcular el tama\u00f1o de muestra\nn = math.ceil((z ** 2 * sigma ** 2) / E ** 2)\n\nprint(f\"Tama\u00f1o de muestra necesario: {n}\")\n</pre> import math  # Datos dados confianza = 0.95  # Nivel de confianza z= 1.96  # Valor cr\u00edtico para el nivel de confianza del 95% sigma = 40  # Desviaci\u00f3n est\u00e1ndar poblacional E = 10  # Margen de error deseado  # Calcular el tama\u00f1o de muestra n = math.ceil((z ** 2 * sigma ** 2) / E ** 2)  print(f\"Tama\u00f1o de muestra necesario: {n}\")  <pre>Tama\u00f1o de muestra necesario: 62\n</pre> <p>2. En un conjunto de datos se estima que el rango es 36.</p> a) Valor planeado para la desviaci\u00f3n est\u00e1ndar poblacional b) Tama\u00f1o de muestra para un margen de error de 3 en un intervalo de confianza del 95% c) Tama\u00f1o de muestra para un margen de error de 2 en un intervalo de confianza del 95% In\u00a0[9]: Copied! <pre>import math\n\n# Datos dados\nrango = 36\nconfianza = 0.95\nmargen_error_1 = 3\nmargen_error_2 = 2\n\n# a) Calcular la desviaci\u00f3n est\u00e1ndar poblacional\nsigma = rango / 6\n\n# b) Calcular el tama\u00f1o de la muestra para un margen de error de 3\nz = 1.96  # para un intervalo de confianza del 95%\nn1 = math.ceil((z * sigma / margen_error_1) ** 2)\n\n# c) Calcular el tama\u00f1o de la muestra para un margen de error de 2\nn2 = math.ceil((z * sigma / margen_error_2) ** 2)\n\n# Mostrar resultados\nprint(f\"a) Valor planeado para la desviaci\u00f3n est\u00e1ndar poblacional: {sigma}\")\nprint(f\"b) Tama\u00f1o de muestra para margen de error 3: {n1}\")\nprint(f\"c) Tama\u00f1o de muestra para margen de error 2: {n2}\")\n</pre> import math  # Datos dados rango = 36 confianza = 0.95 margen_error_1 = 3 margen_error_2 = 2  # a) Calcular la desviaci\u00f3n est\u00e1ndar poblacional sigma = rango / 6  # b) Calcular el tama\u00f1o de la muestra para un margen de error de 3 z = 1.96  # para un intervalo de confianza del 95% n1 = math.ceil((z * sigma / margen_error_1) ** 2)  # c) Calcular el tama\u00f1o de la muestra para un margen de error de 2 n2 = math.ceil((z * sigma / margen_error_2) ** 2)  # Mostrar resultados print(f\"a) Valor planeado para la desviaci\u00f3n est\u00e1ndar poblacional: {sigma}\") print(f\"b) Tama\u00f1o de muestra para margen de error 3: {n1}\") print(f\"c) Tama\u00f1o de muestra para margen de error 2: {n2}\")  <pre>a) Valor planeado para la desviaci\u00f3n est\u00e1ndar poblacional: 6.0\nb) Tama\u00f1o de muestra para margen de error 3: 16\nc) Tama\u00f1o de muestra para margen de error 2: 35\n</pre> <p>$Aplicaciones$</p> <p> 3. Seg\u00fan el informe del Ministro del 3 de febrero de 2006, el costo promedio de un gal\u00f3n de gasolina sin plomo en Greater Cincinnati es 2.41Bs.</p> <p>Se asume que la desviaci\u00f3n est\u00e1ndar en los precios del gal\u00f3n de gasolina sin plomo es de 0.15Bs.</p>  a) Margen de error requerido: 0.07Bs  b) Margen de error deseado: 0.05Bs c) Margen de error requerido: 0.03Bs In\u00a0[6]: Copied! <pre>import math\n\n# Datos dados\npromedio = 2.41\ndesviacionestandar = 0.15\nnivelconfianza = 0.95\n\n# a) Margen de error requerido: $0.07\nmargenerror1 = 0.07\nz = 1.96  # para un intervalo de confianza del 95%\nn1 = math.ceil((z * desviacionestandar / margenerror1) ** 2)\n\n# b) Margen de error deseado: $0.05\nmargenerror2 = 0.05\nn2 = math.ceil((z * desviacionestandar / margenerror2) ** 2)\n\n# c) Margen de error requerido: $0.03\nmargenerror3 = 0.03\nn3 = math.ceil((z * desviacionestandar / margenerror3) ** 2)\n\n# Mostrar resultados\nprint(f\"a) Tama\u00f1o de muestra para margen de error $0.07: {n1}\")\nprint(f\"b) Tama\u00f1o de muestra para margen de error $0.05: {n2}\")\nprint(f\"c) Tama\u00f1o de muestra para margen de error $0.03: {n3}\")\n</pre> import math  # Datos dados promedio = 2.41 desviacionestandar = 0.15 nivelconfianza = 0.95  # a) Margen de error requerido: $0.07 margenerror1 = 0.07 z = 1.96  # para un intervalo de confianza del 95% n1 = math.ceil((z * desviacionestandar / margenerror1) ** 2)  # b) Margen de error deseado: $0.05 margenerror2 = 0.05 n2 = math.ceil((z * desviacionestandar / margenerror2) ** 2)  # c) Margen de error requerido: $0.03 margenerror3 = 0.03 n3 = math.ceil((z * desviacionestandar / margenerror3) ** 2)  # Mostrar resultados print(f\"a) Tama\u00f1o de muestra para margen de error $0.07: {n1}\") print(f\"b) Tama\u00f1o de muestra para margen de error $0.05: {n2}\") print(f\"c) Tama\u00f1o de muestra para margen de error $0.03: {n3}\")  <pre>a) Tama\u00f1o de muestra para margen de error $0.07: 18\nb) Tama\u00f1o de muestra para margen de error $0.05: 35\nc) Tama\u00f1o de muestra para margen de error $0.03: 97\n</pre> <p> 4. Los tiempos requeridos para transportarse al trabajo en La Paz se han consignado en el 2003 El imforme de la alcaldia .</p> <p>Supongamos que se utiliza una muestra aleatoria simple preliminar de los habitantes de San Francisco con el fin de establecer un valor planeado de 6.25 minutos para la desviaci\u00f3n est\u00e1ndar poblacional.</p> a) Margen de error de 2 minutos b) Margen de error de 1 minuto In\u00a0[8]: Copied! <pre>import math\n\n# Datos dados\ndesviacion_estandar = 6.25\nnivel_confianza = 0.95\n\n# a) Margen de error de 2 minutos\nmargen_error_1 = 2\nz1 = 1.96\nn1 = math.ceil((z1 * desviacion_estandar / margen_error_1) ** 2)\n\n# b) Margen de error de 1 minuto\nmargen_error_2 = 1\nz2 = 1.96\nn2 = math.ceil((z2 * desviacion_estandar / margen_error_2) ** 2)\n\n# Mostrar resultados\nprint(f\"a) Tama\u00f1o de muestra para margen de error de 2 minutos: {n1}\")\nprint(f\"b) Tama\u00f1o de muestra para margen de error de 1 minuto: {n2}\")\n</pre> import math  # Datos dados desviacion_estandar = 6.25 nivel_confianza = 0.95  # a) Margen de error de 2 minutos margen_error_1 = 2 z1 = 1.96 n1 = math.ceil((z1 * desviacion_estandar / margen_error_1) ** 2)  # b) Margen de error de 1 minuto margen_error_2 = 1 z2 = 1.96 n2 = math.ceil((z2 * desviacion_estandar / margen_error_2) ** 2)  # Mostrar resultados print(f\"a) Tama\u00f1o de muestra para margen de error de 2 minutos: {n1}\") print(f\"b) Tama\u00f1o de muestra para margen de error de 1 minuto: {n2}\")  <pre>a) Tama\u00f1o de muestra para margen de error de 2 minutos: 38\nb) Tama\u00f1o de muestra para margen de error de 1 minuto: 151\n</pre> 8.4 Proporcion poblacional  <p>Hasta el momento conosemso la formula general para obtener una estimacion por intervalo de la proporcion poblacional P: $$ \\bar{p} \\pm \\text{margen de error} $ $$</p> <p>La manera en que las muestras son seleccionadas influye directamente en la precisi\u00f3n de las estimaciones por intervalo de una proporci\u00f3n p. La variabilidad en estas muestras juega un papel clave al determinar cu\u00e1n seguros podemos estar sobre la verdadera proporci\u00f3n en la poblaci\u00f3n general. En el cap\u00edtulo 7 se ha mencionado que la distribuci\u00f3n de muestreo de p se aproxima mediante una distribuci\u00f3n normal siempre que: $$ np \\geq 5 \\quad \\text{y} \\quad n(1-p) \\geq 5 $$</p> <p> Figura 8.9 Aproximaci\u00f3n normal a la distribuci\u00f3n de muestreo de $\\bar{p}$</p> In\u00a0[4]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\n\n# Nivel de significancia\nalfa = 0.05\n\n# Generar datos para la distribuci\u00f3n normal est\u00e1ndar (z)\nx = np.linspace(-4, 4, 1000)\ny = stats.norm.pdf(x)\n\n# Encontrar el valor cr\u00edtico para el nivel de significancia alfa/2\nvalor_critico = stats.norm.ppf(1 - alfa/2)\n\n# Crear el gr\u00e1fico con la l\u00ednea de color verde y etiqueta con el s\u00edmbolo mu (\u03bc)\nplt.figure(figsize=(9, 4))\nplt.plot(x, y, label=r'Distribuci\u00f3n Normal Est\u00e1ndar ($\\mu$)', color='green')  # Cambi\u00e9 el color a verde y a\u00f1ad\u00ed el s\u00edmbolo mu\n\n# Sombrear el \u00e1rea debajo de la l\u00ednea con un verde m\u00e1s oscuro\nplt.fill_between(x, y, color='#5CCB5F', alpha=0.3)\n\n# Etiqueta de texto 1: Distribuci\u00f3n de muestreo de x\u0304\nplt.text(-4, 0.20, 'Distribuci\u00f3n de muestreo\\n   de $\\\\bar{p}$', ha='left')\n\n# Etiqueta de texto 2: \u03c3/\u221an\nplt.text(3, 0.20, r'$\\sigma_\\bar{p} = \\sqrt{\\frac{p(1 - p)}{n}}$', fontsize=12, ha='right')\n\n# Establecer el color de fondo\nplt.gca().set_facecolor('#d4f8b7')\n\nplt.text(-2.5, 0.04, '${\u03b1/2}$', ha='left')\n\nplt.text(2.5, 0.04, '${\u03b1/2}$', ha='left')\n\nplt.text(-1.5, 0.01, '&lt;--$z_{\u03b1/2}$--&gt;', ha='left')\nplt.text(0.8, 0.01, '&lt;--$z_{\u03b1/2}$--&gt;', ha='left')\n\n# Mostrar el gr\u00e1fico\nplt.grid(False)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt import scipy.stats as stats  # Nivel de significancia alfa = 0.05  # Generar datos para la distribuci\u00f3n normal est\u00e1ndar (z) x = np.linspace(-4, 4, 1000) y = stats.norm.pdf(x)  # Encontrar el valor cr\u00edtico para el nivel de significancia alfa/2 valor_critico = stats.norm.ppf(1 - alfa/2)  # Crear el gr\u00e1fico con la l\u00ednea de color verde y etiqueta con el s\u00edmbolo mu (\u03bc) plt.figure(figsize=(9, 4)) plt.plot(x, y, label=r'Distribuci\u00f3n Normal Est\u00e1ndar ($\\mu$)', color='green')  # Cambi\u00e9 el color a verde y a\u00f1ad\u00ed el s\u00edmbolo mu  # Sombrear el \u00e1rea debajo de la l\u00ednea con un verde m\u00e1s oscuro plt.fill_between(x, y, color='#5CCB5F', alpha=0.3)  # Etiqueta de texto 1: Distribuci\u00f3n de muestreo de x\u0304 plt.text(-4, 0.20, 'Distribuci\u00f3n de muestreo\\n   de $\\\\bar{p}$', ha='left')  # Etiqueta de texto 2: \u03c3/\u221an plt.text(3, 0.20, r'$\\sigma_\\bar{p} = \\sqrt{\\frac{p(1 - p)}{n}}$', fontsize=12, ha='right')  # Establecer el color de fondo plt.gca().set_facecolor('#d4f8b7')  plt.text(-2.5, 0.04, '${\u03b1/2}$', ha='left')  plt.text(2.5, 0.04, '${\u03b1/2}$', ha='left')  plt.text(-1.5, 0.01, '&lt;--$z_{\u03b1/2}$--&gt;', ha='left') plt.text(0.8, 0.01, '&lt;--$z_{\u03b1/2}$--&gt;', ha='left')  # Mostrar el gr\u00e1fico plt.grid(False) plt.show() <p>La media de la distribuci\u00f3n de muestreo de \\( p \\) es la proporci\u00f3n poblacional \\( p \\), y el error est\u00e1ndar de \\( p \\) es:</p> $$ \\begin{equation} \\sigma_\\bar{p} = \\sqrt{\\frac{p(1 - p)}{n}} \\tag{8.4} \\end{equation} $$    <p>Como la distribuci\u00f3n de muestreo de \\(\\bar{p}\\) es una distribuci\u00f3n normal, en la estimaci\u00f3n por intervalo de la proporci\u00f3n poblacional se elige como margen de error \\(z_{\\alpha/2} \\cdot \\sigma_{\\bar{p}}\\). Entonces, \\( 100(1-\\alpha)\\% \\) de los intervalos que se obtengan contendr\u00e1n la verdadera proporci\u00f3n poblacional. Sin embargo, para calcular el margen de error, no podemos usar directamente \\(\\sigma_{\\bar{p}}\\) ya que no se conoce \\(p\\), puesto que se trata de estimarlo. Lo que se hace es que \\(p\\) se sustituye por \\(\\bar{p}\\) y de esta manera, el margen de error es dado por:</p> $$ \\begin{equation} \\text{Margen de error} = z_{\\alpha/2} \\cdot \\sqrt{\\frac{\\bar{p}(1-\\bar{p})}{n}} \\tag{8.5} \\end{equation} $$    ESTIMACION POR INTERVALO DE UNA PROPORCION POBLACIONAL   $$   \\begin{equation}   \\bar{p} \\pm  z_{\\alpha/2} \\cdot \\sqrt{\\frac{\\bar{p}(1-\\bar{p})}{n}} \\tag{8.6}   \\end{equation}   $$   <p>Donde: </p> <p>\\(\\bar{p}\\) = Coeficiente de confianza.  \\(z_{\\alpha/2}\\) = Valor de \\(z\\) que deja un area \\({\\alpha/2}\\) en la cola superior de la distribucion normal est\u00e1ndar.</p> EJEMPLO:  <p>Un estudio en Bolivia encuest\u00f3 a $900$ mujeres futbolistas para conocer su opini\u00f3n acerca de como se les trata en los cursos de futbol, en este estudio se encontro que $396$ estaban satisfechas con la disponibilidad de horarios de salida. Por tanto la estamacion puntual de la proporcion poblacional de futbolistas satisfechas con la disponibilidad de horarios de salida es de $396/900 = 0.44$. Utilizando la expresion $\\text(8.5)$ y la $\\text(8.6)$ junto al nivel de confianza es de $95$%, calcular el margen de error y la estimaci\u00f3n por intervalo para una proporci\u00f3n poblacional.</p> <p>$$ \\begin{equation} \\text{Margen de error} = z_{\\alpha/2} \\cdot \\sqrt{\\frac{\\bar{p}(1-\\bar{p})}{n}} \\tag{8.5} \\end{equation} $$</p> <p>$$ \\begin{equation} \\text{Margen de error} = 1.96 \\cdot \\sqrt{\\frac{{0.44}(1-0.44)}{n}} \\end{equation} $$</p> <p>$$ \\begin{equation} \\text{Margen de error} = 0.0324 \\end{equation} $$</p> <p>Y ahora con la expresion $\\text(8.6)$ y reemplazando la proporcion poblacional $0.44$ tenemos: </p> $$ \\begin{equation} \\bar{p} \\pm 0.0324 \\end{equation} $$  <p>$$ \\begin{equation} \\ 0.44 \\pm 0.0324 \\end{equation} $$</p> <p>Empleando porcentajes, los resultados de la investigacion permiten decir que con un $95$ % de confianza que entre $40.76$ % y $47.24$ % de las mujeres futbolistas estan satisfechas con la disponibilidad de horarios de salida.</p>  Determinacion del tama\u00f1o de la muestra  <p>Al determinar el tama\u00f1o de la muestra para estimar la proporci\u00f3n de una poblaci\u00f3n con cierta precisi\u00f3n, se utiliza una funci\u00f3n similar a la empleada en la estimaci\u00f3n de la media poblacional. La f\u00f3rmula para determinar el tama\u00f1o de la muestra se asemeja a la utilizada en la estimaci\u00f3n de la media poblacional en la formula $\\text(8.3)$. </p> <p>Este margen se basa en el valor de $z_{\\alpha/2}$ en la proporcion muestral de $\\bar{p}$ y en el tama\u00f1o de la muestra $n$. <p>NOTA: Muestras mayores, m\u00e1rgenes de error menores y con mejor precisi\u00f3n.</p> </p> <p>Sea $E$ el margen de error deseado: </p> $$ \\begin{equation} \\text{E} = z_{\\alpha/2} \\cdot \\sqrt{\\frac{\\bar{p}(1-\\bar{p})}{n}} \\end{equation} $$ <p>Si despejamos $n$ de esta formula, obtenemos el tama\u00f1o de la muestra para obtener el margen de error deseado $E$ y esta dada por: </p> $$ \\begin{equation} \\text{$n$} = \\frac{(z_{\\alpha/2})^2\\bar{p}(1-\\bar{p})}{E^2} \\end{equation} $$    <p>Sin embargo, si no se conoce $\\bar{p}$, no es posible usar esta f\u00f3rmula para calcular el tama\u00f1o de la muestra con el que se obtendr\u00e1 $E$.</p> <p>Entonces necesitaremos un valor planeado de $\\bar{p}$, con $p^*$ como valor planeado de $\\bar{p}$, la formula queda:  </p> TAMA\u00d1O DE LA MUESTAR PARA UNA ESTIMACI\u00d3N POR INTERVALO DE LA PROPORCI\u00d3N POBLACIONAL   $$   \\begin{equation}   \\text{$n$} = \\frac{(z_{\\alpha/2})^2 \\cdot {p^*} \\cdot (1-{p^*})}{E^2} \\tag{8.7}   \\end{equation}   $$  <p>El valor planeado $p^*$ es determinado mediante: </p> <p> 1. Se utiliza la proporci\u00f3n poblacional de una muestra previa de las mismas unidades o de unidades similares. 2. Se toma un estudio piloto y se elige una muestra preliminar. La proporci\u00f3n muestral de esta muestra se usa como valor planeado, $p^*$. 3. Se utiliza el criterio o una \u201cmejor aproximaci\u00f3n\u201d para el valor de $p^*$. 4. Si no es aplicable ninguna de las alternativas anteriores, se emplea como valor planeado $p^* = 0.50$. </p> <p>Volviendo al ejemplo, de mujeres futbolistas, spongamos que la empresa desea llevar a cabo otra investigaci\u00f3n para determinar la proporcion actual en la poblacion de futbolistas que esta satisfecha con la disponibilidad de horarios de salida. \u00bfDe qu\u00e9 tama\u00f1o debe ser la muestra si se desea en la estimacion de la proporcion poblacional un margen de error de $0.025$ a $95$% de confianza?</p> <p>DATOS: </p> <p>       $E = 0.025$ $z_{\\alpha/2} = 1.96$  $\\bar{p} = 0.44$     </p> <p> Con la ecuacion $(8.7)$ tenemos que: </p>       \\begin{equation}       \\text{$n$} = \\frac{(z_{\\alpha/2})^2 \\cdot {p^*} \\cdot (1-{p^*})}{E^2}       \\end{equation}       \\begin{equation}       \\text{$n$} = \\frac{(1.96)^2 \\cdot {(0.44)} \\cdot (1-{0.44})}{(0.025)^2}       \\end{equation}       \\begin{equation}       \\text{$n$} = 1514.5       \\end{equation}    <p>Entonces tenemos que, el tama\u00f1o de muestra debe ser por lo menos $1514.5$ mujeres futbolistas para satisfacer el margen de error requerido. Redondeando, tenemos que se necesitan $1515$ futbolistas para obtener el margen de error deseado.</p> <p>TABLA 8.5  Valores posibles de $p^*(1-p^*)$</p> $p^*$ $p^*$$(1$$- p^*$$)$ 0.10 (0.10)(0.90) = 0.09 0.30 (0.30)(0.70) = 0.21 0.40 (0.40)(0.60) = 0.24 0.50 (0.50)(0.50) = 0.25 &lt;---------- m\u00e1ximo valor de $p^*(1-p^*)$  0.60 (0.60)(0.40) = 0.24 0.70 (0.70)(0.30) = 0.21 0.90 (0.90)(0.10) = 0.09 <p>Seleccionar $p^* = 0.50$ es una alternativa simple cuando no hay informacion especifica disponible. Esto se debe a que, seg\u00fan la ecuacion $(8.7)$, el tama\u00f1o de la muestar es proporcional a $p^*(1-p^*)$. Cuando $p^*(1-p^*)$ es grande, el tama\u00f1o de la muestra tambien lo es. Escoger $p^* = 0.50$ garantiza el tama\u00f1o de la muestra maxima posible cuando no esta seguro del valor planificado. Esto significa que, incluso si la proporcion muestral difiere del valor planificado, el margen de error sera menor de lo esperado.En resumen, al usar $p^* = 0.50$, aseguramos que el tama\u00f1o de la muestra sea suficiente para obtener la precision deseada, incluso en situaciones de incertidumbre sobre la proporcion real en la poblacion.</p> <p>Volviendo otra vez, al ejemplo, si se usa como valor planteado $p^* = 0.50$, el tama\u00f1o de muestra que se obtiene es: </p> \\begin{equation} \\text{$n$} = \\frac{(z_{\\alpha/2})^2 \\cdot {p^*} \\cdot (1-{p^*})}{E^2} \\end{equation} \\begin{equation} \\text{$n$} = \\frac{(1.96)^2 \\cdot {(0.50)} \\cdot (1-{0.50})}{(0.025)^2} \\end{equation} \\begin{equation} \\text{$n$} = 1536.6 \\end{equation} <p>Es decir, una muestra ligeramente mayor: $1537$ mujeres futbolistas.</p> 8.5 Un poco mas de conocimiento  F\u00f3rmulas clave Estimaci\u00f3n por intervalo de la media poblacional: $\\sigma$ conocida   $$   \\begin{equation}   \\bar{x} \\pm z_{\u03b1/2}  \\frac{\\sigma}{\\sqrt{n}}\\tag{8.1}   \\end{equation}   $$    Estimaci\u00f3n por intervalo de la media poblacional: $\\sigma$ desconocida  $$   \\begin{equation}   \\bar{x} \\pm t_{\u03b1/2}  \\frac{s}{\\sqrt{n}}\\tag{8.2}   \\end{equation}   $$    Tama\u00f1o de la muestra para una estimaci\u00f3n por intervalo de la media poblacional  $$   \\begin{equation}   \\text{$n$} = \\frac{(z_{\\alpha/2})^2\\sigma^2}{E^2}\\tag{8.3}   \\end{equation}   $$    Estimaci\u00f3n por intervalo de una proporci\u00f3n poblacional   $$   \\begin{equation}   \\bar{p} \\pm  z_{\\alpha/2} \\cdot \\sqrt{\\frac{\\bar{p}(1-\\bar{p})}{n}}\\tag{8.6}   \\end{equation}   $$    Tama\u00f1o de la muestra para una estimaci\u00f3n por intervalo de la proporcion poblacional  $$   \\begin{equation}   \\text{$n$} = \\frac{(z_{\\alpha/2})^2 \\cdot {p^*} \\cdot (1-{p^*})}{E^2}\\tag{8.7}   \\end{equation}   $$     Estimaci\u00f3n por intervalo con Minitab  <p>A continuaci\u00f3n se describe c\u00f3mo usar Minitab para obtener intervalos de confi anza de la me\u0002dia poblacional y la proporci\u00f3n poblacional<p></p> </p> <p>Para calcular un intervalo de confianza del 95% para estimar la media poblacional con desviaci\u00f3n est\u00e1ndar conocida, sigue estos pasos:</p> <ol> <li>Abre Minitab y selecciona \"Stat\" en el men\u00fa.</li> <li>Elige \"Basic Statistics\".</li> <li>Selecciona \"1-Sample Z\".</li> <li>En el cuadro de di\u00e1logo \"1-Sample Z\":</li> <ul> <li>Ingresa los datos de la muestra en la columna designada, por ejemplo, en C1.</li> <li>Ingresa el valor de la desviaci\u00f3n est\u00e1ndar poblacional, por ejemplo, 20.</li> </ul> <li>Luego, haz clic en \"OK\". Por defecto, Minitab emplear\u00e1 un nivel de confianza del 95%. Si deseas especificar otro nivel de confianza, como el 90%, sigue estos pasos adicionales:</li> <li>Despu\u00e9s de seleccionar \"1-Sample Z\", elige \"Options\".</li> <li>En el cuadro de di\u00e1logo \"1-Sample Z-Options\":</li> <ul> <li>Ingresa el nivel de confianza deseado, por ejemplo, 90, en el cuadro de \"Confidence level\".</li> </ul> <li>Finalmente, haz clic en \"OK\" para obtener el intervalo de confiaol&gt; de confianza.   </li></ol> <p>Utilizando una muestra de 70 hogares con datos de saldos en tarjetas de cr\u00e9dito en la columna Cl de una hoja de c\u00e1lculo en Minitab, se ilustra la estimaci\u00f3n por intervalo para la media poblacional. En lugar de la desviaci\u00f3n est\u00e1ndar poblacional \u03c3, se estima utilizando la desviaci\u00f3n est\u00e1ndar muestral s. Sigue estos pasos:</p> <ol> <li>Abre el men\u00fa \"Stat\".</li> <li>Selecciona \"Basic Statistics\".</li> <li>Escoge \"1-Sample t\".</li> <li>En el cuadro de di\u00e1logo \"1-Sample t\":</li> <ul> <li>Ingresa los datos de la muestra en la columna especificada, por ejemplo, C1.</li> </ul> <li>Haz clic en \"OK\".</li> </ol> <p>Por defecto, Minitab usa un nivel de confianza del 95%. Para especificar otro nivel, como 90%, sigue estos pasos adicionales:</p> <ol> <li>Despu\u00e9s de seleccionar \"1-Sample t\", selecciona \"Options\".</li> <li>En el cuadro de di\u00e1logo \"1-Sample t-Options\":</li> <ul> <li>Ingresa el nivel de confianza deseado, por ejemplo, 90, en el campo de \"Confidence level\".</li> </ul> <li>Haz clic en \"OK\".</li> </ol> <p>Se utiliza la informaci\u00f3n de mujeres golfistas, registradas como 'S\u00ed' o 'No' en la disponibilidad de horarios de salida en la columna C1 de Minitab, para calcular un intervalo de confianza del 95% sobre la proporci\u00f3n de golfistas satisfechas con los horarios de salida. Los pasos son:</p> <ol> <li>Abre Minitab y selecciona 'Stat'.</li> <li>Escoge 'Basic Statistics'.</li> <li>Selecciona '1 Proportion'.</li> <li>Ingresa los datos de la muestra en la columna indicada (por ejemplo, C1).</li> <li>Selecciona 'Options' y elige 'Use test and interval based on normal distribution'. Haz clic en 'OK'.</li> <li>Obtendr\u00e1s el intervalo de confianza predeterminado del 95%. Para cambiar el nivel de confianza, como a 90%, ingresa este valor en 'Confidence Level' dentro de 'Options' en el paso 5.</li> </ol> <p>Recuerda: Minitab asume el segundo valor en orden alfab\u00e9tico como la proporci\u00f3n de inter\u00e9s. Si este no es el caso, puedes definir un orden personalizado en Minitab para obtener la respuesta deseada.</p> rden personalizado.  In\u00a0[17]: Copied! <pre>from IPython.display import YouTubeVideo\nyoutube_video = YouTubeVideo('Sf5TvUPp-rc')\ndisplay(youtube_video)\n</pre> from IPython.display import YouTubeVideo youtube_video = YouTubeVideo('Sf5TvUPp-rc') display(youtube_video)  Estimaci\u00f3n por intervalo usando Excel  <p>A continuaci\u00f3n se describe el uso de Excel para calcular intervalos de confi anza para la media  poblacional y la proporci\u00f3n poblacional</p> <p>La estimaci\u00f3n por intervalo se ilustra con el ejemplo de Lloyd's en la secci\u00f3n 8.1, asumiendo una desviaci\u00f3n est\u00e1ndar poblacional conocida \u03c3 = 20. Los gastos de una muestra de 100 clientes est\u00e1n en la columna A de Excel. Para calcular el margen de error y la media poblacional, sigue estos pasos:</p> <ol> <li>Haz clic en la ficha \"Data\" en la cinta de opciones.</li> <li>En el grupo \"Analysis\", selecciona \"Data Analysis\".</li> <li>Elige \"Descriptive Statistics\" de la lista \"Analysis Tools\".</li> <li>En el cuadro de di\u00e1logo \"Descriptive Statistics\":</li> <ul> <li>Ingresa \"A1:A101\" en el cuadro \"Input Range\".</li> <li>Selecciona \"Grouped by Columns\".</li> <li>Elige \"Labels in First Row\".</li> <li>Selecciona \"Output Range\".</li> <li>Ingresa \"C1\" en el cuadro \"Output Range\".</li> <li>Selecciona \"Summary Statistics\".</li> <li>Haz clic en \"OK\".</li> </ul> <li>El resumen estad\u00edstico aparecer\u00e1 en las columnas C y D. Contin\u00faa con el c\u00e1lculo del margen de error usando la funci\u00f3n \"CONFIDENCE\" de Excel de la siguiente manera:</li> <ul> <li>Selecciona la celda C16 e ingresa el t\u00edtulo \"Margin of error\".</li> <li>Elige la celda D16 e ingresa la f\u00f3rmula de Excel \"CONFIDENCE(0.5,20,100)\".</li> <li>Los tres par\u00e1metros de esta funci\u00f3n son:       <ul> <li>Alfa = 1 - coeficiente de confianza = 0.95 = 0.05.</li> <li>Desviaci\u00f3n est\u00e1ndar poblacional = 20.</li> <li>Tama\u00f1o de la muestra = 100 (Nota: Aparece como Count en la celda D15).</li> </ul> </li> </ul> <li>La estimaci\u00f3n puntual de la media poblacional est\u00e1 en la celda D3 y el margen de error en la celda D16. Estos valores permiten calcular f\u00e1cilmente el intervalo de confianza para la media poblacional.</li> </ol> <p>La estimaci\u00f3n por intervalo se ilustra con los datos de la tabla 8.2, donde se registran los saldos en las tarjetas de cr\u00e9dito de 70 hogares en la columna A de Excel. Sigue estos pasos para calcular la estimaci\u00f3n puntual y el margen de error de la media poblacional:</p> <ol> <li>Haz clic en la ficha \"Data\" en la cinta de opciones.</li> <li>En el grupo \"Analysis\", selecciona \"Data Analysis\".</li> <li>Elige \"Descriptive Statistics\" de la lista \"Analysis Tools\".</li> <li>En el cuadro de di\u00e1logo \"Descriptive Statistics\":</li> <ul> <li>Ingresa \"A1:A71\" en el cuadro \"Input Range\".</li> <li>Selecciona \"Grouped by Columns\".</li> <li>Elige \"Labels in First Row\".</li> <li>Selecciona \"Output Range\".</li> <li>Ingresa \"C1\" en el cuadro \"Output Range\".</li> <li>Selecciona \"Summary Statistics\".</li> <li>Elige \"Confidence Level for Mean\".</li> <li>Ingresa \"95\" en el cuadro \"Confidence Level for Mean\".</li> <li>Haz clic en \"OK\".</li> </ul> <li>El resumen estad\u00edstico aparecer\u00e1 en las columnas C y D. La estimaci\u00f3n puntual de la media poblacional se presenta en la celda D3. El margen de error aparecer\u00e1 como \"Confidence Level(95.0%)\" en la celda D16. Estos valores ($9,312 y $955, respectivamente) permiten estimar con facilidad el intervalo de confianza para la media poblacional.</li> </ol> In\u00a0[18]: Copied! <pre>from IPython.display import YouTubeVideo\nyoutube_video = YouTubeVideo('WUEANlXlnfc')\ndisplay(youtube_video)\n</pre> from IPython.display import YouTubeVideo youtube_video = YouTubeVideo('WUEANlXlnfc') display(youtube_video)  Estimaci\u00f3n por intervalo con StatTools  <p>En este ap\u00e9ndice se muestra el uso de StatTools para establecer una estimaci\u00f3n por intervalo de  una media poblacional cuando se desconoce \u03c3, y determinar el tama\u00f1o de la muestra necesario  para obtener el margen de error deseado.</p> <p>Para estimar la desviaci\u00f3n est\u00e1ndar poblacional \u03c3 utilizando la desviaci\u00f3n est\u00e1ndar muestral s de los saldos en las tarjetas de cr\u00e9dito de la tabla 8.3, sigue estos pasos utilizando StatTools para calcular un intervalo de confianza del 95% para la media poblacional:</p> <ol> <li>Haz clic en la ficha \"StatTools\" en la cinta de opciones.</li> <li>En el grupo \"Analyses\", selecciona \"Statistical Inference\".</li> <li>Elige la opci\u00f3n \"Confidence Interval\".</li> <li>Selecciona \"Mean/Std. Deviation\".</li> <li>En el cuadro de di\u00e1logo \"StatTools-Confidence Interval for Mean/Std. Deviation\":</li> <ul> <li>En \"Analysis Type\", elige \"One-Sample Analysis\".</li> <li>En la secci\u00f3n \"Variables\", selecciona \"NewBalance\".</li> <li>En la secci\u00f3n \"Confidence Intervals to Calculate\":</li> <ul> <li>Elige \"For the Mean\".</li> <li>Selecciona \"95%\" en \"Confidence Level\".</li> </ul> <li>Haz clic en \"OK\".</li> </ul> <li>Aparecer\u00e1n estad\u00edsticos descriptivos y el intervalo de confianza estimado.</li> </ol>"},{"location":"capitulo8/#margen-de-error-y-estimacion-por-intervalo","title":"Margen de error y estimaci\u00f3n por intervalo\u00b6","text":"<p>Para calcular una estimaci\u00f3n por intervalo de $\ud835\udf07$ cuando no se conoce $\u03c3$, se usa la desviaci\u00f3n est\u00e1ndar muestral s para estimar $\u03c3$, y $z_{\\frac{\u03b1}{2}}$ se sustituye por el valor $t_{\\frac{\u03b1}{2}}$ de la distribuci\u00f3n t. El margen de error est\u00e1 dado, entonces, por $t_{\\frac{\u03b1}{2}}$ $\\frac{s}{\\sqrt{n}}$. Con este margen, la expresi\u00f3n general para una estimaci\u00f3n por intervalo de la media poblacional cuando \u03c3 no se conoce es la siguiente.</p>"},{"location":"capitulo8/#consejo-practico","title":"Consejo Pr\u00e1ctico\u00b6","text":"<ul> <li>Si la poblaci\u00f3n tiene una distribuci\u00f3n normal, el intervalo de confianza suministrado en la expresi\u00f3n (8.2) es exacto y se puede usar con cualquier tama\u00f1o de muestra.</li> <li>Si la poblaci\u00f3n no sigue una distribuci\u00f3n normal, el intervalo de confianza en la expresi\u00f3n (8.2) ser\u00e1 aproximado. En este caso la calidad de la aproximaci\u00f3n depende tanto de la distribuci\u00f3n de la poblaci\u00f3n como del tama\u00f1o de la muestra.</li> </ul> <p>En la mayor\u00eda de las aplicaciones, un tama\u00f1o de muestra $n\\geq30$ es suficiente al usar la expresi\u00f3n (8.2) para obtener una estimaci\u00f3n por intervalo de la media poblacional. Sin embargo,si la distribuci\u00f3n de la poblaci\u00f3n es muy sesgada o si hay observaciones at\u00edpicas, se recomienda un tama\u00f1o de muestra de 50 o m\u00e1s. Si la poblaci\u00f3n no tiene una distribuci\u00f3n normal pero es m\u00e1s o menos sim\u00e9trica, con un tama\u00f1o de muestra de 15 puede esperarse una buena aproximaci\u00f3n al intervalo de confianza. Con muestras m\u00e1s peque\u00f1as la expresi\u00f3n (8.2) s\u00f3lo debe usarse si el analista cree, o est\u00e1 dispuesto a suponer, que la distribuci\u00f3n de la poblaci\u00f3n es por lo menos aproximadamente normal.</p>"},{"location":"capitulo8/#uso-de-una-muestra-pequena","title":"Uso de una muestra peque\u00f1a \u00b6","text":"<p>En el ejemplo siguiente se desarrolla una estimaci\u00f3n por intervalo para una media poblacional manejando una muestra peque\u00f1a. Como ya se indic\u00f3, conocer la distribuci\u00f3n de la poblaci\u00f3n es importante para decidir si mediante una estimaci\u00f3n por intervalo se obtendr\u00e1n resultados aceptables. Wiltech considera un nuevo programa asistido por computadora destinado a capacitar a los empleados de mantenimiento para reparar las m\u00e1quinas. Con objeto de evaluar este programa, el director de manufactura solicita una estimaci\u00f3n de la media poblacional del tiempo requerido para que los empleados de mantenimiento completen la capacitaci\u00f3n asistida por computadora. Considere una muestra de 20 individuos que siguen el programa de capacitaci\u00f3n. En la tabla 8.4 se muestran los datos del tiempo, en d\u00edas, que necesit\u00f3 cada uno para completar el programa.</p> Figura 8.6 Intervalo de confianza para el estudio de los saldos en las tarjetas  de cr\u00e9dito  Variable N Media Desviaci\u00f3n Est\u00e1ndar Error Est\u00e1ndar de la Media Intervalo de za  NewBalance 70 9,312 4,007 479 (8,357, 10,267  &lt;"},{"location":"capitulo8/#resumen-de-los-procedimientos-de-estimacion-por-intervalo","title":"Resumen de los procedimientos de estimaci\u00f3n por intervalo\u00b6","text":"<p>Se presentaron dos m\u00e9todos para calcular una estimaci\u00f3n por intervalo de la media poblacional.</p> <ul> <li>En el caso en que \u03c3 es conocida, en la expresi\u00f3n (8.1) se usan \u03c3 y la distribuci\u00f3n normal est\u00e1ndar para calcular el margen de error y la estimaci\u00f3n por intervalo.</li> <li>En el caso en que $\u03c3$ no es conocida, en la expresi\u00f3n (8.2) se utilizan la desviaci\u00f3n est\u00e1ndar muestral s y la distribuci\u00f3n t para calcular el margen de error y desarrollar la estimaci\u00f3n por intervalo.</li> </ul> <p>A continuacion se presenta un resumen de los procedimientos para la estimaci\u00f3n por intervalo de los dos casos. En la mayor\u00eda de las aplicaciones, un tama\u00f1o de muestra $n\\geq30$ es adecuado. Sin embargo, si la poblaci\u00f3n tiene distribuci\u00f3n normal o aproximadamente normal  FIGURA 8.8 Resumen de los procedimientos para la estimaci\u00f3n por intervalo de la media poblacional </p>"},{"location":"capitulo8/#notas-y-comentarios","title":"NOTAS Y COMENTARIOS\u00b6","text":"<ol> <li>En los casos en que conoce $\u03c3$, el margen de error, $z_{\u03b1/2}(\u03c3/\\sqrt{n})$, es fijo y es el mismo para todas las muestras de tama\u00f1o n. Cuando \u03c3 no se conoce, el margen de error, $t_{\u03b1/2}(s/\\sqrt{n})$, var\u00eda de una muestra a otra. Esta variaci\u00f3n se debe a que la desviaci\u00f3n est\u00e1ndar muestral s cambia de acuerdo con la muestra que se seleccione. Si s es grande, se obtiene un margen de error mayor, mientras que si s es peque\u00f1a, se obtiene un margen de error menor.</li> <li>\u00bfQu\u00e9 sucede con las estimaciones por intervalo cuando la poblaci\u00f3n es sesgada? Considere una poblaci\u00f3n sesgada a la derecha en la cual los datos con valores grandes jalan la distribuci\u00f3n hacia esa direcci\u00f3n. Cuando existe un sesgo as\u00ed, hay una correlaci\u00f3n positiva entre la media muestral $\\bar{x}$ y la desviaci\u00f3n est\u00e1ndar muestral s. Valores mayores de s tienden a corresponderse con valores mayores de $\\bar{x}$ De esta manera, cuando x es mayor que la media poblacional, s tiende a ser mayor que \u03c3. Este sesgo hace que el margen de error, $t_{\u03b1/2}(s/\\sqrt{n})$ sea mayor de lo que ser\u00eda si se conociera $\u03c3$. Un intervalo de confianza con un margen de error mayor tender\u00e1 a incluir con m\u00e1s frecuencia la media poblacional $\ud835\udf07$ que si se usara el verdadero valor $\u03c3$. Pero cuando $\\bar{x}$ es menor que la media poblacional, la correlaci\u00f3n entre $\\bar{x}$ y s hace que el margen de error sea m\u00e1s peque\u00f1o. En este caso, dichos intervalos de confianza con menor margen de error incluir\u00e1n la media poblacional menos veces que si se conociera y se usara \u03c3. Por esta raz\u00f3n se recomienda usar tama\u00f1os de muestra m\u00e1s grandes cuando la distribuci\u00f3n de la poblaci\u00f3n es muy sesgada.</li> </ol>"},{"location":"capitulo8/#ejercicios","title":"Ejercicios\u00b6","text":""},{"location":"capitulo8/#metodos","title":"Metodos\u00b6","text":"<ol> <li>En la distribuci\u00f3n t con 16 grados de libertad, encuentre el \u00e1rea, o la probabilidad, de cada una de las regiones siguientes. a) A la derecha de 2.120</li> </ol> <p>b) A la izquierda de 1.337</p> <p>c) A la izquierda de -1.746</p> <p>d) A la derecha de 2.583</p> <p>e) Entre -2.120 y 2.120</p> <p>f ) Entre -1.746 y 1.746</p>"},{"location":"capitulo8/#ejercicios","title":"$Ejercicios$\u00b6","text":""},{"location":"capitulo8/#glosario","title":"Glosario\u00b6","text":"<ul> <li>\u03c3 Conocida  Este dato se usa para obtener un valor confiable de la desviaci\u00f3n est\u00e1ndar poblacional antes de tomar una muestra. Este valor conocido (\u03c3) se emplea en la estimaci\u00f3n por intervalo para calcular el margen de error.</li> <li>\u03c3 Desconocida  Este es un caso com\u00fan, para estimar la desviaci\u00f3n est\u00e1ndar poblacional antes de tomar la muestra. En la estimaci\u00f3n por intervalo se usa la desviaci\u00f3n est\u00e1ndar muestral $s$ para calcular el margen de error</li> <li>Coeficiente de confianza Nivel de confianza expresado como valor decimal.</li> <li>Distribucion $t$ Es una familia de distribuciones utilizada para estimar por intervalo la media poblacional cuando la desviaci\u00f3n est\u00e1ndar poblacional no es conocida y se estima con la desviaci\u00f3n est\u00e1ndar muestral.</li> <li>Estimaci\u00f3n por intervalo Proporciona un rango que se cree contiene el valor del par\u00e1metro, utilizando una f\u00f3rmula que combina la estimaci\u00f3n puntual y el margen de error.</li> <li>Grados de libertad Son un par\u00e1metro esencial. Cuando esta distribuci\u00f3n se emplea para realizar una estimaci\u00f3n por intervalo de la media poblacional, la distribuci\u00f3n t asociada tiene n - 1 grados de libertad, siendo n el tama\u00f1o de la muestra aleatoria simple.</li> <li>Margen de error Es el valor que se suma y resta de la estimaci\u00f3n puntual.</li> <li>Nivel de confianza Asociado con la probabilidad de que el intervalo contenga el par\u00e1metro poblacional. Por ejemplo, un nivel de confianza del 95% indica que el 95% de los intervalos estimados contendr\u00e1n el par\u00e1metro.</li> </ul>"},{"location":"capitulo8/#media-poblacional-conocida","title":"Media poblacional: \u03c3 conocida\u00b6","text":""},{"location":"capitulo8/#media-poblacional-desconocida","title":"Media poblacional: \u03c3 desconocida \u00b6","text":""},{"location":"capitulo8/#proporcion-poblacional","title":"Proporci\u00f3n poblacional \u00b6","text":""},{"location":"capitulo8/#media-poblacional-conocida","title":"Media poblacional: \u03c3 conocida \u00b6","text":""},{"location":"capitulo8/#media-poblacional-desconocida","title":"Media poblacional: \u03c3 desconocida \u00b6","text":""},{"location":"capitulo8/#estimacion-por-intervalo-de-la-media-poblacional-caso-de-desconocida","title":"Estimaci\u00f3n por intervalo de la media poblacional  : caso de \u03c3 desconocida \u00b6","text":""},{"location":"capitulo9/","title":"Capitulo 9","text":"<p>Portada</p> In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, HTML\n\nhtmlCod = \"\"\"\n&lt;!DOCTYPE html&gt;\n&lt;html lang=\"es\"&gt;\n&lt;head&gt;\n&lt;meta charset=\"UTF-8\"&gt;\n&lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;\n&lt;style&gt;\n  body1 {\n    font-family: 'Cambria', sans-serif;\n    background-color: #FFF; /* Fondo blanco */\n    color: #000; /* Texto negro */\n    margin: 0;\n    padding: 0;\n  }\n  .chapter-box {\n    background-color: #009929;\n    color: #FFF;\n    padding: 20px 0; /* Ajusta este valor para centrar verticalmente como desees */\n    width: 100%; /* Ancho al 100% para ocupar la parte superior de la pantalla */\n    box-sizing: border-box; /* Asegura que el padding no a\u00f1ada m\u00e1s ancho */\n    text-align: center; /* Centra el texto horizontalmente */\n  }\n  .chapter-box h1 {\n    margin: 0;\n    font-size: 6em; /* Tama\u00f1o CAP\u00cdTULO 1 */\n  }\n  .content {\n    padding: 20px;\n    column-count: 2; \n    column-gap: 40px; \n  }\n  .content h2 {\n    color: #009929; \n    font-size: 1.5em;\n    margin-top: 0;\n    font-weight: normal;\n    text-transform: uppercase;\n    text-align: left; \n    border-bottom: 1px solid #009929; /* L\u00ednea debajo del texto */\n    padding-bottom: 5px; /* Espacio entre texto y l\u00ednea */\n    display: inline-block; /* Permite que la l\u00ednea ocupe el ancho del contenedor */\n    width: 100%; /* Asegura que el subrayado se extienda a lo largo de la p\u00e1gina */\n  }\n  .content ul {\n    list-style-type: none; /* No queremos vi\u00f1etas */\n    padding: 0;\n    margin-top: 0; /* Evitar espacios adicionales antes de la lista */\n  }\n  .content ul li {\n    margin-bottom: 10px; /* Espaciado entre l\u00edneas */\n    font-size: 1em;\n  }\n  .content ul li strong {\n    font-weight: bold;\n    display: block; /* Asegura que cada t\u00edtulo de secci\u00f3n comience en una nueva l\u00ednea */\n    break-inside: avoid-column; /* Evita que los t\u00edtulos de secci\u00f3n se dividan entre columnas */\n    -webkit-column-break-inside: avoid; /* Para navegadores basados en WebKit como Safari */\n    page-break-inside: avoid; /* Para la paginaci\u00f3n al imprimir */\n  }\n&lt;/style&gt;\n&lt;/head&gt;\n&lt;/html&gt;\n\"\"\"\n\ndisplay(HTML(htmlCod))\n</pre> from IPython.display import display, HTML  htmlCod = \"\"\"   \"\"\"  display(HTML(htmlCod)) <p>otros estilos</p> In\u00a0[8]: Copied! <pre>from IPython.display import display, HTML\n\nhtmlCod = \"\"\"\n&lt;style&gt;\n  body {\n    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n    background: #fafafa;\n    margin: 0;\n    padding: 20px;\n  }\n  .encuesta {\n    max-width: 700px;\n    margin: auto;\n    padding: 20px;\n    background: #ffffff;\n    box-shadow: 0 2px 5px rgba(0,0,0,0.1);\n  }\n  .encuesta h2 {\n    text-align: center;\n    color: #333333;\n  }\n  .campo {\n    margin: 15px 0;\n  }\n  .campo label {\n    margin: 0 10px 0 0;\n    font-weight: bold;\n  }\n  .campo input[type=\"text\"],\n  .campo textarea {\n    width: calc(100% - 22px);\n    padding: 10px;\n    margin-top: 5px;\n    border: 1px solid #dddddd;\n    border-radius: 4px;\n  }\n  .pregunta {\n    margin: 15px 0;\n  }\n  .pregunta span {\n    font-weight: bold;\n  }\n  .opciones label {\n    margin-right: 5px;\n  }\n  .opciones input[type=\"checkbox\"] {\n    margin-right: 10px;\n  }\n  .comentario {\n    margin: 15px 0;\n  }\n  .boton-envio {\n    width: 100%;\n    padding: 10px;\n    background-color: #555555;\n    color: white;\n    border: none;\n    border-radius: 4px;\n    cursor: pointer;\n  }\n  .tabulado {\n  margin-left: 20px; /* Esto a\u00f1ade espacio antes del elemento, como un tabulador. */\n  .tab {\n  margin-left: 20px; /* Esto a\u00f1ade espacio antes del elemento, como un tabulador. */\n}\n&lt;/style&gt;\n\"\"\"\ndisplay(HTML(htmlCod))\n</pre> from IPython.display import display, HTML  htmlCod = \"\"\"  \"\"\" display(HTML(htmlCod)) In\u00a0[8]: Copied! <pre>from IPython.display import display, HTML\n\nhtmlCod = \"\"\"\n&lt;style&gt;\n  body {\n    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n    background: #fafafa;\n    margin: 0;\n    padding: 20px;\n  }\n  .encuesta {\n    max-width: 700px;\n    margin: auto;\n    padding: 20px;\n    background: #ffffff;\n    box-shadow: 0 2px 5px rgba(0,0,0,0.1);\n  }\n  .encuesta h2 {\n    text-align: center;\n    color: #333333;\n  }\n  .campo {\n    margin: 15px 0;\n  }\n  .campo label {\n    margin: 0 10px 0 0;\n    font-weight: bold;\n  }\n  .campo input[type=\"text\"],\n  .campo textarea {\n    width: calc(100% - 22px);\n    padding: 10px;\n    margin-top: 5px;\n    border: 1px solid #dddddd;\n    border-radius: 4px;\n  }\n  .pregunta {\n    margin: 15px 0;\n  }\n  .pregunta span {\n    font-weight: bold;\n  }\n  .opciones label {\n    margin-right: 5px;\n  }\n  .opciones input[type=\"checkbox\"] {\n    margin-right: 10px;\n  }\n  .comentario {\n    margin: 15px 0;\n  }\n  .boton-envio {\n    width: 100%;\n    padding: 10px;\n    background-color: #555555;\n    color: white;\n    border: none;\n    border-radius: 4px;\n    cursor: pointer;\n  }\n  .tabulado {\n  margin-left: 20px; /* Esto a\u00f1ade espacio antes del elemento, como un tabulador. */\n  .tab {\n  margin-left: 20px; /* Esto a\u00f1ade espacio antes del elemento, como un tabulador. */\n}\n&lt;/style&gt;\n\"\"\"\ndisplay(HTML(htmlCod))\n</pre> from IPython.display import display, HTML  htmlCod = \"\"\"  \"\"\" display(HTML(htmlCod)) CAPITULO 9 Pruebas de hipotesis CONTENIDO <ul> <li>9.1 FORMULACION DE LAS HIPOTESIS NULA Y ALTERNATIVA</li> <li>Lahipotesis alternativa como hipotesis de investigacion</li> <li>la hipotesis nula como un supuesto para ser rebatido</li> <li>Formas para la hipotesis nula y alternativa</li> </ul> <ul> <li>9.2 ERRORES TIPO I Y TIPO II</li> </ul> <ul> <li>9.3 MEDIA POBLACIONAL $\\sigma$ CONOCIDA</li> <li>Prueba de una cola</li> <li>Prueba de dos colas</li> <li>Resumen y consejo practico </li> <li>Relacion entre estimacion por intervalo y prueba de hipotesis</li> </ul> <ul> <li>9.4 MEDIA POBLACIONAL $\\sigma$ DESCONOCIDA</li> <li>Prueba de una cola</li> <li>Prueba de dos colas</li> <li>Resumen y consejo practico </li> </ul> <ul> <li>9.5 PROPORCION POBLACIONAL</li> <li>Resumen</li> </ul> <ul> <li>9.6 PRUEBA DE HIPOTESIS Y TOMA DE DECISIONES</li> </ul> <ul> <li>9.7 CALCULO DE LA PROBABILIDAD DE LOS ERRORES TIPO II</li> </ul> <ul> <li>9.8 DETERMINACION DEL TAMA\u00d1O DE LA MUESTRA EN UNA PRUEBA DE HIPOTESIS PARA LA MEDIA POBLACIONAL</li> </ul> En primer lugar es importante comprender que una hip\u00f3tesis es una afirmacion que puede ser sometida a prueba para determinar si es verdadera o falsa. Esta nos proporciona una estructura para investigar y analizar si la evidencia respalda o contradice la afirmaci\u00f3n. A continuaci\u00f3n, se presenta un ejemplo para ilustrar este concepto: Ejemplo Imagina que piensas que la mayor\u00eda de los estudiantes de la carrera de inform\u00e1tica de la UMSA prefiere utilizar laptops en lugar de computadoras de escritorio. Para comprobar si esto es cierto, planteas dos posibilidades:  Afirmaci\u00f3n: La mayor parte de los estudiantes de la carrera de inform\u00e1tica de la UMSA tienen preferencia por laptops en lugar de computadoras de escritorio.  Negaci\u00f3n: No todos los estudiantes de la carrera de inform\u00e1tica de la UMSA comparte preferencia por laptops en lugar de computadoras de escritorio.  Luego, observas las elecciones de dispositivos de los estudiantes y revisas los datos para ver cu\u00e1l de estas posibilidades parece m\u00e1s acertada. Si los datos respaldan la idea de que la mayor\u00eda prefiere laptops, entonces tu idea original queda reforzada. Sin embargo, si los datos indican que no hay una preferencia clara o que no todos prefieren laptops, podr\u00edas reconsiderar tu idea inicial.  Basicamente se trata de probar y ver si lo que piensas est\u00e1 respaldado por la evidencia o si necesitas cambiar tu perspectiva.  En estadistica platearemos dos tipos de hipotesis la Hipotesis Nula $\ud835\udc3b_\ud835\udc5c$y la Hipotesis Alternativa  $\ud835\udc3b_\ud835\udc4e$.La hip\u00f3tesis nula $\ud835\udc3b_0$ representa una suposici\u00f3n inicial sobre un par\u00e1metro poblacional, como la media o la proporci\u00f3n, es co     mo una afirmaci\u00f3n que estamos dispuestos a poner a prueba. Por otro lado la Hipotesis Alternativa  $\ud835\udc3b\ud835\udc4e$ es una declaraci\u00f3n que va en contra de la hip\u00f3tesis nula es la idea que estamos tratando de respaldar con nuestra investigaci\u00f3n. Generalmente la hip\u00f3tesis nula sostiene de que no hay un efecto o diferencia importante, mientras que la hip\u00f3tesis alternativa plantea que s\u00ed existe algo significativo que merece ser descubierto o investigado      La hip\u00f3tesis alternativa como hip\u00f3tesis de investigaci\u00f3n En muchas ocasiones al hacer pruebas de hip\u00f3tesis, comenzamos enfoc\u00e1ndonos en respaldar nuestra idea original. Esto se logra mediante la formulaci\u00f3n de la hip\u00f3tesis alternativa, que b\u00e1sicamente es nuestra idea inicial. Al rechazar la hip\u00f3tesis nula, estamos dando paso para aceptar nuestra hip\u00f3tesis de investigaci\u00f3n, la idea que queremos respaldar,es como decir \"pensamos que hay algo interesante aqu\u00ed y queremos demostrarlo\". Este proceso act\u00faa como una gu\u00eda en nuestra investigaci\u00f3n, permiti\u00e9ndonos evaluar si los resultados que observamos respaldan o contradicen nuestra hipotesis iniciales.      Ejemplo   En este caso, planteamos la idea de que, en general, los estudiantes no superan una nota de 75, pero nos interesa investigar si aquellos que estudian al menos 8 horas a la semana obtienen calificaciones superiores.  <p>Estamos formulando una pregunta de investigaci\u00f3n espec\u00edfica sobre la relaci\u00f3n entre el tiempo de estudio y el rendimiento acad\u00e9mico, considerando abiertamente la posibilidad de que m\u00e1s tiempo de estudio est\u00e9 asociado con notas superiores a 75.</p>      $ H_0: \\mu \\leq 75$          $ H_a: \\mu &gt; 75$   Si los resultados conducen a rechazar $H_0$, podemos afirmar que $ \\mu &gt; 75$ es verdadera. Al hacerlo, estamos aceptando la evidencia significativa de que los estudiantes de estad\u00edstica que dedican al menos 8 horas a la semana de estudio tienen un rendimiento acad\u00e9mico mejorado, con una media de calificaciones mayor a 75.  <p>Si rechazamos $H_0$, no podemos concluir que la Hip\u00f3tesis Nula $H_0$ \u2014la cantidad promedio de tiempo de estudio no tiene un impacto significativo en las notas promedio de los estudiantes de estad\u00edstica, y la media de las notas es igual o menor a 75 sea v\u00e1lida.</p> <p>Este ejemplo puede aplicarse en diversas situaciones, como el rendimiento en ex\u00e1menes, el tiempo de estudio y la mejora en las calificaciones.</p> <p>formulando una pregunta de investigaci\u00f3n espec\u00edfica sobre la relaci\u00f3n entre el tiempo de estudio y el rendimiento acad\u00e9mico, considerando abiertamente la posibilidad de que m\u00e1s tiempo de estudio est\u00e9 asociado con notas superiores a 75.</p>      $ H_0: \\mu \\leq 75$          $ H_a: \\mu &gt; 75$   Si los resultados conducen a rechazar $H_0$, podemos afirmar que $ \\mu &gt; 75$ es verdadera. Al hacerlo, estamos aceptando la evidencia significativa de que los estudiantes de estad\u00edstica que dedican al menos 8 horas a la semana de estudio tienen un rendimiento acad\u00e9mico mejorado, con una media de calificaciones mayor a 75.  <p>Si rechazamos $H_0$, no podemos concluir que la Hip\u00f3tesis Nula $H_0$ \u2014la cantidad promedio de tiempo de estudio no tiene un impacto significativo en las notas promedio de los estudiantes de estad\u00edstica, y la media de las notas es igual o menor a 75 sea v\u00e1lida.</p> <p>Este ejemplo puede aplicarse en diversas situaciones, como el rendimiento en ex\u00e1menes, el tiempo de estudio y la mejora en las calificaciones.</p> La hip\u00f3tesis nula como un supesto para ser rebatido   En el an\u00e1lisis de pruebas de hip\u00f3tesis, se destaca la hip\u00f3tesis nula es como una idea inicial que tratamos de cuestionar. No siempre estamos investigando algo nuevo, a veces partimos de la creencia de que una afirmaci\u00f3n sobre un grupo de cosas es verdadera ,luego usamos la prueba de hip\u00f3tesis para ver si hay evidencia estad\u00edstica que indica lo contrario. En otras palabras es como decir: \"Aqu\u00ed hay algo que creemos, pero queremos ver si los datos nos dicen que estamos equivocados\".    Ejemplo   Un ejemplo es el del fabricante de bebidas refrescantes, donde se afirma que los envases contienen 67.6 onzas de l\u00edquido, se establece la hip\u00f3tesis nula asumiendo que esta afirmaci\u00f3n es correcta (`\u03bc = 67.6`). La hip\u00f3tesis alternativa se formula para desafiar este supuesto (`\u03bc \u2260 67.6`). La prueba de hip\u00f3tesis, basada en una muestra de envases, proporciona evidencia estad\u00edstica para aceptar o rechazar la hip\u00f3tesis nula.     $H_0: \\mu \\geq 67.6$   $H_a: \\mu &lt; 67,6$  <p>Si se rechaza la hip\u00f3tesis nula, se infiere que la afirmaci\u00f3n del fabricante es incorrecta, respaldando as\u00ed la hip\u00f3tesis alternativa. En este caso, la agencia gubernamental puede tomar medidas para garantizar el cumplimiento de los est\u00e1ndares de etiquetado. Sin embargo, si no se puede rechazar la hip\u00f3tesis nula, no hay evidencia suficiente para cuestionar la afirmaci\u00f3n del fabricante, y no se toma ninguna acci\u00f3n basada en la prueba de hip\u00f3tesis. Este proceso destaca la importancia de la hip\u00f3tesis nula como punto de partida para la evaluaci\u00f3n de afirmaciones y la toma de decisiones basada en evidencia estad\u00edstica.</p> Formas para la hipotesis nula y alternativa   En las pruebas de hip\u00f3tesis para la media poblacional, hay tres formas de plantear las hip\u00f3tesis nula $H_0$ y alternativa $H_a$. Estas se dividen en pruebas de una cola y pruebas de dos colas. Aqu\u00ed est\u00e1n las tres formas:   $H_0: \\mu \\leq \\mu_0$ $H_0: \\mu \\geq \\mu_0$ $H_0: \\mu = \\mu_0$ $H_a: \\mu &gt; \\mu_0$ $H_a: \\mu &lt; \\mu_0$ $H_a: \\mu \\neq \\mu_0$ <p>Estas formas reflejan la direcci\u00f3n en la que se est\u00e1 interesado en encontrar evidencia significativa. Si se espera que la media poblacional sea mayor que $\\mu_0$, se elige la primera forma; si se espera que sea menor, se elige la segunda forma. La tercera forma se selecciona cuando el inter\u00e9s es determinar si hay alguna diferencia significativa, ya sea mayor o menor.</p> <p>Es importante destacar que la igualdad siempre aparece en la hip\u00f3tesis nula $H_0$, ya sea con el s\u00edmbolo de igualdad $=$.</p> <p>La elecci\u00f3n entre estas formas depende de la pregunta que se busca responder y de la direcci\u00f3n de la evidencia que se espera encontrar. Si se busca respaldar la idea de que la media es mayor, menor o simplemente diferente de $\\mu_0$, entonces se elige la forma correspondiente para $H_a$.</p> <p>Este enfoque permite estructurar adecuadamente las pruebas de hip\u00f3tesis para la media poblacional y proporciona un marco claro para interpretar los resultados. La comprensi\u00f3n de estas formas es esencial para evitar errores tipo I y tipo II y garantizar que las pruebas sean efectivas en la evaluaci\u00f3n de las afirmaciones sobre la media poblacional.</p> Ejercicios M\u00e9todos Ejercicio 1  El gerente del Danvers-Hilton Resort Hotel afirma que la cantidad media que gastan los hu\u00e9spedes en un fin de semana es de $4,148 bs$ o menos. Un miembro del equipo de contadores observ\u00f3  que en los \u00faltimos meses hab\u00edan aumentado tales cantidades. El contador emplea una muestra  de las cuentas de fin de semana de los hu\u00e9spedes para probar la afirmaci\u00f3n del gerente.  <p>a) \u00bfQu\u00e9 forma de hip\u00f3tesis deber\u00e1 usar para probar la afirmaci\u00f3n del gerente? Explique</p>  $H_0: \\mu \\geq 4,148 $  -    $H_0: \\mu \\leq 4,148 $-$ H_0: \\mu = 4,148$   $H_a: \\mu &lt; 4,148 $ - $H_a: \\mu &gt;4,148 $ -$H_a: \\mu \\neq 4,148$  <p>b) \u00bfCu\u00e1l es la conclusi\u00f3n apropiada cuando no se puede rechazar la hip\u00f3tesis nula $H_0$</p> <p>c) \u00bfQu\u00e9 conclusi\u00f3n es adecuada cuando se puede rechazar la hip\u00f3tesis nula $H_0$?</p> Soluci\u00f3n a)          $H_0: \\mu \\leq 4,148$         $H_a: \\mu &gt; 4,148$      <p>Esto indica que la afirmaci\u00f3n nula $H_0$ es que la cantidad media que gastan los hu\u00e9spedes en un fin de semana es igual o menor que 4,148 bs. La hip\u00f3tesis alternativa $H_a$ ser\u00eda que la cantidad media es mayor de 4,148 bs.</p> <p>b) Cuando no se puede rechazar la hip\u00f3tesis nula $H_0$la conclusi\u00f3n apropiada es que no hay evidencia suficiente para afirmar que la cantidad media que gastan los hu\u00e9spedes en un fin de semana es mayor que 4,148\ud835\udc4f\ud835\udc60. En otras palabras, se acepta la afirmaci\u00f3n del gerente..</p> <p>c) Cuando se puede rechazar la hip\u00f3tesis nula $H_0$la conclusi\u00f3n adecuada es que hay evidencia suficiente para afirmar que la cantidad media que gastan los hu\u00e9spedes en un fin de semana es mayor que 4,148\ud835\udc4f\ud835\udc60. </p> Ejercicio 2 <p>El gerente de un negocio de venta de autom\u00f3viles piensa en un nuevo plan de bono dise\u00f1ado para incrementar el volumen de ventas. En el momento actual, el volumen medio de ventas es 14 autom\u00f3viles por mes. El gerente desea realizar un estudio para ver si el plan de bono incrementa el volumen de ventas. Para recolectar los datos, se le permitir\u00e1 a una muestra de vendedores vender bajo el nuevo plan de bono durante un mes.</p> <p>a) Desarrolle las hip\u00f3tesis nula y alternativa m\u00e1s adecuadas para esta situaci\u00f3n.</p> <p>b) Comente la conclusi\u00f3n en caso de que no pueda rechazarse $H_0$.</p> <p>c) Comente la conclusi\u00f3n en caso de que pueda rechazarse $H_0$</p> Soluci\u00f3n a)          $H_0: \\mu \\leq 14$         $H_a: \\mu &gt; 14$      <p>Esto indica que la afirmaci\u00f3n nula $H_0$ es que la cantidad media que gastan los hu\u00e9spedes en un fin de semana es igual o mayor que 600. La hip\u00f3tesis alternativa $H_a$ ser\u00eda que la cantidad media es menor de 600, que es la afirmaci\u00f3n del gerente.</p> <p>b) No hay evidencia de que el nuevo plan incremente las  ventas</p> <p>c) La hip\u00f3tesis de investigaci\u00f3n $\u03bc 14$ es apoyada, el  nuevo plan incrementa las ventas</p> Ejercicio 3 <p>Una operaci\u00f3n de la l\u00ednea de producci\u00f3n est\u00e1 dise\u00f1ada para llenar cajas con un peso medio de 32 onzas de detergente para lavar. Con periodicidad se selecciona una muestra de los empaques y se pesan para determinar si se est\u00e1n llenando de manera insuficiente o en demas\u00eda. Si los datos muestrales llevan a la conclusi\u00f3n de que hay llenado insuficiente o excesivo, la producci\u00f3n se suspende y se ajusta al llenado correcto.</p> <p>a) Formule las hip\u00f3tesis nula y alternativa que ayudar\u00e1n a determinar si se debe detener la producci\u00f3n y ajustar el peso.</p> <p>b) Comente sobre la conclusi\u00f3n y la decisi\u00f3n en caso de que $H_0$ no se pueda rechazar.</p> <p>c) Comente acerca de la conclusi\u00f3n y la decisi\u00f3n en caso de que $H_0$  se pueda rechazar.$</p> Soluci\u00f3n a) Formulaci\u00f3n de hip\u00f3tesis: El proceso de formulaci\u00f3n de hip\u00f3tesis implica establecer dos declaraciones ,la hip\u00f3tesis nula $H_0$ y la hip\u00f3tesis alternativa $H_a$ estamos interesados en determinar si el peso de las cajas de detergente es adecuado.  <p>Hip\u00f3tesis nula ($H_0$): El peso medio de las cajas de detergente es igual a 32 onzas.</p> <p>Hip\u00f3tesis alternativa $H_a$ El peso medio de las cajas de detergente no es igual a 32 onzas (puede ser menor o mayor).</p>      $H_0: \\mu = 32$     $H_a: \\mu \\neq 32 $  En palabras, estas hip\u00f3tesis establecen que la producci\u00f3n se considera adecuada si el peso medio de las cajas de detergente es igual a 32 onzas (nula), y se considera inadecuada si el peso medio es diferente de 32 onzas (alternativa).   b) Conclusi\u00f3n y decisi\u00f3n si $H_0$ no se puede rechazar: Si no se puede rechazar $H_0$ es decir, si no hay suficiente evidencia para afirmar que el peso medio difiere de 32 onzases, es decir la producci\u00f3n actual cumple con los est\u00e1ndares y no es necesario realizar ajustes. En este caso, no se detendr\u00eda la producci\u00f3n ni se realizar\u00edan ajustes al peso de las cajas.   c) Conclusi\u00f3n y decisi\u00f3n si $H_0$ se puede rechazar: Si se puede rechazar $H_0$ es decir, si hay suficiente evidencia para afirmar que el peso medio difiere de 32 onzas, la producci\u00f3n actual no cumple con los est\u00e1ndares y es necesario realizar ajustes. En este caso, se detendr\u00eda la producci\u00f3n y se llevar\u00edan a cabo ajustes para garantizar que el peso de las cajas de detergente sea el adecuado.    Ejercicio 4   Antes de implantar un m\u00e9todo de fabricaci\u00f3n propuesto, y debido a los costos y al tiempo de  adaptaci\u00f3n de la producci\u00f3n, un director de manufactura debe convencer a la direcci\u00f3n de que  ese m\u00e9todo nuevo reducir\u00e1 los costos. El costo medio del actual m\u00e9todo de producci\u00f3n es $220  por hora. Un estudio de investigaci\u00f3n medir\u00e1 el costo del m\u00e9todo nuevo durante un periodo  muestral de producci\u00f3n.  <p>a) Formule las hip\u00f3tesis nula y alternativa m\u00e1s adecuadas para este estudio.</p> <p>b) Comente acerca de la conclusi\u00f3n cuando $H_0$ no pueda rechazarse.</p> <p>c) Comente acerca de la conclusi\u00f3n cuando  $H_0$ pueda rechazarse.$</p> Soluci\u00f3n a) Hip\u00f3tesis nula $H_0$: El costo medio del nuevo m\u00e9todo de producci\u00f3n es igual al costo medio del m\u00e9todo actual.  <p>Hip\u00f3tesis alternativa $H_a$ El costo medio del nuevo m\u00e9todo de producci\u00f3n es diferente al costo medio del m\u00e9todo actual.</p>  $H_0: \\mu = 220$ $H_a: \\mu \\neq 220$  <p>b) Si no se puede rechazar $H_0$, se concluye que no hay suficiente evidencia para afirmar que el costo medio del nuevo m\u00e9todo es diferente al del m\u00e9todo actual. En este caso, no se tendr\u00eda base estad\u00edstica para convencer a la direcci\u00f3n de que el nuevo m\u00e9todo reducir\u00e1 los costos..</p> <p>c) Si se puede rechazar $H_0$, se concluye que hay evidencia estad\u00edstica para afirmar que el costo medio del nuevo m\u00e9todo es diferente al del m\u00e9todo actual. En este caso, el director de fabricaci\u00f3n podr\u00eda utilizar estos resultados como base para convencer a la direcci\u00f3n de que el nuevo m\u00e9todo reducir\u00e1 los costos.   </p> Condicion poblacional <p> Tabla 1 <p>Errores y conclusiones correctas en las pruebas de hipotesis</p> $H_0$ es aceptada $H_a$ verdadera $H_0$ es rechazada Conclusion correcta Error tipo II $H_0 es rechazada Error tipo I Conclusion correcta <pre></pre> <p></p></p> <p>En la figura, se representa gr\u00e1ficamente qu\u00e9 sucede cuando se acepta o se rechaza  $H_0$. Si $H_0$es aceptada y es verdadera, la conclusi\u00f3n es correcta. Pero si  $H_a$ es verdadera, se comete un Error Tipo II al aceptar incorrectamente  $H_0$. Si  $H_0$ es rechazada y es verdadera, se comete un Error Tipo I, pero si Ha es verdadera, es correcto rechazar  $H_0$.</p> NIVEL DE SIGNIFICANCIA <p> Consiste en comter un Error de tipo I cuando $H_0$ es verdadera como igualdad</p> <p>La probabilidad de cometer el Error Tipo I se controla con el nivel de significancia (\u03b1), que es la probabilidad de rechazar  $H_0$ cuando es verdadera. Elegir un \u03b1 m\u00e1s peque\u00f1o reduce la probabilidad de este error, pero aumenta la probabilidad de cometer el Error Tipo II.</p> <p> Video: Error de tipo I y tipo II</p> In\u00a0[47]: Copied! <pre># importar la clase que permite ver videos\nfrom IPython.display import YouTubeVideo\n# crear una instancia del objeto YouTubeVideo\nyoutube_video=YouTubeVideo('dtXMIQp2n5U')\n#mostrar el video de youtube\ndisplay(youtube_video)\n</pre> # importar la clase que permite ver videos from IPython.display import YouTubeVideo # crear una instancia del objeto YouTubeVideo youtube_video=YouTubeVideo('dtXMIQp2n5U') #mostrar el video de youtube display(youtube_video) Ejercicios Ejercicio 5 <p>Nielsen inform\u00f3 que los hombres j\u00f3venes estadounidenses ven diariamente 56.2 minutos de televisi\u00f3n en las horas de mayor audiencia (The Wall Street Journal Europe, 18 de noviembre de 2003). Un investigador cree que en Alemania los j\u00f3venes ven m\u00e1s tiempo la televisi\u00f3n en las horas de mayor audiencia. Este investigador toma una muestra de hombres j\u00f3venes alemanes y registra el tiempo que ven televisi\u00f3n en un d\u00eda. Los resultados muestrales se usan para probar las siguientes hip\u00f3tesis nula y alternativa.</p>  $H_0: \\mu \\leq 56.2$ $H_a: \\mu &gt; 56.2$  <p>a) \u00bfCu\u00e1l es el error tipo I en esta situaci\u00f3n? \u00bfQu\u00e9 consecuencia tiene cometerlo?</p> <p>b) \u00bfCu\u00e1l es el error tipo II en esta situaci\u00f3n? \u00bfQu\u00e9 consecuencia tiene cometerlo?</p> Soluci\u00f3n a)<p>Definici\u00f3n:Rechazar incorrectamente la hip\u00f3tesis nula $H_0$cuando es verdadera.  <p>Consecuencia: Concluir que los j\u00f3venes alemanes ven m\u00e1s tiempo la televisi\u00f3n en las horas de mayor audiencia cuando, de hecho, no hay evidencia suficiente para respaldar esta afirmaci\u00f3n. Puede llevar a tomar decisiones o implementar cambios basados en informaci\u00f3n incorrecta.</p></p> <p>b) Definici\u00f3n: No rechazar la hip\u00f3tesis nula $H_0$cuando es falsa.  <p>Consecuencia: No reconocer que los j\u00f3venes alemanes ven m\u00e1s tiempo la televisi\u00f3n en las horas de mayor audiencia cuando, de hecho, hay evidencia para respaldar esta afirmaci\u00f3n. Puede llevar a perder la oportunidad de tomar decisiones informadas o implementar cambios necesarios.</p></p> Ejercicio 6 <p>En la etiqueta de una botella de jugo de naranja de 3 cuartos de gal\u00f3n se afirma que el jugo contiene en promedio 1 gramo o menos de grasa. Responda las preguntas siguientes relacionadas con una prueba de hip\u00f3tesis para probar lo que se asegura en la etiqueta.</p> <p>a) Desarrolle las hip\u00f3tesis nula y alternativa adecuadas.</p> <p>b) \u00bfCu\u00e1l es el error tipo I en esta situaci\u00f3n? \u00bfQu\u00e9 consecuencias tiene cometerlo?</p> <p>c) \u00bfCu\u00e1l es el error tipo II en esta situaci\u00f3n? \u00bfQu\u00e9 consecuencias tiene cometerlo?</p> Soluci\u00f3n a)          $H_0: \\mu \\leq 1$         $H_a: \\mu &gt; 1$      <p>$H_0$: La afirmaci\u00f3n en la etiqueta es verdadera; el jugo de naranja tiene 1 gramo o menos de grasa en promedio.  <p>$H_a$: La afirmaci\u00f3n en la etiqueta es falsa; el jugo de naranja tiene m\u00e1s de 1 gramo de grasa en promedio.</p></p> <p>b)  Error Tipo I: Definici\u00f3n: Rechazar incorrectamente la hip\u00f3tesis nula$H_0$ cuando es verdadera.  <p>Consecuencia: Concluir que el jugo de naranja tiene m\u00e1s de 1 gramo de grasa en promedio cuando, de hecho, la afirmaci\u00f3n en la etiqueta es correcta. Esto podr\u00eda llevar a decisiones incorrectas sobre la producci\u00f3n, marketing u otras \u00e1reas basadas en informaci\u00f3n incorrecta.</p></p> <p>c)  Error Tipo II: Definici\u00f3n: No rechazar la hip\u00f3tesis nula $H_0$cuando es falsa.  <p>Consecuencia: No reconocer que el jugo de naranja tiene m\u00e1s de 1 gramo de grasa en promedio cuando, de hecho, la afirmaci\u00f3n en la etiqueta es falsa. Esto podr\u00eda llevar a que el producto se comercialice como bajo en grasa cuando no lo es, lo que podr\u00eda afectar la confianza del consumidor y la reputaci\u00f3n del producto.</p></p> Ejercicio 7 <p>El personal de ventas de Carpetland tiene un promedio de $8 000 semanales en ventas. Steve Contois, vicepresidente de la empresa, propone un plan de compensaci\u00f3n con nuevos incen\u0002tivos. Steve espera que los resultados de un periodo de prueba permitir\u00e1n concluir que el plan de compensaci\u00f3n aumenta el promedio de ventas de los vendedores.</p> <p>a) Establezca las hip\u00f3tesis nula y alternativa adecuadas.</p> <p>b) \u00bfCu\u00e1l es el error tipo I en esta situaci\u00f3n? \u00bfQu\u00e9 consecuencias tiene cometerlo?.</p> <p>c) \u00bfCu\u00e1l es el error tipo II en esta situaci\u00f3n? \u00bfQu\u00e9 consecuencias tiene cometerlo?</p> Soluci\u00f3n a)          $H_0: \\mu \\leq 8,000$         $H_a: \\mu &gt; 8,000$      <p>$H_0$: El plan no aumenta el promedio de ventas.  <p>$H_a$: El plan aumenta el promedio de ventas.</p></p> <p>b) Rechazar incorrectamente $H_0$cuando es cierta. Consecuencia: Implementar un plan que no mejora las ventas, con costos innecesarios.</p> <p>c)No rechazar$H_0$ cuando $H_a$ es cierta. Consecuencia: Perder la oportunidad de implementar un plan beneficioso que aumenta las ventas.</p> Prueba de una cola   La prueba de una cola para la media poblacional toma una de las dos formas siguientes.  Prueba de cola inferior (o izquierda) Prueba de cola superior (o derecha) $$H_0: \u03bc \u2265 \u03bc_0$$ $$H_0: \u03bc \u2264 \u03bc_0$$ $$H_a: \u03bc &lt; \u03bc_0$$ $$H_a: \u03bc &gt; \u03bc_0$$   A continuaci\u00f3n se presenta un ejemplo de una prueba para la cola inferior:  El Instituto Boliviano de Regulaci\u00f3n Comercial (IBRC) realiza estudios para verificar afirmaciones de fabricantes sobre productos, como el peso de caf\u00e9 en latas de \"Caf\u00e9 Sierra\".  <ul> <li><p>La hip\u00f3tesis nula ($H_0$) establece que la media poblacional del peso de llenado es al menos 3 libras por lata: $H_0: \u03bc \u2265 3$</p> </li> <li><p>La hip\u00f3tesis alternativa ($H_a$) sugiere que la media es menor de 3 libras: $H_0: \u03bc &lt; 3$</p> </li> </ul> <p>Se utiliza un nivel de significancia ($\u03b1 = 0.01$). En el caso de \"Caf\u00e9 Sierra\", si los datos no rechazan $H_0$, no se toman medidas; de lo contrario, se concluye que $H_a$ es verdadera, lo que justificar\u00eda un cargo por violaci\u00f3n en la etiqueta. El director de pruebas de la IBRC est\u00e1 dispuesto a asumir un riesgo del 1% de cometer un error tipo I.</p> <p>Se selecciona una muestra de 36 latas y se calcula la media muestral $x$ como una estimaci\u00f3n de la media poblacional $\u03bc$. Si $x$ es menor de 3 libras, se cuestiona la hip\u00f3tesis nula. El factor clave es el valor de $\u03b1$, la probabilidad de cometer un error tipo I. Con los pasos iniciales completados, el siguiente paso es recopilar datos muestrales y calcular el estad\u00edstico de prueba para tomar una decisi\u00f3n basada en la evidencia estad\u00edstica.</p> Estad\u00edstico de prueba ESTAD\u00cdSTICO DE PRUEBA EN LAS PRUEBAS DE HIP\u00d3TESIS PARA LA MEDIA POBLACIONAL: \u03c3 CONOCIDA $$z = \\frac{{\\bar{x} - \\mu_0}}{{\\frac{\\sigma}{\\sqrt{n}}}}$$    En el estudio de \"Caf\u00e9 Sierra\", se realizan pruebas de hip\u00f3tesis para la media poblacional ($\u03bc$) en el caso de que la desviaci\u00f3n est\u00e1ndar poblacional ($\u03c3$) sea conocida. Los resultados previos de la IBRC indican que $\u03c3$ tiene un valor de 0.18 y que la distribuci\u00f3n de los pesos de llenado en la poblaci\u00f3n sigue una distribuci\u00f3n normal.  <p>Con un tama\u00f1o de muestra $n = 36$ y asumiendo la hip\u00f3tesis nula $H_0$ como verdadera $\u03bc = \u03bc_0 = 3$, se puede ilustrar la distribuci\u00f3n de muestreo de la media muestral $\\bar{x}$ en una distribuci\u00f3n normal. El error est\u00e1ndar de $\\bar{x}(\u03c3_\\bar{x})$ se calcula como $\\frac{\\sigma}{\\sqrt{n}} = \\frac{0.18}{\\sqrt{36}} = 0.03 $</p> <p>La variable aleatoria normal est\u00e1ndar:</p> $z =\\frac{\\bar{x} - \\mu_0}{\\sigma_{\\bar{x}}} = \\frac{\\bar{x} - 3}{0.03}$ <p>La probabilidad asociada a un valor espec\u00edfico de $z$ en la cola inferior se determina utilizando la tabla de probabilidad normal est\u00e1ndar.</p> <p>Por ejemplo, si $z=-3.00$, el \u00e1rea en la cola inferior es $0.0013$, lo que significa que la probabilidad de obtener un valor de $\\bar{x}$ que sea tres o m\u00e1s errores est\u00e1ndar menor que la media hipot\u00e9tica ($\\mu_0=3$) es $0.0013$. En una prueba de hip\u00f3tesis, un resultado tan extremo sugiere que la hip\u00f3tesis nula es poco probable, lo que podr\u00eda llevar al rechazo de la hip\u00f3tesis nula en favor de la hip\u00f3tesis alternativa. El estad\u00edstico de prueba utilizado es $z$, y se compara con un umbral cr\u00edtico basado en el nivel de significancia predefinido ($\u03b1$).</p> FIGURA 9.1 Distribuci\u00f3n de muestreo de x en el estudio de \"Caf\u00e9 Sierra\" cuando la hip\u00f3tesis nula es verdadera como igualdad (\u03bc = 3)  In\u00a0[16]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Par\u00e1metros de la distribuci\u00f3n muestral\nmedia_poblacional = 3\nerror_estandar = 0.03\n# Generar datos de la distribuci\u00f3n muestral\nx = np.linspace(media_poblacional - 4 * error_estandar, media_poblacional + 4 * error_estandar, 1000)\ny = norm.pdf(x, media_poblacional, error_estandar)\n\n# Crear la gr\u00e1fica\nfig, ax = plt.subplots()\nax.plot(x, y, color='#009929')\n# Establecer el color de fondo\nax.set_facecolor('#d4f8b7')  \n# Pintar el fondo externo del gr\u00e1fico\nfig.patch.set_facecolor('#D4F8B7')\nax.set_xlabel(f'\u03bc = {media_poblacional}', fontsize=12)\nax.set_ylabel(r'Distribuci\u00f3n de muestreo de $\\bar{x}$', fontsize=12)\n\n# Agregar informaci\u00f3n sobre el error est\u00e1ndar\ninfo_error_estandar = r'$\u03c3_\\bar{x}$ = $\\frac{\\sigma}{\\sqrt{n}} = \\frac{0.18}{\\sqrt{36}} = 0.03 $'\nax.text(0.6, 0.85, info_error_estandar, transform=ax.transAxes, fontsize=12, color='#000')\n\nax.grid(False)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm  # Par\u00e1metros de la distribuci\u00f3n muestral media_poblacional = 3 error_estandar = 0.03 # Generar datos de la distribuci\u00f3n muestral x = np.linspace(media_poblacional - 4 * error_estandar, media_poblacional + 4 * error_estandar, 1000) y = norm.pdf(x, media_poblacional, error_estandar)  # Crear la gr\u00e1fica fig, ax = plt.subplots() ax.plot(x, y, color='#009929') # Establecer el color de fondo ax.set_facecolor('#d4f8b7')   # Pintar el fondo externo del gr\u00e1fico fig.patch.set_facecolor('#D4F8B7') ax.set_xlabel(f'\u03bc = {media_poblacional}', fontsize=12) ax.set_ylabel(r'Distribuci\u00f3n de muestreo de $\\bar{x}$', fontsize=12)  # Agregar informaci\u00f3n sobre el error est\u00e1ndar info_error_estandar = r'$\u03c3_\\bar{x}$ = $\\frac{\\sigma}{\\sqrt{n}} = \\frac{0.18}{\\sqrt{36}} = 0.03 $' ax.text(0.6, 0.85, info_error_estandar, transform=ax.transAxes, fontsize=12, color='#000')  ax.grid(False) plt.show() <p>La cuesti\u00f3n clave en una prueba de cola inferior es: \u00bfqu\u00e9 tan peque\u00f1o debe ser el estad\u00edstico de prueba z para que se decida rechazar la hip\u00f3tesis nula? Para responder esta pregunta se usandos m\u00e9todos: el m\u00e9todo del valor-p y el m\u00e9todo del valor cr\u00edtico.</p> M\u00e9todo del valor-p <p>En este enfoque se usa el valor del estad\u00edstico de prueba $z$ paracalcular una probabilidad llamada valor-p.</p> VALOR-p: Es una probabilidad que aporta una medida de la evidenciasuministrada por la muestra contra la hip\u00f3tesis nula. Valores-p peque\u00f1os indican una evidencia mayor contra $H_0$. El valor - p se utiliza para determinar si la hip\u00f3tesis nula debe ser rechazada.  El c\u00e1lculo del valor-p depende del tipo de prueba (cola inferior, cola superior o dos colas). Para una prueba de cola inferior con $\u03c3$ conocida, se determina el \u00e1rea bajo la curva normal est\u00e1ndar para valores de $z \u2264$ al valor del estad\u00edstico de prueba.  <p>Ahora calculamos el valor-p para la prueba de cola inferior del estudio de \"Caf\u00e9 Sierra\".Suponga que en la muestra de las 36 latas de caf\u00e9, la media muestral obtenida es $\\bar{x} = 2.92$ libras. \u00bfEs $\\bar{x} = 2.92$ lo suficientemente peque\u00f1a para que se rechace $H_0$? Como es una prueba de cola inferior, el valor-p es el \u00e1rea bajo la curva normal est\u00e1ndar para valores de $z$ que el valor del estad\u00edstico de prueba. Al usar $\\bar{x} = 2.92$, $\u03c3 = 0.18$ y $n = 36$, se determina el valor del estad\u00edstico de prueba z.</p> <p>$$z = \\frac{{\\bar{x} - \\mu_0}}{{\\frac{\\sigma}{\\sqrt{n}}}} = \\frac{{2.92 - 3}}{{\\frac{0.18}{\\sqrt{36}}}} = -2.67$$</p> <p>Por consiguiente, el valor-p es la probabilidad de que el estad\u00edstico de prueba $z$ sea menor o igual que $-2.67$(el \u00e1rea bajo la curva normal est\u00e1ndar a la izquierda del estad\u00edstico de prueba).</p> <p>Como se indic\u00f3 antes, el director del programa de pruebas de la IBRC eligi\u00f3 como nivel de significancia un valor de 0.01. Seleccionar $\u03b1 = 0.01$ significa que \u00e9l est\u00e1 dispuesto a tolerar una probabilidad de 0.01 para rechazar la hip\u00f3tesis nula cuando sea verdadera como igualdad ($\u03bc_0 = 3$). La muestra de 36 latas de \"Caf\u00e9 Sierra\" dio como resultado un $valor-p = 0.0038$, lo cual significa que la probabilidad de obtener $\\bar{x} = 2.92$ o menor, si la hip\u00f3tesis nula considerada como igualdad es verdadera, es 0.0038. Como 0.0038 es menor o igual que $\u03b1 = 0.01$, $H_0$ es rechazada. De manera que para el nivel de significancia 0.01 se encontr\u00f3 evidencia estad\u00edstica suficiente para rechazar la hip\u00f3tesis nula.</p> FIGURA 9.2 Valor-p en el estudio de Hilltop Coffee, en el que $\\bar{x} = 2.92$ y $z = -2.67$  In\u00a0[2]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\nfrom scipy.stats import t\n\n#GRAFICO1\n# Generar datos de la distribuci\u00f3n muestral\nx = np.linspace(0 - 4 * 1, 0 + 4 * 1, 1000)\ny = norm.pdf(x*3, 0, 4)\n\n# Crear la gr\u00e1fica\nfig, ax = plt.subplots()\nax.plot(x, y, color='#009929')\n# Establecer el color de fondo\nax.set_facecolor('#d4f8b7')\n# Pintar el fondo externo del gr\u00e1fico\nfig.patch.set_facecolor('#D4F8B7')\nax.set_xlabel(f'$\u03bc_0$ = 3', fontsize=12)\n\n# Agregar informaci\u00f3n sobre el error est\u00e1ndar\ninfo_error_estandar = r'$\u03c3_\\bar{x}$ = $\\frac{\\sigma}{\\sqrt{n}} = 0.03 $'\nax.text(0.6, 0.88, info_error_estandar, transform=ax.transAxes, fontsize=13, color='#000')\nax.text(-0.03, -0.15, r'$\\bar{x} = 2.92$',transform=ax.transAxes, fontsize=12, color='#000')\nax.text(0.02, 0.85, r'Distribuci\u00f3n de muestreo',transform=ax.transAxes, fontsize=10, color='#000')\nax.text(0.17, 0.77, r'de $\\bar{x}$',transform=ax.transAxes, fontsize=12, color='#000')\n\n# L\u00ednea vertical\nax.axvline(t.ppf(0.005, 47), color='#009929', linestyle='--', label=r'$t_{\\alpha/2}$')\n\n# Sombrear la parte de -2.67 hacia la izquierda\nax.fill_between(x, y, where=(x &lt;= -2.67), color='#009929', alpha=0.5)\n\n\nax.grid(False)\nplt.show()\n\n#GRAFICO2\n# Generar datos de la distribuci\u00f3n muestral\nx = np.linspace(0 - 4 * 1, 0 + 4 * 1, 1000)\ny = norm.pdf(x*3, 0, 4)\n\n# Crear la gr\u00e1fica\nfig, ax = plt.subplots()\nax.plot(x, y, color='#009929')\n# Establecer el color de fondo\nax.set_facecolor('#d4f8b7')\n# Pintar el fondo externo del gr\u00e1fico\nfig.patch.set_facecolor('#D4F8B7')\n\n# Agregar informaci\u00f3n sobre el error est\u00e1ndar\nax.text(0.58, 0.85, r'Distribuci\u00f3n de muestreo de',transform=ax.transAxes, fontsize=10, color='#000')\nax.text(0.69, 0.72, r'$z = \\frac{{\\bar{x} - \\mu_0}}{{\\frac{\\sigma}{\\sqrt{n}}}}$',transform=ax.transAxes, fontsize=14, color='#000')\n\nax.text(0.23, 0.07, r'valor-p = 0.0038',transform=ax.transAxes, fontsize=10, color='#000')\nax.text(0.08, -0.15, r'z = -2.67',transform=ax.transAxes, fontsize=12, color='#000')\n\n# L\u00ednea vertical\nax.axvline(t.ppf(0.005, 47), color='#009929', linestyle='--', label=r'$t_{\\alpha/2}$')\n\n# Sombrear la parte de -2.67 hacia la izquierda\nax.fill_between(x, y, where=(x &lt;= -2.67), color='#009929', alpha=0.5)\n\nax.grid(False)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm from scipy.stats import t  #GRAFICO1 # Generar datos de la distribuci\u00f3n muestral x = np.linspace(0 - 4 * 1, 0 + 4 * 1, 1000) y = norm.pdf(x*3, 0, 4)  # Crear la gr\u00e1fica fig, ax = plt.subplots() ax.plot(x, y, color='#009929') # Establecer el color de fondo ax.set_facecolor('#d4f8b7') # Pintar el fondo externo del gr\u00e1fico fig.patch.set_facecolor('#D4F8B7') ax.set_xlabel(f'$\u03bc_0$ = 3', fontsize=12)  # Agregar informaci\u00f3n sobre el error est\u00e1ndar info_error_estandar = r'$\u03c3_\\bar{x}$ = $\\frac{\\sigma}{\\sqrt{n}} = 0.03 $' ax.text(0.6, 0.88, info_error_estandar, transform=ax.transAxes, fontsize=13, color='#000') ax.text(-0.03, -0.15, r'$\\bar{x} = 2.92$',transform=ax.transAxes, fontsize=12, color='#000') ax.text(0.02, 0.85, r'Distribuci\u00f3n de muestreo',transform=ax.transAxes, fontsize=10, color='#000') ax.text(0.17, 0.77, r'de $\\bar{x}$',transform=ax.transAxes, fontsize=12, color='#000')  # L\u00ednea vertical ax.axvline(t.ppf(0.005, 47), color='#009929', linestyle='--', label=r'$t_{\\alpha/2}$')  # Sombrear la parte de -2.67 hacia la izquierda ax.fill_between(x, y, where=(x &lt;= -2.67), color='#009929', alpha=0.5)   ax.grid(False) plt.show()  #GRAFICO2 # Generar datos de la distribuci\u00f3n muestral x = np.linspace(0 - 4 * 1, 0 + 4 * 1, 1000) y = norm.pdf(x*3, 0, 4)  # Crear la gr\u00e1fica fig, ax = plt.subplots() ax.plot(x, y, color='#009929') # Establecer el color de fondo ax.set_facecolor('#d4f8b7') # Pintar el fondo externo del gr\u00e1fico fig.patch.set_facecolor('#D4F8B7')  # Agregar informaci\u00f3n sobre el error est\u00e1ndar ax.text(0.58, 0.85, r'Distribuci\u00f3n de muestreo de',transform=ax.transAxes, fontsize=10, color='#000') ax.text(0.69, 0.72, r'$z = \\frac{{\\bar{x} - \\mu_0}}{{\\frac{\\sigma}{\\sqrt{n}}}}$',transform=ax.transAxes, fontsize=14, color='#000')  ax.text(0.23, 0.07, r'valor-p = 0.0038',transform=ax.transAxes, fontsize=10, color='#000') ax.text(0.08, -0.15, r'z = -2.67',transform=ax.transAxes, fontsize=12, color='#000')  # L\u00ednea vertical ax.axvline(t.ppf(0.005, 47), color='#009929', linestyle='--', label=r'$t_{\\alpha/2}$')  # Sombrear la parte de -2.67 hacia la izquierda ax.fill_between(x, y, where=(x &lt;= -2.67), color='#009929', alpha=0.5)  ax.grid(False) plt.show() <p>Ahora se puede establecer ya la regla general para determinar cu\u00e1ndo rechazar la hip\u00f3tesis nula al usar el m\u00e9todo del valor-p. Dado un nivel de significancia $\u03b1$, la regla para el rechazo utilizando el m\u00e9todo del valor-p es la siguiente.</p> REGLA PARA EL RECHAZO USANDO EL VALOR-p Rechazar $H_0$ si el $valor-p \u2264 \u03b1$  En la prueba para \"Caf\u00e9 Sierra\", el valor-p de 0.0038 condujo al rechazo de la hip\u00f3tesis nula. Aunque la decisi\u00f3n de rechazar se bas\u00f3 en comparar el valor-p con el nivel de significancia especificado por el director de la IBRC, el valor-p observado de 0.0038 sugiere que $H_0$ habr\u00eda sido rechazada para cualquier valor de $\u03b1 \u2265 0.0038$. Por esta raz\u00f3n, el valor-p tambi\u00e9n se conoce como nivel de significancia observado.  M\u00e9todo del valor cr\u00edtico El valor cr\u00edtico es el valor del estad\u00edstico de prueba que corresponde a un \u00e1rea de \u03b1 (nivel de significancia) en la cola inferior de la distribuci\u00f3n de muestreo del estad\u00edstico. <p>En el ejemplo de \"Caf\u00e9 Sierra\", se ilustra el funcionamiento del m\u00e9todo del valor cr\u00edtico. En situaciones donde se conoce la desviaci\u00f3n est\u00e1ndar $\u03c3$, la distribuci\u00f3n de muestreo del estad\u00edstico de prueba $z$ es la distribuci\u00f3n normal est\u00e1ndar. El valor cr\u00edtico es aquel que corresponde a un \u00e1rea de $\u03b1 = 0.01$ en la cola inferior de esta distribuci\u00f3n.</p> <p>Consultando la tabla de probabilidad normal est\u00e1ndar, se observa que $z \u2264 \u22122.33$ proporciona un \u00e1rea de 0.01 en la cola inferior (ver figura 9.3). Por lo tanto, si el valor del estad\u00edstico de prueba obtenido con la muestra es menor o igual a \u22122.33, el valor-p correspondiente ser\u00e1 menor o igual a 0.01, lo que lleva al rechazo de la hip\u00f3tesis nula. Entonces, en el estudio de \"Caf\u00e9 Sierra\" la regla para el rechazo usando el valor cr\u00edtico para un nivel de significancia de 0.01 es:</p> Rechazar $H_0$ si el $z \u2264 -2.33$  En nuestro ejemplo, $\\bar{x} = 2.92$ y el estad\u00edstico de prueba es $z = -2.67$. Como $z = -2.67 &lt; -2.33$, $H_0$ puede ser rechazada y concluir que \"Caf\u00e9 Sierra\" est\u00e1 llenando las latas de manera deficiente.  FIGURA 9.3 Valor cr\u00edtico  = -2.33 en la prueba de hip\u00f3tesis de \"Caf\u00e9 Sierra\" <p> Video:Prueba de hipotesis Valor-P</p> In\u00a0[\u00a0]: Copied! <pre># importar la clase que permite ver videos\nfrom IPython.display import YouTubeVideo\n# crear una instancia del objeto YouTubeVideo\nyoutube_video=YouTubeVideo('aaJndWRoWWo')\n#mostrar el video de youtube\ndisplay(youtube_video)\n</pre> # importar la clase que permite ver videos from IPython.display import YouTubeVideo # crear una instancia del objeto YouTubeVideo youtube_video=YouTubeVideo('aaJndWRoWWo') #mostrar el video de youtube display(youtube_video) <p> Video:Prueba de hipotesis Valor Critico</p> In\u00a0[\u00a0]: Copied! <pre># importar la clase que permite ver videos\nfrom IPython.display import YouTubeVideo\n# crear una instancia del objeto YouTubeVideo\nyoutube_video=YouTubeVideo('FJHh-l7OMT0')\n#mostrar el video de youtube\ndisplay(youtube_video)\n</pre> # importar la clase que permite ver videos from IPython.display import YouTubeVideo # crear una instancia del objeto YouTubeVideo youtube_video=YouTubeVideo('FJHh-l7OMT0') #mostrar el video de youtube display(youtube_video) In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Generar datos de la distribuci\u00f3n muestral\nx = np.linspace(0 - 4 * 1, 0 + 4 * 1, 1000)\ny = norm.pdf(x*3, 0, 4)\n\n# Crear la gr\u00e1fica\nfig, ax = plt.subplots()\nax.plot(x, y, color='#009929')\n# Establecer el color de fondo\nax.set_facecolor('#d4f8b7')\n# Pintar el fondo externo del gr\u00e1fico\nfig.patch.set_facecolor('#D4F8B7')\n\n# Agregar informaci\u00f3n sobre el error est\u00e1ndar\nax.text(0.02, 0.85, r'Distribuci\u00f3n de muestreo de',transform=ax.transAxes, fontsize=9, color='#000')\nax.text(0.13, 0.72, r'$z = \\frac{{\\bar{x} - \\mu_0}}{{\\frac{\\sigma}{\\sqrt{n}}}}$',transform=ax.transAxes, fontsize=15, color='#000')\n\nax.text(0.02, 0.15, r'\u03b1 = 0.01',transform=ax.transAxes, fontsize=13, color='#000')\n\nax.text(0.15, -0.15, r'z = -2.33',transform=ax.transAxes, fontsize=10, color='#000')\n\n# Sombrear la parte de -2.33 hacia la izquierda\nax.fill_between(x, y, where=(x &lt;= -2.33), color='#009929', alpha=0.5)\n\nax.grid(False)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm  # Generar datos de la distribuci\u00f3n muestral x = np.linspace(0 - 4 * 1, 0 + 4 * 1, 1000) y = norm.pdf(x*3, 0, 4)  # Crear la gr\u00e1fica fig, ax = plt.subplots() ax.plot(x, y, color='#009929') # Establecer el color de fondo ax.set_facecolor('#d4f8b7') # Pintar el fondo externo del gr\u00e1fico fig.patch.set_facecolor('#D4F8B7')  # Agregar informaci\u00f3n sobre el error est\u00e1ndar ax.text(0.02, 0.85, r'Distribuci\u00f3n de muestreo de',transform=ax.transAxes, fontsize=9, color='#000') ax.text(0.13, 0.72, r'$z = \\frac{{\\bar{x} - \\mu_0}}{{\\frac{\\sigma}{\\sqrt{n}}}}$',transform=ax.transAxes, fontsize=15, color='#000')  ax.text(0.02, 0.15, r'\u03b1 = 0.01',transform=ax.transAxes, fontsize=13, color='#000')  ax.text(0.15, -0.15, r'z = -2.33',transform=ax.transAxes, fontsize=10, color='#000')  # Sombrear la parte de -2.33 hacia la izquierda ax.fill_between(x, y, where=(x &lt;= -2.33), color='#009929', alpha=0.5)  ax.grid(False) plt.show() <p>La regla de rechazo se puede generalizar empleando el m\u00e9todo del valor cr\u00edtico para cualquier nivel de significancia. La regla de rechazo en una prueba de cola inferior es la siguiente:</p> REGLA PARA EL RECHAZO EN UNA PRUEBA DE COLA INFERIOR: M\u00c9TODO DEL VALOR CR\u00cdTICO Rechazar $H_0$ si el $z \u2264 z_\u03b1$ donde $-z_\u03b1$ es el valor cr\u00edtico; es decir, el valor $z$ que proporciona un \u00e1rea de \u03b1 en la cola inferior de la distribuci\u00f3n normal est\u00e1ndar.  El estudio de \"Caf\u00e9 Sierra\" sirvi\u00f3 para ilustrar c\u00f3mo realizar una prueba de cola inferior. El mismo m\u00e9todo general se usa para realizar una prueba de cola superior.  <p>Utilizando el m\u00e9todo del valor cr\u00edtico, la hip\u00f3tesis nula es rechazada si el valor del estad\u00edstico de prueba es mayor o igual al valor cr\u00edtico $z_\u03b1$; en otras palabras, $H_0$ es rechazada si $z \u2265 z_\u03b1$.</p> <p>Para abardor mejor el punto de \"PRUEBA DE UNA COLA\" se puede observar el siguiente video, para un mejor entendimiento.</p> In\u00a0[5]: Copied! <pre># importar la clase que permite ver videos\nfrom IPython.display import YouTubeVideo\n# crear una instancia del objeto YouTubeVideo\nyoutube_video=YouTubeVideo('UNnQewoA8C0')\n#mostrar el video de youtube\ndisplay(youtube_video)\n</pre> # importar la clase que permite ver videos from IPython.display import YouTubeVideo # crear una instancia del objeto YouTubeVideo youtube_video=YouTubeVideo('UNnQewoA8C0') #mostrar el video de youtube display(youtube_video) Prueba de dos colas <p>En las pruebas de hip\u00f3tesis, la forma general de una prueba de dos colas es la siguiente:</p> $$H_0: \u03bc = \u03bc_0$$ $$H_a: \u03bc \\neq \u03bc_0$$ <p>Consideremos el caso de una prueba de hip\u00f3tesis en la empresa \"BoliviaGolfCrafters\".</p> <p>La Federaci\u00f3n Boliviana de Golf (FBG) establece est\u00e1ndares para los fabricantes de equipos de golf, y \"BoliviaGolfCrafters\", una empresa de fabricaci\u00f3n de pelotas de golf, utiliza procesos de alta tecnolog\u00eda. La distancia media de recorrido objetivo es 295 yardas, pero el proceso puede desajustarse, produciendo pelotas con distancias diferentes. \"BoliviaGolfCrafters\" implementa un programa de control de calidad que implica pruebas de hip\u00f3tesis con muestras de 50 pelotas. La hip\u00f3tesis nula asume que el proceso est\u00e1 funcionando correctamente, con una distancia media de 295 yardas, mientras que la hip\u00f3tesis alternativa sugiere que la distancia media no es igual a 295 yardas. Estas hip\u00f3tesis se expresan como:</p> $H_0: \u03bc = 295$ $H_a: \u03bc \\ne 295$ <p>Este enfoque permite a \"BoliviaGolfCrafters\" monitorear y ajustar su proceso de fabricaci\u00f3n para cumplir con los est\u00e1ndares de la FBG y satisfacer las expectativas de los clientes.</p> <p>Si la media muestral $\\bar{x}$ es significativamente menor o significativamente mayor que 295 yardas, $H_0$ ser\u00e1 rechazada. En este caso, se tomar\u00e1n medidas para ajustar el proceso de manufactura. Por otro lado, si $x$ no se desv\u00eda una cantidad significativa de la media hipot\u00e9tica $\u03bc_0 = 295$, $H_0$ no ser\u00e1 rechazada, y no se tomar\u00e1 medida alguna para ajustar el proceso de manufactura.</p> <p>El equipo de control de calidad elige $\u03b1 = 0.05$ como nivel de significancia para esta prueba. Datos de pruebas anteriores realizadas sabiendo que el proceso est\u00e1 ajustado, indican que se puede suponer que la desviaci\u00f3n est\u00e1ndar poblacional se conoce y que su valor es $\u03c3 = 12$. Por ende, con un tama\u00f1o de muestra $n = 50$, el error est\u00e1ndar $\\bar{x}$ es:</p> $\u03c3_\\bar{x} = \\frac{\\sigma}{\\sqrt{n}} = \\frac{12}{\\sqrt{50}} = 1.7 $ <p>Como el tama\u00f1o de la muestra es grande, el teorema del l\u00edmite central (cap\u00edtulo 7) permite concluir que la distribuci\u00f3n de muestreo de $\\bar{x}$ puede aproximarse mediante una distribuci\u00f3n normal. En la (figura 9.4) se ilustra la distribuci\u00f3n de muestreo de $\\bar{x}$ para la prueba de hip\u00f3tesis de \"BoliviaGolfCrafters\" con una media poblacional hipot\u00e9tica de $\u03bc_0 = 295$.</p> FIGURA 9.4 Distribuci\u00f3n de muestreo de $\\bar{x}$ en la prueba de hip\u00f3tesis de \"BoliviaGolfCrafters\" In\u00a0[6]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Par\u00e1metros de la distribuci\u00f3n muestral\nmedia_poblacional = 295\nerror_estandar = 1.7\n# Generar datos de la distribuci\u00f3n muestral\nx = np.linspace(media_poblacional - 4 * error_estandar, media_poblacional + 4 * error_estandar, 1000)\ny = norm.pdf(x, media_poblacional, error_estandar)\n\n# Crear la gr\u00e1fica\nfig, ax = plt.subplots()\nax.plot(x, y, color='#009929')\n# Establecer el color de fondo\nax.set_facecolor('#d4f8b7')\n# Pintar el fondo externo del gr\u00e1fico\nfig.patch.set_facecolor('#D4F8B7')\nax.set_xlabel(f'$\u03bc_0$ = {media_poblacional}', fontsize=12)\n\n# Agregar informaci\u00f3n sobre el error est\u00e1ndar\ninfo_error_estandar = r'$\u03c3_\\bar{x}$ = $\\frac{\\sigma}{\\sqrt{n}} = \\frac{12}{\\sqrt{50}} = 1.7$'\nax.text(0.63, 0.85, info_error_estandar, transform=ax.transAxes, fontsize=12, color='#000')\nax.text(0.02, 0.85, r'Distribuci\u00f3n de muestreo',transform=ax.transAxes, fontsize=11, color='#000')\nax.text(0.17, 0.77, r'de $\\bar{x}$',transform=ax.transAxes, fontsize=12, color='#000')\nax.text(0.50, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#000')\n\nax.grid(False)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm  # Par\u00e1metros de la distribuci\u00f3n muestral media_poblacional = 295 error_estandar = 1.7 # Generar datos de la distribuci\u00f3n muestral x = np.linspace(media_poblacional - 4 * error_estandar, media_poblacional + 4 * error_estandar, 1000) y = norm.pdf(x, media_poblacional, error_estandar)  # Crear la gr\u00e1fica fig, ax = plt.subplots() ax.plot(x, y, color='#009929') # Establecer el color de fondo ax.set_facecolor('#d4f8b7') # Pintar el fondo externo del gr\u00e1fico fig.patch.set_facecolor('#D4F8B7') ax.set_xlabel(f'$\u03bc_0$ = {media_poblacional}', fontsize=12)  # Agregar informaci\u00f3n sobre el error est\u00e1ndar info_error_estandar = r'$\u03c3_\\bar{x}$ = $\\frac{\\sigma}{\\sqrt{n}} = \\frac{12}{\\sqrt{50}} = 1.7$' ax.text(0.63, 0.85, info_error_estandar, transform=ax.transAxes, fontsize=12, color='#000') ax.text(0.02, 0.85, r'Distribuci\u00f3n de muestreo',transform=ax.transAxes, fontsize=11, color='#000') ax.text(0.17, 0.77, r'de $\\bar{x}$',transform=ax.transAxes, fontsize=12, color='#000') ax.text(0.50, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#000')  ax.grid(False) plt.show() M\u00e9todo del valor-p <p>A continuaci\u00f3n veremos c\u00f3mo se calcula el valor-p en la prueba de hip\u00f3tesis de \"BoliviaGolfCrafters\". Primero calculamos el valor del estad\u00edstico de prueba. En el caso en que se conoce $\u03c3$, el estad\u00edstico de prueba $z$ es la variable aleatoria normal est\u00e1ndar. Empleando la ecuaci\u00f3n ya conocida con $\\bar{x} = 297.6$, el valor del estad\u00edstico de prueba es:</p> <p>$$z = \\frac{{\\bar{x} - \\mu_0}}{{\\frac{\\sigma}{\\sqrt{n}}}} = \\frac{{297.6 - 295}}{{\\frac{12}{\\sqrt{50}}}} = 1.53$$</p> <p>En el c\u00e1lculo del valor-p para la prueba de hip\u00f3tesis de dos colas en \"BoliviaGolfCrafters\", se busca la probabilidad de obtener un valor tan improbable como $z = 1.53$. Dado que es una prueba de dos colas, se consideran tanto los valores $z \u2265 1.53$ como $z \u2264 \u22121.53$. La probabilidad se calcula duplicando el \u00e1rea bajo la curva normal est\u00e1ndar a la derecha de $z = 1.53$. Para $z = 1.53$, el \u00e1rea a la izquierda es $0.9370$, y el \u00e1rea a la derecha es $1.0000 - 0.9370 = 0.0630$. Al duplicar este valor, se obtiene $2(0.0630) = 0.1260$ como el valor-p.</p> FIGURA 9.5 Valor-p en la prueba de hip\u00f3tesis de \"BoliviaGolfCrafters\" In\u00a0[7]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Generar datos de la distribuci\u00f3n muestral\nx = np.linspace(0 - 1 * 2, 0 + 1 * 2, 1000)\ny = norm.pdf(x*3, 0, 2)\n\n\n# Crear la gr\u00e1fica\nfig, ax = plt.subplots()\nax.plot(x, y, color='#009929')\n# Establecer el color de fondo\nax.set_facecolor('#d4f8b7')\n# Pintar el fondo externo del gr\u00e1fico\nfig.patch.set_facecolor('#D4F8B7')\nax.set_xlabel(f'$valor-p = 2(0.0630) = 0.1260$', fontsize=10)\n\n# Agregar informaci\u00f3n sobre el error est\u00e1ndar\nax.text(0.02, 0.15, r'P(z \u2264 -1.53) = 0.0630',transform=ax.transAxes, fontsize=9, color='#000')\nax.text(0.76, 0.15, r'P(z \u2265 1.53) = 0.0630',transform=ax.transAxes, fontsize=9, color='#000')\n\nax.text(0.06, -0.15, r'-1.53',transform=ax.transAxes, fontsize=12, color='#000')\nax.text(0.86, -0.15, r'1.53',transform=ax.transAxes, fontsize=12, color='#000')\n\n# Sombrear la parte de -1.53 hacia la izquierda\nax.fill_between(x, y, where=(x &lt;= -1.53), color='#009929', alpha=0.5)\n# Sombrear la parte de 1.53 hacia la derecha\nax.fill_between(x, y, where=(x &gt;= 1.53), color='#009929', alpha=0.5)\n\nax.grid(False)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm  # Generar datos de la distribuci\u00f3n muestral x = np.linspace(0 - 1 * 2, 0 + 1 * 2, 1000) y = norm.pdf(x*3, 0, 2)   # Crear la gr\u00e1fica fig, ax = plt.subplots() ax.plot(x, y, color='#009929') # Establecer el color de fondo ax.set_facecolor('#d4f8b7') # Pintar el fondo externo del gr\u00e1fico fig.patch.set_facecolor('#D4F8B7') ax.set_xlabel(f'$valor-p = 2(0.0630) = 0.1260$', fontsize=10)  # Agregar informaci\u00f3n sobre el error est\u00e1ndar ax.text(0.02, 0.15, r'P(z \u2264 -1.53) = 0.0630',transform=ax.transAxes, fontsize=9, color='#000') ax.text(0.76, 0.15, r'P(z \u2265 1.53) = 0.0630',transform=ax.transAxes, fontsize=9, color='#000')  ax.text(0.06, -0.15, r'-1.53',transform=ax.transAxes, fontsize=12, color='#000') ax.text(0.86, -0.15, r'1.53',transform=ax.transAxes, fontsize=12, color='#000')  # Sombrear la parte de -1.53 hacia la izquierda ax.fill_between(x, y, where=(x &lt;= -1.53), color='#009929', alpha=0.5) # Sombrear la parte de 1.53 hacia la derecha ax.fill_between(x, y, where=(x &gt;= 1.53), color='#009929', alpha=0.5)  ax.grid(False) plt.show() <p>Al comparar el valor-p con el nivel de significancia $\u03b1 = 0.05$, se encuentra que $0.1260 &gt; 0.05$. Por lo tanto, la hip\u00f3tesis nula no es rechazada, indicando que no se necesitan medidas para ajustar el proceso de manufactura de \"BoliviaGolfCrafters\", ya que la distancia media de recorrido no difiere significativamente de $295$ yardas seg\u00fan la muestra analizada.</p> C\u00c1LCULO DEL VALOR-p EN UNA PRUEBA DE DOS COLAS <ol> <li>Determine el valor del estad\u00edstico de prueba $z$.</li> <li>Si el valor del estad\u00edstico de prueba est\u00e1 en la cola superior ($z &gt; 0$), encuentre el \u00e1rea bajo la curva normal est\u00e1ndar a la derecha de $z$; si est\u00e1 en la cola inferior ($z &lt; 0$), localice el \u00e1rea bajo la curva normal est\u00e1ndar a la izquierda de $z$.</li> <li>Duplique el \u00e1rea, o probabilidad, en la cola, obtenida en el paso 2 y determine el valor-p.</li></ol> M\u00e9todo del valor cr\u00edtico <p>En la figura 9.6 se aprecia que los valores cr\u00edticos en esta prueba se encuentran tanto en la cola superior como en la cola inferior de la distribuci\u00f3n normal est\u00e1ndar. Si el nivel de significancia es $\u03b1 = 0.05$, en cada cola, el \u00e1rea m\u00e1s all\u00e1 del valor cr\u00edtico es $\u03b1/2 = 0.05/2 = 0.025$. En la tabla de probabilidad normal est\u00e1ndar se encuentra que los valores cr\u00edticos para el estad\u00edstico de prueba son $-z_0.025 = -1.96$ y $z_0.025 = 1.96. Entonces, al utilizar el m\u00e9todo del valor cr\u00edtico, la regla de rechazo para dos colas es:</p> Rechazar $H_0$ si el $z \u2264 -1.96$ o $z \u2265 1.96$  Como en el estudio de MaxFlight el valor del estad\u00edstico de prueba es $z = 1.53$, la evidenciaestad\u00edstica no permitir\u00e1 rechazar la hip\u00f3tesis nula a un nivel de signifi cancia de $0.05$.  FIGURA 9.6 Valores cr\u00edticos en la prueba de hip\u00f3tesis de \"BoliviaGolfCrafters\" In\u00a0[8]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Generar datos de la distribuci\u00f3n muestral\nx = np.linspace(0 - 3 * 1, 0 + 3 * 1, 1000)\ny = norm.pdf(x*3, 0, 3)\n\n# Crear la gr\u00e1fica\nfig, ax = plt.subplots()\nax.plot(x, y, color='#009929')\n# Establecer el color de fondo\nax.set_facecolor('#d4f8b7')\n# Pintar el fondo externo del gr\u00e1fico\nfig.patch.set_facecolor('#D4F8B7')\nax.set_xlabel(f'&lt;-----|                              Rechazar $H_0$                                |-----&gt;', fontsize=10)\n\n# Agregar informaci\u00f3n sobre el error est\u00e1ndar\nax.text(0.02, 0.20, r'\u00c1rea = 0.025',transform=ax.transAxes, fontsize=10, color='#000')\nax.text(0.80, 0.20, r'\u00c1rea = 0.025',transform=ax.transAxes, fontsize=10, color='#000')\n\nax.text(0.15, -0.15, r'-1.96',transform=ax.transAxes, fontsize=12, color='#000')\nax.text(0.76, -0.15, r'1.96',transform=ax.transAxes, fontsize=12, color='#000')\n\n# Sombrear la parte de -1.96 hacia la izquierda\nax.fill_between(x, y, where=(x &lt;= -1.96), color='#009929', alpha=0.5)\n# Sombrear la parte de 1.96 hacia la derecha\nax.fill_between(x, y, where=(x &gt;= 1.96), color='#009929', alpha=0.5)\n\nax.grid(False)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm  # Generar datos de la distribuci\u00f3n muestral x = np.linspace(0 - 3 * 1, 0 + 3 * 1, 1000) y = norm.pdf(x*3, 0, 3)  # Crear la gr\u00e1fica fig, ax = plt.subplots() ax.plot(x, y, color='#009929') # Establecer el color de fondo ax.set_facecolor('#d4f8b7') # Pintar el fondo externo del gr\u00e1fico fig.patch.set_facecolor('#D4F8B7') ax.set_xlabel(f'&lt;-----|                              Rechazar $H_0$                                |-----&gt;', fontsize=10)  # Agregar informaci\u00f3n sobre el error est\u00e1ndar ax.text(0.02, 0.20, r'\u00c1rea = 0.025',transform=ax.transAxes, fontsize=10, color='#000') ax.text(0.80, 0.20, r'\u00c1rea = 0.025',transform=ax.transAxes, fontsize=10, color='#000')  ax.text(0.15, -0.15, r'-1.96',transform=ax.transAxes, fontsize=12, color='#000') ax.text(0.76, -0.15, r'1.96',transform=ax.transAxes, fontsize=12, color='#000')  # Sombrear la parte de -1.96 hacia la izquierda ax.fill_between(x, y, where=(x &lt;= -1.96), color='#009929', alpha=0.5) # Sombrear la parte de 1.96 hacia la derecha ax.fill_between(x, y, where=(x &gt;= 1.96), color='#009929', alpha=0.5)  ax.grid(False) plt.show() <p>Para abardor mejor el punto de \"PRUEBA DE DOS COLAS\" se puede observar el siguiente video, para un mejor entendimiento.</p> <p> Video:  Prueba de hip\u00f3tesis de 2 colas para la media (P-Valor)</p> In\u00a0[81]: Copied! <pre># importar la clase que permite ver videos\nfrom IPython.display import YouTubeVideo\n# crear una instancia del objeto YouTubeVideo\nyoutube_video=YouTubeVideo('qusDCMZiUms')\n#mostrar el video de youtube\ndisplay(youtube_video)\n</pre> # importar la clase que permite ver videos from IPython.display import YouTubeVideo # crear una instancia del objeto YouTubeVideo youtube_video=YouTubeVideo('qusDCMZiUms') #mostrar el video de youtube display(youtube_video) <p> Video: Prueba de hip\u00f3tesis de 2 colas para la media (valor cr\u00edtico)</p> In\u00a0[77]: Copied! <pre># importar la clase que permite ver videos\nfrom IPython.display import YouTubeVideo\n# crear una instancia del objeto YouTubeVideo\nyoutube_video=YouTubeVideo('HfFCuRK3H94')\n#mostrar el video de youtube\ndisplay(youtube_video)\n</pre> # importar la clase que permite ver videos from IPython.display import YouTubeVideo # crear una instancia del objeto YouTubeVideo youtube_video=YouTubeVideo('HfFCuRK3H94') #mostrar el video de youtube display(youtube_video) In\u00a0[\u00a0]: Copied! <pre>&lt;span &gt;&lt;h2 style=\"color:#009929\"&gt; Video: Prueba de hip\u00f3tesis de una media con Z &lt;/h2&gt;&lt;/span&gt;\n</pre>  Video: Prueba de hip\u00f3tesis de una media con Z  In\u00a0[72]: Copied! <pre># importar la clase que permite ver videos\nfrom IPython.display import YouTubeVideo\n# crear una instancia del objeto YouTubeVideo\nyoutube_video=YouTubeVideo('MKHjW6gG3SY')\n#mostrar el video de youtube\ndisplay(youtube_video)\n</pre> # importar la clase que permite ver videos from IPython.display import YouTubeVideo # crear una instancia del objeto YouTubeVideo youtube_video=YouTubeVideo('MKHjW6gG3SY') #mostrar el video de youtube display(youtube_video) TABLA 9.2 Resumen de las pruebas de hip\u00f3tesis para la media poblacional: caso con \u03c3 conocida Prueba de cola inferior Prueba de cola superior Prueba de dos colas Hip\u00f3tesis $$H_0: \u03bc \u2265 \u03bc_0$$ $$H_a: \u03bc &lt; \u03bc_0$$ $$H_0: \u03bc \u2264 \u03bc_0$$ $$H_a: \u03bc &gt; \u03bc_0$$ $$H_0: \u03bc = \u03bc_0$$ $$H_a: \u03bc \\ne \u03bc_0$$ Estad\u00edstico de prueba $$z = \\frac{{\\bar{x} - \\mu_0}}{{\\frac{\\sigma}{\\sqrt{n}}}}$$ $$z = \\frac{{\\bar{x} - \\mu_0}}{{\\frac{\\sigma}{\\sqrt{n}}}}$$ $$z = \\frac{{\\bar{x} - \\mu_0}}{{\\frac{\\sigma}{\\sqrt{n}}}}$$ Regla de rechazo: M\u00e9todo del valor-p Rechazar $H_0$ si el valor-p $\u2264 \u03b1$ Rechazar $H_0$ si el valor-p $\u2264 \u03b1$ Rechazar $H_0$ si el valor-p $\u2264 \u03b1$ Regla de rechazo: M\u00e9todo del valor cr\u00edtico Rechazar $H_0$ si $z \u2264 -z_\u03b1$ Rechazar $H_0$ si $z \u2265 z_\u03b1$ Rechazar $H_0$ si $z \u2264 -z_{\u03b1/2}$ o si $z \u2265 z_{\u03b1/2}$ <p>En el siguiente c\u00f3digo se muestra un video para ayudar a entender mejor el tema, haciendo un repaso de todo lo avanzado. </p> Ejercicios Para la parte de ejercicios, primeramente observaremos algunos videos y posteriormente se resolvera los ejercicios planteados. In\u00a0[62]: Copied! <pre># importar la clase que permite ver videos\nfrom IPython.display import YouTubeVideo\n# crear una instancia del objeto YouTubeVideo\nyoutube_video=YouTubeVideo('03utL7myA3g')\n#mostrar el video de youtube\ndisplay(youtube_video)\n</pre> # importar la clase que permite ver videos from IPython.display import YouTubeVideo # crear una instancia del objeto YouTubeVideo youtube_video=YouTubeVideo('03utL7myA3g') #mostrar el video de youtube display(youtube_video) In\u00a0[64]: Copied! <pre># importar la clase que permite ver videos\nfrom IPython.display import YouTubeVideo\n# crear una instancia del objeto YouTubeVideo\nyoutube_video=YouTubeVideo('V036IS_sga0')\n#mostrar el video de youtube\ndisplay(youtube_video)\n</pre> # importar la clase que permite ver videos from IPython.display import YouTubeVideo # crear una instancia del objeto YouTubeVideo youtube_video=YouTubeVideo('V036IS_sga0') #mostrar el video de youtube display(youtube_video) Ejercicio 1  Considere la prueba de hip\u00f3tesis siguiente: $H_0: \u03bc \u2264 25$ $H_a: \u03bc &gt; 25$ En una muestra de 40, la media muestral es 26.4 y la desviaci\u00f3n est\u00e1ndar poblacional es 6.  <p>a) Calcule el valor del estad\u00edstico de prueba.</p> <p>b) \u00bfCu\u00e1l es el valor-p?</p> <p>c) Use $\u03b1 = 0.01$, \u00bfcu\u00e1l es su conclusi\u00f3n?</p> <p>d) \u00bfCu\u00e1l es la regla de rechazo si se usa el m\u00e9todo del valor cr\u00edtico? \u00bfQu\u00e9 concluye?</p> <p>$Datos:$</p> <p>$n =40$</p> <p>$\\bar{x} = 26.4$</p> <p>$\u03c3 = 6$</p> <p>$\u03c3_\\bar{x} = \\frac{\u03c3}{\\sqrt{n}}$</p> <p>Inciso a)</p> <p>$$z = \\frac{{\\bar{x} - \\mu_0}}{{\\frac{\\sigma}{\\sqrt{n}}}} = \\frac{{{26.4} - 25}}{{\\frac{6}{\\sqrt{40}}}} = 1.48$$</p> <p>Inciso b)</p> <p>Se busca el valor de $z = 1.48$ en la tabla normal, entonces:</p> $valor-p = (1 - 0.9306) = 0.0694$ <p>Inciso c)</p> <p>La regla me dice que se debe rechazar $H_0$ si el $valor-p \u2264 \u03b1$, por lo cual tenemos que como el valor-p es mayor que $\u03b1$ (0.01) se acepta la hip\u00f3tesis nula.</p> <p>Inciso d)</p> <p>El m\u00e9todo del valor critico me dice que debo rechazar $H_0$ si $z \u2265 2.33$, por lo que tenemos que utilizando el valor de $z$ se acepta la hip\u00f3tesis nula, ya que $1.48 &lt; 2.33$</p> Ejercicio en c\u00f3digo In\u00a0[12]: Copied! <pre>import math\n# Datos\nn = 40  # Tama\u00f1o de la muestra\nx_bar = 26.4  # Media muestral\nsigma = 6  # Desviaci\u00f3n est\u00e1ndar poblacional\n\n# Estad\u00edstico de prueba\nmu_0 = 25  # Valor de la hip\u00f3tesis nula\nse = sigma / (n ** 0.5)  # Error est\u00e1ndar de la media\nz = (x_bar - mu_0) / se  # C\u00e1lculo del estad\u00edstico de prueba (z)\nprint(\"Estad\u00edstico de prueba (z):\", round(z, 2))\n\n# Valor-p\n#p_value = 1 - stats.norm.cdf(z)  # C\u00e1lculo del valor-p utilizando la funci\u00f3n cdf() de la distribuci\u00f3n normal est\u00e1ndar\np_value = 1 - 0.9306  # C\u00e1lculo del valor-p utilizando la funci\u00f3n cdf() de la distribuci\u00f3n normal est\u00e1ndar\nprint(\"Valor-p:\", round(p_value, 4))\n\n# Conclusi\u00f3n\nalpha = 0.01  # Nivel de significancia\nif p_value &lt;= alpha:\n    print(\"Se rechaza la hip\u00f3tesis nula (H0)\")\nelse:\n    print(\"Se acepta la hip\u00f3tesis nula (H0)\")\n</pre> import math # Datos n = 40  # Tama\u00f1o de la muestra x_bar = 26.4  # Media muestral sigma = 6  # Desviaci\u00f3n est\u00e1ndar poblacional  # Estad\u00edstico de prueba mu_0 = 25  # Valor de la hip\u00f3tesis nula se = sigma / (n ** 0.5)  # Error est\u00e1ndar de la media z = (x_bar - mu_0) / se  # C\u00e1lculo del estad\u00edstico de prueba (z) print(\"Estad\u00edstico de prueba (z):\", round(z, 2))  # Valor-p #p_value = 1 - stats.norm.cdf(z)  # C\u00e1lculo del valor-p utilizando la funci\u00f3n cdf() de la distribuci\u00f3n normal est\u00e1ndar p_value = 1 - 0.9306  # C\u00e1lculo del valor-p utilizando la funci\u00f3n cdf() de la distribuci\u00f3n normal est\u00e1ndar print(\"Valor-p:\", round(p_value, 4))  # Conclusi\u00f3n alpha = 0.01  # Nivel de significancia if p_value &lt;= alpha:     print(\"Se rechaza la hip\u00f3tesis nula (H0)\") else:     print(\"Se acepta la hip\u00f3tesis nula (H0)\")           <pre>Estad\u00edstico de prueba (z): 1.48\nValor-p: 0.0694\nSe acepta la hip\u00f3tesis nula (H0)\n</pre> Ejercicio 2  Considere la prueba de hip\u00f3tesis siguiente: $H_0: \u03bc \u2265 80$ $H_a: \u03bc &lt; 80$ Se utiliz\u00f3 una muestra de 100 y la desviaci\u00f3n est\u00e1ndar poblacional es 12. Calcule el valor-p y establezca su conclusi\u00f3n para cada uno de los resultados muestrales siguientes. Use $\u03b1 = 0.01$. a) $\\bar{x} = 78.5$ b) $\\bar{x} = 77$ c) $\\bar{x} = 75.5$ d) $\\bar{x} = 81$ <p>$Datos:$</p> <p>$n = 100$</p> <p>$\u03c3 = 12$</p> <p>$\u03c3_\\bar{x} = \\frac{\u03c3}{\\sqrt{n}}$</p> <p>Inciso a)</p> <p>$$z = \\frac{{\\bar{x} - \\mu_0}}{{\\frac{\\sigma}{\\sqrt{n}}}} = \\frac{{{78.5} - 80}}{{\\frac{12}{\\sqrt{100}}}} = -1.25$$</p> $valor-p = 0.1056$ $\u2234 H_0$ no es rechazada. <p>Inciso b)</p> <p>$$z = \\frac{{\\bar{x} - \\mu_0}}{{\\frac{\\sigma}{\\sqrt{n}}}} = \\frac{{{77} - 80}}{{\\frac{12}{\\sqrt{100}}}} = -2.50$$</p> $valor-p = 0.0062$ $\u2234 H_0$ es rechazada. <p>Inciso c)</p> <p>$$z = \\frac{{\\bar{x} - \\mu_0}}{{\\frac{\\sigma}{\\sqrt{n}}}} = \\frac{{{75.5} - 80}}{{\\frac{12}{\\sqrt{100}}}} = -3.75$$</p> $valor-p = 0$ $\u2234 H_0$ es rechazada. <p>Inciso d)</p> <p>$$z = \\frac{{\\bar{x} - \\mu_0}}{{\\frac{\\sigma}{\\sqrt{n}}}} = \\frac{{{81} - 80}}{{\\frac{12}{\\sqrt{100}}}} = 0.83$$</p> $valor-p = 0.7967$ $\u2234 H_0$ no es rechazada. Ejercicio en c\u00f3digo In\u00a0[16]: Copied! <pre>import math\n\n# Datos\nn = 100\nsigma = 12\nmu_0 = 80\n\n# C\u00e1lculo de sigma_x\nsigma_x = sigma / math.sqrt(n)\n\n# Inciso a)\nx_a = 78.5\nz_a = (x_a - mu_0) / sigma_x\nprint(\"Inciso a)\")\nprint(\"z =\", z_a)\nif z_a &gt;= -2.33:  # Valor cr\u00edtico para alpha = 0.01 (una cola)\n    print(\"\u2234 H0 no es rechazada.\")\nelse:\n    print(\"\u2234 H0 es rechazada.\")\n\n# Inciso b)\nx_b = 78.5\nz_b = (x_b - mu_0) / sigma_x\nprint(\"Inciso b)\")\nprint(\"z =\", z_b)\nif z_b &gt;= -2.33:  # Valor cr\u00edtico para alpha = 0.01 (una cola)\n    print(\"\u2234 H0 no es rechazada.\")\nelse:\n    print(\"\u2234 H0 es rechazada.\")\n\n# Inciso c)\nx_c = 75.5\nz_c = (x_c - mu_0) / sigma_x\nprint(\"Inciso c)\")\nprint(\"z =\", z_c)\nif z_c &gt;= -2.33:  # Valor cr\u00edtico para alpha = 0.01 (una cola)\n    print(\"\u2234 H0 no es rechazada.\")\nelse:\n    print(\"\u2234 H0 es rechazada.\")\n\n# Inciso d)\nx_d = 81\nz_d = (x_d - mu_0) / sigma_x\nprint(\"Inciso d)\")\nprint(\"z =\", z_d)\nif z_d &gt;= -2.33:  # Valor cr\u00edtico para alpha = 0.01 (una cola)\n    print(\"\u2234 H0 no es rechazada.\")\nelse:\n    print(\"\u2234 H0 es rechazada.\")\n</pre> import math  # Datos n = 100 sigma = 12 mu_0 = 80  # C\u00e1lculo de sigma_x sigma_x = sigma / math.sqrt(n)  # Inciso a) x_a = 78.5 z_a = (x_a - mu_0) / sigma_x print(\"Inciso a)\") print(\"z =\", z_a) if z_a &gt;= -2.33:  # Valor cr\u00edtico para alpha = 0.01 (una cola)     print(\"\u2234 H0 no es rechazada.\") else:     print(\"\u2234 H0 es rechazada.\")  # Inciso b) x_b = 78.5 z_b = (x_b - mu_0) / sigma_x print(\"Inciso b)\") print(\"z =\", z_b) if z_b &gt;= -2.33:  # Valor cr\u00edtico para alpha = 0.01 (una cola)     print(\"\u2234 H0 no es rechazada.\") else:     print(\"\u2234 H0 es rechazada.\")  # Inciso c) x_c = 75.5 z_c = (x_c - mu_0) / sigma_x print(\"Inciso c)\") print(\"z =\", z_c) if z_c &gt;= -2.33:  # Valor cr\u00edtico para alpha = 0.01 (una cola)     print(\"\u2234 H0 no es rechazada.\") else:     print(\"\u2234 H0 es rechazada.\")  # Inciso d) x_d = 81 z_d = (x_d - mu_0) / sigma_x print(\"Inciso d)\") print(\"z =\", z_d) if z_d &gt;= -2.33:  # Valor cr\u00edtico para alpha = 0.01 (una cola)     print(\"\u2234 H0 no es rechazada.\") else:     print(\"\u2234 H0 es rechazada.\") <pre>Inciso a)\nz = -1.25\n\u2234 H0 no es rechazada.\nInciso b)\nz = -1.25\n\u2234 H0 no es rechazada.\nInciso c)\nz = -3.75\n\u2234 H0 es rechazada.\nInciso d)\nz = 0.8333333333333334\n\u2234 H0 no es rechazada.\n</pre> Ejercicio 3 Las declaraciones de impuestos presentadas antes del 31 de marzo obtienen un reembolso que en promedio es de $Bs. 1 056$. Considere la poblaci\u00f3n de los contribuyentes de \u201c\u00faltima hora\u201d que presentan su declaraci\u00f3n en los \u00faltimos cinco d\u00edas del periodo para este tr\u00e1mite (normalmente del 10 al 15 de abril). a) Un investigador sugiere que la raz\u00f3n por la que estos declarantes esperan hasta los \u00faltimos d\u00edas se debe a que en promedio obtienen un reembolso menor que los que declaran:  antes del 31 de marzo. Establezca las hip\u00f3tesis apropiadas de manera que el rechazo de $H_0$ favorezca la sugerencia de este investigador. b) En una muestra de 400 personas que presentaron su declaraci\u00f3n entre el 10 y el 15 de abril, la media muestral de los reembolsos fue $Bs. 910$. Por experiencia se sabe que es posible considerar que la desviaci\u00f3n est\u00e1ndar poblacional es $\u03c3 = Bs. 1 600$. \u00bfCu\u00e1l es el valor-p? c) Con $\u03c3 = 0.05$, \u00bfcu\u00e1l es su conclusi\u00f3n? d) Repita la prueba de hip\u00f3tesis anterior usando el m\u00e9todo del valor cr\u00edtico. <p>Inciso a)</p> $H_0: \u03bc \u2265 1056$ $H_a: \u03bc &lt; 1056$ <p>Inciso b)</p> <p>$Datos:$</p> <p>$n = 400$</p> <p>$\\bar{x} = Bs. 910$</p> <p>$\u03c3 = Bs. 1600$</p> <p>$\u03c3_\\bar{x} = \\frac{\u03c3}{\\sqrt{n}}$</p> <p>$$z = \\frac{{\\bar{x} - \\mu_0}}{{\\frac{\\sigma}{\\sqrt{n}}}} = \\frac{{{910} - 1056}}{{\\frac{1600}{\\sqrt{400}}}} = -1.83$$</p> <p>Se busca el valor de $z = -1.83$ en la tabla normal, entonces:</p> $valor-p = (1 - 0.9664) = 0.0336$ <p>Inciso c)</p> <p>La regla me dice que se debe rechazar $H_0$ si el $valor-p \u2264 \u03b1$, por lo cual tenemos que como el valor-p es menor que $\u03b1$ (0.05) se rechaza $H_0$, el reembolso medio de los contribuyentes de \"\u00faltima hora\" es menor de $Bs. 1056$ .</p> <p>Inciso d)</p> $H_0$ es rechazada si $z \u2264 -1.645$ Se tiene $-1.83 \u2264 -1.645$ $\u2234 H_0$ es rechazada. Ejercicio en c\u00f3digo In\u00a0[17]: Copied! <pre>import math\nfrom scipy.stats import norm\n\n# Datos del ejercicio\nn = 400\nx_barra = 910\nsigma = 1600\nmu_0 = 1056\n\n# C\u00e1lculo del error est\u00e1ndar de la media muestral\nsigma_x_barra = sigma / math.sqrt(n)\n\n# Inciso a)\nz_a = (x_barra - mu_0) / sigma_x_barra\nprint(\"Inciso a)\")\nprint(\"z =\", z_a)\nif z_a &gt;= -1.645:  # Valor cr\u00edtico para alpha = 0.05 (una cola)\n    print(\"\u2234 H0 no es rechazada.\")\nelse:\n    print(\"\u2234 H0 es rechazada.\")\n\n# Inciso b) (ya que no hay un valor x_b en el ejercicio, utilizamos x_barra)\nz_b = (x_barra - mu_0) / sigma_x_barra\nprint(\"Inciso b)\")\nprint(\"z =\", z_b)\np_value_b = norm.cdf(z_b)\nprint(f\"Valor-p: {p_value_b:.4f}\")\nif p_value_b &lt; 0.05:\n    print(\"\u2234 H0 es rechazada.\")\nelse:\n    print(\"\u2234 H0 no es rechazada.\")\n\n# Inciso c)\nx_c = 75.5\nz_c = (x_c - mu_0) / sigma_x_barra\nprint(\"Inciso c)\")\nprint(\"z =\", z_c)\nif z_c &gt;= -1.645:  # Valor cr\u00edtico para alpha = 0.05 (una cola)\n    print(\"\u2234 H0 no es rechazada.\")\nelse:\n    print(\"\u2234 H0 es rechazada.\")\n\n# Inciso d)\nx_d = 81\nz_d = (x_d - mu_0) / sigma_x_barra\nprint(\"Inciso d)\")\nprint(\"z =\", z_d)\nif z_d &gt;= -1.645:  # Valor cr\u00edtico para alpha = 0.05 (una cola)\n    print(\"\u2234 H0 no es rechazada.\")\nelse:\n    print(\"\u2234 H0 es rechazada.\")\n</pre> import math from scipy.stats import norm  # Datos del ejercicio n = 400 x_barra = 910 sigma = 1600 mu_0 = 1056  # C\u00e1lculo del error est\u00e1ndar de la media muestral sigma_x_barra = sigma / math.sqrt(n)  # Inciso a) z_a = (x_barra - mu_0) / sigma_x_barra print(\"Inciso a)\") print(\"z =\", z_a) if z_a &gt;= -1.645:  # Valor cr\u00edtico para alpha = 0.05 (una cola)     print(\"\u2234 H0 no es rechazada.\") else:     print(\"\u2234 H0 es rechazada.\")  # Inciso b) (ya que no hay un valor x_b en el ejercicio, utilizamos x_barra) z_b = (x_barra - mu_0) / sigma_x_barra print(\"Inciso b)\") print(\"z =\", z_b) p_value_b = norm.cdf(z_b) print(f\"Valor-p: {p_value_b:.4f}\") if p_value_b &lt; 0.05:     print(\"\u2234 H0 es rechazada.\") else:     print(\"\u2234 H0 no es rechazada.\")  # Inciso c) x_c = 75.5 z_c = (x_c - mu_0) / sigma_x_barra print(\"Inciso c)\") print(\"z =\", z_c) if z_c &gt;= -1.645:  # Valor cr\u00edtico para alpha = 0.05 (una cola)     print(\"\u2234 H0 no es rechazada.\") else:     print(\"\u2234 H0 es rechazada.\")  # Inciso d) x_d = 81 z_d = (x_d - mu_0) / sigma_x_barra print(\"Inciso d)\") print(\"z =\", z_d) if z_d &gt;= -1.645:  # Valor cr\u00edtico para alpha = 0.05 (una cola)     print(\"\u2234 H0 no es rechazada.\") else:     print(\"\u2234 H0 es rechazada.\")  <pre>Inciso a)\nz = -1.825\n\u2234 H0 es rechazada.\nInciso b)\nz = -1.825\nValor-p: 0.0340\n\u2234 H0 es rechazada.\nInciso c)\nz = -12.25625\n\u2234 H0 es rechazada.\nInciso d)\nz = -12.1875\n\u2234 H0 es rechazada.\n</pre> Ejercicio en 4  En Bolivia, un hogar paga en promedio $32.79$ mensuales por el servicio de Internet. En una muestra de 50 hogares de un estado del sur la media muestral fue $Bs. 30.63$. Use la desviaci\u00f3n est\u00e1ndar poblacional de $\u03c3 = Bs. 5.60$. a) Formule las hip\u00f3tesis para una prueba en la que se quiere determinar si los datos muestrales favorecen la conclusi\u00f3n de que la cantidad media mensual pagada por el servicio de Internet en este estado del sur es menor a la media de todo el pa\u00eds, que es de $Bs. 32.79$. b) \u00bfCu\u00e1l es el valor del estad\u00edstico de prueba? c) \u00bfCu\u00e1l es el valor-p? d) Con $\u03b1 = 0.01$, \u00bfqu\u00e9 concluye? <p>Inciso a)</p> $H_0: \u03bc \u2265 32.79$ $H_a: \u03bc &lt; 32.79$ <p>Inciso b)</p> <p>$Datos:$</p> <p>$n = 50$</p> <p>$\\bar{x} = Bs. 30.63$</p> <p>$\u03c3 = Bs. 5.60$</p> <p>$\u03c3_\\bar{x} = \\frac{\u03c3}{\\sqrt{n}}$</p> <p>$$z = \\frac{{\\bar{x} - \\mu_0}}{{\\frac{\\sigma}{\\sqrt{n}}}} = \\frac{{{30.63} - 32.79}}{{\\frac{5.60}{\\sqrt{50}}}} = -2.73$$</p> <p>Inciso c)</p> <p>Se busca el valor de $z = -2.73$ en la tabla normal, entonces:</p> $valor-p = (1 - 0.9968) = 0.0032$ <p>Inciso d)</p> <p>La regla me dice que se debe rechazar $H_0$ si el $valor-p \u2264 \u03b1$, por lo cual tenemos que como el valor-p es menor que $\u03b1$ (0.01) se rechaza $H_0$, se concluye que el promedio mensual facturado en Internet es menor en los estados del sur.</p> Ejercicio en c\u00f3digo In\u00a0[18]: Copied! <pre>import math\nfrom scipy.stats import norm\n\n# Datos del ejercicio\nn = 50\nx_barra = 30.63\nmu_0 = 32.79\nsigma = 5.60\n\n# C\u00e1lculo del error est\u00e1ndar de la media muestral\nsigma_x_barra = sigma / math.sqrt(n)\n\n# C\u00e1lculo del valor del estad\u00edstico de prueba (z)\nz = (x_barra - mu_0) / sigma_x_barra\n\n# C\u00e1lculo del valor-p\nvalor_p = norm.cdf(z)\n\n# Imprimiendo resultados\nprint(f\"Valor del estad\u00edstico de prueba (z): {z:.2f}\")\nprint(f\"Valor-p: {valor_p:.4f}\")\n\n# Conclusi\u00f3n con un nivel de significancia \u03b1 = 0.01\nalpha = 0.01\nif valor_p &lt; alpha:\n    print(\"Se rechaza la hip\u00f3tesis nula. Concluimos que el promedio mensual facturado en Internet es menor en los estados del sur.\")\nelse:\n    print(\"No se puede rechazar la hip\u00f3tesis nula. No hay suficiente evidencia para afirmar que el promedio mensual facturado en Internet es menor en los estados del sur.\")\n</pre> import math from scipy.stats import norm  # Datos del ejercicio n = 50 x_barra = 30.63 mu_0 = 32.79 sigma = 5.60  # C\u00e1lculo del error est\u00e1ndar de la media muestral sigma_x_barra = sigma / math.sqrt(n)  # C\u00e1lculo del valor del estad\u00edstico de prueba (z) z = (x_barra - mu_0) / sigma_x_barra  # C\u00e1lculo del valor-p valor_p = norm.cdf(z)  # Imprimiendo resultados print(f\"Valor del estad\u00edstico de prueba (z): {z:.2f}\") print(f\"Valor-p: {valor_p:.4f}\")  # Conclusi\u00f3n con un nivel de significancia \u03b1 = 0.01 alpha = 0.01 if valor_p &lt; alpha:     print(\"Se rechaza la hip\u00f3tesis nula. Concluimos que el promedio mensual facturado en Internet es menor en los estados del sur.\") else:     print(\"No se puede rechazar la hip\u00f3tesis nula. No hay suficiente evidencia para afirmar que el promedio mensual facturado en Internet es menor en los estados del sur.\") <pre>Valor del estad\u00edstico de prueba (z): -2.73\nValor-p: 0.0032\nSe rechaza la hip\u00f3tesis nula. Concluimos que el promedio mensual facturado en Internet es menor en los estados del sur.\n</pre> Ejercicio 5  ATB y RedUno presentaron un canal de televisi\u00f3n dirigido a las personas que esperan en las colas de los supermercados. En este canal se transmit\u00edan noticias, reportajes cortos y publicidad. La duraci\u00f3n de la programaci\u00f3n se basaba en el supuesto de que la media poblacional del tiempo que los clientes esperan en la fila de la caja es 8 minutos. Se utilizar\u00e1 una muestra de tiempos de espera reales para probar ese supuesto y determinar si el tiempo medio de espera difiere de ese est\u00e1ndar. a) Formule las hip\u00f3tesis para esta aplicaci\u00f3n. b) En una muestra de 120 clientes, la media muestral de tiempo de espera fue 8.5 minutos. Suponga que la desviaci\u00f3n est\u00e1ndar poblacional es $\u03c3 = 3.2 minutos$. \u00bfCu\u00e1l es el valor-p? c) Con $\u03b1 = 0.05$, \u00bfcu\u00e1l es su conclusi\u00f3n? <p>Inciso a)</p> $H_0: \u03bc = 8$ $H_a: \u03bc \\ne 8$ <p>Inciso b)</p> <p>$Datos:$</p> <p>$n = 120$</p> <p>$\\bar{x} = 8.5 minutos$</p> <p>$\u03c3 = 3.2 minutos$</p> <p>$\u03c3_\\bar{x} = \\frac{\u03c3}{\\sqrt{n}}$</p> <p>$$z = \\frac{{\\bar{x} - \\mu_0}}{{\\frac{\\sigma}{\\sqrt{n}}}} = \\frac{{{8.5} - 8}}{{\\frac{3.2}{\\sqrt{120}}}} = 1.71$$</p> <p>Se busca el valor de $z = 1.71$ en la tabla normal, entonces:</p> $valor-p = (1 - 0.8294) = 0.1706$ <p>Inciso c)</p> <p>La regla me dice que se debe rechazar $H_0$ si el $valor-p \u2264 \u03b1$, por lo cual tenemos que como el valor-p es mayor que $\u03b1$ (0.05) no se rechaza $H_0$, se concluye que no se puede concluir que el tiempo promedio de espera difiera de 8 minutos.</p> Ejercicio en c\u00f3digo In\u00a0[19]: Copied! <pre>import math\nfrom scipy.stats import norm\n\n# Datos del ejercicio\nn = 120\nx_barra = 8.5\nmu_0 = 8\nsigma = 3.2\n\n# C\u00e1lculo del error est\u00e1ndar de la media muestral\nsigma_x_barra = sigma / math.sqrt(n)\n\n# C\u00e1lculo del valor del estad\u00edstico de prueba (z)\nz = (x_barra - mu_0) / sigma_x_barra\n\n# C\u00e1lculo del valor-p (dos colas)\nvalor_p = (1 - 0.8294)\n\n# Imprimiendo resultados\nprint(f\"Valor del estad\u00edstico de prueba (z): {z:.2f}\")\nprint(f\"Valor-p: {valor_p:.4f}\")\n\n# Conclusi\u00f3n con un nivel de significancia \u03b1 = 0.05\nalpha = 0.05\nif valor_p &lt; alpha:\n    print(\"Se rechaza la hip\u00f3tesis nula. Concluimos que el tiempo promedio de espera difiere de 8 minutos.\")\nelse:\n    print(\"No se puede rechazar la hip\u00f3tesis nula. No hay suficiente evidencia para afirmar que el tiempo promedio de espera difiere de 8 minutos.\")\n</pre> import math from scipy.stats import norm  # Datos del ejercicio n = 120 x_barra = 8.5 mu_0 = 8 sigma = 3.2  # C\u00e1lculo del error est\u00e1ndar de la media muestral sigma_x_barra = sigma / math.sqrt(n)  # C\u00e1lculo del valor del estad\u00edstico de prueba (z) z = (x_barra - mu_0) / sigma_x_barra  # C\u00e1lculo del valor-p (dos colas) valor_p = (1 - 0.8294)  # Imprimiendo resultados print(f\"Valor del estad\u00edstico de prueba (z): {z:.2f}\") print(f\"Valor-p: {valor_p:.4f}\")  # Conclusi\u00f3n con un nivel de significancia \u03b1 = 0.05 alpha = 0.05 if valor_p &lt; alpha:     print(\"Se rechaza la hip\u00f3tesis nula. Concluimos que el tiempo promedio de espera difiere de 8 minutos.\") else:     print(\"No se puede rechazar la hip\u00f3tesis nula. No hay suficiente evidencia para afirmar que el tiempo promedio de espera difiere de 8 minutos.\")  <pre>Valor del estad\u00edstico de prueba (z): 1.71\nValor-p: 0.1706\nNo se puede rechazar la hip\u00f3tesis nula. No hay suficiente evidencia para afirmar que el tiempo promedio de espera difiere de 8 minutos.\n</pre> ESTADISTICO DE PRUEBA EN LAS PRUEBAS DE HIPOTESIS PARA LA MEDIA POBLACIONAL: $\\sigma$ DESCONOCIDA \\(\\large t = \\frac{\\bar{x} - \\mu}{s/\\sqrt{n}}\\)  En el capitulo 8 tambien se dijo que la distribucion $t$ se basa en el supesto de que la poblacion de la que se toma la muestra tiene distribucion normal. sin embargo, las investigaciones demuestran que este supuesto no es muy fuerte si el tama\u00f1o de la muestra es suficientemente grande. Al final de esta seccion se proporciona una recomendacion practica acerca acerca de la distribucion de la poblacion y del tama\u00f1o de la muestra.  Prueba de una cola En este ejemplo se realiza una prueba de hip\u00f3tesis de una cola para la media poblacional con una desviaci\u00f3n est\u00e1ndar desconocida. La revista de viajes de negocios busca clasificar los aeropuertos internacionales seg\u00fan la evaluaci\u00f3n de viajeros de negocios, considerando superiores aquellos con una media mayor de 7 en una escala del 0 al 10. Se toma una muestra de 60 viajeros en el aeropuerto Heathrow, con una media muestral (x\u0304) de 7.25 y una desviaci\u00f3n est\u00e1ndar muestral (s) de 1.052. Se plantea una prueba de hip\u00f3tesis de cola superior (Ha: \u03bc &gt; 7) para determinar si Heathrow debe ser considerado un aeropuerto de servicio superior. Las hip\u00f3tesis nula y alternativa son H0: \u03bc \u2264 7 y Ha: \u03bc &gt; 7, respectivamente, con un nivel de significancia (\u03b1) de 0.05. Aplicando la ecuaci\u00f3n (9.2) con los datos de la muestra, se obtiene un estad\u00edstico de prueba (t) de 1.84. La distribuci\u00f3n de muestreo de t tiene 59 grados de libertad. Al ser una prueba de cola superior, el valor-p se obtiene del \u00e1rea a la derecha de t = 1.84. Sin embargo, las tablas de distribuci\u00f3n t en muchos libros no ofrecen la precisi\u00f3n necesaria para determinar el valor-p exacto.  Prueba de una cola En este ejemplo se realiza una prueba de hip\u00f3tesis de una cola para la media poblacional con una desviaci\u00f3n est\u00e1ndar desconocida. La revista de viajes de negocios busca clasificar los aeropuertos internacionales seg\u00fan la evaluaci\u00f3n de viajeros de negocios, considerando superiores aquellos con una media mayor de 7 en una escala del 0 al 10. Se toma una muestra de 60 viajeros en el aeropuerto Heathrow, con una media muestral (x\u0304) de 7.25 y una desviaci\u00f3n est\u00e1ndar muestral (s) de 1.052. Se plantea una prueba de hip\u00f3tesis de cola superior (Ha: \u03bc &gt; 7) para determinar si Heathrow debe ser considerado un aeropuerto de servicio superior. Las hip\u00f3tesis nula y alternativa son H0: \u03bc \u2264 7 y Ha: \u03bc &gt; 7, respectivamente, con un nivel de significancia (\u03b1) de 0.05. Aplicando la ecuaci\u00f3n (9.2) con los datos de la muestra, se obtiene un estad\u00edstico de prueba (t) de 1.84. La distribuci\u00f3n de muestreo de t tiene 59 grados de libertad. Al ser una prueba de cola superior, el valor-p se obtiene del \u00e1rea a la derecha de t = 1.84. Sin embargo, las tablas de distribuci\u00f3n t en muchos libros no ofrecen la precisi\u00f3n necesaria para determinar el valor-p exacto.   Las tablas de distribucion $t$ proporcionadas en la mayor parte de los libros de texto no son suficientemente detalladas para determinar el valor-p exacto, como es el caso del valor-p correspondiente a t=1.84. Por ejemplo, en la tabla 2 del apendice B, la distribucion $t$ con 59 grados de libertad proporciona la informacion siguiente:  TABLA 9.2 Prueba de una colas \u00c1rea en la cola superior 0.20 0.10 0.05 0.025 0.01 0.005 Valor t (59 gl) 0.848 1.296 1.671 2.001 2.391 2.662 Como se ve, t = 1.84 est\u00e1 entre 1.671 y 2.001. Aunque esta tabla no proporciona el valor exacto de t, los valores en la fi la \u201c\u00c1rea en la cola superior\u201d indican que el valor-p debe ser menor que 0.05 y mayor que 0.025. Con un nivel de signifi cancia $\\alpha$ = 0.05, esto es todo lo que se necesita saber para rechazar la hip\u00f3tesis nula y concluir que Heathrow debe ser considerado un aeropuerto de servicio superior. Debido a que es engorroso usar una tabla t para calcular los valores-p, y puesto que s\u00f3lo se pueden obtener valores-p aproximados, se mostrar\u00e1 c\u00f3mo calcular valores-p exactos usando Excel o Minitab. Estas instrucciones se encuentran al fi nal del libro, en el ap\u00e9ndice F. Usando ambos programas con t = 1.84, el valor-p que se obtiene en la cola superior es 0.0354 para la prueba de hip\u00f3tesis del aeropuerto de Heathrow. Como 0.0354 &lt; 0.05, la hip\u00f3tesis nula es rechazada y se concluye que \u00e9ste se debe considerar un aeropuerto de servicio superior.                                          Prueba de dos colas <p>concluye que es adecuado usar la distribuci\u00f3n t con n - 1 = 24 grados de libertad. Usando la ecuaci\u00f3n (9.2) con x = 37.4, \u03bc0 = 40, s = 11.79 y n = 25, el valor que se obtiene para el estad\u00edstico de prueba es</p> \\(\\large t = \\frac{\\bar{x} - \\mu}{s/\\sqrt{n}} = \\frac{37.4 - 40}{11.79/\\sqrt{25}} = -1.10\\) <p>Como se trata de una prueba de dos colas, el valor-p es el doble del \u00e1rea bajo la curva de la distribuci\u00f3n t para t &lt;=1.10. En la tabla 2 del ap\u00e9ndice B, la fi la de la distribuci\u00f3n t para 24 grados de libertad proporciona la informaci\u00f3n siguiente.</p> TABLA 9.3 prueba de dos colas \u00c1rea en la cola superior 0.20 0.10 0.05 0.025 0.01 0.005 Valor t (24 gl) 0.857 1.318 1.711 2.064 2.492 2.797 La tabla de distribuci\u00f3n t solo contiene valores t positivos. Sin embargo, como la distribuci\u00f3n t es sim\u00e9trica, el \u00e1rea bajo la curva a la derecha de t = 1.10 es igual al \u00e1rea bajo la curva a la izquierda de t = -1.10. Se encuentra as\u00ed que t = 1.10 est\u00e1 entre 0.857 y 1.318. En la fila \"\u00c1rea en la cola superior\", se ve que el \u00e1rea en la cola a la derecha de t = 1.10 est\u00e1 entre 0.20 y 0.10. Duplicando estas cantidades, el valor-p debe estar entre 0.40 y 0.20. Como el nivel de significancia es \u03b1 = 0.05, se ve que el valor-p es mayor que \u03b1. Por tanto, (H_0) no puede ser rechazada. No hay evidencia suficiente para concluir que Holiday deba modificar su plan de producci\u00f3n para la temporada siguiente. En el Ap\u00e9ndice F se indica c\u00f3mo calcular el valor-p para esta prueba usando Minitab o Excel. El valor-p que se obtiene es 0.2822. Con el nivel de significancia \u03b1 = 0.05, (H_0) no puede ser rechazada, dado que 0.2822 &gt; 0.05. Para tomar la decisi\u00f3n en esta prueba de dos colas, tambi\u00e9n se puede comparar el estad\u00edstico de prueba con el valor cr\u00edtico. Usando \u03b1 = 0.05 y la distribuci\u00f3n t con 24 grados de libertad, $(-t_{0.025} = -2.064)$ y $(t_{0.025} = 2.064)$ son los valores cr\u00edticos para la prueba de dos colas. La regla de rechazo usando el estad\u00edstico de prueba es: Rechazar (H_0) si (t $\\leq$ -2.064) o si (t $\\geq$ 2.064). Con base en el estad\u00edstico de prueba t = -1.10, (H_0) no puede ser rechazada. Este resultado indica que Holiday puede continuar con su plan de producci\u00f3n para la temporada pr\u00f3xima con base en la expectativa de (\u03bc = 40).  Resumen y consejo practico <p>En la tabla 9.3 se proporciona un resumen de los procedimientos de prueba de hip\u00f3tesis en los casos de \u03c3 desconocida. La diferencia principal entre estos procedimientos y el del caso de \u03c3 conocida estriba en que para calcular el estad\u00edstico de prueba se usa s en lugar de \u03c3. A esto se debe que el estad\u00edstico de prueba siga la distribuci\u00f3n t. La aplicabilidad de los procedimientos de prueba de hip\u00f3tesis de esta secci\u00f3n depende de la distribuci\u00f3n de la poblaci\u00f3n de donde se toma la muestra y del tama\u00f1o de \u00e9sta. Si la poblaci\u00f3n tiene una distribuci\u00f3n normal, las pruebas de hip\u00f3tesis descritas en esta secci\u00f3n dan resultados exactos con cualquier tama\u00f1o de muestra. Si la poblaci\u00f3n no est\u00e1 distribuida normalmente, los procedimientos son aproximaciones. De cualquier manera, se encuentra que tama\u00f1os de muestra de 30 o mayores proporcionan buenos resultados en la mayor parte de los casos. Si la poblaci\u00f3n es aproximadamente normal, muestras peque\u00f1as (por ejemplo, n = 15) pueden ofrecer resultados aceptables. Si la poblaci\u00f3n es muy sesgada o si contiene observaciones at\u00edpicas, se recomiendan tama\u00f1os de alrededor de 50.</p> <p> Video: Prueba de hip\u00f3tesis</p> In\u00a0[84]: Copied! <pre># importar la clase que permite ver videos\nfrom IPython.display import YouTubeVideo\n# crear una instancia del objeto YouTubeVideo\nyoutube_video=YouTubeVideo('k3oBZQ5Brbs')\n#mostrar el video de youtube\ndisplay(youtube_video)\n</pre> # importar la clase que permite ver videos from IPython.display import YouTubeVideo # crear una instancia del objeto YouTubeVideo youtube_video=YouTubeVideo('k3oBZQ5Brbs') #mostrar el video de youtube display(youtube_video) TABLA 9.2 Resumen de las pruebas de hip\u00f3tesis para la media poblacional: caso con \u03c3 conocida Prueba de cola inferior Prueba de cola superior Prueba de dos colas Hip\u00f3tesis $$H_0: \u03bc \u2265 \u03bc_0$$ $$H_a: \u03bc &lt; \u03bc_0$$ $$H_0: \u03bc \u2264 \u03bc_0$$ $$H_a: \u03bc &gt; \u03bc_0$$ $$H_0: \u03bc = \u03bc_0$$ $$H_a: \u03bc \\ne \u03bc_0$$ Estad\u00edstico de prueba $$t = \\frac{{\\bar{x} - \\mu_0}}{{\\frac{s}{\\sqrt{n}}}}$$ $$z = \\frac{{\\bar{x} - \\mu_0}}{{\\frac{s}{\\sqrt{n}}}}$$ $$z = \\frac{{\\bar{x} - \\mu_0}}{{\\frac{s}{\\sqrt{n}}}}$$ Regla de rechazo: M\u00e9todo del valor-p Rechazar $H_0$ si el valor-p $\u2264 \u03b1$ Rechazar $H_0$ si el valor-p $\u2264 \u03b1$ Rechazar $H_0$ si el valor-p $\u2264 \u03b1$ Regla de rechazo: M\u00e9todo del valor cr\u00edtico Rechazar $H_0$ si $t \u2264 -t_\u03b1$ Rechazar $H_0$ si $t \u2265 t_\u03b1$ Rechazar $H_0$ si $t \u2264 -t_{\u03b1/2}$ o si $t \u2265 t_{\u03b1/2}$ Ejercicios Metodos Ejercicio 1  Considere la prueba de hip\u00f3tesis siguiente.  <p>$$H_0: \\mu \\leq 12$$ $$H_a: \\mu &gt; 12 $$</p> <p>En una muestra de 25, la media muestral es $ \\bar{x} = 14 $ y la desviaci\u00f3n est\u00e1ndar $s = 4.32 $.</p> <p>a) Calcule el valor del estad\u00edstico de prueba.</p> <p>b) Use la tabla de distribuci\u00f3n t (tabla 2 del ap\u00e9ndice B) a fin de calcular un intervalo para el valor-p.</p> <p>c) Con $\\alpha = 0.05 $, \u00bfcu\u00e1l es su conclusi\u00f3n?</p> <p>d) \u00bfCu\u00e1l es la regla de rechazo usando el valor cr\u00edtico? \u00bfQu\u00e9 concluye?</p> Soluci\u00f3n <p>Inciso a)</p> El estad\u00edstico de prueba \\(t\\) se calcula utilizando la f\u00f3rmula:  <p>$$ t = \\frac{(\\bar{x} - \\mu_0)}{(s/\\sqrt{n})} $$</p> <p>Donde:</p> <ul> <li>$(\\bar{x})$ es la media muestral,</li> <li>$(\\mu_0)$ es la media bajo la hip\u00f3tesis nula,</li> <li>$(s)$ es la desviaci\u00f3n est\u00e1ndar muestral, y</li> <li>$(n)$ es el tama\u00f1o de la muestra.</li> </ul> <p>En este caso: $$ t = \\frac{(14 - 12)}{(4.32/\\sqrt{25})} $$</p> <p>Calculamos (t) y obtenemos el valor del estad\u00edstico de prueba.</p> <p>Inciso b) Intervalo para el Valor-p:</p> <p>Usaremos la tabla de distribuci\u00f3n t (Tabla 2 del ap\u00e9ndice B) para encontrar los valores cr\u00edticos $(t_{\\text{cr\u00edtico}})$ con 24 grados de libertad y $(\\alpha/2 = 0.025)$. Luego, calcularemos el intervalo para el valor-p.</p> <p>Inciso c)</p> <p>$(\\alpha = 0.05)$:</p> <p>Si el valor-p es menor que $(\\alpha)$, rechazamos la hip\u00f3tesis nula $((H_0))$.</p> <p>Inciso d)</p> <p>Rechazamos $(H_0)$ si $(t &gt; t_{\\text{cr\u00edtico}})$.</p> <p>a)</p> <p>$$ t = \\frac{(14 - 12)}{(4.32/\\sqrt{25})} $$</p> <p>$$ t = 3.108 $$</p> <p>b)</p> <p>Usando la tabla de distribuci\u00f3n t, encontramos $(t_{\\text{cr\u00edtico}})$ para $( \\alpha/2 = 0.025 )$ con 24 grados de libertad.</p> <p>c)</p> <p>Compararemos el valor-p con $(\\alpha)$ y decidiremos si rechazamos $(H_0)$.</p> <p>d)</p> <p>Rechazamos $(H_0)$ si $(t &gt; t_{\\text{cr\u00edtico}})$.</p> FIGURA 9.1 Valores cr\u00edticos en la prueba de hip\u00f3tesis\" In\u00a0[16]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Generar datos de la distribuci\u00f3n muestral\nx = np.linspace(0 - 1 * 2, 0 + 1 * 2, 1000)\ny = norm.pdf(x*4, 0, 2)\n\n# Crear la gr\u00e1fica\nfig, ax = plt.subplots()\nax.plot(x, y, color='#009929')\n\n# Establecer el color de fondo\nax.set_facecolor('#d4f8b7')\n\n# Pintar el fondo externo del gr\u00e1fico\nfig.patch.set_facecolor('#D4F8B7')\n\n# Etiquetas y texto\nax.set_xlabel(f'$valor-p = 2(0.0630) = 0.1260$', fontsize=10)\nax.text(0.02, 0.15, r'P(z \u2264 -1.53) = 0.0630', transform=ax.transAxes, fontsize=7.5, color='#000')\nax.text(0.76, 0.15, r'P(z \u2265 1.53) = 0.0630', transform=ax.transAxes, fontsize=7.5, color='#000')\nax.text(0.06, -0.11, r'-1.53', transform=ax.transAxes, fontsize=12, color='#000')\nax.text(0.86, -0.11, r'1.53', transform=ax.transAxes, fontsize=12, color='#000')\n\n# L\u00edneas verticales\nfor i in np.arange(0.02, 0.98, 0.02):\n    ax.text(i, 0.01, r'|', transform=ax.transAxes, fontsize=12, color='#009929')\n\n# L\u00edneas horizontales\nax.text(0.10, -0.04, r'|', transform=ax.transAxes, fontsize=12, color='#000')\nax.text(0.89, -0.04, r'|', transform=ax.transAxes, fontsize=12, color='#000')\nax.text(0.89, 0.01, r'|', transform=ax.transAxes, fontsize=12, color='#009929')\n\n# Ajustes del gr\u00e1fico\nax.grid(False)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm  # Generar datos de la distribuci\u00f3n muestral x = np.linspace(0 - 1 * 2, 0 + 1 * 2, 1000) y = norm.pdf(x*4, 0, 2)  # Crear la gr\u00e1fica fig, ax = plt.subplots() ax.plot(x, y, color='#009929')  # Establecer el color de fondo ax.set_facecolor('#d4f8b7')  # Pintar el fondo externo del gr\u00e1fico fig.patch.set_facecolor('#D4F8B7')  # Etiquetas y texto ax.set_xlabel(f'$valor-p = 2(0.0630) = 0.1260$', fontsize=10) ax.text(0.02, 0.15, r'P(z \u2264 -1.53) = 0.0630', transform=ax.transAxes, fontsize=7.5, color='#000') ax.text(0.76, 0.15, r'P(z \u2265 1.53) = 0.0630', transform=ax.transAxes, fontsize=7.5, color='#000') ax.text(0.06, -0.11, r'-1.53', transform=ax.transAxes, fontsize=12, color='#000') ax.text(0.86, -0.11, r'1.53', transform=ax.transAxes, fontsize=12, color='#000')  # L\u00edneas verticales for i in np.arange(0.02, 0.98, 0.02):     ax.text(i, 0.01, r'|', transform=ax.transAxes, fontsize=12, color='#009929')  # L\u00edneas horizontales ax.text(0.10, -0.04, r'|', transform=ax.transAxes, fontsize=12, color='#000') ax.text(0.89, -0.04, r'|', transform=ax.transAxes, fontsize=12, color='#000') ax.text(0.89, 0.01, r'|', transform=ax.transAxes, fontsize=12, color='#009929')  # Ajustes del gr\u00e1fico ax.grid(False) plt.show()   Ejercicio 2  Considere la prueba de hip\u00f3tesis siguiente.  <p>$$H_0: \\mu = 18 $$ $$H_a: \\mu\\neq 18 $$</p> <p>En una muestra de 48, la media muestral es $\\bar{x} = 17 $ y la desviaci\u00f3n est\u00e1ndar muestral  $s = 4.5$ .</p> <p>a) Calcule el valor del estad\u00edstico de prueba.</p> <p>b) Use la tabla de distribuci\u00f3n t (tabla 2 del ap\u00e9ndice B) con objeto de calcular un intervalo para el valor-p.</p> <p>c) Con $\\alpha = 0.05 $, \u00bfcu\u00e1l es su conclusi\u00f3n?</p> <p>d) \u00bfCu\u00e1l es la regla de rechazo usando el valor cr\u00edtico? \u00bfQu\u00e9 concluye?</p> Soluci\u00f3n <p>Inciso a)</p> <p>El estad\u00edstico de prueba (t) se calcula utilizando la f\u00f3rmula:</p> <p>$$ t = \\frac{(\\bar{x} - \\mu_0)}{(s/\\sqrt{n})} $$</p> <p>Donde:</p> <ul> <li>$\\bar{x}$ es la media muestral,</li> <li>$\\mu_0$ es la media bajo la hip\u00f3tesis nula,</li> <li>$s$ es la desviaci\u00f3n est\u00e1ndar muestral, y</li> <li>$n$ es el tama\u00f1o de la muestra.</li> </ul> <p>En este caso: $$ t = \\frac{(17 - 18)}{(4.5/\\sqrt{48})} $$</p> <p>Calculamos (t) y obtenemos el valor del estad\u00edstico de prueba.</p> <p>Inciso b)</p> <p>Usaremos la tabla de distribuci\u00f3n t (Tabla 2 del ap\u00e9ndice B) para encontrar los valores cr\u00edticos $t_{\\text{cr\u00edtico}}$ con 47 grados de libertad y $\\alpha/2 = 0.025$. Luego, calcularemos el intervalo para el valor-p.</p> <p>Inciso c)</p> <p>Si el valor-p es menor que $\\alpha$, rechazamos la hip\u00f3tesis nula $(H_0)$.</p> <p>Inciso d)</p> <p>Rechazamos $H_0$ si $t &gt; t_{\\text{cr\u00edtico}}$ o $t &lt; -t_{\\text{cr\u00edtico}}$.</p> <p>a)</p> <p>$$t = \\frac{(17 - 18)}{(4.5/\\sqrt{48})} $$</p> <p>b)</p> <p>Usando la tabla de distribuci\u00f3n t, encontramos $t_{\\text{cr\u00edtico}}$ para $\\alpha/2 = 0.025$ con 47 grados de libertad.</p> <p>cc)</p> <p>Compararemos el valor-p con $\\alpha$ y decidiremos si rechazamos $H_0$.</p> <p>d)</p> <p>Rechazamos $H_0$ si $t &gt; t_{\\text{cr\u00edtico}}$ o $t &lt; -t_{\\text{cr\u00edtico}}$.</p> FIGURA 9.2 Valores cr\u00edticos en la prueba de hip\u00f3tesis\" In\u00a0[27]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import t\n\n# Generar datos de la distribuci\u00f3n t\nx = np.linspace(-4, 4, 1000)\ny = t.pdf(x, 47)\n\n# Crear la gr\u00e1fica\nfig, ax = plt.subplots()\nax.plot(x, y, color='#009929')\n\n# Establecer el color de fondo\nax.set_facecolor('#d4f8b7')\n\n# Pintar el fondo externo del gr\u00e1fico\nfig.patch.set_facecolor('#D4F8B7')\n\n\n# Etiquetas y texto\nax.set_xlabel('Distribuci\u00f3n t con 47 grados de libertad', fontsize=10)\n\n    \n# L\u00ednea vertical en t cr\u00edtico para alfa/2\nax.axvline(t.ppf(0.025, 47), color='#009929', linestyle='--', label=r'$t_{\\alpha/2}$')\n\n# L\u00ednea vertical en -t cr\u00edtico para alfa/2\nax.axvline(-t.ppf(0.025, 47), color='#009929', linestyle='--')\n\n# Ajustes del gr\u00e1fico\nax.legend()\nax.grid(False)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import t  # Generar datos de la distribuci\u00f3n t x = np.linspace(-4, 4, 1000) y = t.pdf(x, 47)  # Crear la gr\u00e1fica fig, ax = plt.subplots() ax.plot(x, y, color='#009929')  # Establecer el color de fondo ax.set_facecolor('#d4f8b7')  # Pintar el fondo externo del gr\u00e1fico fig.patch.set_facecolor('#D4F8B7')   # Etiquetas y texto ax.set_xlabel('Distribuci\u00f3n t con 47 grados de libertad', fontsize=10)       # L\u00ednea vertical en t cr\u00edtico para alfa/2 ax.axvline(t.ppf(0.025, 47), color='#009929', linestyle='--', label=r'$t_{\\alpha/2}$')  # L\u00ednea vertical en -t cr\u00edtico para alfa/2 ax.axvline(-t.ppf(0.025, 47), color='#009929', linestyle='--')  # Ajustes del gr\u00e1fico ax.legend() ax.grid(False) plt.show()  Ejercicio 3  Considere la prueba de hip\u00f3tesis siguiente.  <p>$$H_0: \\mu \\geq 45 $$ $$ H_a: \\mu &lt; 45 $$</p> <p>Se usa una muestra de 36. Identifique el valor-p y establezca su conclusi\u00f3n para cada uno de los siguientes resultados muestrales. Use $\\alpha$ = 0.01 .</p> <p>a) $ \\bar{x} = 44$  y  $s = 5.2 $</p> <p>b) $ \\bar{x} = 43 $ y $ s = 4.6 $</p> <p>c) $ \\bar{x} = 46 $ y $ s = 5.0 $</p> Solucion <p>La prueba de hip\u00f3tesis se realiza utilizando la f\u00f3rmula del valor-p para una prueba de una cola (p-value):</p> <p>$$ p = P(\\bar{X} &lt; \\bar{x} \\,|\\, H_0 \\, \\text{es verdadera}) $$</p> <p>Donde:</p> <ul> <li>$\\bar{X}$ es la media muestral bajo la hip\u00f3tesis nula,</li> <li>$\\bar{x}$ es la media muestral observada,</li> <li>$n$ es el tama\u00f1o de la muestra, y</li> <li>$s$ es la desviaci\u00f3n est\u00e1ndar muestral.</li> </ul> <p>Si $p &lt; \\alpha$, se rechaza la hip\u00f3tesis nula.</p> <p>a)</p> <p>Para $\\bar{x} = 44$ y $s = 5.2$:</p> <p>$$ p = P(\\bar{X} &lt; 44 \\,|\\, \\mu \\geq 45) $$</p> <p>b)</p> <p>Para $\\bar{x} = 43$ y $s = 4.6$:</p> <p>$$ p = P(\\bar{X} &lt; 43 \\,|\\, \\mu \\geq 45) $$</p> <p>c)</p> <p>Para $\\bar{x} = 46$ y $s = 5.0$:</p> <p>$$ p = P(\\bar{X} &lt; 46 \\,|\\, \\mu \\geq 45) $$</p> FIGURA 9.3 Valores cr\u00edticos en la prueba de hip\u00f3tesis\" In\u00a0[32]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import t\n\n# Par\u00e1metros del problema\nmu_0 = 45\nalpha = 0.01\nn = 36\n\n# Valores cr\u00edticos para la regi\u00f3n de rechazo\ncritical_value = t.ppf(alpha, n-1)\n\n# Datos para cada caso\nsample_means = [44, 43, 46]\nsample_std_devs = [5.2, 4.6, 5.0]\n\n# Crear la gr\u00e1fica\nfig, ax = plt.subplots()\n\n# Dibujar la distribuci\u00f3n t bajo H0\nx = np.linspace(mu_0 - 3 * (sample_std_devs[0] / np.sqrt(n)), mu_0 + 3 * (sample_std_devs[0] / np.sqrt(n)), 1000)\nax.plot(x, t.pdf(x, n-1), color='#009929', label=r'$H_0: \\mu \\geq 45$')\n\n# L\u00ednea vertical en t cr\u00edtico para alfa\nax.axvline(mu_0 + critical_value * (sample_std_devs[0] / np.sqrt(n)), color='#009929', linestyle='--', label=r'Regi\u00f3n de Rechazo')\n\n# Pintar el \u00e1rea de rechazo\nx_fill = np.linspace(mu_0 + critical_value * (sample_std_devs[0] / np.sqrt(n)), mu_0 + 3 * (sample_std_devs[0] / np.sqrt(n)), 1000)\ny_fill = t.pdf(x_fill, n-1)\nax.fill_between(x_fill, y_fill, color='#009929', alpha=0.3)\n\n# Establecer el color de fondo\nax.set_facecolor('#d4f8b7')\n\n# Pintar el fondo externo del gr\u00e1fico\nfig.patch.set_facecolor('#D4F8B7')\n\n# Etiquetas y texto\nax.set_xlabel('Media Muestral ($\\\\bar{x}$)', fontsize=10)\n\n# Ajustes del gr\u00e1fico\nax.legend()\nax.grid(False)\n\n# Mostrar la gr\u00e1fica\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import t  # Par\u00e1metros del problema mu_0 = 45 alpha = 0.01 n = 36  # Valores cr\u00edticos para la regi\u00f3n de rechazo critical_value = t.ppf(alpha, n-1)  # Datos para cada caso sample_means = [44, 43, 46] sample_std_devs = [5.2, 4.6, 5.0]  # Crear la gr\u00e1fica fig, ax = plt.subplots()  # Dibujar la distribuci\u00f3n t bajo H0 x = np.linspace(mu_0 - 3 * (sample_std_devs[0] / np.sqrt(n)), mu_0 + 3 * (sample_std_devs[0] / np.sqrt(n)), 1000) ax.plot(x, t.pdf(x, n-1), color='#009929', label=r'$H_0: \\mu \\geq 45$')  # L\u00ednea vertical en t cr\u00edtico para alfa ax.axvline(mu_0 + critical_value * (sample_std_devs[0] / np.sqrt(n)), color='#009929', linestyle='--', label=r'Regi\u00f3n de Rechazo')  # Pintar el \u00e1rea de rechazo x_fill = np.linspace(mu_0 + critical_value * (sample_std_devs[0] / np.sqrt(n)), mu_0 + 3 * (sample_std_devs[0] / np.sqrt(n)), 1000) y_fill = t.pdf(x_fill, n-1) ax.fill_between(x_fill, y_fill, color='#009929', alpha=0.3)  # Establecer el color de fondo ax.set_facecolor('#d4f8b7')  # Pintar el fondo externo del gr\u00e1fico fig.patch.set_facecolor('#D4F8B7')  # Etiquetas y texto ax.set_xlabel('Media Muestral ($\\\\bar{x}$)', fontsize=10)  # Ajustes del gr\u00e1fico ax.legend() ax.grid(False)  # Mostrar la gr\u00e1fica plt.show()   Ejemplo       Considere el caso del Coliseo de la UMSA del equipo de Voleibol. En los a\u00f1os anteriores, 20% de los jugadores del campo eran mujeres. Para aumentar la proporci\u00f3n del sector femenino, el directivo del equipo realiz\u00f3 una promoci\u00f3n especial dise\u00f1ada para atraer a mujeres voleibolistas de la UMSA. Un mes despu\u00e9s se realizada la promoci\u00f3n, el directivo del equipo solicit\u00f3 un estudio estad\u00edstico para determinar si la proporci\u00f3n de jugadoras hab\u00eda aumentado. Como el objetivo es determinar si la proporci\u00f3n de jugadoras se increment\u00f3, lo apropiado es una prueba de cola superior en la que $H_{a}:p &gt; 0,20$     Las hipotesis nula y alternativa para esta prueba son:      $H_{0}:p \\geq 0,20$ $H_{a}:p &gt; 0,20$      Si $H_0$ se puede rechazar, los resultados de la prueba dar\u00e1n sustento estad\u00edstico a la conclusi\u00f3n de que la proporci\u00f3n de voleibolistas aument\u00f3 y que la promoci\u00f3n fue efectiva.      El directivo del campo especific\u00f3 que el nivel de significancia sera $\u03b1 =0,05$ para realizar esta prueba de hip\u00f3tesis     El paso siguiente en el procedimiento de prueba de hip\u00f3tesis es seleccionar una muestra y calcular el valor del estad\u00edstico de prueba adecuado.   Error estandar de $\\bar{p}$: \\(\\large  \\sigma_{\\bar{p}}=\\sqrt{\\frac{p_0(1-p_0)}{n}}\\) En el capitulo 7 se dijo que si $np \\geq 5$ y $n(1-p)$ la distribucion de muestreo de $\\bar {p}$ puede aproximarse mediante una distribcion normal entonces aplicamos el estadistico: \\(\\large z = \\frac{\\bar{p} - p_0}{\\sigma_{\\bar{p}}}\\) ESTADISTICO DE PRUEBA EN LAS PRUEBAS DE HIPOTESIS PARA LA PROPORCION POBLACIONAL: \\(\\large z = \\frac{\\bar{p} - p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}}\\)      Teniendo la ecuacion para calcular el estadistico de prueba para la prueba de hipotesis del equipo de voleibol de la UMSA. Concideramos una muestra aletoria de 400jugadores en la que 100 son mujeres.  \\(\\large \\bar {p} = \\frac{100}{400}=0.25\\)  Ya obteniendo la proporcion de la  muestra, aplicamos la ecuacion del estadistico  de prueba:  \\(\\large z = \\frac{\\bar{p} - p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}}= \\frac{0.25 - 0.20}{\\sqrt{\\frac{0.20(1-0.20)}{400}}}=\\frac{0.05}{0.02}=2.50\\)  Nuestra prueba de hipotesis para el equipo de voli es una cola superior, el valor-$p$ es la probabiidad de que $z$ sea mayor o igual que $z=2.50$;esto es, el area bajo la cuerva normal estandar para $z=2.50$.  In\u00a0[23]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Generar datos de la distribuci\u00f3n muestral\nx = np.linspace(0 - 2.05 * 1, 0 + 2.05 * 1, 2000)\ny = norm.pdf(x*4, 0, 2)\n\n# Crear la gr\u00e1fica\nfig, ax = plt.subplots()\nax.plot(x, y, color='#009929')\n# Establecer el color de fondo\nax.set_facecolor('#d4f8b7')\n# Pintar el fondo externo del gr\u00e1fico\nfig.patch.set_facecolor('#D4F8B7')\n\n# Agregar informaci\u00f3n sobre el error est\u00e1ndar\n\n\nax.text(0.60, 0.80, r'\u00c1rea = 0.9938',transform=ax.transAxes, fontsize=10, color='#000')\n\nax.text(0.60, 0.10, r'Valor-p = P(z \u2265 2.50)=0.0062',transform=ax.transAxes, fontsize=10, color='#000')\n\nax.text(0.86, -0.11, r'2.5',transform=ax.transAxes, fontsize=12, color='#000')\n\n\n\nax.text(0.89, -0.04, r'|',transform=ax.transAxes, fontsize=12, color='#000')\n\nax.text(0.89, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.891, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.893, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.895, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.897, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.899, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.90, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.902, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.904, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.906, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.908, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.910, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.912, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.914, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.916, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.918, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.920, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.922, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.924, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.926, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.928, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.930, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.932, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.934, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.936, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.938, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.940, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.942, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.944, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.946, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.948, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.950, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.952, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.954, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.956, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.958, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.960, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.962, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.964, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.966, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.968, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.970, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\n\nax.grid(False)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm  # Generar datos de la distribuci\u00f3n muestral x = np.linspace(0 - 2.05 * 1, 0 + 2.05 * 1, 2000) y = norm.pdf(x*4, 0, 2)  # Crear la gr\u00e1fica fig, ax = plt.subplots() ax.plot(x, y, color='#009929') # Establecer el color de fondo ax.set_facecolor('#d4f8b7') # Pintar el fondo externo del gr\u00e1fico fig.patch.set_facecolor('#D4F8B7')  # Agregar informaci\u00f3n sobre el error est\u00e1ndar   ax.text(0.60, 0.80, r'\u00c1rea = 0.9938',transform=ax.transAxes, fontsize=10, color='#000')  ax.text(0.60, 0.10, r'Valor-p = P(z \u2265 2.50)=0.0062',transform=ax.transAxes, fontsize=10, color='#000')  ax.text(0.86, -0.11, r'2.5',transform=ax.transAxes, fontsize=12, color='#000')    ax.text(0.89, -0.04, r'|',transform=ax.transAxes, fontsize=12, color='#000')  ax.text(0.89, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.891, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.893, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.895, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.897, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.899, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.90, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.902, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.904, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.906, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.908, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.910, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.912, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.914, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.916, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.918, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.920, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.922, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.924, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.926, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.928, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.930, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.932, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.934, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.936, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.938, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.940, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.942, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.944, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.946, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.948, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.950, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.952, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.954, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.956, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.958, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.960, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.962, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.964, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.966, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.968, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.970, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')  ax.grid(False) plt.show() TABLA 9.4 Resumen de las pruebas de hip\u00f3tesis para la proporcion poblacional Prueba de cola inferior Prueba de cola superior Prueba de dos colas Hip\u00f3tesis $$H_0: p \u2265 p_0$$ $$H_a: p &lt; p_0$$ $$H_0: p \u2264 p_0$$ $$H_a: p &gt; p_0$$ $$H_0: p = p_0$$ $$H_a: p \\ne p_0$$ Estad\u00edstico de prueba $$z = \\frac{\\bar{p} - p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}}$$ $$z = \\frac{\\bar{p} - p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}}$$ $$z = \\frac{\\bar{p} - p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}}$$ Regla de rechazo: M\u00e9todo del valor-p Rechazar $H_0$ si el valor-p $\u2264 \u03b1$ Rechazar $H_0$ si el valor-p $\u2264 \u03b1$ Rechazar $H_0$ si el valor-p $\u2264 \u03b1$ Regla de rechazo: M\u00e9todo del valor cr\u00edtico Rechazar $H_0$ si $z \u2264 -z_\u03b1$ Rechazar $H_0$ si $z \u2265 z_\u03b1$ Rechazar $H_0$ si $z \u2264 -z_{\u03b1/2}$ o si $z \u2265 z_{\u03b1/2}$ Para un valor-$p=0.0062$, la hipotesis nula sera rechazada para cualquier nivel de significancia mayor o igual que $0.0062$. Resumen      El procedimiento empleado en una prueba de hip\u00f3tesis para la proporci\u00f3n poblacional es semejante al m\u00e9todo usado en una prueba de hip\u00f3tesis para la media poblacional. Aunque s\u00f3lo se ilustr\u00f3 c\u00f3mo realizar una prueba de hip\u00f3tesis de cola superior para la proporci\u00f3n poblacional, en el caso de pruebas de cola inferior o de dos colas se recurre a procedimientos similares. En la tabla 9.4 se presenta una s\u00edntesis de las pruebas de hip\u00f3tesis para la proporci\u00f3n poblacional. Se supone que $np \\geq 5$ y $n(1-p)\\geq 5$ , con lo cual se puede usar una distribuci\u00f3n normal como aproximaci\u00f3n a la distribuci\u00f3n de muestreo de $\\bar {p}$.  Ejercicios M\u00e9todos <p>1. Considere la prueba de hip\u00f3tesis siguiente.</p>  $H_0: p = 0.20$    $H_a: p \\neq 0.20 $ <p>En una muestra de 400, se encontro un proporcion muestral de $\\bar {p}=0.175$  a) Calcule el valor del estad\u00edstico de prueba.</p> <p>b) \u00bfCual es el valor-p.?</p> <p>c) Con $\\alpha = 0.05 $, \u00bfcu\u00e1l es su conclusi\u00f3n?</p> <p>d) \u00bfCu\u00e1l es la regla de rechazo usando el valor cr\u00edtico? \u00bfQu\u00e9 concluye?</p> Soluci\u00f3n  FIGURA 9.1 Valores cr\u00edticos en la prueba de hip\u00f3tesis\" In\u00a0[64]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Generar datos de la distribuci\u00f3n muestral\nx = np.linspace(0 - 2.05 * 1, 0 + 2.05 * 1, 1000)\ny = norm.pdf(x*4, 0, 2)\n\n# Crear la gr\u00e1fica\nfig, ax = plt.subplots()\nax.plot(x, y, color='#009929')\n# Establecer el color de fondo\nax.set_facecolor('#d4f8b7')\n# Pintar el fondo externo del gr\u00e1fico\nfig.patch.set_facecolor('#D4F8B7')\n\n# Agregar informaci\u00f3n sobre el error est\u00e1ndar\n\n\nax.text(0.06, -0.11, r'-1.36',transform=ax.transAxes, fontsize=12, color='#000')\nax.text(0.86, -0.11, r'1.36',transform=ax.transAxes, fontsize=12, color='#000')\nax.text(0.02, 0.15, r'P(z \u2264 -1.25) = 0.1056', transform=ax.transAxes, fontsize=7.5, color='#000')\nax.text(0.76, 0.15, r'P(z \u2265 1.25) = 0.1056', transform=ax.transAxes, fontsize=7.5, color='#000')\n\nax.text(0.10, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.098, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.096, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.094, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.092, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.090, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.088, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.086, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.084, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.082, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.080, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.078, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.076, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.074, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.072, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.070, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.068, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.066, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.064, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.062, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.060, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.058, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.056, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.054, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.052, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.050, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.048, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.046, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.044, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.042, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.040, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.038, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.036, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.034, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.032, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.030, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.028, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.026, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.024, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.022, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.020, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.028, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\n\nax.text(0.10, -0.04, r'|',transform=ax.transAxes, fontsize=12, color='#000')\nax.text(0.89, -0.04, r'|',transform=ax.transAxes, fontsize=12, color='#000')\n\nax.text(0.89, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.891, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.893, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.895, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.897, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.899, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.90, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.902, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.904, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.906, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.908, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.910, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.912, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.914, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.916, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.918, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.920, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.922, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.924, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.926, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.928, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.930, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.932, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.934, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.936, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.938, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.940, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.942, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.944, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.946, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.948, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.950, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.952, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.954, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.956, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.958, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.960, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.962, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.964, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.966, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.968, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.970, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\n\nax.grid(False)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm  # Generar datos de la distribuci\u00f3n muestral x = np.linspace(0 - 2.05 * 1, 0 + 2.05 * 1, 1000) y = norm.pdf(x*4, 0, 2)  # Crear la gr\u00e1fica fig, ax = plt.subplots() ax.plot(x, y, color='#009929') # Establecer el color de fondo ax.set_facecolor('#d4f8b7') # Pintar el fondo externo del gr\u00e1fico fig.patch.set_facecolor('#D4F8B7')  # Agregar informaci\u00f3n sobre el error est\u00e1ndar   ax.text(0.06, -0.11, r'-1.36',transform=ax.transAxes, fontsize=12, color='#000') ax.text(0.86, -0.11, r'1.36',transform=ax.transAxes, fontsize=12, color='#000') ax.text(0.02, 0.15, r'P(z \u2264 -1.25) = 0.1056', transform=ax.transAxes, fontsize=7.5, color='#000') ax.text(0.76, 0.15, r'P(z \u2265 1.25) = 0.1056', transform=ax.transAxes, fontsize=7.5, color='#000')  ax.text(0.10, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.098, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.096, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.094, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.092, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.090, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.088, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.086, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.084, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.082, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.080, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.078, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.076, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.074, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.072, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.070, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.068, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.066, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.064, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.062, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.060, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.058, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.056, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.054, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.052, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.050, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.048, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.046, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.044, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.042, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.040, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.038, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.036, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.034, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.032, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.030, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.028, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.026, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.024, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.022, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.020, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.028, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')  ax.text(0.10, -0.04, r'|',transform=ax.transAxes, fontsize=12, color='#000') ax.text(0.89, -0.04, r'|',transform=ax.transAxes, fontsize=12, color='#000')  ax.text(0.89, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.891, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.893, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.895, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.897, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.899, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.90, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.902, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.904, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.906, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.908, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.910, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.912, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.914, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.916, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.918, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.920, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.922, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.924, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.926, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.928, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.930, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.932, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.934, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.936, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.938, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.940, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.942, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.944, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.946, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.948, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.950, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.952, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.954, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.956, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.958, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.960, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.962, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.964, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.966, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.968, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.970, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')  ax.grid(False) plt.show() <p>2. Considere la prueba de hip\u00f3tesis siguiente.</p>  $H_0: p \\geq 0.75$    $H_a: p &lt; 0.75 $ <p>En una muestra de 300 elementos. Calcule el valor-$p$ y estableza su conclusion para cada uno de los resultados muestrales siguiientes. Use $(\\alpha = 0.05)$  a) $\\bar {p}=0.68$</p> <p>b) $\\bar {p}=0.72$</p> <p>c) $\\bar {p}=0.70$</p> <p>d) $\\bar {p}=0.77$</p> Soluci\u00f3n  <p>Utilizando la f\u00f3rmula: $ \\large z = \\frac{\\bar{p} - p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}} $  Donde:</p> <ul> <li>$(\\bar{p})$ es la proporcion muestral,</li> <li>$(p_0)$ es la proporcion poblacional,</li> <li>$(n)$ es el tama\u00f1o de la muestra. Si valor-$p$ $es \\leq \\alpha$ rechazamos $H_0$ </li> </ul> FIGURA 9.2.1 Valores cr\u00edticos en la prueba de hip\u00f3tesis\" In\u00a0[30]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Generar datos de la distribuci\u00f3n muestral\nx = np.linspace(0 - 2.05 * 1, 0 + 2.05 * 1, 2000)\ny = norm.pdf(x*4, 0, 2)\n\n# Crear la gr\u00e1fica\nfig, ax = plt.subplots()\nax.plot(x, y, color='#009929')\n# Establecer el color de fondo\nax.set_facecolor('#d4f8b7')\n# Pintar el fondo externo del gr\u00e1fico\nfig.patch.set_facecolor('#D4F8B7')\n\n# Agregar informaci\u00f3n sobre el error est\u00e1ndar\n\nax.text(0.06, -0.11, r'-2.50',transform=ax.transAxes, fontsize=12, color='#000')\nax.text(0.60, 0.80, r'\u00c1rea = 0.9974',transform=ax.transAxes, fontsize=10, color='#000')\n\nax.text(0.10, 0.10, r'Valor-p = P(z \u2264 -2.80)=0.0026',transform=ax.transAxes, fontsize=10, color='#000')\n\n\nax.text(0.10, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.098, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.096, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.094, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.092, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.090, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.088, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.086, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.084, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.082, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.080, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.078, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.076, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.074, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.072, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.070, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.068, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.066, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.064, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.062, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.060, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.058, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.056, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.054, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.052, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.050, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.048, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.046, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.044, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.042, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.040, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.038, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.036, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.034, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.032, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.030, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.028, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.026, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.024, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.022, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.020, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.028, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\n\n\nax.text(0.89, -0.04, r'|',transform=ax.transAxes, fontsize=12, color='#000')\n\n\n\nax.grid(False)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm  # Generar datos de la distribuci\u00f3n muestral x = np.linspace(0 - 2.05 * 1, 0 + 2.05 * 1, 2000) y = norm.pdf(x*4, 0, 2)  # Crear la gr\u00e1fica fig, ax = plt.subplots() ax.plot(x, y, color='#009929') # Establecer el color de fondo ax.set_facecolor('#d4f8b7') # Pintar el fondo externo del gr\u00e1fico fig.patch.set_facecolor('#D4F8B7')  # Agregar informaci\u00f3n sobre el error est\u00e1ndar  ax.text(0.06, -0.11, r'-2.50',transform=ax.transAxes, fontsize=12, color='#000') ax.text(0.60, 0.80, r'\u00c1rea = 0.9974',transform=ax.transAxes, fontsize=10, color='#000')  ax.text(0.10, 0.10, r'Valor-p = P(z \u2264 -2.80)=0.0026',transform=ax.transAxes, fontsize=10, color='#000')   ax.text(0.10, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.098, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.096, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.094, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.092, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.090, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.088, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.086, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.084, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.082, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.080, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.078, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.076, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.074, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.072, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.070, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.068, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.066, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.064, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.062, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.060, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.058, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.056, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.054, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.052, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.050, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.048, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.046, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.044, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.042, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.040, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.038, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.036, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.034, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.032, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.030, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.028, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.026, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.024, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.022, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.020, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.028, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')   ax.text(0.89, -0.04, r'|',transform=ax.transAxes, fontsize=12, color='#000')    ax.grid(False) plt.show() FIGURA 9.2.3 Valores cr\u00edticos en la prueba de hip\u00f3tesis\" In\u00a0[31]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Generar datos de la distribuci\u00f3n muestral\nx = np.linspace(0 - 2.05 * 1, 0 + 2.05 * 1, 2000)\ny = norm.pdf(x*4, 0, 2)\n\n# Crear la gr\u00e1fica\nfig, ax = plt.subplots()\nax.plot(x, y, color='#009929')\n# Establecer el color de fondo\nax.set_facecolor('#d4f8b7')\n# Pintar el fondo externo del gr\u00e1fico\nfig.patch.set_facecolor('#D4F8B7')\n\n# Agregar informaci\u00f3n sobre el error est\u00e1ndar\n\nax.text(0.06, -0.11, r'-1.20',transform=ax.transAxes, fontsize=12, color='#000')\nax.text(0.60, 0.80, r'\u00c1rea = 0.8849',transform=ax.transAxes, fontsize=10, color='#000')\n\nax.text(0.10, 0.10, r'Valor-p = P(z \u2264 -1.20)=0.1151',transform=ax.transAxes, fontsize=10, color='#000')\n\n\nax.text(0.10, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.098, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.096, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.094, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.092, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.090, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.088, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.086, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.084, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.082, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.080, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.078, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.076, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.074, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.072, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.070, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.068, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.066, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.064, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.062, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.060, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.058, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.056, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.054, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.052, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.050, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.048, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.046, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.044, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.042, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.040, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.038, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.036, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.034, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.032, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.030, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.028, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.026, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.024, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.022, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.020, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.028, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\n\n\nax.text(0.89, -0.04, r'|',transform=ax.transAxes, fontsize=12, color='#000')\n\n\n\nax.grid(False)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm  # Generar datos de la distribuci\u00f3n muestral x = np.linspace(0 - 2.05 * 1, 0 + 2.05 * 1, 2000) y = norm.pdf(x*4, 0, 2)  # Crear la gr\u00e1fica fig, ax = plt.subplots() ax.plot(x, y, color='#009929') # Establecer el color de fondo ax.set_facecolor('#d4f8b7') # Pintar el fondo externo del gr\u00e1fico fig.patch.set_facecolor('#D4F8B7')  # Agregar informaci\u00f3n sobre el error est\u00e1ndar  ax.text(0.06, -0.11, r'-1.20',transform=ax.transAxes, fontsize=12, color='#000') ax.text(0.60, 0.80, r'\u00c1rea = 0.8849',transform=ax.transAxes, fontsize=10, color='#000')  ax.text(0.10, 0.10, r'Valor-p = P(z \u2264 -1.20)=0.1151',transform=ax.transAxes, fontsize=10, color='#000')   ax.text(0.10, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.098, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.096, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.094, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.092, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.090, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.088, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.086, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.084, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.082, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.080, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.078, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.076, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.074, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.072, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.070, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.068, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.066, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.064, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.062, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.060, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.058, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.056, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.054, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.052, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.050, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.048, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.046, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.044, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.042, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.040, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.038, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.036, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.034, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.032, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.030, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.028, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.026, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.024, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.022, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.020, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.028, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')   ax.text(0.89, -0.04, r'|',transform=ax.transAxes, fontsize=12, color='#000')    ax.grid(False) plt.show() FIGURA 9.2.3 Valores cr\u00edticos en la prueba de hip\u00f3tesis\" In\u00a0[33]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Generar datos de la distribuci\u00f3n muestral\nx = np.linspace(0 - 2.05 * 1, 0 + 2.05 * 1, 2000)\ny = norm.pdf(x*4, 0, 2)\n\n# Crear la gr\u00e1fica\nfig, ax = plt.subplots()\nax.plot(x, y, color='#009929')\n# Establecer el color de fondo\nax.set_facecolor('#d4f8b7')\n# Pintar el fondo externo del gr\u00e1fico\nfig.patch.set_facecolor('#D4F8B7')\n\n# Agregar informaci\u00f3n sobre el error est\u00e1ndar\n\nax.text(0.06, -0.11, r'-2.00',transform=ax.transAxes, fontsize=12, color='#000')\nax.text(0.60, 0.80, r'\u00c1rea = 0.9778',transform=ax.transAxes, fontsize=10, color='#000')\n\nax.text(0.10, 0.10, r'Valor-p = P(z \u2264 -2.00)=0.0228',transform=ax.transAxes, fontsize=10, color='#000')\n\n\nax.text(0.10, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.098, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.096, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.094, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.092, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.090, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.088, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.086, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.084, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.082, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.080, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.078, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.076, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.074, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.072, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.070, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.068, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.066, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.064, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.062, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.060, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.058, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.056, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.054, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.052, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.050, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.048, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.046, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.044, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.042, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.040, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.038, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.036, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.034, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.032, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.030, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.028, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.026, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.024, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.022, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.020, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.028, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\n\n\nax.text(0.89, -0.04, r'|',transform=ax.transAxes, fontsize=12, color='#000')\n\n\n\nax.grid(False)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm  # Generar datos de la distribuci\u00f3n muestral x = np.linspace(0 - 2.05 * 1, 0 + 2.05 * 1, 2000) y = norm.pdf(x*4, 0, 2)  # Crear la gr\u00e1fica fig, ax = plt.subplots() ax.plot(x, y, color='#009929') # Establecer el color de fondo ax.set_facecolor('#d4f8b7') # Pintar el fondo externo del gr\u00e1fico fig.patch.set_facecolor('#D4F8B7')  # Agregar informaci\u00f3n sobre el error est\u00e1ndar  ax.text(0.06, -0.11, r'-2.00',transform=ax.transAxes, fontsize=12, color='#000') ax.text(0.60, 0.80, r'\u00c1rea = 0.9778',transform=ax.transAxes, fontsize=10, color='#000')  ax.text(0.10, 0.10, r'Valor-p = P(z \u2264 -2.00)=0.0228',transform=ax.transAxes, fontsize=10, color='#000')   ax.text(0.10, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.098, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.096, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.094, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.092, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.090, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.088, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.086, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.084, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.082, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.080, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.078, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.076, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.074, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.072, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.070, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.068, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.066, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.064, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.062, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.060, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.058, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.056, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.054, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.052, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.050, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.048, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.046, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.044, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.042, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.040, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.038, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.036, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.034, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.032, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.030, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.028, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.026, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.024, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.022, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.020, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.028, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')   ax.text(0.89, -0.04, r'|',transform=ax.transAxes, fontsize=12, color='#000')    ax.grid(False) plt.show() FIGURA 9.2.4 Valores cr\u00edticos en la prueba de hip\u00f3tesis\" In\u00a0[34]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Generar datos de la distribuci\u00f3n muestral\nx = np.linspace(0 - 2.05 * 1, 0 + 2.05 * 1, 2000)\ny = norm.pdf(x*4, 0, 2)\n\n# Crear la gr\u00e1fica\nfig, ax = plt.subplots()\nax.plot(x, y, color='#009929')\n# Establecer el color de fondo\nax.set_facecolor('#d4f8b7')\n# Pintar el fondo externo del gr\u00e1fico\nfig.patch.set_facecolor('#D4F8B7')\n\n# Agregar informaci\u00f3n sobre el error est\u00e1ndar\n\nax.text(0.06, -0.11, r'0.80',transform=ax.transAxes, fontsize=12, color='#000')\nax.text(0.60, 0.80, r'\u00c1rea = 0.2119',transform=ax.transAxes, fontsize=10, color='#000')\n\nax.text(0.10, 0.10, r'Valor-p = P(z \u2264 0.80)=0.7881',transform=ax.transAxes, fontsize=10, color='#000')\n\n\nax.text(0.10, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.098, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.096, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.094, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.092, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.090, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.088, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.086, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.084, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.082, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.080, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.078, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.076, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.074, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.072, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.070, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.068, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.066, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.064, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.062, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.060, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.058, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.056, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.054, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.052, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.050, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.048, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.046, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.044, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.042, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.040, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.038, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.036, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.034, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.032, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.030, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.028, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.026, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.024, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.022, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.020, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.028, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\n\n\nax.text(0.89, -0.04, r'|',transform=ax.transAxes, fontsize=12, color='#000')\n\n\n\nax.grid(False)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm  # Generar datos de la distribuci\u00f3n muestral x = np.linspace(0 - 2.05 * 1, 0 + 2.05 * 1, 2000) y = norm.pdf(x*4, 0, 2)  # Crear la gr\u00e1fica fig, ax = plt.subplots() ax.plot(x, y, color='#009929') # Establecer el color de fondo ax.set_facecolor('#d4f8b7') # Pintar el fondo externo del gr\u00e1fico fig.patch.set_facecolor('#D4F8B7')  # Agregar informaci\u00f3n sobre el error est\u00e1ndar  ax.text(0.06, -0.11, r'0.80',transform=ax.transAxes, fontsize=12, color='#000') ax.text(0.60, 0.80, r'\u00c1rea = 0.2119',transform=ax.transAxes, fontsize=10, color='#000')  ax.text(0.10, 0.10, r'Valor-p = P(z \u2264 0.80)=0.7881',transform=ax.transAxes, fontsize=10, color='#000')   ax.text(0.10, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.098, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.096, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.094, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.092, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.090, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.088, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.086, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.084, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.082, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.080, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.078, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.076, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.074, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.072, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.070, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.068, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.066, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.064, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.062, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.060, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.058, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.056, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.054, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.052, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.050, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.048, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.046, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.044, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.042, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.040, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.038, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.036, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.034, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.032, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.030, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.028, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.026, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.024, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.022, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.020, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.028, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')   ax.text(0.89, -0.04, r'|',transform=ax.transAxes, fontsize=12, color='#000')    ax.grid(False) plt.show() 3. Un estudio realizado por La Alcaldia de La Paz indica que 64% de los clientes de los supermercados piensa que las marcas de esos establecimientos son tan buenas como las marcas nacionales. Para investigar si estos resultados aplican a sus propios productos, un fabricante de salsa de tomate de una marca nacional pregunt\u00f3 a los integrantes de una muestra si consideraban las salsas de tomate de marca propia de los supermercados tan buenas como la de marca nacional. $a)$ Formule las hip\u00f3tesis para determinar si el porcentaje de clientes de los supermercados que considera las salsas de tomate de marca propia de estos establecimientos tan buenas como la de marca nacional difiere de $64$%.  $b)$ Si en una muestra de $100$ clientes, $52$ opinan que las marcas de los supermercados son tan buenas como las nacionales, \u00bfcu\u00e1l es el valor-$p$?  $c)$ Con \u03b1 = 0.05, \u00bfcu\u00e1l es la conclusi\u00f3n?  $d)$ \u00bfLe dar\u00e1 gusto esta conclusi\u00f3n al fabricante de la marca nacional de salsa de tomate? Explique.  Soluci\u00f3n  <p>Utilizando la f\u00f3rmula: $ \\large z = \\frac{\\bar{p} - p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}} $  Donde:</p> <ul> <li>$(\\bar{p})$ es la proporcion muestral,</li> <li>$(p_0)$ es la proporcion poblacional,</li> <li>$(n)$ es el tama\u00f1o de la muestra. Si valor-$p$ $es \\leq \\alpha$ rechazamos $H_0$ </li> </ul> FIGURA 9.3 Valores cr\u00edticos en la prueba de hip\u00f3tesis\" In\u00a0[35]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Generar datos de la distribuci\u00f3n muestral\nx = np.linspace(0 - 2.05 * 1, 0 + 2.05 * 1, 1000)\ny = norm.pdf(x*4, 0, 2)\n\n# Crear la gr\u00e1fica\nfig, ax = plt.subplots()\nax.plot(x, y, color='#009929')\n# Establecer el color de fondo\nax.set_facecolor('#d4f8b7')\n# Pintar el fondo externo del gr\u00e1fico\nfig.patch.set_facecolor('#D4F8B7')\n\n# Agregar informaci\u00f3n sobre el error est\u00e1ndar\n\n\nax.text(0.06, -0.11, r'-2.50',transform=ax.transAxes, fontsize=12, color='#000')\nax.text(0.86, -0.11, r'2.50',transform=ax.transAxes, fontsize=12, color='#000')\nax.text(0.02, 0.15, r'P(z \u2264 -2.50) = 0.0062', transform=ax.transAxes, fontsize=7.5, color='#000')\nax.text(0.76, 0.15, r'P(z \u2265 2.96) = 0.0062', transform=ax.transAxes, fontsize=7.5, color='#000')\n\nax.text(0.10, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.098, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.096, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.094, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.092, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.090, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.088, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.086, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.084, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.082, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.080, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.078, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.076, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.074, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.072, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.070, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.068, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.066, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.064, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.062, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.060, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.058, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.056, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.054, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.052, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.050, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.048, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.046, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.044, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.042, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.040, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.038, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.036, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.034, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.032, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.030, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.028, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.026, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.024, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.022, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.020, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.028, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\n\nax.text(0.10, -0.04, r'|',transform=ax.transAxes, fontsize=12, color='#000')\nax.text(0.89, -0.04, r'|',transform=ax.transAxes, fontsize=12, color='#000')\n\nax.text(0.89, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.891, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.893, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.895, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.897, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.899, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.90, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.902, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.904, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.906, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.908, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.910, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.912, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.914, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.916, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.918, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.920, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.922, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.924, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.926, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.928, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.930, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.932, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.934, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.936, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.938, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.940, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.942, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.944, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.946, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.948, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.950, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.952, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.954, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.956, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.958, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.960, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.962, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.964, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\nax.text(0.966, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.968, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.970, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')\n\nax.grid(False)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm  # Generar datos de la distribuci\u00f3n muestral x = np.linspace(0 - 2.05 * 1, 0 + 2.05 * 1, 1000) y = norm.pdf(x*4, 0, 2)  # Crear la gr\u00e1fica fig, ax = plt.subplots() ax.plot(x, y, color='#009929') # Establecer el color de fondo ax.set_facecolor('#d4f8b7') # Pintar el fondo externo del gr\u00e1fico fig.patch.set_facecolor('#D4F8B7')  # Agregar informaci\u00f3n sobre el error est\u00e1ndar   ax.text(0.06, -0.11, r'-2.50',transform=ax.transAxes, fontsize=12, color='#000') ax.text(0.86, -0.11, r'2.50',transform=ax.transAxes, fontsize=12, color='#000') ax.text(0.02, 0.15, r'P(z \u2264 -2.50) = 0.0062', transform=ax.transAxes, fontsize=7.5, color='#000') ax.text(0.76, 0.15, r'P(z \u2265 2.96) = 0.0062', transform=ax.transAxes, fontsize=7.5, color='#000')  ax.text(0.10, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.098, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.096, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.094, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.092, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.090, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.088, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.086, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.084, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.082, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.080, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.078, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.076, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.074, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.072, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.070, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.068, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.066, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.064, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.062, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.060, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.058, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.056, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.054, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.052, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.050, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.048, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.046, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.044, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.042, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.040, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.038, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.036, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.034, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.032, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.030, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.028, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.026, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.024, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.022, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.020, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.028, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')  ax.text(0.10, -0.04, r'|',transform=ax.transAxes, fontsize=12, color='#000') ax.text(0.89, -0.04, r'|',transform=ax.transAxes, fontsize=12, color='#000')  ax.text(0.89, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.891, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.893, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.895, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.897, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.899, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.90, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.902, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.904, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.906, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.908, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.910, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.912, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.914, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.916, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.918, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.920, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.922, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.924, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.926, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.928, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.930, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.932, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.934, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.936, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.938, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.940, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.942, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.944, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.946, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.948, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.950, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.952, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.954, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.956, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.958, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.960, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.962, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.964, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929') ax.text(0.966, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.968, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929');ax.text(0.970, 0.01, r'|',transform=ax.transAxes, fontsize=12, color='#009929')  ax.grid(False) plt.show() In\u00a0[66]: Copied! <pre># importar la clase que permite ver videos\nfrom IPython.display import YouTubeVideo\n# crear una instancia del objeto YouTubeVideo\nyoutube_video=YouTubeVideo('EsTm9MGZacI')\n#mostrar el video de youtube\ndisplay(youtube_video)\n</pre> # importar la clase que permite ver videos from IPython.display import YouTubeVideo # crear una instancia del objeto YouTubeVideo youtube_video=YouTubeVideo('EsTm9MGZacI') #mostrar el video de youtube display(youtube_video) <p> Video: Prueba de hipotesis para la Proporcion Poblacional </p> In\u00a0[20]: Copied! <pre># importar la clase que permite ver videos\nfrom IPython.display import YouTubeVideo\n# crear una instancia del objeto YouTubeVideo\nyoutube_video=YouTubeVideo('hm6CkL-Y8vY')\n#mostrar el video de youtube\ndisplay(youtube_video)\n</pre> # importar la clase que permite ver videos from IPython.display import YouTubeVideo # crear una instancia del objeto YouTubeVideo youtube_video=YouTubeVideo('hm6CkL-Y8vY') #mostrar el video de youtube display(youtube_video) En esta secci\u00f3n se describe c\u00f3mo calcular la probabilidad de cometer un error tipo II en una prueba de hip\u00f3tesis para la media poblacional. Este procedimiento se ilustra usando el ejemplo del muestreo de aceptaci\u00f3n de lotes descrito en la secci\u00f3n 9.6. Las hip\u00f3tesis nula y alternativa para el n\u00famero medio de horas de vida \u00fatil de un pedido de bater\u00edas son: $(H_0: \\mu \\geq 120)$ y $(H_a: \\mu &lt; 120)$. Si $(H_0)$ es rechazada, la decisi\u00f3n ser\u00e1 devolver el producto al proveedor, debido a que la media del n\u00famero de horas de vida \u00fatil es menor que la especificada de 120 horas. Si $(H_0)$ no se rechaza, la decisi\u00f3n ser\u00e1 aceptar el pedido. Suponga que se usa el nivel de significancia $(\\alpha = 0.05)$ para realizar la prueba de hip\u00f3tesis.  <p>$$  z = \\frac{{\\bar{x} - \\mu_0}}{{\\frac{\\sigma}{\\sqrt{n}}}} = \\frac{{\\bar{x} - 120}}{{\\frac{\\sigma}{\\sqrt{n}}}}  $$</p> Con base en el m\u00e9todo del valor cr\u00edtico y $z_{0.05} = 1.645$, la regla de rechazo en esta prueba de cola inferior es:  $$Rechazar H_0   si z \\leq -1.645$$  Asuma que se seleccionar\u00e1 una muestra de 36 bater\u00edas y que por pruebas anteriores se puede considerar que se conoce la desviaci\u00f3n est\u00e1ndar poblacional y que su valor es $\\sigma = 12$ horas. La regla de rechazo indica que $H_0$ ser\u00e1 descartada si:  $$ z = \\frac{{\\bar{x} - 120}}{{\\frac{12}{\\sqrt{36}}}} \\leq -1.645 $$  Donde $\\bar{x}$ es la media de la muestra, $\\mu_0$ es la hip\u00f3tesis nula $\\mu_0 = 120$, $\\sigma$ es la desviaci\u00f3n est\u00e1ndar poblacional $\\sigma = 12$, y $n$ es el tama\u00f1o de la muestra $n = 36$.  Al despejar $x$ de la expresi\u00f3n anterior, tenemos que $H_0$ ser\u00e1 rechazada si:  $$x \\geq 120 + 1.645 \\cdot \\frac{12}{\\sqrt{36}} = 116.71$$ Rechazar $H_0$ siempre que $x \\geq 116.71$ significa que se tomar\u00e1 la decisi\u00f3n de aceptar el pedido siempre que $x \\leq 116.71$.  Con esta informaci\u00f3n, se pueden calcular las probabilidades asociadas con cometer un error tipo II. Primero, recuerde que se comete este error cuando la verdadera media del pedido es menor de 120 horas y se decide aceptar $H_0: \\mu \\geq 120$. Por tanto, para calcular la probabilidad de cometerlo, se debe elegir un valor de $\\mu$ menor que 120 horas.  Por ejemplo, suponga que la calidad del env\u00edo es pobre si la vida promedio de las bater\u00edas es $\\mu = 112$ horas. Si en realidad es verdad que $\\mu = 112$, \u00bfcu\u00e1l es la probabilidad de aceptar $H_0: \\mu \\geq 120$ y cometer as\u00ed un error tipo II? Observamos que es la probabilidad de que la media muestral $x$ sea mayor de 116.71 cuando $\\mu = 112$.  En la figura 9.8 se presenta la distribuci\u00f3n de muestreo de $x$ si la media es $\\mu = 112$. El \u00e1rea sombreada en la cola superior da la probabilidad de obtener $x \\geq 116.71$. Utilizando la distribuci\u00f3n normal est\u00e1ndar vemos que para $x \\geq 116.71$:  $$z = \\frac{x - \\mu}{\\frac{\\sigma}{\\sqrt{n}}} = \\frac{116.71 - 112}{\\frac{12}{\\sqrt{36}}} = 2.36 $$  La tabla de probabilidad normal est\u00e1ndar indica que para $z = 2.36$, el \u00e1rea en la cola superior es $1.0000 - 0.9909 = 0.0091$. Entonces, $0.0091$ es la probabilidad de cometer un error tipo II cuando $\\mu = 112$. Si usamos $\\beta$ para denotar la probabilidad de cometer este error, tenemos que si $\\mu = 112$, $\\beta = 0.0091$. Podemos concluir que si la media de la poblaci\u00f3n es $112$ horas, la probabilidad de incurrir en un error tipo II es solo $0.0091$.  FIGURA 9.8 Probabilidad de un error tipo II cuando $\\mu$=112 In\u00a0[52]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Par\u00e1metros\nn = 36\nalpha = 0.05\ncritical_value = norm.ppf(alpha)\n\n# Valor espec\u00edfico de \u03bc\nmu = 112\n\n# Calcular la media y la desviaci\u00f3n est\u00e1ndar de la distribuci\u00f3n de muestreo\nsampling_mean = mu\nsampling_std = 12 / np.sqrt(n)\n\n# Generar datos para la distribuci\u00f3n de muestreo\nx_values = np.linspace(mu - 3 * sampling_std, mu + 3 * sampling_std, 1000)\ny_values = norm.pdf(x_values, loc=sampling_mean, scale=sampling_std)\n\n# Calcular el valor z correspondiente a la zona de rechazo\nrejection_zone = x_values[x_values &gt;= mu + critical_value * sampling_std]\n\n# Crear la gr\u00e1fica\nfig, ax = plt.subplots()\nax.plot(x_values, y_values, label=f'Distribuci\u00f3n de muestreo de $x$, \u03bc = {mu}', color='#009929')\nax.fill_between(rejection_zone, norm.pdf(rejection_zone, loc=sampling_mean, scale=sampling_std), alpha=0.3, label=f'Zona de rechazo, \u03bc = {mu}', color='#D4F8B7')\n\n# Punto espec\u00edfico en la gr\u00e1fica\nplt.scatter([116.71], [0], color='#D4F8B7', marker='o', label='Punto espec\u00edfico (116.71, 0)')\n\n# Anotaciones\nplt.annotate(f'$\\mu = {mu}$', xy=(mu, 0), xytext=(mu, 0.02), ha='center', arrowprops=dict(facecolor='#D4F8B7', shrink=0.05))\n\n# Etiquetas y t\u00edtulo\nax.set_title('Distribuci\u00f3n de muestreo de $x$ con Zona de rechazo y Punto Espec\u00edfico', fontsize=14)\nax.set_xlabel('$x$', fontsize=12)\nax.set_ylabel('Densidad de probabilidad', fontsize=12)\nax.legend()\n\n# Cambiar el color de fondo del gr\u00e1fico\nax.set_facecolor('#d4f8b7')\n\n# Cambiar el color de fondo de la figura\nfig.patch.set_facecolor('#D4F8B7')\n\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm  # Par\u00e1metros n = 36 alpha = 0.05 critical_value = norm.ppf(alpha)  # Valor espec\u00edfico de \u03bc mu = 112  # Calcular la media y la desviaci\u00f3n est\u00e1ndar de la distribuci\u00f3n de muestreo sampling_mean = mu sampling_std = 12 / np.sqrt(n)  # Generar datos para la distribuci\u00f3n de muestreo x_values = np.linspace(mu - 3 * sampling_std, mu + 3 * sampling_std, 1000) y_values = norm.pdf(x_values, loc=sampling_mean, scale=sampling_std)  # Calcular el valor z correspondiente a la zona de rechazo rejection_zone = x_values[x_values &gt;= mu + critical_value * sampling_std]  # Crear la gr\u00e1fica fig, ax = plt.subplots() ax.plot(x_values, y_values, label=f'Distribuci\u00f3n de muestreo de $x$, \u03bc = {mu}', color='#009929') ax.fill_between(rejection_zone, norm.pdf(rejection_zone, loc=sampling_mean, scale=sampling_std), alpha=0.3, label=f'Zona de rechazo, \u03bc = {mu}', color='#D4F8B7')  # Punto espec\u00edfico en la gr\u00e1fica plt.scatter([116.71], [0], color='#D4F8B7', marker='o', label='Punto espec\u00edfico (116.71, 0)')  # Anotaciones plt.annotate(f'$\\mu = {mu}$', xy=(mu, 0), xytext=(mu, 0.02), ha='center', arrowprops=dict(facecolor='#D4F8B7', shrink=0.05))  # Etiquetas y t\u00edtulo ax.set_title('Distribuci\u00f3n de muestreo de $x$ con Zona de rechazo y Punto Espec\u00edfico', fontsize=14) ax.set_xlabel('$x$', fontsize=12) ax.set_ylabel('Densidad de probabilidad', fontsize=12) ax.legend()  # Cambiar el color de fondo del gr\u00e1fico ax.set_facecolor('#d4f8b7')  # Cambiar el color de fondo de la figura fig.patch.set_facecolor('#D4F8B7')  plt.show()  Considera realizar una prueba de hip\u00f3tesis para el valor de la media poblacional. El nivel de significancia elegido por el usuario determina la probabilidad de cometer un error tipo I en esta prueba. Al controlar el tama\u00f1o de la muestra, el usuario tambi\u00e9n controla la probabilidad de cometer un error tipo II. A continuaci\u00f3n se muestra c\u00f3mo determinar el tama\u00f1o de la muestra en la prueba de hip\u00f3tesis de cola inferior para la media poblacional:  $$H_0: \\mu \\leq \\mu_0$$ $$H_a: \\mu &gt; \\mu_0$$  En la Figura 9.8, la gr\u00e1fica superior presenta la distribuci\u00f3n de muestreo de $x$ cuando $H_0$ es verdadera y $\\mu &gt; \\mu_0$. En una prueba de cola inferior, el valor cr\u00edtico del estad\u00edstico de prueba se denota como \\(c\\). La l\u00ednea vertical, $c$, en la gr\u00e1fica superior de la figura, se\u00f1ala el valor correspondiente de $x$. Observa que si $H_0$ es rechazada cuando $x \\geq c$, la probabilidad de cometer un error tipo I ser\u00e1 $\\alpha$. Si $z_\\alpha$ representa el valor de $z$ que corresponde al \u00e1rea $\\alpha$ en la cola superior de la distribuci\u00f3n normal est\u00e1ndar, la siguiente f\u00f3rmula se emplea para calcular $c$:  $$c = \\mu_0 - z_\\alpha \\frac{\\sigma}{\\sqrt{n}}$$    Ahora, lo que buscamos es elegir un valor para \\(c\\), de manera que cuando $H_0$ sea rechazada y $H_a$ aceptada, la probabilidad de cometer un error tipo I sea igual a la probabilidad elegida para $\\alpha$, y la probabilidad de cometer un error tipo II sea igual al valor elegido para $\\beta$. Por consiguiente, con ambas ecuaciones (9.5) y (9.6) se debe obtener el mismo valor de $c$ y la ecuaci\u00f3n siguiente debe satisfacerse.  $$ \\frac{{\\mu_0 - \\mu_a}}{{\\frac{{z_\\alpha}}{{\\sqrt{n}}}}} = \\frac{{z_\\beta}}{{\\sqrt{n}}} $$  <p>Para determinar el tama\u00f1o de muestra que se necesita, primero se despeja $\\sqrt{n}$ como sigue.</p> <p>$$ \\sqrt{n} = \\frac{{(\\mu_0 - \\mu_a)}}{{(z_\\alpha - z_\\beta)}} \\cdot \\sigma $$</p> <p>y</p> <p>$$ n = \\left(\\frac{{z_\\alpha - z_\\beta \\cdot \\sigma}}{{\\mu_0 - \\mu_a}}\\right)^2 $$</p> Al elevar al cuadrado ambos lados de la expresi\u00f3n, obtenemos la f\u00f3rmula siguiente para el tama\u00f1o de la muestra necesario en una prueba de hip\u00f3tesis de una cola para la media poblacional.   Tama\u00f1o de la Muestra en una Prueba de Hip\u00f3tesis de una Cola para la Media Poblacional  <p>$$ n = \\left(\\frac{{(z_\\alpha - z_\\beta)^2 \\cdot \\sigma^2}}{{(\\mu_0 - \\mu_a)^2}}\\right) $$</p> <p>donde:</p> <ul> <li>$z_\\alpha$ = el valor de $z$ que proporciona un \u00e1rea de $\\alpha$ en la cola superior de la distribuci\u00f3n normal est\u00e1ndar.</li> <li>$z_\\beta$ = el valor de $z$ que proporciona un \u00e1rea de $\\beta$ en la cola superior de la distribuci\u00f3n normal est\u00e1ndar.</li> <li>$\\sigma$ = la desviaci\u00f3n est\u00e1ndar poblacional.</li> <li>$\\mu_0$ = el valor de la media poblacional en la hip\u00f3tesis nula.</li> <li>$\\mu_a$ = el valor de la media poblacional utilizado para el error tipo II.</li> </ul> Nota_: Para una prueba de hip\u00f3tesis de dos colas, en la ecuaci\u00f3n (9.7) se usa $z_{\\alpha/2}$ en lugar de $z_\\alpha$. Aunque la l\u00f3gica de la ecuaci\u00f3n (9.7) se desarroll\u00f3 para la prueba de hip\u00f3tesis mostrada en la figura 9.10, tambi\u00e9n es v\u00e1lida en cualquier prueba de hip\u00f3tesis de una cola para la media poblacional. En una prueba de hip\u00f3tesis de dos colas para la media poblacional se usa $z_{\\alpha/2}$ en lugar de $z_\\alpha$ en la misma ecuaci\u00f3n.  Volviendo al ejemplo del muestreo de aceptaci\u00f3n de lotes presentado en las secciones 9.6 y 9.7. Las especificaciones de dise\u00f1o para el embarque de las bater\u00edas indican una vida media \u00fatil de por lo menos 120 horas. Los pedidos se regresan si $H_0$ es rechazada: $\\mu \\geq 120$. Supongamos que el gerente de control de calidad establece las siguientes declaraciones acerca de las probabilidades admisibles de cometer los errores tipo I y tipo II:   Declaraci\u00f3n para el error tipo I: Si la vida media de las bater\u00edas del pedido es $\\mu \\leq 120$, estoy dispuesto a asumir el riesgo de que la probabilidad de rechazar el embarque sea $\\alpha = 0.05$.   Declaraci\u00f3n para el error tipo II: Si la vida media de las bater\u00edas del pedido es 5 horas por debajo de lo que indican las especificaciones (es decir, $\\mu = 115$, estoy dispuesto a asumir el riesgo de que la probabilidad de aceptar el embarque sea $\\beta = 0.10$.  Estas declaraciones se basan en el criterio del gerente. Otra persona podr\u00eda establecer diferentes restricciones para las probabilidades. Sin embargo, las declaraciones acerca de las probabilidades admisibles de ambos errores deben establecerse antes de determinar el tama\u00f1o de la muestra.  En el ejemplo, $\\alpha = 0.05$ y $\\beta = 0.10$. Mediante la distribuci\u00f3n de probabilidad normal est\u00e1ndar, se tiene $z_{0.05} = 1.645$ y $z_{0.10} = 1.28$.De acuerdo con lo dicho al especificar las probabilidades para los errores, observamos que $\\mu_0 = 120$ y $\\mu_a = 115$. Por ultimo, supusimos que las desviaciones estandar poblacional se conocia y era $\\alpha = 12$.   <p>$$ n = \\left(\\frac{{(1.645 + 1.28)^2 \\cdot (12)^2}}{{(120 - 115)^2}} = 49.3\\right) $$</p> Como las probabilidades de los dos errores tipo I y tipo II se han controlado usando $n = 50$, queda justificado que el gerente de control de calidad utilice las declaraciones $H_0$ es aceptada o $H_0$ es rechazada en esta prueba de hip\u00f3tesis. Las inferencias correspondientes se hacen teniendo probabilidades admisibles de cometer un error de cualquiera de ambos tipos.  Acerca de la relaci\u00f3n entre $\\alpha$, $\\beta$ y el tama\u00f1o $n$ de la muestra caben tres observaciones.  <ol> <li><p>Una vez que se tienen dos de estos tres valores, el tercero puede calcularse.</p> </li> <li><p>Dado un nivel de significancia $\\alpha$, aumentando el tama\u00f1o de la muestra se reduce $\\beta$.</p> </li> <li><p>Dado un tama\u00f1o de muestra, al reducirse $\\alpha$ aumenta $\\beta$ y al incrementarse $\\alpha$, disminuye $\\beta$.</p> </li> </ol> La tercera observaci\u00f3n debe tenerse en cuenta cuando no se controla la probabilidad de cometer un error tipo II. Dicha observaci\u00f3n indica que no se deben elegir niveles de significancia $\\alpha$ innecesariamente peque\u00f1os. Para un tama\u00f1o de muestra dado, elegir un nivel de significancia peque\u00f1o implica m\u00e1s riesgo de cometer un error tipo II. Personas con poca experiencia piensan que al realizar una prueba de hip\u00f3tesis es mejor usar siempre valores peque\u00f1os de $\\alpha$, lo cual es cierto si la \u00fanica preocupaci\u00f3n es cometer un error tipo I. Sin embargo, los valores peque\u00f1os de $\\alpha$ tienen la desventaja de incrementar la probabilidad de cometer un error tipo II.  Ejercicios M\u00e9todos Ejercicio 1   Para resolver este ejercicio, podemos utilizar la f\u00f3rmula para el tama\u00f1o de muestra en una prueba de hip\u00f3tesis de una cola para la media poblacional. La f\u00f3rmula es:  <p>$$ n = \\left(\\frac{(z_\\alpha + z_\\beta)^2 \\cdot \\sigma^2}{(\\mu_0 - \\mu_a)^2}\\right) $$</p> <p>donde:</p> <ul> <li>$ z_\\alpha $ es el valor cr\u00edtico correspondiente al nivel de significancia $ \\alpha $, y como $ \\alpha = 0.05 $, entonces $ z_\\alpha = -1.645 $ (ya que estamos en la cola inferior),</li> <li>$ z_\\beta $ es el valor cr\u00edtico correspondiente a la probabilidad de error tipo II $ \\beta $, y como $\\beta = 0.10 $, entonces $z_\\beta = -1.28 $ (seg\u00fan la informaci\u00f3n proporcionada),</li> <li>$ \\sigma $ es la desviaci\u00f3n est\u00e1ndar poblacional, que en este caso es $ \\sigma = 5 $,</li> <li>$ \\mu_0 $ es la media bajo la hip\u00f3tesis nula, que es $ \\mu_0 = 10 $,</li> <li>$ \\mu_a $ es la media bajo la hip\u00f3tesis alternativa, que es $ \\mu_a = 9 $.</li> </ul> <p>Sustituimos estos valores en la f\u00f3rmula:</p> <p>$$ n = \\left(\\frac{(-1.645 - (-1.28))^2 \\cdot 5^2}{(10 - 9)^2}\\right) $$</p> <p>Calculamos:</p> <p>$$ n = \\left(\\frac{(-0.365)^2 \\cdot 25}{1}\\right) $$</p> <p>$$ n = \\left(\\frac{0.133225 \\cdot 25}{1}\\right) $$</p> <p>$$ n = \\left(\\frac{3.330625}{1}\\right) $$</p> <p>$$ n = 3.330625 $$</p> <p>Redondeamos hacia arriba para obtener un n\u00famero entero, ya que el tama\u00f1o de la muestra debe ser un n\u00famero entero positivo:</p> <p>$$ n = 4 $$</p> <p>Por lo tanto, se recomienda un tama\u00f1o de muestra de 4 para reducir la probabilidad de error tipo II a $ \\beta = 0.10 $ si la media poblacional verdadera es $ \\mu = 9 $.</p> FIGURA 9.8 Ejercicio 1 In\u00a0[61]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Par\u00e1metros del problema\nalpha = 0.05\nbeta = 0.10\nsigma = 5\nmu_0 = 10\nmu_a = 9\n\n# Valores cr\u00edticos z_alpha y z_beta\nz_alpha = norm.ppf(alpha)\nz_beta = norm.ppf(beta)\n\n# Datos para la distribuci\u00f3n muestral bajo H0\nx_h0 = np.linspace(mu_0 - 4 * sigma, mu_0 + 4 * sigma, 1000)\ny_h0 = norm.pdf(x_h0, mu_0, sigma)\n\n# Datos para la distribuci\u00f3n muestral bajo Ha\nx_ha = np.linspace(mu_a - 4 * sigma, mu_a + 4 * sigma, 1000)\ny_ha = norm.pdf(x_ha, mu_a, sigma)\n\n# Crear la gr\u00e1fica\nfig, ax = plt.subplots()\nax.plot(x_h0, y_h0, label=r'$H_0: \\mu \\geq 10$', color='green')\nax.plot(x_ha, y_ha, label=r'$H_a: \\mu &lt; 10$', color='green')\n\n# Marcar los valores cr\u00edticos\n\nax.axvline(mu_a + z_beta * sigma, color='green', linestyle='--', label=r'$z_\\beta$')\n\n# Establecer el color de fondo\nax.set_facecolor('#d4f8b7')\n# Pintar el fondo externo del gr\u00e1fico\nfig.patch.set_facecolor('#D4F8B7')\nax.set_xlabel(r'$\\bar{x}$ (Media Muestral)', fontsize=12)\n\n# Agregar informaci\u00f3n sobre los valores cr\u00edticos\n\nax.text(0.76, 0.15, f'$z_{{\\\\beta}}$ = {z_beta:.2f}', transform=ax.transAxes, fontsize=9, color='green')\n\n# Sombrear las regiones cr\u00edticas\nax.fill_between(x_h0, y_h0, where=(x_h0 &lt;= mu_0 + z_alpha * sigma), color='green', alpha=0.3)\nax.fill_between(x_ha, y_ha, where=(x_ha &lt;= mu_a + z_beta * sigma), color='green', alpha=0.3)\n\n# Leyenda y etiquetas adicionales\nax.legend()\nax.grid(False)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm  # Par\u00e1metros del problema alpha = 0.05 beta = 0.10 sigma = 5 mu_0 = 10 mu_a = 9  # Valores cr\u00edticos z_alpha y z_beta z_alpha = norm.ppf(alpha) z_beta = norm.ppf(beta)  # Datos para la distribuci\u00f3n muestral bajo H0 x_h0 = np.linspace(mu_0 - 4 * sigma, mu_0 + 4 * sigma, 1000) y_h0 = norm.pdf(x_h0, mu_0, sigma)  # Datos para la distribuci\u00f3n muestral bajo Ha x_ha = np.linspace(mu_a - 4 * sigma, mu_a + 4 * sigma, 1000) y_ha = norm.pdf(x_ha, mu_a, sigma)  # Crear la gr\u00e1fica fig, ax = plt.subplots() ax.plot(x_h0, y_h0, label=r'$H_0: \\mu \\geq 10$', color='green') ax.plot(x_ha, y_ha, label=r'$H_a: \\mu &lt; 10$', color='green')  # Marcar los valores cr\u00edticos  ax.axvline(mu_a + z_beta * sigma, color='green', linestyle='--', label=r'$z_\\beta$')  # Establecer el color de fondo ax.set_facecolor('#d4f8b7') # Pintar el fondo externo del gr\u00e1fico fig.patch.set_facecolor('#D4F8B7') ax.set_xlabel(r'$\\bar{x}$ (Media Muestral)', fontsize=12)  # Agregar informaci\u00f3n sobre los valores cr\u00edticos  ax.text(0.76, 0.15, f'$z_{{\\\\beta}}$ = {z_beta:.2f}', transform=ax.transAxes, fontsize=9, color='green')  # Sombrear las regiones cr\u00edticas ax.fill_between(x_h0, y_h0, where=(x_h0 &lt;= mu_0 + z_alpha * sigma), color='green', alpha=0.3) ax.fill_between(x_ha, y_ha, where=(x_ha &lt;= mu_a + z_beta * sigma), color='green', alpha=0.3)  # Leyenda y etiquetas adicionales ax.legend() ax.grid(False) plt.show()  In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"capitulo9/#91-formulacion-de-la-hipotesis-nula-y-alternativa","title":"9.1 Formulaci\u00f3n de la hip\u00f3tesis nula y alternativa\u00b6","text":"En el proceso para formular las hip\u00f3tesis nula y alternativa, es importante estructurarla correctamente para obtener conclusiones \u00fatiles en las pruebas de hip\u00f3tesis.  Depende en gran medida del contexto de la situaci\u00f3n para formular la hipotesis,como tambien la  recolecci\u00f3n de una muestra y el uso de resultados muestrales son importantes todas las aplicaciones de prueba de hip\u00f3tesis para respaldar conclusiones. Al realizar la formulaci\u00f3n de las hip\u00f3tesis, es importante considerar preguntas clave, como el prop\u00f3sito de recolectar la muestra y las conclusiones esperadas. El proceso de identificar la hip\u00f3tesis nula y alternativa puede variar dependiendo de las situaciones, es m\u00e1s sencillo identificar la hip\u00f3tesis alternativa primero y luego desarrollar la nula, mientras que en otras situaciones ocurre lo contrario."},{"location":"capitulo9/#92-errores-tipo-i-y-tipo-ii","title":"9.2 Errores tipo I y tipo II\u00b6","text":"<p>Las hip\u00f3tesis nula y alternativa son afirmaciones opuestas acerca de la poblaci\u00f3n. Una de las dos, ya sea la hip\u00f3tesis nula $H_0$ o la alternativa $H_a$, es verdadera, pero no ambas. Lo ideal es que la prueba de hip\u00f3tesis lleve a la aceptaci\u00f3n de $H_0$ cuando sea verdadera y a su rechazo en $H_a$ sea verdadera,sin enbargo debe considerarse que existe la posibilidad de un error.</p>"},{"location":"capitulo9/#93-medida-poblacional-conocida","title":"9.3 Medida Poblacional: \u03c3 conocida\u00b6","text":"<p>En esta secci\u00f3n se muestra c\u00f3mo realizar una prueba de hip\u00f3tesis para la media poblacional en el caso en que \u03c3 es conocida.</p> <p>Los m\u00e9todos que se presentan dan resultados exactos si la poblaci\u00f3n de la que se selecciona la muestra tiene distribuci\u00f3n normal. En los casos en los que no sea razonable suponer que la poblaci\u00f3n tiene esta distribuci\u00f3n, se pueden aplicar estos m\u00e9todos siempre y cuando el tama\u00f1o de la muestra sea suficientemente grande.</p>"},{"location":"capitulo9/#94-medida-poblacional-desconocida","title":"9.4 Medida Poblacional: \u03c3 desconocida\u00b6","text":"En esta secci\u00f3n se describe c\u00f3mo realizar pruebas de hip\u00f3tesis para la media poblacional en el caso de $\\sigma$ desconocida. Esta situaci\u00f3n corresponde a cuando no se tiene una estimaci\u00f3n de la desviaci\u00f3n est\u00e1ndar poblacional antes de tomar la muestra. Esta \u00faltima se utiliza para obtener una estimaci\u00f3n tanto de $\\mu$ como de $\\sigma$. Por tanto, para realizar una prueba sobre la media poblacional en el caso en que $\\sigma$ no se conoce, la media muestral $\\bar{\\chi}$ se utiliza como estimaci\u00f3n de $\\mu$ y la desviaci\u00f3n est\u00e1ndar muestral $s$ como estimaci\u00f3n de $\\sigma$. En la Secci\u00f3n 8.2 se vio que una estimaci\u00f3n por intervalo de la media poblacional en el caso de $\\sigma$ desconocida se basa en una distribuci\u00f3n $t$. Para $\\sigma$ desconocida, el estad\u00edstico de prueba tiene distribuciones $t$ con $n-1$ grados de libertad."},{"location":"capitulo9/#95-proporcion-poblacional","title":"9.5 Proporcion Poblacional\u00b6","text":"En esta secci\u00f3n se describe c\u00f3mo realizar una prueba de hip\u00f3tesis para la proporci\u00f3n poblacional p si mediante p0 se denota el valor hipot\u00e9tico para la proporci\u00f3n poblacional. Las tres formas de una prueba de hip\u00f3tesis para la proporci\u00f3n poblacional son las siguientes:  $H_{0}:p \\geq p_0$ $H_{0}:p \\leq  p_0$ $H_{0}:p =  p_0$ $H_{a}:p &lt; p_0$ $H_{a}:p &gt; p_0$ $H_{a}:p \\neq p_0$  La primera forma es una prueba de cola inferior, la segunda es de cola superior y la tercera es de dos colas.  Las pruebas de hip\u00f3tesis para la proporci\u00f3n poblacional se basan en la diferencia entre la proporci\u00f3n muestral p y la proporci\u00f3n poblacional hipot\u00e9tica p0. Los m\u00e9todos son semejantes a los usados para las pruebas de hip\u00f3tesis de la media poblacional. La diferencia radica en que para calcular el estad\u00edstico de prueba se usa la proporci\u00f3n muestral y su error est\u00e1ndar. Para determinar si la hip\u00f3tesis nula es rechazada, se utiliza el m\u00e9todo del valor-p o el m\u00e9todo del valor cr\u00edtico."},{"location":"capitulo9/#a-estadistico-de-prueba-t","title":"a) Estad\u00edstico de Prueba ((t)):\u00b6","text":"<p>El estad\u00edstico de prueba (t) se calcula utilizando la f\u00f3rmula: $$ \\large z = \\frac{\\bar{p} - p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}} $$  Donde:</p> <ul> <li>$(\\bar{p})$ es la proporcion muestral,</li> <li>$(p_0)$ es la proporcion poblacional,</li> <li>$(n)$ es el tama\u00f1o de la muestra.</li> </ul> <p>En este caso: $$ \\large z = \\frac{0.175 - 0.20}{\\sqrt{\\frac{0.20(1-0.20)}{400}}} $$</p> <p>Calculamos (z) y obtenemos el valor del estad\u00edstico de prueba.</p>"},{"location":"capitulo9/#b-intervalo-para-el-valor-p","title":"b) Intervalo para el Valor-p:\u00b6","text":"<p>Usaremos la tabla de distribuci\u00f3n z para encontrar los valores cr\u00edticos $(z_{\\text{cr\u00edtico}})$ y $(\\alpha/2 = 0.025)$. Luego, calcularemos el intervalo para el valor-p.</p>"},{"location":"capitulo9/#c-conclusion-con-alpha-005","title":"c) Conclusi\u00f3n con $(\\alpha = 0.05)$:\u00b6","text":"<p>Si el valor-p es menor que $(\\alpha)$, rechazamos la hip\u00f3tesis nula $((H_0))$.</p>"},{"location":"capitulo9/#d-regla-de-rechazo-usando-el-valor-critico","title":"d) Regla de Rechazo usando el Valor Cr\u00edtico:\u00b6","text":"<p>Rechazamos $(H_0)$ si $(z &gt; z_{\\text{cr\u00edtico}})$.</p>"},{"location":"capitulo9/#resultados","title":"Resultados:\u00b6","text":"<p>a) Estad\u00edstico de Prueba ((z)): $$ \\large z = \\frac{0.175 - 0.20}{\\sqrt{\\frac{0.20(1-0.20)}{400}}} $$</p> <p>$$\\large z = -1.25 $$</p> <p>b) Intervalo para el Valor-p: Usando la tabla de distribuci\u00f3n normal z, encontramos $(z_{\\text{cr\u00edtico}})$ para $( \\alpha/2 = 0.025 )$.</p> <p>c) Con $\u03b1 = 0.05$</p> <p>El valor$-p=2(0.1056)=0.2112$ El valor$-p\\neq (0.05);H_0$ no es rechazada </p> <p>d) Regla de Rechazo usando el Valor Cr\u00edtico: Rechazamos $(H_0)$ si $(z &gt; z_{\\text{cr\u00edtico}})$.  Se concluye que no se rechaza la $(H_0)$ y se acepta la $(H_a)$</p>"},{"location":"capitulo9/#resultados","title":"Resultados:\u00b6","text":"<p>a) $\\bar {p}=0.68$</p> \\(\\large z = \\frac{\\bar{p} - p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}}= \\frac{0.68 - 0.75}{\\sqrt{\\frac{0.75(1-0.75)}{300}}}=-2.80\\)     El valor$-p=0.0026$     El valor$-p\\leq0.05; H_0$ es rechazada   b) $\\bar {p}=0.72$  \\(\\large z = \\frac{\\bar{p} - p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}}= \\frac{0.72 - 0.75}{\\sqrt{\\frac{0.75(1-0.75)}{300}}}=-1.20\\)     El valor$-p=0.1151$     El valor$-p\\leq0.05; H_0$ no es rechazada   c) $\\bar {p}=0.70$  \\(\\large z = \\frac{\\bar{p} - p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}}= \\frac{0.70 - 0.75}{\\sqrt{\\frac{0.75(1-0.75)}{300}}}=-2\\)     El valor$-p=0.0228$     El valor$-p\\leq0.05; H_0$ es rechazada   d) $\\bar {p}=0.77$  \\(\\large z = \\frac{\\bar{p} - p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}}= \\frac{0.77 - 0.75}{\\sqrt{\\frac{0.75(1-0.75)}{300}}}=0.8\\)     El valor$-p=0.7881$     El valor$-p\\leq0.05; H_0$ no es rechazada"},{"location":"capitulo9/#resultados","title":"Resultados:\u00b6","text":"<p>a) con el $64$%</p>  $H_0: p = 0.64$    $H_a: p \\neq 0.64 $ b) con $\\bar {p}=100$ $p_0=50$  \\(\\large \\bar {p} = \\frac{50}{100}=0.52\\)  \\(\\large z = \\frac{\\bar{p} - p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}}= \\frac{0.52 - 0.64}{\\sqrt{\\frac{0.64(1-0.64)}{100}}}=-2.50\\)     El valor$-p=2(0.0062)$  c) Con $\u03b1 = 0.05$ El valor$-p=2(0.0062)=0.0124$ El valor$-p\\neq (0.05);H_0$ no es rechazada  La proporcion difiere del $0.64$ reportado  d) S\u00ed, porque p  $0.52$ indica que muy pocos creen que la marca de supermercados sea tan buena como la marca nacional"},{"location":"capitulo9/#96-prueba-de-hipotesis-y-toma-de-decisiones","title":"9.6 Prueba de hipotesis y toma de decisiones\u00b6","text":"En las secciones previas de este cap\u00edtulo se estudiaron aplicaciones de pruebas de hip\u00f3tesis consideradas pruebas de signifi cancia. Despu\u00e9s de formular las hip\u00f3tesis nula y alternativa, se selecciona una muestra y se calcula el valor de un estad\u00edstico de prueba y el valor-$p$ asociado. Se compara, entonces, el valor-p con una probabilidad controlada de cometer un error tipo I, \u03b1,que se conoce como nivel de significancia para la prueba. Si el valor-$p$ \u2264 \u03b1, se concluye \u201crechazar $H_0$\u201d, y los resultados se declaran significantes; de otra manera, se concluye \u201cno rechazar $H_0$\u201d. Con una prueba de significancia se controla la probabilidad de cometer un error tipo I, pero no uno tipo II. Por tanto, se recomienda la conclusi\u00f3n \u201cno rechazar $H0$\u201d m\u00e1s que \u201caceptar $H_0$\u201d,por que esta \u00faltima nos expone al riesgo de cometer un error tipo II de aceptar $H_0$ cuando es falsa. Con la conclusi\u00f3n de \u201cno rechazar $H0$\u201d la evidencia estad\u00edstica se considera no concluyente y es por lo general un indicador para postergar una decisi\u00f3n o una acci\u00f3n hasta que se pueda realizar mayor investigaci\u00f3n y pruebas. Pero si el prop\u00f3sito de una prueba de hip\u00f3tesis es tomar cierta decisi\u00f3n cuando H0 es verdadera y una decisi\u00f3n diferente cuando Ha es verdadera, quien debe tomarla desear\u00e1, y en muchos casos tendr\u00e1 que actuar tanto en el caso en que la conclusi\u00f3n sea no rechazar $H_0$ como en el caso en que sea rechazar $H_0$. Si se da esta situaci\u00f3n, los expertos en estad\u00edstica recomiendan controlar la probabilidad de cometer un error tipo II. Con las probabilidades controladas de cometer tanto un error tipo I como tipo II, la conclusi\u00f3n de la prueba de hip\u00f3tesis es ya sea aceptar $H_0$ o rechazar $H_0$. En el primer caso, se concluye que $H_0$ es verdadera, mientras que en el segundo, que $H_a$ es verdadera. As\u00ed, se puede tomar una decisi\u00f3n y emprender una acci\u00f3n apropiada cuando se lleg\u00f3 a una conclusi\u00f3n. Una buena ilustraci\u00f3n de una prueba de hip\u00f3tesis para tomar decisiones es el muestreo de aceptaci\u00f3n de lotes, un tema que se discutir\u00e1 con m\u00e1s detalle en el cap\u00edtulo 20. Por ejemplo, un director de control de calidad tiene que decidir si acepta un pedido de bater\u00edas de un proveedor o si lo rechaza por ser de mala calidad. Suponga que las especifi caciones de dise\u00f1o indican que se requieren bater\u00edas con una vida \u00fatil promedio de por lo menos 120 horas. Para evaluar si el pedido recibido satisface esta especifi caci\u00f3n, se selecciona una muestra de 36 bater\u00edas y se prueban. Con base en esta muestra, se deber\u00e1 tomar la decisi\u00f3n de aceptar el pedido o devolverlo al proveedor por no tener la calidad adecuada. Sea \u03bc el n\u00famero medio de horas de vida \u00fatil que tienen las bater\u00edas del env\u00edo. Las hip\u00f3tesis nula y alternativa para la media poblacional se presentan a continuaci\u00f3n.      $H_0: \\mu \\geq 120$    $H_a: \\mu &lt; 120 $ <p>Si $H_0$ es rechazada, se concluye que la hip\u00f3tesis alternativa es verdadera. Esta conclusi\u00f3n indica que lo adecuado es devolver el pedido al proveedor. Pero si $H_0$ no es rechazada, la personaque toma la decisi\u00f3n deber\u00e1 determinar qu\u00e9 medidas tomar. As\u00ed, sin haber concluido que $H_0$ es verdadera, sino s\u00f3lo por no haberla rechazado, dicha persona tendr\u00e1 que aceptar el env\u00edo y considerarlo de la calidad adecuada. En tales situaciones es recomendable que el procedimiento de prueba de hip\u00f3tesis se ampl\u00ede para controlar la probabilidad de cometer un error tipo II. Como se tomar\u00e1 una decisi\u00f3n y alguna medida cuando H0 no sea rechazada, ser\u00e1 \u00fatil conocer la probabilidad de cometer un error de este tipo. En las secciones 9.7 y 9.8 se explica c\u00f3mo calcular la probabilidad de cometer un error tipo II y ajustar el tama\u00f1o de la muestra para controlar esta probabilidad.</p>"},{"location":"capitulo9/#97-calculo-de-la-probabilidad-de-los-errores-tipo-ii","title":"9.7 Calculo de la probabilidad de los errores tipo II \u00b6","text":""},{"location":"capitulo9/#98determinacion-del-tamano-de-la-muestra-en-una-prueba-de-hipotesis-para-la-media-poblacional","title":"9.8Determinaci\u00f3n del tama\u00f1o de la muestra en una prueba de hip\u00f3tesis para la media poblacional \u00b6","text":""}]}